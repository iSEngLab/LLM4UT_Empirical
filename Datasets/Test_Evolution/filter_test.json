[
    {
        "test_src": "@Test public void testMessageForConsole() { System.out.println(\"messageForConsole\"); String msg = \"\"; Boolean verbose = null; GUIBackend instance = new GUIBackend(); instance.messageForConsole(msg, verbose); fail(\"The test case is a prototype.\"); } ",
        "focal_tgt": "void messageForConsole(MessageType type, String msg); ",
        "focal_src": "void messageForConsole(String msg, Boolean verbose); ",
        "test_tgt": "@Test public void testMessageForConsole() { System.out.println(\"messageForConsole\"); String msg = \"\"; Boolean verbose = null; GUIBackend instance = new GUIBackend(); fail(\"The test case is a prototype.\"); } "
    },
    {
        "test_src": "@Test public void drop() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname, \"<dummy/>\", \"doc.xml\")); query(_DB_DROP.args(dbname)); query(_DB_EXISTS.args(dbname), \"false\"); error(_DB_DROP.args(dbname), Err.BXDB_OPEN); } ",
        "focal_tgt": "private Item drop(final QueryContext ctx)throws QueryException { checkCreate(ctx); final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))throw BXDB_NAME.get(info, name); if( ! ctx.context.globalopts.dbexists(name))throw BXDB_WHICH.get(info, name); ctx.updates.add(new DBDrop(name, info, ctx), ctx); return null; } ",
        "focal_src": "private Item drop(final QueryContext ctx)throws QueryException { ctx.updates.add(new DBDrop(checkData(ctx), info, ctx), ctx); return null; } ",
        "test_tgt": "@Test public void drop() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname, \"<dummy/>\", \"doc.xml\")); query(_DB_DROP.args(dbname)); query(_DB_EXISTS.args(dbname), \"false\"); error(_DB_DROP.args(dbname), Err.BXDB_WHICH); } "
    },
    {
        "test_src": "@Test public void testFetchFile()throws Exception { URL url = new URL(Settings.getString(Settings.KEYS.CVE_MODIFIED_20_URL)); File outputPath = new File(\"target/downloaded_cve.xml\"); Downloader.fetchFile(url, outputPath); } ",
        "focal_tgt": "public static void fetchFile(URL url, File outputPath)throws DownloadFailedException { fetchFile(url, outputPath, false); } ",
        "focal_src": "public static void fetchFile(URL url, File outputPath)throws DownloadFailedException { HttpURLConnection conn = null; try { conn = Downloader.getConnection(url); conn.setRequestProperty(\"Accept-Encoding\", \"gzip, deflate\"); conn.connect(); } catch(IOException ex) { try { if(conn != null) { conn.disconnect(); } } finally { conn = null; } throw new DownloadFailedException(\"Error downloading file.\", ex); } final String encoding = conn.getContentEncoding(); BufferedOutputStream writer = null; InputStream reader = null; try { if(encoding != null && \"gzip\".equalsIgnoreCase(encoding)) { reader = new GZIPInputStream(conn.getInputStream()); } else if(encoding != null && \"deflate\".equalsIgnoreCase(encoding)) { reader = new InflaterInputStream(conn.getInputStream()); } else { reader = conn.getInputStream(); } writer = new BufferedOutputStream(new FileOutputStream(outputPath)); final byte[]buffer = new byte[4096]; int bytesRead; while((bytesRead = reader.read(buffer)) > 0) { writer.write(buffer, 0, bytesRead); } } catch(Exception ex) { throw new DownloadFailedException(\"Error saving downloaded file.\", ex); } finally { if(writer != null) { try { writer.close(); } catch(Exception ex) { Logger.getLogger(Downloader.class.getName()).log(Level.FINEST, \"Error closing the writer in Downloader.\", ex); } } if(reader != null) { try { reader.close(); } catch(Exception ex) { Logger.getLogger(Downloader.class.getName()).log(Level.FINEST, \"Error closing the reader in Downloader.\", ex); } } try { conn.disconnect(); } finally { conn = null; } } } ",
        "test_tgt": "@Test public void testFetchFile()throws Exception { URL url = new URL(Settings.getString(Settings.KEYS.CPE_URL)); String outputPath = \"target/downloaded_cpe.xml\"; Downloader.fetchFile(url, outputPath, true); url = new URL(Settings.getString(Settings.KEYS.CVE_MODIFIED_20_URL)); outputPath = \"target/downloaded_cve.xml\"; Downloader.fetchFile(url, outputPath, false); } "
    },
    {
        "test_src": "@Test public void testReadPom_File()throws Exception { File file = BaseTest.getResourceAsFile(this, \"dwr-pom.xml\"); String expResult = \"Direct Web Remoting\"; Model result = PomUtils.readPom(file); assertEquals(expResult, result.getName()); file = BaseTest.getResourceAsFile(this, \"jmockit-1.26.pom\"); expResult = \"Main\"; result = PomUtils.readPom(file); assertEquals(expResult, result.getName()); } ",
        "focal_tgt": "public static Model readPom(File file)throws AnalysisException { try { final PomParser parser = new PomParser(); final Model model = parser.parse(file); if(model == null) { throw new AnalysisException(String.format(\"Unable to parse pom '%s'\", file.getPath())); } return model; } catch(AnalysisException ex) { throw ex; } catch(PomParseException ex) { LOGGER.warn(\"Unable to parse pom '{}'\", file.getPath()); LOGGER.debug(\"\", ex); throw new AnalysisException(ex); } catch(Throwable ex) { LOGGER.warn(\"Unexpected error during parsing of the pom '{}'\", file.getPath()); LOGGER.debug(\"\", ex); throw new AnalysisException(ex); } } ",
        "focal_src": "public static Model readPom(File file)throws AnalysisException { try { final PomParser parser = new PomParser(); final Model model = parser.parse(file); if(model == null) { throw new AnalysisException(String.format(\"Unable to parse pom '%s'\", file.getPath())); } return model; } catch(PomParseException ex) { LOGGER.warn(\"Unable to parse pom '{}'\", file.getPath()); LOGGER.debug(\"\", ex); throw new AnalysisException(ex); } catch(IOException ex) { LOGGER.warn(\"Unable to parse pom '{}'(IO Exception)\", file.getPath()); LOGGER.debug(\"\", ex); throw new AnalysisException(ex); } catch(Throwable ex) { LOGGER.warn(\"Unexpected error during parsing of the pom '{}'\", file.getPath()); LOGGER.debug(\"\", ex); throw new AnalysisException(ex); } } ",
        "test_tgt": "@Test public void testReadPom_File()throws Exception { File file = BaseTest.getResourceAsFile(this, \"dwr-pom.xml\"); String expResult = \"Direct Web Remoting\"; Model result = PomUtils.readPom(file); assertEquals(expResult, result.getName()); expResult = \"get ahead\"; assertEquals(expResult, result.getOrganization()); expResult = \"http://getahead.ltd.uk/dwr\"; assertEquals(expResult, result.getOrganizationUrl()); file = BaseTest.getResourceAsFile(this, \"jmockit-1.26.pom\"); expResult = \"Main\"; result = PomUtils.readPom(file); assertEquals(expResult, result.getName()); } "
    },
    {
        "test_src": "@Ignore@Test public void testUploadFile()throws Exception { Response response = uploadFile(\"/tmp/\", \"testUpload\", \".tmp\", \"Hello world\"); Assert.assertEquals(200, response.getStatus()); Response listdir = fileBrowserService.fileOps().listdir(\"/tmp\", httpHeaders, uriInfo); JSONArray statuses = (JSONArray)listdir.getEntity(); System.out.println(statuses.size()); Response response2 = fileBrowserService.download().browse(\"/tmp/testUpload.tmp\", false, httpHeaders, uriInfo); Assert.assertEquals(200, response2.getStatus()); } ",
        "focal_tgt": "@PUT@Consumes(MediaType.MULTIPART_FORM_DATA)@Produces(MediaType.APPLICATION_JSON)public Response uploadFile(@FormDataParam(\"file\")InputStream uploadedInputStream, @FormDataParam(\"file\")FormDataContentDisposition contentDisposition, @FormDataParam(\"path\")String path)throws Exception { if( ! path.endsWith(\"/\"))path = path + \"/\"; String filePath = path + contentDisposition.getFileName(); uploadFile(filePath, uploadedInputStream); return Response.ok(HdfsApi.fileStatusToJSON(getApi(context).getFileStatus(filePath))).build(); } ",
        "focal_src": "@PUT@Consumes(MediaType.MULTIPART_FORM_DATA)@Produces(MediaType.APPLICATION_JSON)public Response uploadFile(@FormDataParam(\"file\")InputStream uploadedInputStream, @FormDataParam(\"file\")FormDataContentDisposition contentDisposition, @FormDataParam(\"path\")String path)throws IOException, Exception { if( ! path.endsWith(\"/\"))path = path + \"/\"; String filePath = path + contentDisposition.getFileName(); uploadFile(filePath, uploadedInputStream); return Response.ok(HdfsApi.fileStatusToJSON(getApi(context).getFileStatus(filePath))).build(); } ",
        "test_tgt": "@Test public void testUploadFile()throws Exception { Response response = uploadFile(\"/tmp/\", \"testUpload\", \".tmp\", \"Hello world\"); Assert.assertEquals(200, response.getStatus()); Response listdir = fileBrowserService.fileOps().listdir(\"/tmp\"); JSONArray statuses = (JSONArray)listdir.getEntity(); System.out.println(statuses.size()); Response response2 = fileBrowserService.download().browse(\"/tmp/testUpload.tmp\", false, httpHeaders, uriInfo); Assert.assertEquals(200, response2.getStatus()); } "
    },
    {
        "test_src": "@Test public void getGroupFromGrpcClient()throws Exception { Configuration.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); Assert.assertEquals(\"\", SecurityUtils.getGroupFromGrpcClient()); Configuration.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); Configuration.set(PropertyKey.SECURITY_GROUP_MAPPING_CLASS, IdentityUserGroupsMapping.class.getName()); AuthenticatedClientUser.set(\"test_client_user\"); Assert.assertEquals(\"test_client_user\", SecurityUtils.getGroupFromGrpcClient()); } ",
        "focal_tgt": "public static String getGroupFromGrpcClient(AlluxioConfiguration conf) { try { User user = AuthenticatedClientUser.get(conf); if(user == null) { return \"\"; } return CommonUtils.getPrimaryGroupName(user.getName(), conf); } catch(IOException e) { return \"\"; } } ",
        "focal_src": "public static String getGroupFromGrpcClient() { try { User user = AuthenticatedClientUser.get(); if(user == null) { return \"\"; } return CommonUtils.getPrimaryGroupName(user.getName()); } catch(IOException e) { return \"\"; } } ",
        "test_tgt": "@Test public void getGroupFromGrpcClient()throws Exception { mConfiguration.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); Assert.assertEquals(\"\", SecurityUtils.getGroupFromGrpcClient(mConfiguration)); mConfiguration.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); mConfiguration.set(PropertyKey.SECURITY_GROUP_MAPPING_CLASS, IdentityUserGroupsMapping.class.getName()); AuthenticatedClientUser.set(\"test_client_user\"); Assert.assertEquals(\"test_client_user\", SecurityUtils.getGroupFromGrpcClient(mConfiguration)); } "
    },
    {
        "test_src": "@Test public void testPutBucketMaxAge() { Client client = new Client(); Response response; try { long maxAges[] = { Integer.MIN_VALUE, - 54321, - 1, 0, 1, 8, 1234567, Integer.MAX_VALUE }; for(int i = 0; i < maxAges.length; i ++ ) { long maxAge = maxAges[i]; System.out.println(\"maxAge=\" + maxAge); response = bucketManager.putBucketMaxAge(TestConfig.testBucket_z0, maxAge); Assert.assertEquals(200, response.statusCode); response = client.get(TestConfig.testUrl_z0); String value = respHeader(TestConfig.testUrl_z0, \"Cache-Control\"); System.out.println(value); } } catch(IOException e) { if(e instanceof QiniuException) { Assert.fail(((QiniuException)e).response.toString()); } } } ",
        "focal_tgt": "public Response putBucketMaxAge(String bucket, long maxAge)throws QiniuException { String url = String.format(\"%s/maxAge?bucket=%s&maxAge=%d\", configuration.ucHost(), bucket, maxAge); Response res = post(url, null); if( ! res.isOK()) { throw new QiniuException(res); } return res; } ",
        "focal_src": "public Response putBucketMaxAge(String bucket, long maxAge)throws QiniuException { String url = String.format(\"%s/maxAge?bucket=%s&maxAge=%d\", configuration.ucHost(), bucket, maxAge); Response res = post(url, null); if( ! res.isOK()) { throw new QiniuException(res); } res.close(); return res; } ",
        "test_tgt": "@Test public void testPutBucketMaxAge() { String[]buckets = new String[] { TestConfig.testBucket_z0, TestConfig.testBucket_na0 }; for(String bucket : buckets) { final long maxAges[] = { Integer.MIN_VALUE, - 54321, - 1, 0, 1, 8, 1234567, 11111111, Integer.MAX_VALUE }; try { for(long maxAge : maxAges) { Response response = bucketManager.putBucketMaxAge(bucket, maxAge); Assert.assertEquals(200, response.statusCode); BucketInfo bucketInfo = bucketManager.getBucketInfo(bucket); long expect = maxAge; long actual = bucketInfo.getMaxAge(); System.out.println(\"expect=\" + expect); System.out.println(\"actual=\" + actual); Assert.assertEquals(expect, actual); } } catch(QiniuException e) { Assert.fail(e.response.toString()); } } } "
    },
    {
        "test_src": "@Test public void testExecuteDMLUpdates()throws Exception { Method removeNagiosService = UpgradeCatalog200.class.getDeclaredMethod(\"removeNagiosService\"); Method updateHiveDatabaseType = UpgradeCatalog200.class.getDeclaredMethod(\"updateHiveDatabaseType\"); Method addNewConfigurationsFromXml = AbstractUpgradeCatalog.class.getDeclaredMethod(\"addNewConfigurationsFromXml\"); Method setSecurityType = UpgradeCatalog200.class.getDeclaredMethod(\"setSecurityType\"); UpgradeCatalog200 upgradeCatalog = createMockBuilder(UpgradeCatalog200.class).addMockedMethod(removeNagiosService).addMockedMethod(updateHiveDatabaseType).addMockedMethod(addNewConfigurationsFromXml).addMockedMethod(setSecurityType).createMock(); upgradeCatalog.removeNagiosService(); expectLastCall().once(); upgradeCatalog.addNewConfigurationsFromXml(); expectLastCall(); upgradeCatalog.updateHiveDatabaseType(); expectLastCall().once(); upgradeCatalog.setSecurityType(); expectLastCall().once(); replay(upgradeCatalog); upgradeCatalog.executeDMLUpdates(); verify(upgradeCatalog); } ",
        "focal_tgt": "@Override protected void executeDMLUpdates()throws AmbariException, SQLException { removeNagiosService(); addNewConfigurationsFromXml(); updateDfsClusterAdmintistratorsProperty(); updateHiveDatabaseType(); setSecurityType(); } ",
        "focal_src": "@Override protected void executeDMLUpdates()throws AmbariException, SQLException { removeNagiosService(); addNewConfigurationsFromXml(); updateHiveDatabaseType(); setSecurityType(); } ",
        "test_tgt": "@Test public void testExecuteDMLUpdates()throws Exception { Method removeNagiosService = UpgradeCatalog200.class.getDeclaredMethod(\"removeNagiosService\"); Method updateHiveDatabaseType = UpgradeCatalog200.class.getDeclaredMethod(\"updateHiveDatabaseType\"); Method addNewConfigurationsFromXml = AbstractUpgradeCatalog.class.getDeclaredMethod(\"addNewConfigurationsFromXml\"); Method setSecurityType = UpgradeCatalog200.class.getDeclaredMethod(\"setSecurityType\"); Method updateDfsClusterAdmintistratorsProperty = UpgradeCatalog200.class.getDeclaredMethod(\"updateDfsClusterAdmintistratorsProperty\"); UpgradeCatalog200 upgradeCatalog = createMockBuilder(UpgradeCatalog200.class).addMockedMethod(removeNagiosService).addMockedMethod(updateHiveDatabaseType).addMockedMethod(addNewConfigurationsFromXml).addMockedMethod(setSecurityType).addMockedMethod(updateDfsClusterAdmintistratorsProperty).createMock(); upgradeCatalog.removeNagiosService(); expectLastCall().once(); upgradeCatalog.addNewConfigurationsFromXml(); expectLastCall(); upgradeCatalog.updateDfsClusterAdmintistratorsProperty(); expectLastCall(); upgradeCatalog.updateHiveDatabaseType(); expectLastCall().once(); upgradeCatalog.setSecurityType(); expectLastCall().once(); replay(upgradeCatalog); upgradeCatalog.executeDMLUpdates(); verify(upgradeCatalog); } "
    },
    {
        "test_src": "@Test public void testNotifyCreditAvailable()throws Exception { final NetworkBufferPool networkBufferPool = new NetworkBufferPool(10, 32); final SingleInputGate inputGate = createSingleInputGate(); final RemoteInputChannel inputChannel1 = createRemoteInputChannel(inputGate); final RemoteInputChannel inputChannel2 = createRemoteInputChannel(inputGate); inputGate.setInputChannel(inputChannel1.getPartitionId().getPartitionId(), inputChannel1); inputGate.setInputChannel(inputChannel2.getPartitionId().getPartitionId(), inputChannel2); try { final BufferPool bufferPool = networkBufferPool.createBufferPool(6, 6); inputGate.setBufferPool(bufferPool); final int numExclusiveBuffers = 2; inputGate.assignExclusiveSegments(networkBufferPool, numExclusiveBuffers); final CreditBasedClientHandler handler = new CreditBasedClientHandler(); final EmbeddedChannel channel = new EmbeddedChannel(handler); inputChannel1.requestSubpartition(0); inputChannel2.requestSubpartition(0); handler.addInputChannel(inputChannel1); handler.addInputChannel(inputChannel2); final BufferResponse bufferResponse1 = createBufferResponse(TestBufferFactory.createBuffer(32), 0, inputChannel1.getInputChannelId(), 1); final BufferResponse bufferResponse2 = createBufferResponse(TestBufferFactory.createBuffer(32), 0, inputChannel2.getInputChannelId(), 1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse2); handler.notifyCreditAvailable(inputChannel1); handler.notifyCreditAvailable(inputChannel2); assertEquals(2, inputChannel1.getUnannouncedCredit()); assertEquals(2, inputChannel2.getUnannouncedCredit()); channel.runPendingTasks(); assertTrue(channel.isWritable()); Object readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(2, ((AddCredit)readFromOutbound).credit); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(2, ((AddCredit)readFromOutbound).credit); assertNull(channel.readOutbound()); final int highWaterMark = channel.config().getWriteBufferHighWaterMark(); ByteBuf channelBlockingBuffer = Unpooled.buffer(highWaterMark).writerIndex(highWaterMark); channel.write(channelBlockingBuffer); final BufferResponse bufferResponse3 = createBufferResponse(TestBufferFactory.createBuffer(32), 1, inputChannel1.getInputChannelId(), 1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse3); handler.notifyCreditAvailable(inputChannel1); assertEquals(1, inputChannel1.getUnannouncedCredit()); assertEquals(0, inputChannel2.getUnannouncedCredit()); channel.runPendingTasks(); assertFalse(channel.isWritable()); assertNull(channel.readOutbound()); channel.flush(); assertSame(channelBlockingBuffer, channel.readOutbound()); assertTrue(channel.isWritable()); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(1, ((AddCredit)readFromOutbound).credit); assertEquals(0, inputChannel1.getUnannouncedCredit()); assertEquals(0, inputChannel2.getUnannouncedCredit()); assertNull(channel.readOutbound()); } finally { inputGate.releaseAllResources(); networkBufferPool.destroyAllBufferPools(); networkBufferPool.destroy(); } } ",
        "focal_tgt": "void notifyCreditAvailable(final RemoteInputChannel inputChannel) { ctx.executor().execute(new Runnable() { @Override public void run() { ctx.pipeline().fireUserEventTriggered(inputChannel); } }); } ",
        "focal_src": "void notifyCreditAvailable(RemoteInputChannel inputChannel) { } ",
        "test_tgt": "@Test public void testNotifyCreditAvailable()throws Exception { final PartitionRequestClientHandler handler = new PartitionRequestClientHandler(); final EmbeddedChannel channel = new EmbeddedChannel(handler); final PartitionRequestClient client = new PartitionRequestClient(channel, handler, mock(ConnectionID.class), mock(PartitionRequestClientFactory.class)); final NetworkBufferPool networkBufferPool = new NetworkBufferPool(10, 32); final SingleInputGate inputGate = createSingleInputGate(); final RemoteInputChannel inputChannel1 = createRemoteInputChannel(inputGate, client); final RemoteInputChannel inputChannel2 = createRemoteInputChannel(inputGate, client); try { final BufferPool bufferPool = networkBufferPool.createBufferPool(6, 6); inputGate.setBufferPool(bufferPool); final int numExclusiveBuffers = 2; inputGate.assignExclusiveSegments(networkBufferPool, numExclusiveBuffers); inputChannel1.requestSubpartition(0); inputChannel2.requestSubpartition(0); assertTrue(channel.isWritable()); Object readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(PartitionRequest.class)); assertEquals(inputChannel1.getInputChannelId(), ((PartitionRequest)readFromOutbound).receiverId); assertEquals(2, ((PartitionRequest)readFromOutbound).credit); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(PartitionRequest.class)); assertEquals(inputChannel2.getInputChannelId(), ((PartitionRequest)readFromOutbound).receiverId); assertEquals(2, ((PartitionRequest)readFromOutbound).credit); final BufferResponse bufferResponse1 = createBufferResponse(TestBufferFactory.createBuffer(32), 0, inputChannel1.getInputChannelId(), 1); final BufferResponse bufferResponse2 = createBufferResponse(TestBufferFactory.createBuffer(32), 0, inputChannel2.getInputChannelId(), 1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse2); assertEquals(2, inputChannel1.getUnannouncedCredit()); assertEquals(2, inputChannel2.getUnannouncedCredit()); channel.runPendingTasks(); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(inputChannel1.getInputChannelId(), ((AddCredit)readFromOutbound).receiverId); assertEquals(2, ((AddCredit)readFromOutbound).credit); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(inputChannel2.getInputChannelId(), ((AddCredit)readFromOutbound).receiverId); assertEquals(2, ((AddCredit)readFromOutbound).credit); assertNull(channel.readOutbound()); ByteBuf channelBlockingBuffer = blockChannel(channel); final BufferResponse bufferResponse3 = createBufferResponse(TestBufferFactory.createBuffer(32), 1, inputChannel1.getInputChannelId(), 1); handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse3); assertEquals(1, inputChannel1.getUnannouncedCredit()); assertEquals(0, inputChannel2.getUnannouncedCredit()); channel.runPendingTasks(); assertFalse(channel.isWritable()); assertNull(channel.readOutbound()); channel.flush(); assertSame(channelBlockingBuffer, channel.readOutbound()); assertTrue(channel.isWritable()); readFromOutbound = channel.readOutbound(); assertThat(readFromOutbound, instanceOf(AddCredit.class)); assertEquals(1, ((AddCredit)readFromOutbound).credit); assertEquals(0, inputChannel1.getUnannouncedCredit()); assertEquals(0, inputChannel2.getUnannouncedCredit()); assertNull(channel.readOutbound()); } finally { inputGate.releaseAllResources(); networkBufferPool.destroyAllBufferPools(); networkBufferPool.destroy(); } } "
    },
    {
        "test_src": "@Test public void doDynamic()throws Exception { r.createWebClient().goTo(\"plugin/credentials/images/24x24/credentials.png\", \"image/png\"); r.createWebClient().assertFails(\"plugin/credentials/images/%2E%2E/images/24x24/credentials.png\", HttpServletResponse.SC_INTERNAL_SERVER_ERROR); r.createWebClient().assertFails(\"plugin/credentials/images/%252E%252E/images/24x24/credentials.png\", HttpServletResponse.SC_NOT_FOUND); r.createWebClient().assertFails(\"plugin/credentials/images/%25252E%25252E/images/24x24/credentials.png\", HttpServletResponse.SC_NOT_FOUND); } ",
        "focal_tgt": "public void doDynamic(StaplerRequest req, StaplerResponse rsp)throws IOException, ServletException { String path = req.getRestOfPath(); if(path.startsWith(\"/META-INF/\") || path.startsWith(\"/WEB-INF/\")) { throw HttpResponses.notFound(); } if(path.length() == 0)path = \"/\"; String requestPath = req.getRequestURI().substring(req.getContextPath().length()); boolean staticLink = requestPath.startsWith(\"/static/\"); long expires = staticLink ? TimeUnit2.DAYS.toMillis(365) : - 1; try { rsp.serveLocalizedFile(req, wrapper.baseResourceURL.toURI().resolve(new URI(null, '.' + path, null)).toURL(), expires); } catch(URISyntaxException x) { throw new IOException(x); } } ",
        "focal_src": "public void doDynamic(StaplerRequest req, StaplerResponse rsp)throws IOException, ServletException { String path = req.getRestOfPath(); if(path.length() == 0)path = \"/\"; String requestPath = req.getRequestURI().substring(req.getContextPath().length()); boolean staticLink = requestPath.startsWith(\"/static/\"); long expires = staticLink ? TimeUnit2.DAYS.toMillis(365) : - 1; try { rsp.serveLocalizedFile(req, wrapper.baseResourceURL.toURI().resolve(new URI(null, '.' + path, null)).toURL(), expires); } catch(URISyntaxException x) { throw new IOException(x); } } ",
        "test_tgt": "@Test public void doDynamic()throws Exception { r.createWebClient().goTo(\"plugin/credentials/images/24x24/credentials.png\", \"image/png\"); r.createWebClient().assertFails(\"plugin/credentials/images/%2E%2E/images/24x24/credentials.png\", HttpServletResponse.SC_INTERNAL_SERVER_ERROR); r.createWebClient().assertFails(\"plugin/credentials/images/%252E%252E/images/24x24/credentials.png\", HttpServletResponse.SC_NOT_FOUND); r.createWebClient().assertFails(\"plugin/credentials/images/%25252E%25252E/images/24x24/credentials.png\", HttpServletResponse.SC_NOT_FOUND); r.createWebClient().assertFails(\"plugin/credentials/WEB-INF/licenses.xml\", HttpServletResponse.SC_NOT_FOUND); r.createWebClient().assertFails(\"plugin/credentials/META-INF/MANIFEST.MF\", HttpServletResponse.SC_NOT_FOUND); } "
    },
    {
        "test_src": "@Test public void error()throws Exception { try(final QueryProcessor qp = new QueryProcessor(_HTTP_SEND_REQUEST.args(\"<http:request method='get'/>\", RESTURL + \"unknown\") + \"[1]/@status/data()\", ctx)) { assertEquals(\"404\", qp.value().serialize().toString()); } } ",
        "focal_tgt": "private static void error(final String query, final QNm error, final QueryError qe) { final String q = \"import module namespace geo='http://expath.org/ns/geo'; \" + \"declare namespace gml='http://www.opengis.net/gml';\" + query; try(QueryProcessor qp = new QueryProcessor(q, context)) { final String res = qp.value().serialize().toString().replaceAll(\"(\\\\r|\\\\n) *\", \"\"); fail(\"Query did not fail:\\n\" + query + \"\\n[E] \" + error + \"...\\n[F] \" + res); } catch(final QueryException ex) { final QueryError qerr = ex.error(); if(qe != null && qerr != null && qe != qerr) { Util.stack(ex); final StringBuilder sb = new StringBuilder(\"Wrong error code:\\n[E] \"); fail(sb.append(qe.name()).append(\"\\n[F] \").append(qerr.name()).toString()); } else if( ! ex.qname().eq(error)) { Util.stack(ex); final StringBuilder sb = new StringBuilder(\"Wrong error code:\\n[E] \"); fail(sb.append(error).append(\"\\n[F] \").append(ex.qname()).toString()); } } catch(final Exception ex) { Util.stack(ex); fail(ex.toString()); } } ",
        "focal_src": "private static void error(final String query, final QNm error, final QueryError qe) { final String q = \"import module namespace geo='http://expath.org/ns/geo'; \" + \"declare namespace gml='http://www.opengis.net/gml';\" + query; try(final QueryProcessor qp = new QueryProcessor(q, context)) { final String res = qp.value().serialize().toString().replaceAll(\"(\\\\r|\\\\n) *\", \"\"); fail(\"Query did not fail:\\n\" + query + \"\\n[E] \" + error + \"...\\n[F] \" + res); } catch(final QueryException ex) { final QueryError qerr = ex.error(); if(qe != null && qerr != null && qe != qerr) { Util.stack(ex); final StringBuilder sb = new StringBuilder(\"Wrong error code:\\n[E] \"); fail(sb.append(qe.name()).append(\"\\n[F] \").append(qerr.name()).toString()); } else if( ! ex.qname().eq(error)) { Util.stack(ex); final StringBuilder sb = new StringBuilder(\"Wrong error code:\\n[E] \"); fail(sb.append(error).append(\"\\n[F] \").append(ex.qname()).toString()); } } catch(final Exception ex) { Util.stack(ex); fail(ex.toString()); } } ",
        "test_tgt": "@Test public void error()throws Exception { try(QueryProcessor qp = new QueryProcessor(_HTTP_SEND_REQUEST.args(\"<http:request method='get'/>\", RESTURL + \"unknown\") + \"[1]/@status/data()\", ctx)) { assertEquals(\"404\", qp.value().serialize().toString()); } } "
    },
    {
        "test_src": "@Test public void testAcceptOffers() { new Context() { { new Within(duration(\"10 seconds\")) { @Override protected void run() { try { MesosWorkerStore.Worker worker1 = MesosWorkerStore.Worker.newTask(task1); when(workerStore.getFrameworkID()).thenReturn(Option.apply(framework1)); when(workerStore.recoverWorkers()).thenReturn(singletonList(worker1)); initialize(); assertThat(resourceManagerInstance.workersInNew, hasEntry(extractResourceID(task1), worker1)); resourceManagerInstance.taskRouter.expectMsgClass(TaskMonitor.TaskGoalStateUpdated.class); register(Collections. < ResourceID > emptyList()); Protos.TaskInfo task1info = Protos.TaskInfo.newBuilder().setTaskId(task1).setName(\"\").setSlaveId(slave1).build(); AcceptOffers msg = new AcceptOffers(slave1host, singletonList(offer1), singletonList(launch(task1info))); resourceManager.tell(msg); MesosWorkerStore.Worker worker1launched = worker1.launchTask(slave1, slave1host); verify(workerStore).putWorker(worker1launched); assertThat(resourceManagerInstance.workersInNew.entrySet(), empty()); assertThat(resourceManagerInstance.workersInLaunch, hasEntry(extractResourceID(task1), worker1launched)); resourceManagerInstance.taskRouter.expectMsg(new TaskMonitor.TaskGoalStateUpdated(extractGoalState(worker1launched))); verify(schedulerDriver).acceptOffers(msg.offerIds(), msg.operations(), msg.filters()); } catch(Exception ex) { throw new RuntimeException(ex); } } }; } }; } ",
        "focal_tgt": "private void acceptOffers(AcceptOffers msg) { try { List < TaskMonitor.TaskGoalStateUpdated > toMonitor = new ArrayList < > (msg.operations().size()); for(Protos.Offer.Operation op : msg.operations()) { if(op.getType() != Protos.Offer.Operation.Type.LAUNCH) { continue; } for(Protos.TaskInfo info : op.getLaunch().getTaskInfosList()) { MesosWorkerStore.Worker worker = workersInNew.remove(extractResourceID(info.getTaskId())); assert(worker != null); worker = worker.launchWorker(info.getSlaveId(), msg.hostname()); workerStore.putWorker(worker); workersInLaunch.put(extractResourceID(worker.taskID()), worker); LOG.info(\"Launching Mesos task {} on host {}.\", worker.taskID().getValue(), worker.hostname().get()); toMonitor.add(new TaskMonitor.TaskGoalStateUpdated(extractGoalState(worker))); } } for(TaskMonitor.TaskGoalStateUpdated update : toMonitor) { taskRouter.tell(update, self()); } schedulerDriver.acceptOffers(msg.offerIds(), msg.operations(), msg.filters()); } catch(Exception ex) { fatalError(\"unable to accept offers\", ex); } } ",
        "focal_src": "private void acceptOffers(AcceptOffers msg) { try { List < TaskMonitor.TaskGoalStateUpdated > toMonitor = new ArrayList < > (msg.operations().size()); for(Protos.Offer.Operation op : msg.operations()) { if(op.getType() != Protos.Offer.Operation.Type.LAUNCH) { continue; } for(Protos.TaskInfo info : op.getLaunch().getTaskInfosList()) { MesosWorkerStore.Worker worker = workersInNew.remove(extractResourceID(info.getTaskId())); assert(worker != null); worker = worker.launchTask(info.getSlaveId(), msg.hostname()); workerStore.putWorker(worker); workersInLaunch.put(extractResourceID(worker.taskID()), worker); LOG.info(\"Launching Mesos task {} on host {}.\", worker.taskID().getValue(), worker.hostname().get()); toMonitor.add(new TaskMonitor.TaskGoalStateUpdated(extractGoalState(worker))); } } for(TaskMonitor.TaskGoalStateUpdated update : toMonitor) { taskRouter.tell(update, self()); } schedulerDriver.acceptOffers(msg.offerIds(), msg.operations(), msg.filters()); } catch(Exception ex) { fatalError(\"unable to accept offers\", ex); } } ",
        "test_tgt": "@Test public void testAcceptOffers() { new Context() { { new Within(duration(\"10 seconds\")) { @Override protected void run() { try { MesosWorkerStore.Worker worker1 = MesosWorkerStore.Worker.newWorker(task1); when(workerStore.getFrameworkID()).thenReturn(Option.apply(framework1)); when(workerStore.recoverWorkers()).thenReturn(singletonList(worker1)); initialize(); assertThat(resourceManagerInstance.workersInNew, hasEntry(extractResourceID(task1), worker1)); resourceManagerInstance.taskRouter.expectMsgClass(TaskMonitor.TaskGoalStateUpdated.class); register(Collections. < ResourceID > emptyList()); Protos.TaskInfo task1info = Protos.TaskInfo.newBuilder().setTaskId(task1).setName(\"\").setSlaveId(slave1).build(); AcceptOffers msg = new AcceptOffers(slave1host, singletonList(offer1), singletonList(launch(task1info))); resourceManager.tell(msg); MesosWorkerStore.Worker worker1launched = worker1.launchWorker(slave1, slave1host); verify(workerStore).putWorker(worker1launched); assertThat(resourceManagerInstance.workersInNew.entrySet(), empty()); assertThat(resourceManagerInstance.workersInLaunch, hasEntry(extractResourceID(task1), worker1launched)); resourceManagerInstance.taskRouter.expectMsg(new TaskMonitor.TaskGoalStateUpdated(extractGoalState(worker1launched))); verify(schedulerDriver).acceptOffers(msg.offerIds(), msg.operations(), msg.filters()); } catch(Exception ex) { throw new RuntimeException(ex); } } }; } }; } "
    },
    {
        "test_src": "@Test public void testIsExported() { Module thisModule = this.getClass().getModule(); Module baseModule = Object.class.getModule(); assertFalse(thisModule.isNamed()); assertTrue(thisModule.isExported(\"\", null)); assertTrue(thisModule.isExported(\"\", thisModule)); assertTrue(thisModule.isExported(\"\", baseModule)); assertTrue(thisModule.isExported(\"p\", null)); assertTrue(thisModule.isExported(\"p\", thisModule)); assertTrue(thisModule.isExported(\"p\", baseModule)); assertTrue(baseModule.isNamed()); assertTrue(baseModule.isExported(\"java.lang\", null)); assertTrue(baseModule.isExported(\"java.lang\", thisModule)); assertFalse(baseModule.isExported(\"sun.reflect\", null)); assertFalse(baseModule.isExported(\"sun.reflect\", thisModule)); } ",
        "focal_tgt": "public boolean isExported(String pn, Module target) { Objects.requireNonNull(pn); Objects.requireNonNull(target); return implIsExported(pn, target); } ",
        "focal_src": "public boolean isExported(String pn, Module target) { Objects.requireNonNull(pn); if( ! isNamed())return true; Map < String, Map < Module, Boolean > > exports = this.exports; Map < Module, Boolean > targets = exports.get(pn); if(targets != null) { if(targets.isEmpty() || targets.containsKey(target))return true; } return false; } ",
        "test_tgt": "@Test public void testIsExported() { Module thisModule = this.getClass().getModule(); Module baseModule = Object.class.getModule(); assertFalse(thisModule.isNamed()); assertTrue(thisModule.isExported(\"\")); assertTrue(thisModule.isExported(\"\", thisModule)); assertTrue(thisModule.isExported(\"\", baseModule)); assertTrue(thisModule.isExported(\"p\")); assertTrue(thisModule.isExported(\"p\", thisModule)); assertTrue(thisModule.isExported(\"p\", baseModule)); assertTrue(baseModule.isNamed()); assertTrue(baseModule.isExported(\"java.lang\")); assertTrue(baseModule.isExported(\"java.lang\", thisModule)); assertFalse(baseModule.isExported(\"sun.reflect\")); assertFalse(baseModule.isExported(\"sun.reflect\", thisModule)); } "
    },
    {
        "test_src": "@Test public void localEndpoint_provisionsOnce()throws Exception { List < Callable < Endpoint > > tasks = new ArrayList < > (); for(int i = 0; i < 10; i ++ ) { tasks.add(() -> platform.localEndpoint()); } ExecutorService executor = Executors.newFixedThreadPool(tasks.size()); List < Future < Endpoint > > futures = executor.invokeAll(tasks); Set < Object > results = Sets.newIdentityHashSet(); for(Future < Endpoint > future : futures) { results.add(future.get()); } assertThat(results).hasSize(1); executor.shutdownNow(); } ",
        "focal_tgt": "@Deprecated public Builder localEndpoint(Endpoint localEndpoint) { delegate.endpoint(localEndpoint); return this; } ",
        "focal_src": "public Builder localEndpoint(Endpoint localEndpoint) { delegate.localEndpoint(localEndpoint); return this; } ",
        "test_tgt": "@Test public void localEndpoint_provisionsOnce()throws Exception { List < Callable < Endpoint > > tasks = new ArrayList < > (); for(int i = 0; i < 10; i ++ ) { tasks.add(() -> platform.endpoint()); } ExecutorService executor = Executors.newFixedThreadPool(tasks.size()); List < Future < Endpoint > > futures = executor.invokeAll(tasks); Set < Object > results = Sets.newIdentityHashSet(); for(Future < Endpoint > future : futures) { results.add(future.get()); } assertThat(results).hasSize(1); executor.shutdownNow(); } "
    },
    {
        "test_src": "@Test public void testWhenComplete() { Assert.assertFalse(Task.supplyAsync(() -> { throw new IllegalStateException(); }).whenComplete(exception -> { Assert.assertTrue(exception instanceof IllegalStateException); }).test()); } ",
        "focal_tgt": "public final Task < Void > whenComplete(Executor executor, FinalizedCallback action) { return new Task < Void > () { { setSignificance(TaskSignificance.MODERATE); }@Override public void execute()throws Exception { if(isDependentsSucceeded() != (Task.this.getException() == null))throw new AssertionError(\"When dependents succeeded, Task.exception must be nonnull.\"); action.execute(Task.this.getException()); if( ! isDependentsSucceeded()) { setSignificance(TaskSignificance.MINOR); if(Task.this.getException() == null)throw new CancellationException(); else throw Task.this.getException(); } }@Override public Collection < Task < ? > > getDependents() { return Collections.singleton(Task.this); }@Override public boolean isRelyingOnDependents() { return false; } }.setExecutor(executor).setName(getCaller()); } ",
        "focal_src": "public final Task < Void > whenComplete(Scheduler scheduler, FinalizedCallback action) { return new Task < Void > () { { setSignificance(TaskSignificance.MODERATE); }@Override public Scheduler getScheduler() { return scheduler; }@Override public void execute()throws Exception { if(isDependentsSucceeded() != (Task.this.getException() == null))throw new AssertionError(\"When dependents succeeded, Task.exception must be nonnull.\"); action.execute(Task.this.getException()); if( ! isDependentsSucceeded()) { setSignificance(TaskSignificance.MINOR); if(Task.this.getException() == null)throw new CancellationException(); else throw Task.this.getException(); } }@Override public Collection < Task < ? > > getDependents() { return Collections.singleton(Task.this); }@Override public boolean isRelyingOnDependents() { return false; } }.setName(getCaller()); } ",
        "test_tgt": "@Test public void testWhenComplete() { boolean result = Task.supplyAsync(() -> { throw new IllegalStateException(); }).whenComplete(exception -> { Assert.assertTrue(exception instanceof IllegalStateException); }).test(); Assert.assertFalse(\"Task should fail at this case\", result); } "
    },
    {
        "test_src": "@Test public void test_unpackInMemory_zip() { ArrayByteSource source1 = ArrayByteSource.ofUtf8(\"Hello World\").withFileName(\"TestFile1.txt\"); ArrayByteSource source2 = ArrayByteSource.ofUtf8(\"Hello Planet\").withFileName(\"TestFile2.txt\"); ArrayByteSource zipFile = ZipUtils.zipInMemory(ImmutableList.of(source1, source2)).withFileName(\"Test.zip\"); ZipUtils.unpackInMemory(zipFile, (name, extracted) -> { if(name.equals(\"TestFile1.txt\")) { assertThat(extracted.getFileName()).hasValue(\"TestFile1.txt\"); assertThat(extracted.readUtf8()).isEqualTo(\"Hello World\"); } else if(name.equals(\"TestFile2.txt\")) { assertThat(extracted.getFileName()).hasValue(\"TestFile2.txt\"); assertThat(extracted.readUtf8()).isEqualTo(\"Hello Planet\"); } else { fail(\"Unexpected file: \" + name); } }); } ",
        "focal_tgt": "public static void unpackInMemory(BeanByteSource source, BiConsumer < String, ArrayByteSource > consumer) { String fileName = source.getFileName().orElse(\"\"); if(suffixMatches(fileName, \".zip\")) { unzipInMemory(source, consumer); } else if(suffixMatches(fileName, \".gz\")) { ungzInMemory(source, fileName, consumer); } else if(suffixMatches(fileName, \".base64\")) { try(InputStream in = Base64.getDecoder().wrap(source.openBufferedStream())) { String shortFileName = fileName.substring(0, fileName.length() - 7); ArrayByteSource unbase64 = ArrayByteSource.from(in).withFileName(shortFileName); consumer.accept(shortFileName, unbase64); } catch(IOException ex) { throw new UncheckedIOException(ex); } } else { consumer.accept(fileName, source.load()); } } ",
        "focal_src": "public static void unpackInMemory(BeanByteSource source, BiConsumer < String, ArrayByteSource > consumer) { String fileName = source.getFileName().orElse(\"\"); if(suffixMatches(fileName, \".zip\")) { unzip(source, consumer); } else if(suffixMatches(fileName, \".gz\")) { ungz(source, fileName, consumer); } else if(suffixMatches(fileName, \".base64\")) { try(InputStream in = Base64.getDecoder().wrap(source.openBufferedStream())) { String shortFileName = fileName.substring(0, fileName.length() - 7); ArrayByteSource unbase64 = ArrayByteSource.from(in).withFileName(shortFileName); consumer.accept(shortFileName, unbase64); } catch(IOException ex) { throw new UncheckedIOException(ex); } } else { consumer.accept(fileName, source.load()); } } ",
        "test_tgt": "@Test public void test_unpackInMemory_zip() { ArrayByteSource source1 = ArrayByteSource.ofUtf8(\"Hello World\").withFileName(\"TestFile1.txt\"); ArrayByteSource source2 = ArrayByteSource.ofUtf8(\"Hello Planet\").withFileName(\"TestFile2.txt\"); ArrayByteSource zipFile = ZipUtils.zipInMemory(ImmutableList.of(source1, source2)).withFileName(\"Test.zip\"); AtomicInteger counter = new AtomicInteger(); ZipUtils.unpackInMemory(zipFile, (name, extracted) -> { counter.incrementAndGet(); if(name.equals(\"TestFile1.txt\")) { assertThat(extracted.getFileName()).hasValue(\"TestFile1.txt\"); assertThat(extracted.readUtf8()).isEqualTo(\"Hello World\"); } else if(name.equals(\"TestFile2.txt\")) { assertThat(extracted.getFileName()).hasValue(\"TestFile2.txt\"); assertThat(extracted.readUtf8()).isEqualTo(\"Hello Planet\"); } else { fail(\"Unexpected file: \" + name); } }); assertThat(counter).hasValue(2); } "
    },
    {
        "test_src": "@Test public void testEM() { System.out.println(\"EM\"); double[]data = new double[2000]; GaussianDistribution gaussian = new GaussianDistribution( - 2.0, 1.0); for(int i = 0; i < 500; i ++ )data[i] = gaussian.rand(); ExponentialDistribution exponential = new ExponentialDistribution(0.8); for(int i = 500; i < 1000; i ++ )data[i] = exponential.rand(); GammaDistribution gamma = new GammaDistribution(2.0, 3.0); for(int i = 1000; i < 2000; i ++ )data[i] = gamma.rand(); List < Mixture.Component > m = new ArrayList < > (); Mixture.Component c = new Mixture.Component(); c.priori = 0.25; c.distribution = new GaussianDistribution(0.0, 1.0); m.add(c); c = new Mixture.Component(); c.priori = 0.25; c.distribution = new ExponentialDistribution(1.0); m.add(c); c = new Mixture.Component(); c.priori = 0.5; c.distribution = new GammaDistribution(1.0, 2.0); m.add(c); ExponentialFamilyMixture mixture = new ExponentialFamilyMixture(m, data); System.out.println(mixture); } ",
        "focal_tgt": "public static DiscreteExponentialFamilyMixture fit(int[]x, Component ... components) { return fit(x, components, 0.0, 500, 1E-4); } ",
        "focal_src": "double EM(List < Component > mixture, int[]x, double gamma) { return EM(mixture, x, gamma, Integer.MAX_VALUE); } ",
        "test_tgt": "@Test public void testEM() { System.out.println(\"EM\"); MathEx.setSeed(19650218); double[]data = new double[2000]; GaussianDistribution gaussian = new GaussianDistribution( - 2.0, 1.0); for(int i = 0; i < 500; i ++ )data[i] = gaussian.rand(); ExponentialDistribution exponential = new ExponentialDistribution(0.8); for(int i = 500; i < 1000; i ++ )data[i] = exponential.rand(); GammaDistribution gamma = new GammaDistribution(2.0, 3.0); for(int i = 1000; i < 2000; i ++ )data[i] = gamma.rand(); ExponentialFamilyMixture mixture = ExponentialFamilyMixture.fit(data, new Mixture.Component(0.25, new GaussianDistribution(0.0, 1.0)), new Mixture.Component(0.25, new ExponentialDistribution(1.0)), new Mixture.Component(0.5, new GammaDistribution(1.0, 2.0))); System.out.println(mixture); } "
    },
    {
        "test_src": "@Test public void testEncodeDecode4()throws Exception { Message m1 = Utils2.createDummyMessage(); Random rnd = new Random(42); m1.setType(Message.Type.DENIED); m1.setHintSign(); KeyPairGenerator gen = KeyPairGenerator.getInstance(\"DSA\"); KeyPair pair1 = gen.generateKeyPair(); m1.setPublicKeyAndSign(pair1); Map < Number640, Data > dataMap = new HashMap < Number640, Data > (); dataMap.put(new Number640(rnd), new Data(new byte[] { 3, 4, 5 }, true, true)); dataMap.put(new Number640(rnd), new Data(new byte[] { 4, 5, 6 }, true, true)); dataMap.put(new Number640(rnd), new Data(new byte[] { 5, 6, 7 }, true, true)); m1.setDataMap(new DataMap(dataMap)); Map < Number640, Number160 > keysMap = new HashMap < Number640, Number160 > (); keysMap.put(new Number640(rnd), new Number160(rnd)); keysMap.put(new Number640(rnd), new Number160(rnd)); keysMap.put(new Number640(rnd), new Number160(rnd)); m1.setKeyMap480(new KeyMap640(keysMap)); Message m2 = encodeDecode(m1); Assert.assertEquals(true, m2.getPublicKey() != null); Assert.assertEquals(false, m2.getDataMap(0) == null); Assert.assertEquals(false, m2.getKeyMap640(0) == null); compareMessage(m1, m2); } ",
        "focal_tgt": "private Message encodeDecode(final Message m1)throws Exception { AtomicReference < Message > m2 = new AtomicReference < Message > (); TomP2POutbound encoder = new TomP2POutbound(true, new DefaultSignatureFactory()); CompositeByteBuf buf = Unpooled.compositeBuffer(); ChannelHandlerContext ctx = mockChannelHandlerContext(buf, m2); encoder.write(ctx, m1, null); Decoder decoder = new Decoder(new DefaultSignatureFactory()); decoder.decode(ctx, buf, m1.getRecipient().createSocketTCP(), m1.getSender().createSocketTCP()); return decoder.message(); } ",
        "focal_src": "private Message encodeDecode(final Message m1)throws Exception { AtomicReference < Message > m2 = new AtomicReference < Message > (); TomP2POutbound encoder = new TomP2POutbound(true, new DefaultSignatureFactory()); CompositeByteBuf buf = Unpooled.compositeBuffer(); ChannelHandlerContext ctx = mockChannelHandlerContext(buf, m2); encoder.write(ctx, m1, null); TomP2PDecoder decoder = new TomP2PDecoder(new DefaultSignatureFactory()); decoder.decode(ctx, buf, m1.getRecipient().createSocketTCP(), m1.getSender().createSocketTCP()); return decoder.message(); } ",
        "test_tgt": "@Test public void testEncodeDecode4()throws Exception { Message m1 = Utils2.createDummyMessage(); Random rnd = new Random(42); m1.setType(Message.Type.DENIED); m1.setHintSign(); KeyPairGenerator gen = KeyPairGenerator.getInstance(\"DSA\"); KeyPair pair1 = gen.generateKeyPair(); m1.setPublicKeyAndSign(pair1); Map < Number640, Data > dataMap = new HashMap < Number640, Data > (); dataMap.put(new Number640(rnd), new Data(new byte[] { 3, 4, 5 }, true, true)); dataMap.put(new Number640(rnd), new Data(new byte[] { 4, 5, 6 }, true, true)); dataMap.put(new Number640(rnd), new Data(new byte[] { 5, 6, 7 }, true, true)); m1.setDataMap(new DataMap(dataMap)); Map < Number640, Number160 > keysMap = new HashMap < Number640, Number160 > (); keysMap.put(new Number640(rnd), new Number160(rnd)); keysMap.put(new Number640(rnd), new Number160(rnd)); keysMap.put(new Number640(rnd), new Number160(rnd)); m1.setKeyMap480(new KeyMap640(keysMap)); Message m2 = encodeDecode(m1); Assert.assertEquals(true, m2.getPublicKey() != null); Assert.assertEquals(false, m2.getDataMap(0) == null); Assert.assertEquals(false, m2.getKeyMap640(0) == null); compareMessage(m1, m2); } "
    },
    {
        "test_src": "@Test public void getMinValue() { assertEquals(Integer.MIN_VALUE, Numbers.getMinValue(Integer.class)); assertEquals(Integer.MIN_VALUE, Numbers.getMinValue(int.class)); assertEquals(Long.MIN_VALUE, Numbers.getMinValue(Long.class)); assertEquals(Long.MIN_VALUE, Numbers.getMinValue(long.class)); assertEquals(Float.MIN_VALUE, Numbers.getMinValue(Float.class)); assertEquals(Float.MIN_VALUE, Numbers.getMinValue(float.class)); assertEquals(Double.MIN_VALUE, Numbers.getMinValue(Double.class)); assertEquals(Double.MIN_VALUE, Numbers.getMinValue(double.class)); assertEquals(Byte.MIN_VALUE, Numbers.getMinValue(Byte.class)); assertEquals(Byte.MIN_VALUE, Numbers.getMinValue(byte.class)); assertEquals(Short.MIN_VALUE, Numbers.getMinValue(Short.class)); assertEquals(Short.MIN_VALUE, Numbers.getMinValue(short.class)); assertEquals(Double.MIN_VALUE, Numbers.getMinValue(BigDecimal.class)); assertEquals(Double.MIN_VALUE, Numbers.getMinValue(BigInteger.class)); assertEquals(Double.MIN_VALUE, Numbers.getMinValue(null)); } ",
        "focal_tgt": "public static Number getMinValue(Class < ? extends Number > numberType) { Number result; if(Integer.class == numberType || int.class == numberType) { result = Integer.MIN_VALUE; } else if(Long.class == numberType || long.class == numberType) { result = Long.MIN_VALUE; } else if(Float.class == numberType || float.class == numberType) { result = - Float.MAX_VALUE; } else if(Double.class == numberType || double.class == numberType) { result = - Double.MAX_VALUE; } else if(Byte.class == numberType || byte.class == numberType) { result = Byte.MIN_VALUE; } else if(Short.class == numberType || short.class == numberType) { result = Short.MIN_VALUE; } else { LOG.debug(\"'{}' has no minimum value. Falling back to Double.\", numberType); result = - Double.MAX_VALUE; } return result; } ",
        "focal_src": "public static Number getMinValue(Class < ? extends Number > numberType) { Number result; if(Integer.class == numberType || int.class == numberType) { result = Integer.MIN_VALUE; } else if(Long.class == numberType || long.class == numberType) { result = Long.MIN_VALUE; } else if(Float.class == numberType || float.class == numberType) { result = Float.MIN_VALUE; } else if(Double.class == numberType || double.class == numberType) { result = Double.MIN_VALUE; } else if(Byte.class == numberType || byte.class == numberType) { result = Byte.MIN_VALUE; } else if(Short.class == numberType || short.class == numberType) { result = Short.MIN_VALUE; } else { LOG.debug(\"'{}' has no minimum value. Falling back to Double.MIN_VALUE.\", numberType); result = Double.MIN_VALUE; } return result; } ",
        "test_tgt": "@Test public void getMinValue() { assertEquals(Integer.MIN_VALUE, Numbers.getMinValue(Integer.class)); assertEquals(Integer.MIN_VALUE, Numbers.getMinValue(int.class)); assertEquals(Long.MIN_VALUE, Numbers.getMinValue(Long.class)); assertEquals(Long.MIN_VALUE, Numbers.getMinValue(long.class)); assertEquals( - Float.MAX_VALUE, Numbers.getMinValue(Float.class)); assertEquals( - Float.MAX_VALUE, Numbers.getMinValue(float.class)); assertEquals( - Double.MAX_VALUE, Numbers.getMinValue(Double.class)); assertEquals( - Double.MAX_VALUE, Numbers.getMinValue(double.class)); assertEquals(Byte.MIN_VALUE, Numbers.getMinValue(Byte.class)); assertEquals(Byte.MIN_VALUE, Numbers.getMinValue(byte.class)); assertEquals(Short.MIN_VALUE, Numbers.getMinValue(Short.class)); assertEquals(Short.MIN_VALUE, Numbers.getMinValue(short.class)); assertEquals( - Double.MAX_VALUE, Numbers.getMinValue(BigDecimal.class)); assertEquals( - Double.MAX_VALUE, Numbers.getMinValue(BigInteger.class)); assertEquals( - Double.MAX_VALUE, Numbers.getMinValue(null)); } "
    },
    {
        "test_src": "@SuppressWarnings(\"ThrowableNotThrown\")@Test public void testClose()throws Exception { final Connection conn; try(Connection conn0 = DriverManager.getConnection(urlWithAffinityAwarenessProp)) { conn = conn0; assert conn != null; assert ! conn.isClosed(); } assert conn.isClosed(); assert ! conn.isValid(2) : \"Connection must be closed\"; assertThrows(log, new Callable < Object > () { @Override public Object call()throws Exception { conn.isValid( - 2); return null; } }, SQLException.class, \"Invalid timeout\"); } ",
        "focal_tgt": "@Override public void close()throws SQLException { if(isClosed())return; closed = true; maintenanceExecutor.shutdown(); if(streamState != null) { streamState.close(); streamState = null; } synchronized(stmtsMux) { stmts.clear(); } SQLException err = null; if(partitionAwareness) { for(JdbcThinTcpIo clioIo : ios.values())clioIo.close(); ios.clear(); } else { if(singleIo != null)singleIo.close(); } if(err != null)throw err; } ",
        "focal_src": "@Override public void close()throws SQLException { if(isClosed())return; closed = true; maintenanceExecutor.shutdown(); if(streamState != null) { streamState.close(); streamState = null; } synchronized(stmtsMux) { stmts.clear(); } SQLException err = null; if(affinityAwareness) { for(JdbcThinTcpIo clioIo : ios.values())clioIo.close(); ios.clear(); } else { if(singleIo != null)singleIo.close(); } if(err != null)throw err; } ",
        "test_tgt": "@SuppressWarnings(\"ThrowableNotThrown\")@Test public void testClose()throws Exception { final Connection conn; try(Connection conn0 = DriverManager.getConnection(urlWithPartitionAwarenessProp)) { conn = conn0; assert conn != null; assert ! conn.isClosed(); } assert conn.isClosed(); assert ! conn.isValid(2) : \"Connection must be closed\"; assertThrows(log, new Callable < Object > () { @Override public Object call()throws Exception { conn.isValid( - 2); return null; } }, SQLException.class, \"Invalid timeout\"); } "
    },
    {
        "test_src": "@Test public void compareTo_shouldFailIfStartOrEndDateDoNotMatch()throws Exception { CohortMembership firstMembership = new CohortMembership(4); CohortMembership secondMembership = new CohortMembership(4); Cohort cohort = new Cohort(1); firstMembership.setCohort(cohort); secondMembership.setCohort(cohort); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); Date oneDate = dateFormat.parse(\"2017-01-01 00:00:00\"); Date twoDate = dateFormat.parse(\"2017-01-31 00:00:00\"); firstMembership.setStartDate(oneDate); secondMembership.setStartDate(twoDate); assertEquals(firstMembership.compareTo(secondMembership), - 1); secondMembership.setStartDate(oneDate); secondMembership.setEndDate(twoDate); assertEquals(firstMembership.compareTo(secondMembership), - 1); } ",
        "focal_tgt": "@Override public int compareTo(CohortMembership o) { if((this.getVoided() && ! o.getVoided()) || ( ! this.isActive() && o.isActive())) { return 1; } else if(( ! this.getVoided() && o.getVoided()) || (this.isActive() && ! o.isActive())) { return - 1; } int ret = OpenmrsUtil.compareWithNullAsGreatest(this.getCohort().getCohortId(), o.getCohort().getCohortId()); if(ret != 0) { return ret; } ret = this.getPatientId().compareTo(o.getPatientId()); if(ret != 0) { return ret; } ret = OpenmrsUtil.compareWithNullAsEarliest(this.getEndDate(), o.getEndDate()); if(ret != 0) { return ret; } return OpenmrsUtil.compare(this.getStartDate(), o.getStartDate()); } ",
        "focal_src": "@Override public int compareTo(CohortMembership o) { int ret = - 1; if(Objects.equals(this.getPatientId(), o.getPatientId()) && Objects.equals(this.getCohort().getCohortId(), o.getCohort().getCohortId()) && this.getStartDate().equals(o.getStartDate()) && OpenmrsUtil.compare(this.getStartDate(), o.getStartDate()) == 0 && ((this.getEndDate() != null && o.getEndDate() != null && OpenmrsUtil.compare(this.getEndDate(), o.getEndDate()) == 0) || (this.getEndDate() == null && o.getEndDate() == null))) { ret = 0; } else if(this.isActive() && ! o.isActive()) { ret = - 1; } else if( ! this.isActive() && o.isActive()) { ret = 1; } return ret; } ",
        "test_tgt": "@Test public void compareTo_shouldFailIfStartOrEndDateDoNotMatch()throws Exception { CohortMembership firstMembership = new CohortMembership(4); CohortMembership secondMembership = new CohortMembership(4); Cohort cohort = new Cohort(1); firstMembership.setCohort(cohort); secondMembership.setCohort(cohort); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); Date oneDate = dateFormat.parse(\"2017-01-01 00:00:00\"); Date twoDate = dateFormat.parse(\"2017-01-31 00:00:00\"); firstMembership.setStartDate(oneDate); secondMembership.setStartDate(twoDate); assertEquals( - 1, firstMembership.compareTo(secondMembership)); secondMembership.setStartDate(oneDate); secondMembership.setEndDate(twoDate); assertEquals( - 1, firstMembership.compareTo(secondMembership)); } "
    },
    {
        "test_src": "@Test public void testSizeGt() { assertTrue(instance.sizeGt(\"id\", 3).getQueryCriterions().contains(new SizeGtCriterion(\"id\", 3))); } ",
        "focal_tgt": "public CriteriaQuery sizeGt(String propName, int size) { criterion = criterion.and(criterionBuilder.sizeGt(propName, size)); return this; } ",
        "focal_src": "public CriteriaQuery sizeGt(String propName, int size) { addCriterion(criterionBuilder.sizeGt(propName, size)); return this; } ",
        "test_tgt": "@Test public void testSizeGt() { assertEquals(new SizeGtCriterion(\"id\", 3), instance.sizeGt(\"id\", 3).getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void testAssignLeaseToClientWithRequestIP()throws Exception { dhcpPool = initPool(IPv4Address.of(\"10.0.0.1\"), 1); Optional < IPv4Address > lease = dhcpPool.assignLeaseToClientWithRequestIP(IPv4Address.of(\"10.0.0.1\"), MacAddress.of(1), 60); assertTrue(lease.isPresent()); assertEquals(IPv4Address.of(\"10.0.0.1\"), lease.get()); } ",
        "focal_tgt": "Optional < IPv4Address > assignLeaseToClientWithRequestIP(IPv4Address requestIP, MacAddress clientMac, long timeSec, boolean dynamicLease); ",
        "focal_src": "Optional < IPv4Address > assignLeaseToClientWithRequestIP(IPv4Address requestIP, MacAddress clientMac, long timeSec); ",
        "test_tgt": "@Test public void testAssignLeaseToClientWithRequestIP()throws Exception { dhcpPool = initPool(IPv4Address.of(\"10.0.0.1\"), 1); Optional < IPv4Address > lease = dhcpPool.assignLeaseToClientWithRequestIP(IPv4Address.of(\"10.0.0.1\"), MacAddress.of(1), 60, false); assertTrue(lease.isPresent()); assertEquals(IPv4Address.of(\"10.0.0.1\"), lease.get()); } "
    },
    {
        "test_src": "@Test public void testFind() { List < User > list = toList(new User(\"\", 23), new User(\"\", 24), new User(\"\", 25), new User(\"\", 24)); LOGGER.debug(JsonUtil.format(CollectionsUtil.find(list, \"name\", \"\"))); } ",
        "focal_tgt": "public static < O, V > O find(Iterable < O > iterable, String propertyName, V propertyValue) { return find(iterable, BeanPredicateUtil. < O, V > equalPredicate(propertyName, propertyValue)); } ",
        "focal_src": "public static < O, V > O find(Iterable < O > iterable, String propertyName, V propertyValue) { return find(iterable, new BeanPropertyValueEqualsPredicate < O > (propertyName, propertyValue)); } ",
        "test_tgt": "@Test public void testFind() { User zhangfei = new User(\"\", 23); User guanyu24 = new User(\"\", 24); User liubei = new User(\"\", 25); User guanyu50 = new User(\"\", 50); List < User > list = toList(zhangfei, guanyu24, liubei, guanyu50); assertThat(CollectionsUtil.find(list, \"name\", \"\"), is(equalTo(guanyu24))); } "
    },
    {
        "test_src": "@Test public void testConcat()throws Exception { final String context = \"Concat\"; try(Storage s = createStorage()) { s.initialize(0); HashMap < String, ByteArrayOutputStream > appendData = populate(s, context); val firstSegmentName = getSegmentName(0, context); val firstSegmentHandle = s.openWrite(firstSegmentName).join(); AtomicLong firstSegmentLength = new AtomicLong(s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join().getLength()); assertThrows(\"concat() did not throw for non-existent target segment name.\", () -> s.concat(createHandle(\"foo1\", false), 0, firstSegmentHandle, TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); assertThrows(\"concat() did not throw for invalid source StreamSegment name.\", () -> s.concat(firstSegmentHandle, firstSegmentLength.get(), createHandle(\"foo2\", false), TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); ArrayList < String > concatOrder = new ArrayList < > (); concatOrder.add(firstSegmentName); for(String sourceSegment : appendData.keySet()) { if(sourceSegment.equals(firstSegmentName)) { continue; } val sourceWriteHandle = s.openWrite(sourceSegment).join(); assertThrows(\"Concat allowed when source segment is not sealed.\", () -> s.concat(firstSegmentHandle, firstSegmentLength.get(), sourceWriteHandle, TIMEOUT), ex -> ex instanceof IllegalStateException); s.seal(sourceWriteHandle, TIMEOUT).join(); SegmentProperties preConcatTargetProps = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); SegmentProperties sourceProps = s.getStreamSegmentInfo(sourceSegment, TIMEOUT).join(); s.concat(firstSegmentHandle, firstSegmentLength.get(), sourceWriteHandle, TIMEOUT).join(); concatOrder.add(sourceSegment); SegmentProperties postConcatTargetProps = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); Assert.assertFalse(\"concat() did not delete source segment\", s.exists(sourceSegment, TIMEOUT).join()); Assert.assertEquals(\"Unexpected target StreamSegment.length after concatenation.\", preConcatTargetProps.getLength() + sourceProps.getLength(), postConcatTargetProps.getLength()); firstSegmentLength.set(postConcatTargetProps.getLength()); } SegmentProperties segmentProperties = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); byte[]readBuffer = new byte[(int)segmentProperties.getLength()]; int bytesRead = s.read(firstSegmentHandle, 0, readBuffer, 0, readBuffer.length, TIMEOUT).join(); Assert.assertEquals(\"Unexpected number of bytes read.\", readBuffer.length, bytesRead); int offset = 0; for(String segmentName : concatOrder) { byte[]concatData = appendData.get(segmentName).toByteArray(); AssertExtensions.assertArrayEquals(\"Unexpected concat data.\", concatData, 0, readBuffer, offset, concatData.length); offset += concatData.length; } Assert.assertEquals(\"Concat included more bytes than expected.\", offset, readBuffer.length); } } ",
        "focal_tgt": "CompletableFuture < Void > concat(SegmentHandle targetHandle, long offset, String sourceSegment, Duration timeout); ",
        "focal_src": "CompletableFuture < Void > concat(SegmentHandle targetHandle, long offset, SegmentHandle sourceHandle, Duration timeout); ",
        "test_tgt": "@Test public void testConcat()throws Exception { final String context = \"Concat\"; try(Storage s = createStorage()) { s.initialize(DEFAULT_EPOCH); HashMap < String, ByteArrayOutputStream > appendData = populate(s, context); val firstSegmentName = getSegmentName(0, context); val firstSegmentHandle = s.openWrite(firstSegmentName).join(); AtomicLong firstSegmentLength = new AtomicLong(s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join().getLength()); assertThrows(\"concat() did not throw for non-existent target segment name.\", () -> s.concat(createHandle(\"foo1\", false, DEFAULT_EPOCH), 0, firstSegmentName, TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); assertThrows(\"concat() did not throw for invalid source StreamSegment name.\", () -> s.concat(firstSegmentHandle, firstSegmentLength.get(), \"foo2\", TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); ArrayList < String > concatOrder = new ArrayList < > (); concatOrder.add(firstSegmentName); for(String sourceSegment : appendData.keySet()) { if(sourceSegment.equals(firstSegmentName)) { continue; } assertThrows(\"Concat allowed when source segment is not sealed.\", () -> s.concat(firstSegmentHandle, firstSegmentLength.get(), sourceSegment, TIMEOUT), ex -> ex instanceof IllegalStateException); val sourceWriteHandle = s.openWrite(sourceSegment).join(); s.seal(sourceWriteHandle, TIMEOUT).join(); SegmentProperties preConcatTargetProps = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); SegmentProperties sourceProps = s.getStreamSegmentInfo(sourceSegment, TIMEOUT).join(); s.concat(firstSegmentHandle, firstSegmentLength.get(), sourceSegment, TIMEOUT).join(); concatOrder.add(sourceSegment); SegmentProperties postConcatTargetProps = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); Assert.assertFalse(\"concat() did not delete source segment\", s.exists(sourceSegment, TIMEOUT).join()); Assert.assertEquals(\"Unexpected target StreamSegment.length after concatenation.\", preConcatTargetProps.getLength() + sourceProps.getLength(), postConcatTargetProps.getLength()); firstSegmentLength.set(postConcatTargetProps.getLength()); } SegmentProperties segmentProperties = s.getStreamSegmentInfo(firstSegmentName, TIMEOUT).join(); byte[]readBuffer = new byte[(int)segmentProperties.getLength()]; int bytesRead = s.read(firstSegmentHandle, 0, readBuffer, 0, readBuffer.length, TIMEOUT).join(); Assert.assertEquals(\"Unexpected number of bytes read.\", readBuffer.length, bytesRead); int offset = 0; for(String segmentName : concatOrder) { byte[]concatData = appendData.get(segmentName).toByteArray(); AssertExtensions.assertArrayEquals(\"Unexpected concat data.\", concatData, 0, readBuffer, offset, concatData.length); offset += concatData.length; } Assert.assertEquals(\"Concat included more bytes than expected.\", offset, readBuffer.length); } } "
    },
    {
        "test_src": "@Test public void testgetOutput() { instance.setSlope(1); assertEquals(expected, instance.getOutput(input), 0.0); } ",
        "focal_tgt": "public double getOutput(List < Connection > inputConnections) { if(inputConnections.size() == 0)return 0d; boolean output = true; for(Connection connection : inputConnections) { output = output && (connection.getInput() >= 0.5d); } return output ? 1d : 0d; } ",
        "focal_src": "public double getOutput(Connection[]inputConnections) { if(inputConnections.length == 0)return 0d; boolean output = true; for(Connection connection : inputConnections) { output = output && (connection.getInput() >= 0.5d); } return output ? 1d : 0d; } ",
        "test_tgt": "@Test public void testGetOutput() { instance.setSlope(1); assertEquals(expected, instance.getOutput(input), 0.0); } "
    },
    {
        "test_src": "@Test public void run()throws Exception { context.options.bool(MainOptions.TEXTINDEX, false); context.options.bool(MainOptions.ATTRINDEX, false); context.options.bool(MainOptions.AUTOFLUSH, false); new CreateDB(NAME, \"<X>\" + \"<A>x.xxxxxxxxxxxxxxxxxx</A>\" + \"<A>x.xxxxxxxxxxxxxxxxxx</A></X>\").execute(context); final Random rnd = new Random(); for(int i = 0; i < NQUERIES; i ++ ) { final double d = rnd.nextDouble(); final String qu = \"for $a in //A return replace node $a/text() with \" + d; new XQuery(qu).execute(context); } new Flush().execute(context); new DropDB(NAME).execute(context); } ",
        "focal_tgt": "private void run(final String[]args)throws Exception { ctx.globalopts.set(GlobalOptions.DBPATH, sandbox().path() + \"/data\"); parseArguments(args); init(); final Performance perf = new Performance(); ctx.options.set(MainOptions.CHOP, false); ctx.options.set(MainOptions.INTPARSE, false); ctx.options.set(MainOptions.SERIALIZER, \"omit-xml-declaration=no,indent=no\"); final XdmValue doc = new XQuery(\"doc('\" + file(false, CATALOG) + \"')\", ctx).value(); final String version = asString(\"*:catalog/@version\", doc); Util.outln(NL + \"QT3 Test Suite \" + version); Util.outln(\"Test directory: \" + new File(\".\").getCanonicalPath()); Util.out(\"Parsing queries\"); for(final XdmItem ienv : new XQuery(\"*:catalog/*:environment\", ctx).context(doc))genvs.add(new QT3Env(ctx, ienv)); for(final XdmItem it : new XQuery(\"for $f in //*:test-set/@file return string($f)\", ctx).context(doc))testSet(it.getString()); final StringBuilder result = new StringBuilder(); result.append(\" Rate : \").append(pc(correct, tested)).append(NL); result.append(\" Total : \").append(total).append(NL); result.append(\" Tested : \").append(tested).append(NL); result.append(\" Wrong : \").append(tested - correct).append(NL); result.append(\" Ignored : \").append(ignored).append(NL); Util.outln(NL + \"Writing log file '\" + testid + \".log'...\"); final PrintOutput po = new PrintOutput(testid + \".log\"); po.println(\"QT3TS RESULTS __________________________\" + NL); po.println(result.toString()); po.println(\"WRONG __________________________________\" + NL); po.print(wrong.finish()); if(all || ! single.isEmpty()) { po.println(\"CORRECT ________________________________\" + NL); po.print(right.finish()); } if(ignoring) { po.println(\"IGNORED ________________________________\" + NL); po.print(ignore.finish()); } po.close(); if(report != null) { final String file = \"ReportingResults/results_\" + Prop.NAME + \"_\" + Prop.VERSION + IO.XMLSUFFIX; new IOFile(file).write(report.create(ctx).toArray()); Util.outln(\"Creating report '\" + file + \"'...\"); } Util.out(NL + result); Util.outln(\" Time : \" + perf); if(slow != null && ! slow.isEmpty()) { Util.outln(NL + \"Slow queries:\"); for(final Map.Entry < Long, String > l : slow.entrySet()) { Util.outln(\"- \" + - (l.getKey() / 1000000) + \" ms: \" + l.getValue()); } } ctx.close(); sandbox().delete(); } ",
        "focal_src": "private void run(final String[]args)throws Exception { ctx.globalopts.string(GlobalOptions.DBPATH, sandbox().path() + \"/data\"); parseArguments(args); init(); final Performance perf = new Performance(); ctx.options.bool(MainOptions.CHOP, false); ctx.options.bool(MainOptions.INTPARSE, false); ctx.options.string(MainOptions.SERIALIZER, \"omit-xml-declaration=no,indent=no\"); final XdmValue doc = new XQuery(\"doc('\" + file(false, CATALOG) + \"')\", ctx).value(); final String version = asString(\"*:catalog/@version\", doc); Util.outln(NL + \"QT3 Test Suite \" + version); Util.outln(\"Test directory: \" + new File(\".\").getCanonicalPath()); Util.out(\"Parsing queries\"); for(final XdmItem ienv : new XQuery(\"*:catalog/*:environment\", ctx).context(doc))genvs.add(new QT3Env(ctx, ienv)); for(final XdmItem it : new XQuery(\"for $f in //*:test-set/@file return string($f)\", ctx).context(doc))testSet(it.getString()); final StringBuilder result = new StringBuilder(); result.append(\" Rate : \").append(pc(correct, tested)).append(NL); result.append(\" Total : \").append(total).append(NL); result.append(\" Tested : \").append(tested).append(NL); result.append(\" Wrong : \").append(tested - correct).append(NL); result.append(\" Ignored : \").append(ignored).append(NL); Util.outln(NL + \"Writing log file '\" + testid + \".log'...\"); final PrintOutput po = new PrintOutput(testid + \".log\"); po.println(\"QT3TS RESULTS __________________________\" + NL); po.println(result.toString()); po.println(\"WRONG __________________________________\" + NL); po.print(wrong.finish()); if(all || ! single.isEmpty()) { po.println(\"CORRECT ________________________________\" + NL); po.print(right.finish()); } if(ignoring) { po.println(\"IGNORED ________________________________\" + NL); po.print(ignore.finish()); } po.close(); if(report != null) { final String file = \"ReportingResults/results_\" + Prop.NAME + \"_\" + Prop.VERSION + IO.XMLSUFFIX; new IOFile(file).write(report.create(ctx).toArray()); Util.outln(\"Creating report '\" + file + \"'...\"); } Util.out(NL + result); Util.outln(\" Time : \" + perf); if(slow != null && ! slow.isEmpty()) { Util.outln(NL + \"Slow queries:\"); for(final Map.Entry < Long, String > l : slow.entrySet()) { Util.outln(\"- \" + - (l.getKey() / 1000000) + \" ms: \" + l.getValue()); } } ctx.close(); sandbox().delete(); } ",
        "test_tgt": "@Test public void run()throws Exception { context.options.set(MainOptions.TEXTINDEX, false); context.options.set(MainOptions.ATTRINDEX, false); context.options.set(MainOptions.AUTOFLUSH, false); new CreateDB(NAME, \"<X>\" + \"<A>x.xxxxxxxxxxxxxxxxxx</A>\" + \"<A>x.xxxxxxxxxxxxxxxxxx</A></X>\").execute(context); final Random rnd = new Random(); for(int i = 0; i < NQUERIES; i ++ ) { final double d = rnd.nextDouble(); final String qu = \"for $a in //A return replace node $a/text() with \" + d; new XQuery(qu).execute(context); } new Flush().execute(context); new DropDB(NAME).execute(context); } "
    },
    {
        "test_src": "@Test public void notTest1() { final short[]content = { 1, 3, 5, 7, 9 }; final MappeableContainer c = makeContainer(content); final MappeableContainer c1 = c.not(0, 65535); final short[]s = new short[65536 - content.length]; int pos = 0; for(int i = 0; i < 65536; ++ i)if(Arrays.binarySearch(content, (short)i) < 0)s[pos ++ ] = (short)i; assertTrue(checkContent(c1, s)); assertTrue(checkContent(c, content)); } ",
        "focal_tgt": "private MappeableContainer not(MappeableBitmapContainer answer, final int firstOfRange, final int lastOfRange) { assert bitmap.limit() == MAX_CAPACITY / 64; if(lastOfRange - firstOfRange == MAX_CAPACITY) { final int newCardinality = MAX_CAPACITY - cardinality; for(int k = 0; k < this.bitmap.limit(); ++ k)answer.bitmap.put(k, ~ this.bitmap.get(k)); answer.cardinality = newCardinality; if(newCardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } int cardinalityChange = 0; final int rangeFirstWord = firstOfRange / 64; final int rangeFirstBitPos = firstOfRange & 63; final int rangeLastWord = (lastOfRange - 1) / 64; final long rangeLastBitPos = (lastOfRange - 1) & 63; if(answer != this) { for(int i = 0; i < rangeFirstWord; ++ i)answer.bitmap.put(i, bitmap.get(i)); for(int i = rangeLastWord + 1; i < bitmap.limit(); ++ i)answer.bitmap.put(i, bitmap.get(i)); } final long maskOnLeft = (rangeLastBitPos == 63) ? - 1L : (1L << (rangeLastBitPos + 1)) - 1; long mask = - 1L; mask ^= ((1L << rangeFirstBitPos) - 1); if(rangeFirstWord == rangeLastWord) { mask &= maskOnLeft; cardinalityChange = - Long.bitCount(bitmap.get(rangeFirstWord)); answer.bitmap.put(rangeFirstWord, bitmap.get(rangeFirstWord) ^ mask); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeFirstWord)); answer.cardinality = cardinality + cardinalityChange; if(answer.cardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } cardinalityChange += - Long.bitCount(bitmap.get(rangeFirstWord)); answer.bitmap.put(rangeFirstWord, bitmap.get(rangeFirstWord) ^ mask); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeFirstWord)); cardinalityChange += - Long.bitCount(bitmap.get(rangeLastWord)); answer.bitmap.put(rangeLastWord, bitmap.get(rangeLastWord) ^ maskOnLeft); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeLastWord)); for(int i = rangeFirstWord + 1; i < rangeLastWord; ++ i) { cardinalityChange += (64 - 2 * Long.bitCount(bitmap.get(i))); answer.bitmap.put(i, ~ bitmap.get(i)); } answer.cardinality = cardinality + cardinalityChange; if(answer.cardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } ",
        "focal_src": "private MappeableContainer not(MappeableBitmapContainer answer, final int firstOfRange, final int lastOfRange) { assert bitmap.limit() == MAX_CAPACITY / 64; if(lastOfRange - firstOfRange + 1 == MAX_CAPACITY) { final int newCardinality = MAX_CAPACITY - cardinality; for(int k = 0; k < this.bitmap.limit(); ++ k)answer.bitmap.put(k, ~ this.bitmap.get(k)); answer.cardinality = newCardinality; if(newCardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } int cardinalityChange = 0; final int rangeFirstWord = firstOfRange / 64; final int rangeFirstBitPos = firstOfRange & 63; final int rangeLastWord = lastOfRange / 64; final long rangeLastBitPos = lastOfRange & 63; if(answer != this) { for(int i = 0; i < rangeFirstWord; ++ i)answer.bitmap.put(i, bitmap.get(i)); for(int i = rangeLastWord + 1; i < bitmap.limit(); ++ i)answer.bitmap.put(i, bitmap.get(i)); } final long maskOnLeft = (rangeLastBitPos == 63) ? - 1L : (1L << (rangeLastBitPos + 1)) - 1; long mask = - 1L; mask ^= ((1L << rangeFirstBitPos) - 1); if(rangeFirstWord == rangeLastWord) { mask &= maskOnLeft; cardinalityChange = - Long.bitCount(bitmap.get(rangeFirstWord)); answer.bitmap.put(rangeFirstWord, bitmap.get(rangeFirstWord) ^ mask); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeFirstWord)); answer.cardinality = cardinality + cardinalityChange; if(answer.cardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } cardinalityChange += - Long.bitCount(bitmap.get(rangeFirstWord)); answer.bitmap.put(rangeFirstWord, bitmap.get(rangeFirstWord) ^ mask); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeFirstWord)); cardinalityChange += - Long.bitCount(bitmap.get(rangeLastWord)); answer.bitmap.put(rangeLastWord, bitmap.get(rangeLastWord) ^ maskOnLeft); cardinalityChange += Long.bitCount(answer.bitmap.get(rangeLastWord)); for(int i = rangeFirstWord + 1; i < rangeLastWord; ++ i) { cardinalityChange += (64 - 2 * Long.bitCount(bitmap.get(i))); answer.bitmap.put(i, ~ bitmap.get(i)); } answer.cardinality = cardinality + cardinalityChange; if(answer.cardinality <= MappeableArrayContainer.DEFAULT_MAX_SIZE)return answer.toArrayContainer(); return answer; } ",
        "test_tgt": "@Test public void notTest1() { final short[]content = { 1, 3, 5, 7, 9 }; final MappeableContainer c = makeContainer(content); final MappeableContainer c1 = c.not(0, 65536); final short[]s = new short[65536 - content.length]; int pos = 0; for(int i = 0; i < 65536; ++ i)if(Arrays.binarySearch(content, (short)i) < 0)s[pos ++ ] = (short)i; assertTrue(checkContent(c1, s)); assertTrue(checkContent(c, content)); } "
    },
    {
        "test_src": "@Test public void testGetSplits()throws Exception { Connector conn = getConnector(); String table = getUniqueNames(1)[0]; conn.tableOperations().create(table); insertData(table, currentTimeMillis()); ClientConfiguration clientConf = cluster.getClientConfig(); AccumuloConfiguration clusterClientConf = new ConfigurationCopy(new DefaultConfiguration()); boolean sslEnabled = Boolean.valueOf(clusterClientConf.get(Property.INSTANCE_RPC_SSL_ENABLED)); if(sslEnabled) { ClientProperty[]sslProperties = new ClientProperty[] { ClientProperty.INSTANCE_RPC_SSL_ENABLED, ClientProperty.INSTANCE_RPC_SSL_CLIENT_AUTH, ClientProperty.RPC_SSL_KEYSTORE_PATH, ClientProperty.RPC_SSL_KEYSTORE_TYPE, ClientProperty.RPC_SSL_KEYSTORE_PASSWORD, ClientProperty.RPC_SSL_TRUSTSTORE_PATH, ClientProperty.RPC_SSL_TRUSTSTORE_TYPE, ClientProperty.RPC_SSL_TRUSTSTORE_PASSWORD, ClientProperty.RPC_USE_JSSE, ClientProperty.GENERAL_SECURITY_CREDENTIAL_PROVIDER_PATHS }; for(ClientProperty prop : sslProperties) { clientConf.setProperty(prop, clusterClientConf.get(prop.getAccumuloProperty())); } } Job job = Job.getInstance(); AccumuloInputFormat.setInputTableName(job, table); AccumuloInputFormat.setZooKeeperInstance(job, clientConf); AccumuloInputFormat.setConnectorInfo(job, getAdminPrincipal(), getAdminToken()); TreeSet < Text > splitsToAdd = new TreeSet < Text > (); for(int i = 0; i < 10000; i += 1000)splitsToAdd.add(new Text(String.format(\"%09d\", i))); conn.tableOperations().addSplits(table, splitsToAdd); UtilWaitThread.sleep(500); Collection < Text > actualSplits = conn.tableOperations().listSplits(table); List < InputSplit > splits = inputFormat.getSplits(job); assertEquals(actualSplits.size() + 1, splits.size()); List < Range > ranges = new ArrayList < Range > (); for(Text text : actualSplits)ranges.add(new Range(text)); AccumuloInputFormat.setRanges(job, ranges); splits = inputFormat.getSplits(job); assertEquals(actualSplits.size(), splits.size()); AccumuloInputFormat.setOfflineTableScan(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IOException e) { } conn.tableOperations().offline(table, true); splits = inputFormat.getSplits(job); assertEquals(actualSplits.size(), splits.size()); ranges = new ArrayList < Range > (); for(int i = 0; i < 5; i ++ )ranges.add(new Range(String.format(\"%09d\", i), String.format(\"%09d\", i + 2))); AccumuloInputFormat.setRanges(job, ranges); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setAutoAdjustRanges(job, false); splits = inputFormat.getSplits(job); assertEquals(ranges.size(), splits.size()); AccumuloInputFormat.setBatchScan(job, true); AccumuloInputFormat.setAutoAdjustRanges(job, true); AccumuloInputFormat.setOfflineTableScan(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } conn.tableOperations().online(table, true); AccumuloInputFormat.setOfflineTableScan(job, false); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setScanIsolation(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } AccumuloInputFormat.setScanIsolation(job, false); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setLocalIterators(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } AccumuloInputFormat.setLocalIterators(job, false); conn.tableOperations().online(table); splits = inputFormat.getSplits(job); for(InputSplit split : splits)assert(split instanceof BatchInputSplit); assertEquals(2, splits.size()); } ",
        "focal_tgt": "@Override public InputSplit[]getSplits(JobConf job, int numSplits)throws IOException { Level logLevel = getLogLevel(job); log.setLevel(logLevel); validateOptions(job); Random random = new Random(); LinkedList < InputSplit > splits = new LinkedList < InputSplit > (); Map < String, InputTableConfig > tableConfigs = getInputTableConfigs(job); for(Map.Entry < String, InputTableConfig > tableConfigEntry : tableConfigs.entrySet()) { String tableName = tableConfigEntry.getKey(); InputTableConfig tableConfig = tableConfigEntry.getValue(); Instance instance = getInstance(job); String tableId; if(instance instanceof MockInstance) { tableId = \"\"; } else { try { tableId = Tables.getTableId(instance, tableName); } catch(TableNotFoundException e) { throw new IOException(e); } } Authorizations auths = getScanAuthorizations(job); String principal = getPrincipal(job); AuthenticationToken token = getAuthenticationToken(job); boolean batchScan = InputConfigurator.isBatchScan(CLASS, job); boolean supportBatchScan = ! (tableConfig.isOfflineScan() || tableConfig.shouldUseIsolatedScanners() || tableConfig.shouldUseLocalIterators()); if(batchScan && ! supportBatchScan)throw new IllegalArgumentException(\"BatchScanner optimization not available for offline scan, isolated, or local iterators\"); boolean autoAdjust = tableConfig.shouldAutoAdjustRanges(); if(batchScan && ! autoAdjust)throw new IllegalArgumentException(\"AutoAdjustRanges must be enabled when using BatchScanner optimization\"); List < Range > ranges = autoAdjust ? Range.mergeOverlapping(tableConfig.getRanges()) : tableConfig.getRanges(); if(ranges.isEmpty()) { ranges = new ArrayList < Range > (1); ranges.add(new Range()); } Map < String, Map < KeyExtent, List < Range > > > binnedRanges = new HashMap < String, Map < KeyExtent, List < Range > > > (); TabletLocator tl; try { if(tableConfig.isOfflineScan()) { binnedRanges = binOfflineTable(job, tableId, ranges); while(binnedRanges == null) { UtilWaitThread.sleep(100 + random.nextInt(100)); binnedRanges = binOfflineTable(job, tableId, ranges); } } else { tl = InputConfigurator.getTabletLocator(CLASS, job, tableId); tl.invalidateCache(); ClientContext context = new ClientContext(getInstance(job), new Credentials(getPrincipal(job), getAuthenticationToken(job)), getClientConfiguration(job)); while( ! tl.binRanges(context, ranges, binnedRanges).isEmpty()) { if( ! (instance instanceof MockInstance)) { if( ! Tables.exists(instance, tableId))throw new TableDeletedException(tableId); if(Tables.getTableState(instance, tableId) == TableState.OFFLINE)throw new TableOfflineException(instance, tableId); } binnedRanges.clear(); log.warn(\"Unable to locate bins for specified ranges. Retrying.\"); UtilWaitThread.sleep(100 + random.nextInt(100)); tl.invalidateCache(); } } } catch(Exception e) { throw new IOException(e); } HashMap < Range, ArrayList < String > > splitsToAdd = null; if( ! autoAdjust)splitsToAdd = new HashMap < Range, ArrayList < String > > (); HashMap < String, String > hostNameCache = new HashMap < String, String > (); for(Map.Entry < String, Map < KeyExtent, List < Range > > > tserverBin : binnedRanges.entrySet()) { String ip = tserverBin.getKey().split(\":\", 2)[0]; String location = hostNameCache.get(ip); if(location == null) { InetAddress inetAddress = InetAddress.getByName(ip); location = inetAddress.getCanonicalHostName(); hostNameCache.put(ip, location); } for(Map.Entry < KeyExtent, List < Range > > extentRanges : tserverBin.getValue().entrySet()) { Range ke = extentRanges.getKey().toDataRange(); if(batchScan) { ArrayList < Range > clippedRanges = new ArrayList < Range > (); for(Range r : extentRanges.getValue())clippedRanges.add(ke.clip(r)); BatchInputSplit split = new BatchInputSplit(tableName, tableId, clippedRanges, new String[] { location }); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); splits.add(split); } else { for(Range r : extentRanges.getValue()) { if(autoAdjust) { RangeInputSplit split = new RangeInputSplit(tableName, tableId, ke.clip(r), new String[] { location }); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); split.setOffline(tableConfig.isOfflineScan()); split.setIsolatedScan(tableConfig.shouldUseIsolatedScanners()); split.setUsesLocalIterators(tableConfig.shouldUseLocalIterators()); splits.add(split); } else { ArrayList < String > locations = splitsToAdd.get(r); if(locations == null)locations = new ArrayList < String > (1); locations.add(location); splitsToAdd.put(r, locations); } } } } } if( ! autoAdjust)for(Map.Entry < Range, ArrayList < String > > entry : splitsToAdd.entrySet()) { RangeInputSplit split = new RangeInputSplit(tableName, tableId, entry.getKey(), entry.getValue().toArray(new String[0])); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); split.setOffline(tableConfig.isOfflineScan()); split.setIsolatedScan(tableConfig.shouldUseIsolatedScanners()); split.setUsesLocalIterators(tableConfig.shouldUseLocalIterators()); splits.add(split); } } return splits.toArray(new InputSplit[splits.size()]); } ",
        "focal_src": "@Override public InputSplit[]getSplits(JobConf job, int numSplits)throws IOException { Level logLevel = getLogLevel(job); log.setLevel(logLevel); validateOptions(job); Random random = new Random(); LinkedList < InputSplit > splits = new LinkedList < InputSplit > (); Map < String, InputTableConfig > tableConfigs = getInputTableConfigs(job); for(Map.Entry < String, InputTableConfig > tableConfigEntry : tableConfigs.entrySet()) { String tableName = tableConfigEntry.getKey(); InputTableConfig tableConfig = tableConfigEntry.getValue(); Instance instance = getInstance(job); String tableId; if(instance instanceof MockInstance) { tableId = \"\"; } else { try { tableId = Tables.getTableId(instance, tableName); } catch(TableNotFoundException e) { throw new IOException(e); } } Authorizations auths = getScanAuthorizations(job); String principal = getPrincipal(job); AuthenticationToken token = getAuthenticationToken(job); boolean batchScan = InputConfigurator.isBatchScan(CLASS, job); boolean supportBatchScan = ! (tableConfig.isOfflineScan() || tableConfig.shouldUseIsolatedScanners() || tableConfig.shouldUseLocalIterators()); if(batchScan && ! supportBatchScan)throw new IllegalArgumentException(\"BatchScanner optimization not available for offline scan, isolated, or local iterators\"); boolean autoAdjust = tableConfig.shouldAutoAdjustRanges(); if(batchScan && ! autoAdjust)throw new IllegalArgumentException(\"AutoAdjustRanges must be enabled when using BatchScanner optimization\"); List < Range > ranges = autoAdjust ? Range.mergeOverlapping(tableConfig.getRanges()) : tableConfig.getRanges(); if(ranges.isEmpty()) { ranges = new ArrayList < Range > (1); ranges.add(new Range()); } Map < String, Map < KeyExtent, List < Range > > > binnedRanges = new HashMap < String, Map < KeyExtent, List < Range > > > (); TabletLocator tl; try { if(tableConfig.isOfflineScan()) { binnedRanges = binOfflineTable(job, tableId, ranges); while(binnedRanges == null) { UtilWaitThread.sleep(100 + random.nextInt(100)); binnedRanges = binOfflineTable(job, tableId, ranges); } } else { tl = getTabletLocator(job, tableId); tl.invalidateCache(); ClientContext context = new ClientContext(getInstance(job), new Credentials(getPrincipal(job), getAuthenticationToken(job)), getClientConfiguration(job)); while( ! tl.binRanges(context, ranges, binnedRanges).isEmpty()) { if( ! (instance instanceof MockInstance)) { if( ! Tables.exists(instance, tableId))throw new TableDeletedException(tableId); if(Tables.getTableState(instance, tableId) == TableState.OFFLINE)throw new TableOfflineException(instance, tableId); } binnedRanges.clear(); log.warn(\"Unable to locate bins for specified ranges. Retrying.\"); UtilWaitThread.sleep(100 + random.nextInt(100)); tl.invalidateCache(); } } } catch(Exception e) { throw new IOException(e); } HashMap < Range, ArrayList < String > > splitsToAdd = null; if( ! autoAdjust)splitsToAdd = new HashMap < Range, ArrayList < String > > (); HashMap < String, String > hostNameCache = new HashMap < String, String > (); for(Map.Entry < String, Map < KeyExtent, List < Range > > > tserverBin : binnedRanges.entrySet()) { String ip = tserverBin.getKey().split(\":\", 2)[0]; String location = hostNameCache.get(ip); if(location == null) { InetAddress inetAddress = InetAddress.getByName(ip); location = inetAddress.getCanonicalHostName(); hostNameCache.put(ip, location); } for(Map.Entry < KeyExtent, List < Range > > extentRanges : tserverBin.getValue().entrySet()) { Range ke = extentRanges.getKey().toDataRange(); if(batchScan) { ArrayList < Range > clippedRanges = new ArrayList < Range > (); for(Range r : extentRanges.getValue())clippedRanges.add(ke.clip(r)); BatchInputSplit split = new BatchInputSplit(tableName, tableId, clippedRanges, new String[] { location }); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); splits.add(split); } else { for(Range r : extentRanges.getValue()) { if(autoAdjust) { RangeInputSplit split = new RangeInputSplit(tableName, tableId, ke.clip(r), new String[] { location }); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); split.setOffline(tableConfig.isOfflineScan()); split.setIsolatedScan(tableConfig.shouldUseIsolatedScanners()); split.setUsesLocalIterators(tableConfig.shouldUseLocalIterators()); splits.add(split); } else { ArrayList < String > locations = splitsToAdd.get(r); if(locations == null)locations = new ArrayList < String > (1); locations.add(location); splitsToAdd.put(r, locations); } } } } } if( ! autoAdjust)for(Map.Entry < Range, ArrayList < String > > entry : splitsToAdd.entrySet()) { RangeInputSplit split = new RangeInputSplit(tableName, tableId, entry.getKey(), entry.getValue().toArray(new String[0])); AccumuloInputSplit.updateSplit(split, instance, tableConfig, principal, token, auths, logLevel); split.setOffline(tableConfig.isOfflineScan()); split.setIsolatedScan(tableConfig.shouldUseIsolatedScanners()); split.setUsesLocalIterators(tableConfig.shouldUseLocalIterators()); splits.add(split); } } return splits.toArray(new InputSplit[splits.size()]); } ",
        "test_tgt": "@Test public void testGetSplits()throws Exception { Connector conn = getConnector(); String table = getUniqueNames(1)[0]; conn.tableOperations().create(table); insertData(table, currentTimeMillis()); ClientConfiguration clientConf = cluster.getClientConfig(); AccumuloConfiguration clusterClientConf = new ConfigurationCopy(new DefaultConfiguration()); boolean sslEnabled = Boolean.valueOf(clusterClientConf.get(Property.INSTANCE_RPC_SSL_ENABLED)); if(sslEnabled) { ClientProperty[]sslProperties = new ClientProperty[] { ClientProperty.INSTANCE_RPC_SSL_ENABLED, ClientProperty.INSTANCE_RPC_SSL_CLIENT_AUTH, ClientProperty.RPC_SSL_KEYSTORE_PATH, ClientProperty.RPC_SSL_KEYSTORE_TYPE, ClientProperty.RPC_SSL_KEYSTORE_PASSWORD, ClientProperty.RPC_SSL_TRUSTSTORE_PATH, ClientProperty.RPC_SSL_TRUSTSTORE_TYPE, ClientProperty.RPC_SSL_TRUSTSTORE_PASSWORD, ClientProperty.RPC_USE_JSSE, ClientProperty.GENERAL_SECURITY_CREDENTIAL_PROVIDER_PATHS }; for(ClientProperty prop : sslProperties) { clientConf.setProperty(prop, clusterClientConf.get(prop.getKey())); } } Job job = Job.getInstance(); AccumuloInputFormat.setInputTableName(job, table); AccumuloInputFormat.setZooKeeperInstance(job, clientConf); AccumuloInputFormat.setConnectorInfo(job, getAdminPrincipal(), getAdminToken()); TreeSet < Text > splitsToAdd = new TreeSet < Text > (); for(int i = 0; i < 10000; i += 1000)splitsToAdd.add(new Text(String.format(\"%09d\", i))); conn.tableOperations().addSplits(table, splitsToAdd); UtilWaitThread.sleep(500); Collection < Text > actualSplits = conn.tableOperations().listSplits(table); List < InputSplit > splits = inputFormat.getSplits(job); assertEquals(actualSplits.size() + 1, splits.size()); List < Range > ranges = new ArrayList < Range > (); for(Text text : actualSplits)ranges.add(new Range(text)); AccumuloInputFormat.setRanges(job, ranges); splits = inputFormat.getSplits(job); assertEquals(actualSplits.size(), splits.size()); AccumuloInputFormat.setOfflineTableScan(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IOException e) { } conn.tableOperations().offline(table, true); splits = inputFormat.getSplits(job); assertEquals(actualSplits.size(), splits.size()); ranges = new ArrayList < Range > (); for(int i = 0; i < 5; i ++ )ranges.add(new Range(String.format(\"%09d\", i), String.format(\"%09d\", i + 2))); AccumuloInputFormat.setRanges(job, ranges); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setAutoAdjustRanges(job, false); splits = inputFormat.getSplits(job); assertEquals(ranges.size(), splits.size()); AccumuloInputFormat.setBatchScan(job, true); AccumuloInputFormat.setAutoAdjustRanges(job, true); AccumuloInputFormat.setOfflineTableScan(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } conn.tableOperations().online(table, true); AccumuloInputFormat.setOfflineTableScan(job, false); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setScanIsolation(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } AccumuloInputFormat.setScanIsolation(job, false); splits = inputFormat.getSplits(job); assertEquals(2, splits.size()); AccumuloInputFormat.setLocalIterators(job, true); try { inputFormat.getSplits(job); fail(\"An exception should have been thrown\"); } catch(IllegalArgumentException e) { } AccumuloInputFormat.setLocalIterators(job, false); conn.tableOperations().online(table); splits = inputFormat.getSplits(job); for(InputSplit split : splits)assert(split instanceof BatchInputSplit); assertEquals(2, splits.size()); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"An issue in the API code has been identified (ticket #87). This test must be updated when the ticket is closed.\", method = \"close\", args = { })public void test_close() { fos.setThrowsException(true); try { osw.close(); fail(\"Test 1: IOException expected.\"); } catch(IOException e) { } ByteArrayOutputStream bout = new ByteArrayOutputStream(); try { OutputStreamWriter writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { 'a' }); writer.close(); String converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 4: Invalid conversion: \" + converted, converted.equals(\"a\")); bout.reset(); writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { '' }); writer.flush(); converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 5: Invalid conversion: \" + converted, converted.equals(\"\u001b$B$(\")); writer.close(); converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 6: Invalid conversion: \" + converted, converted.equals(\"\u001b$B$(\u001b(B\")); bout.reset(); writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { '' }); writer.write(new char[] { '' }); writer.close(); assertEquals(\"Test 7: Invalid conversion. \", \"\u001b$B$($(\u001b(B\", new String(bout.toByteArray(), \"ISO8859_1\")); } catch(UnsupportedEncodingException e) { System.out.println(e); } catch(IOException e) { fail(\"Unexpected: \" + e); } } ",
        "focal_tgt": "@Override public void close()throws IOException { buf = null; InputStream localIn = in; in = null; if(localIn != null) { localIn.close(); } } ",
        "focal_src": "@Override public synchronized void close()throws IOException { if(null != in) { super.close(); in = null; } buf = null; closed = true; } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"An issue in the API code has been identified (ticket #87). This test must be updated when the ticket is closed.\", method = \"close\", args = { })public void test_close() { fos.setThrowsException(true); try { osw.close(); fail(\"Test 1: IOException expected.\"); } catch(IOException e) { } ByteArrayOutputStream bout = new ByteArrayOutputStream(); try { OutputStreamWriter writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { 'a' }); writer.close(); String converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 4: Invalid conversion: \" + converted, converted.equals(\"a\")); bout.reset(); writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { '' }); writer.flush(); converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 5: Invalid conversion: \" + converted, converted.equals(\"\u001b$B$(\")); writer.close(); converted = new String(bout.toByteArray(), \"ISO8859_1\"); assertTrue(\"Test 6: Invalid conversion: \" + converted, converted.equals(\"\u001b$B$(\u001b(B\")); bout.reset(); writer = new OutputStreamWriter(bout, \"ISO2022JP\"); writer.write(new char[] { '' }); writer.write(new char[] { '' }); writer.close(); assertEquals(\"Test 7: Invalid conversion. \", \"\u001b$B$($(\u001b(B\", new String(bout.toByteArray(), \"ISO8859_1\")); } catch(UnsupportedEncodingException e) { System.out.println(e); } catch(IOException e) { fail(\"Unexpected: \" + e); } } "
    },
    {
        "test_src": "@Test public void testListChangeRequests() { EasyMock.expect(dnsRpcMock.listChangeRequests(ZONE_INFO.name(), EMPTY_RPC_OPTIONS)).andReturn(LIST_RESULT_OF_PB_CHANGES); EasyMock.replay(dnsRpcMock); dns = options.service(); Page < ChangeRequest > changeRequestPage = dns.listChangeRequests(ZONE_INFO.name()); assertTrue(Lists.newArrayList(changeRequestPage.values()).contains(new ChangeRequest(dns, ZONE_INFO.name(), new ChangeRequestInfo.BuilderImpl(CHANGE_REQUEST_COMPLETE)))); assertTrue(Lists.newArrayList(changeRequestPage.values()).contains(new ChangeRequest(dns, ZONE_INFO.name(), new ChangeRequestInfo.BuilderImpl(CHANGE_REQUEST_PARTIAL)))); assertEquals(2, Lists.newArrayList(changeRequestPage.values()).size()); } ",
        "focal_tgt": "public Page < ChangeRequest > listChangeRequests(Dns.ChangeRequestListOption ... options) { return dns.listChangeRequests(getName(), options); } ",
        "focal_src": "public Page < ChangeRequest > listChangeRequests(Dns.ChangeRequestListOption ... options) { return dns.listChangeRequests(name(), options); } ",
        "test_tgt": "@Test public void testListChangeRequests() { EasyMock.expect(dnsRpcMock.listChangeRequests(ZONE_INFO.getName(), EMPTY_RPC_OPTIONS)).andReturn(LIST_RESULT_OF_PB_CHANGES); EasyMock.replay(dnsRpcMock); dns = options.service(); Page < ChangeRequest > changeRequestPage = dns.listChangeRequests(ZONE_INFO.getName()); assertTrue(Lists.newArrayList(changeRequestPage.values()).contains(new ChangeRequest(dns, ZONE_INFO.getName(), new ChangeRequestInfo.BuilderImpl(CHANGE_REQUEST_COMPLETE)))); assertTrue(Lists.newArrayList(changeRequestPage.values()).contains(new ChangeRequest(dns, ZONE_INFO.getName(), new ChangeRequestInfo.BuilderImpl(CHANGE_REQUEST_PARTIAL)))); assertEquals(2, Lists.newArrayList(changeRequestPage.values()).size()); } "
    },
    {
        "test_src": "@Test public void findProvider_shouldReturnTheListOfProvidersIncludingVoidedProvidersForTheMatchingSearchName()throws Exception { Vector < Object > providers = service.findProvider(\"provider\", true, 0, 10); Assert.assertEquals(3, providers.size()); Assert.assertTrue(CollectionUtils.exists(providers, new Predicate() { @Override public boolean evaluate(Object object) { return((ProviderListItem)object).getDisplayName().equals(\"Jimmy Manana Chemalit\"); } })); } ",
        "focal_tgt": "public Vector < Object > findProvider(String name, boolean includeRetired, Integer start, Integer length) { Vector < Object > providerListItem = new Vector < Object > (); List < Provider > providerList = Context.getProviderService().getProviders(name, start, length, null); if(providerList.size() == 0) { MessageSourceService mss = Context.getMessageSourceService(); providerListItem.add(mss.getMessage(\"Provider.noMatchesFound\", new Object[] { name }, Context.getLocale())); } else { for(Provider p : providerList) { if( ! p.isRetired() || (p.isRetired() && includeRetired == true))providerListItem.add(new ProviderListItem(p)); } } return providerListItem; } ",
        "focal_src": "public Vector < Object > findProvider(String name, boolean includeVoided, Integer start, Integer length) { Vector < Object > providerListItem = new Vector < Object > (); List < Provider > providerList = Context.getProviderService().getProviders(name, start, length, null); if(providerList.size() == 0) { MessageSourceService mss = Context.getMessageSourceService(); providerListItem.add(mss.getMessage(\"Provider.noMatchesFound\", new Object[] { name }, Context.getLocale())); } else { for(Provider p : providerList) { if( ! p.isRetired() || (p.isRetired() && includeVoided == true))providerListItem.add(new ProviderListItem(p)); } } return providerListItem; } ",
        "test_tgt": "@Test public void findProvider_shouldReturnTheListOfProvidersIncludingRetiredProvidersForTheMatchingSearchName()throws Exception { Vector < Object > providers = service.findProvider(\"provider\", true, 0, 10); Assert.assertEquals(3, providers.size()); Assert.assertTrue(CollectionUtils.exists(providers, new Predicate() { @Override public boolean evaluate(Object object) { return((ProviderListItem)object).getDisplayName().equals(\"Jimmy Manana Chemalit\"); } })); } "
    },
    {
        "test_src": "@Test public void listCertificateVersions()throws Exception { String certificateName = \"listCertificateVersions\"; String certificateContent = \"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\"; String certificatePassword = \"123\"; SecretProperties secretProperties = new SecretProperties(); secretProperties.withContentType(MIME_PKCS12); CertificatePolicy certificatePolicy = new CertificatePolicy(); certificatePolicy.withSecretProperties(secretProperties); HashSet < String > certificates = new HashSet < String > (); for(int i = 0; i < MAX_CERTS; ++ i) { int failureCount = 0; for(; ; ) { try { CertificateBundle certificateBundle = keyVaultClient.importCertificate(new ImportCertificateRequest.Builder(getVaultUri(), certificateName, certificateContent).withPassword(certificatePassword).withPolicy(certificatePolicy).build()).getBody(); CertificateIdentifier id = certificateBundle.certificateIdentifier(); certificates.add(id.identifier()); break; } catch(KeyVaultErrorException e) { ++ failureCount; if(e.getBody().error().code().equals(\"Throttled\")) { System.out.println(\"Waiting to avoid throttling\"); Thread.sleep(failureCount * 1500); continue; } throw e; } } } PagedList < CertificateItem > listResult = keyVaultClient.listCertificateVersions(getVaultUri(), certificateName, PAGELIST_MAX_CERTS).getBody(); Assert.assertTrue(PAGELIST_MAX_CERTS >= listResult.currentPage().getItems().size()); listResult = keyVaultClient.listCertificateVersions(getVaultUri(), certificateName).getBody(); for(CertificateItem item : listResult) { if(item != null) { certificates.remove(item.id()); } } Assert.assertEquals(0, certificates.size()); keyVaultClient.deleteCertificate(getVaultUri(), certificateName); } ",
        "focal_tgt": "public PagedList < CertificateItem > listCertificateVersions(final String vaultBaseUrl, final String certificateName, final Integer maxresults)throws KeyVaultErrorException, IOException, IllegalArgumentException { return innerKeyVaultClient.getCertificateVersions(vaultBaseUrl, certificateName, maxresults); } ",
        "focal_src": "public ServiceResponse < PagedList < CertificateItem > > listCertificateVersions(final String vaultBaseUrl, final String certificateName, final Integer maxresults)throws KeyVaultErrorException, IOException, IllegalArgumentException { return innerKeyVaultClient.getCertificateVersions(vaultBaseUrl, certificateName, maxresults); } ",
        "test_tgt": "@Test public void listCertificateVersions()throws Exception { String certificateName = \"listCertificateVersions\"; String certificateContent = \"MIIJOwIBAzCCCPcGCSqGSIb3DQEHAaCCCOgEggjkMIII4DCCBgkGCSqGSIb3DQEHAaCCBfoEggX2MIIF8jCCBe4GCyqGSIb3DQEMCgECoIIE/jCCBPowHAYKKoZIhvcNAQwBAzAOBAj15YH9pOE58AICB9AEggTYLrI+SAru2dBZRQRlJY7XQ3LeLkah2FcRR3dATDshZ2h0IA2oBrkQIdsLyAAWZ32qYR1qkWxLHn9AqXgu27AEbOk35+pITZaiy63YYBkkpR+pDdngZt19Z0PWrGwHEq5z6BHS2GLyyN8SSOCbdzCz7blj3+7IZYoMj4WOPgOm/tQ6U44SFWek46QwN2zeA4i97v7ftNNns27ms52jqfhOvTA9c/wyfZKAY4aKJfYYUmycKjnnRl012ldS2lOkASFt+lu4QCa72IY6ePtRudPCvmzRv2pkLYS6z3cI7omT8nHP3DymNOqLbFqr5O2M1ZYaLC63Q3xt3eVvbcPh3N08D1hHkhz/KDTvkRAQpvrW8ISKmgDdmzN55Pe55xHfSWGB7gPw8sZea57IxFzWHTK2yvTslooWoosmGxanYY2IG/no3EbPOWDKjPZ4ilYJe5JJ2immlxPz+2e2EOCKpDI+7fzQcRz3PTd3BK+budZ8aXX8aW/lOgKS8WmxZoKnOJBNWeTNWQFugmktXfdPHAdxMhjUXqeGQd8wTvZ4EzQNNafovwkI7IV/ZYoa++RGofVR3ZbRSiBNF6TDj/qXFt0wN/CQnsGAmQAGNiN+D4mY7i25dtTu/Jc7OxLdhAUFpHyJpyrYWLfvOiS5WYBeEDHkiPUa/8eZSPA3MXWZR1RiuDvuNqMjct1SSwdXADTtF68l/US1ksU657+XSC+6ly1A/upz+X71+C4Ho6W0751j5ZMT6xKjGh5pee7MVuduxIzXjWIy3YSd0fIT3U0A5NLEvJ9rfkx6JiHjRLx6V1tqsrtT6BsGtmCQR1UCJPLqsKVDvAINx3cPA/CGqr5OX2BGZlAihGmN6n7gv8w4O0k0LPTAe5YefgXN3m9pE867N31GtHVZaJ/UVgDNYS2jused4rw76ZWN41akx2QN0JSeMJqHXqVz6AKfz8ICS/dFnEGyBNpXiMRxrY/QPKi/wONwqsbDxRW7vZRVKs78pBkE0ksaShlZk5GkeayDWC/7Hi/NqUFtIloK9XB3paLxo1DGu5qqaF34jZdktzkXp0uZqpp+FfKZaiovMjt8F7yHCPk+LYpRsU2Cyc9DVoDA6rIgf+uEP4jppgehsxyT0lJHax2t869R2jYdsXwYUXjgwHIV0voj7bJYPGFlFjXOp6ZW86scsHM5xfsGQoK2Fp838VT34SHE1ZXU/puM7rviREHYW72pfpgGZUILQMohuTPnd8tFtAkbrmjLDo+k9xx7HUvgoFTiNNWuq/cRjr70FKNguMMTIrid+HwfmbRoaxENWdLcOTNeascER2a+37UQolKD5ksrPJG6RdNA7O2pzp3micDYRs/+s28cCIxO//J/d4nsgHp6RTuCu4+Jm9k0YTw2Xg75b2cWKrxGnDUgyIlvNPaZTB5QbMid4x44/lE0LLi9kcPQhRgrK07OnnrMgZvVGjt1CLGhKUv7KFc3xV1r1rwKkosxnoG99oCoTQtregcX5rIMjHgkc1IdflGJkZzaWMkYVFOJ4Weynz008i4ddkske5vabZs37Lb8iggUYNBYZyGzalruBgnQyK4fz38Fae4nWYjyildVfgyo/fCePR2ovOfphx9OQJi+M9BoFmPrAg+8ARDZ+R+5yzYuEc9ZoVX7nkp7LTGB3DANBgkrBgEEAYI3EQIxADATBgkqhkiG9w0BCRUxBgQEAQAAADBXBgkqhkiG9w0BCRQxSh5IAGEAOAAwAGQAZgBmADgANgAtAGUAOQA2AGUALQA0ADIAMgA0AC0AYQBhADEAMQAtAGIAZAAxADkANABkADUAYQA2AGIANwA3MF0GCSsGAQQBgjcRATFQHk4ATQBpAGMAcgBvAHMAbwBmAHQAIABTAHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgBhAHAAaABpAGMAIABQAHIAbwB2AGkAZABlAHIwggLPBgkqhkiG9w0BBwagggLAMIICvAIBADCCArUGCSqGSIb3DQEHATAcBgoqhkiG9w0BDAEGMA4ECNX+VL2MxzzWAgIH0ICCAojmRBO+CPfVNUO0s+BVuwhOzikAGNBmQHNChmJ/pyzPbMUbx7tO63eIVSc67iERda2WCEmVwPigaVQkPaumsfp8+L6iV/BMf5RKlyRXcwh0vUdu2Qa7qadD+gFQ2kngf4Dk6vYo2/2HxayuIf6jpwe8vql4ca3ZtWXfuRix2fwgltM0bMz1g59d7x/glTfNqxNlsty0A/rWrPJjNbOPRU2XykLuc3AtlTtYsQ32Zsmu67A7UNBw6tVtkEXlFDqhavEhUEO3dvYqMY+QLxzpZhA0q44ZZ9/ex0X6QAFNK5wuWxCbupHWsgxRwKftrxyszMHsAvNoNcTlqcctee+ecNwTJQa1/MDbnhO6/qHA7cfG1qYDq8Th635vGNMW1w3sVS7l0uEvdayAsBHWTcOC2tlMa5bfHrhY8OEIqj5bN5H9RdFy8G/W239tjDu1OYjBDydiBqzBn8HG1DSj1Pjc0kd/82d4ZU0308KFTC3yGcRad0GnEH0Oi3iEJ9HbriUbfVMbXNHOF+MktWiDVqzndGMKmuJSdfTBKvGFvejAWVO5E4mgLvoaMmbchc3BO7sLeraHnJN5hvMBaLcQI38N86mUfTR8AP6AJ9c2k514KaDLclm4z6J8dMz60nUeo5D3YD09G6BavFHxSvJ8MF0Lu5zOFzEePDRFm9mH8W0N/sFlIaYfD/GWU/w44mQucjaBk95YtqOGRIj58tGDWr8iUdHwaYKGqU24zGeRae9DhFXPzZshV1ZGsBQFRaoYkyLAwdJWIXTi+c37YaC8FRSEnnNmS79Dou1Kc3BvK4EYKAD2KxjtUebrV174gD0Q+9YuJ0GXOTspBvCFd5VT2Rw5zDNrA/J3F5fMCk4wOzAfMAcGBSsOAwIaBBSxgh2xyF+88V4vAffBmZXv8Txt4AQU4O/NX4MjxSodbE7ApNAMIvrtREwCAgfQ\"; String certificatePassword = \"123\"; SecretProperties secretProperties = new SecretProperties(); secretProperties.withContentType(MIME_PKCS12); CertificatePolicy certificatePolicy = new CertificatePolicy(); certificatePolicy.withSecretProperties(secretProperties); HashSet < String > certificates = new HashSet < String > (); for(int i = 0; i < MAX_CERTS; ++ i) { int failureCount = 0; for(; ; ) { try { CertificateBundle certificateBundle = keyVaultClient.importCertificate(new ImportCertificateRequest.Builder(getVaultUri(), certificateName, certificateContent).withPassword(certificatePassword).withPolicy(certificatePolicy).build()); CertificateIdentifier id = certificateBundle.certificateIdentifier(); certificates.add(id.identifier()); break; } catch(KeyVaultErrorException e) { ++ failureCount; if(e.getBody().error().code().equals(\"Throttled\")) { System.out.println(\"Waiting to avoid throttling\"); Thread.sleep(failureCount * 1500); continue; } throw e; } } } PagedList < CertificateItem > listResult = keyVaultClient.listCertificateVersions(getVaultUri(), certificateName, PAGELIST_MAX_CERTS); Assert.assertTrue(PAGELIST_MAX_CERTS >= listResult.currentPage().getItems().size()); listResult = keyVaultClient.listCertificateVersions(getVaultUri(), certificateName); for(CertificateItem item : listResult) { if(item != null) { certificates.remove(item.id()); } } Assert.assertEquals(0, certificates.size()); keyVaultClient.deleteCertificate(getVaultUri(), certificateName); } "
    },
    {
        "test_src": "@Test public void testParseLastInt() { assertEquals( - 1, ParseUtil.parseLastInt(\"foo : bar\", - 1)); assertEquals(1, ParseUtil.parseLastInt(\"foo : 1\", 0)); assertEquals(2, ParseUtil.parseLastInt(\"foo\", 2)); assertEquals(3, ParseUtil.parseLastInt(\"max_int plus one is 2147483648\", 3)); assertEquals( - 1L, ParseUtil.parseLastLong(\"foo : bar\", - 1L)); assertEquals(1L, ParseUtil.parseLastLong(\"foo : 1\", 0L)); assertEquals(2L, ParseUtil.parseLastLong(\"foo\", 2L)); assertEquals(2147483648L, ParseUtil.parseLastLong(\"max_int plus one is 2147483648\", 3L)); double epsilon = 1.1102230246251565E-16; assertEquals( - 1d, ParseUtil.parseLastDouble(\"foo : bar\", - 1d), epsilon); assertEquals(1.0, ParseUtil.parseLastDouble(\"foo : 1.0\", 0d), epsilon); assertEquals(2d, ParseUtil.parseLastDouble(\"foo\", 2d), epsilon); } ",
        "focal_tgt": "public static int parseLastInt(String s, int i) { try { String ls = parseLastString(s); if(ls.toLowerCase().startsWith(\"0x\")) { return Integer.decode(ls); } else { return Integer.parseInt(ls); } } catch(NumberFormatException e) { LOG.trace(DEFAULT_LOG_MSG, s, e); return i; } } ",
        "focal_src": "public static int parseLastInt(String s, int i) { try { return Integer.parseInt(parseLastString(s)); } catch(NumberFormatException e) { LOG.trace(DEFAULT_LOG_MSG, s, e); return i; } } ",
        "test_tgt": "@Test public void testParseLastInt() { assertEquals( - 1, ParseUtil.parseLastInt(\"foo : bar\", - 1)); assertEquals(1, ParseUtil.parseLastInt(\"foo : 1\", 0)); assertEquals(2, ParseUtil.parseLastInt(\"foo\", 2)); assertEquals(3, ParseUtil.parseLastInt(\"max_int plus one is 2147483648\", 3)); assertEquals(255, ParseUtil.parseLastInt(\"0xff\", 4)); assertEquals( - 1L, ParseUtil.parseLastLong(\"foo : bar\", - 1L)); assertEquals(1L, ParseUtil.parseLastLong(\"foo : 1\", 0L)); assertEquals(2L, ParseUtil.parseLastLong(\"foo\", 2L)); assertEquals(2147483648L, ParseUtil.parseLastLong(\"max_int plus one is 2147483648\", 3L)); assertEquals(255L, ParseUtil.parseLastLong(\"0xff\", 0L)); double epsilon = 1.1102230246251565E-16; assertEquals( - 1d, ParseUtil.parseLastDouble(\"foo : bar\", - 1d), epsilon); assertEquals(1.0, ParseUtil.parseLastDouble(\"foo : 1.0\", 0d), epsilon); assertEquals(2d, ParseUtil.parseLastDouble(\"foo\", 2d), epsilon); } "
    },
    {
        "test_src": "@Test public void testGetUntaggedName()throws VersioningSyntaxException { VersioningService instance = new VersioningService(); String expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR + \"RC-\" + VersioningService.EXPRESSION_WILDCARD; String result = instance.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR + \"RC-1.0.0\"; result = instance.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME; result = instance.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR; try { result = instance.getUntaggedName(expression); fail(\"the getUntagged method did not throw a VersioningSyntaxException\"); } catch(VersioningSyntaxException e) { } } ",
        "focal_tgt": "public static final String getUntaggedName(String appName)throws VersioningSyntaxException { if(appName != null && ! appName.isEmpty()) { int colonIndex = appName.indexOf(EXPRESSION_SEPARATOR); if(colonIndex != - 1) { if(colonIndex == (appName.length() - 1)) { throw new VersioningSyntaxException(LOCALSTRINGS.getLocalString(\"invalid.appname\", \"excepted version identifier after colon: {0}\", appName)); } return appName.substring(0, colonIndex); } } return appName; } ",
        "focal_src": "public final String getUntaggedName(String appName)throws VersioningSyntaxException { int colonIndex = appName.indexOf(EXPRESSION_SEPARATOR); if(colonIndex != - 1) { if(colonIndex == (appName.length() - 1)) { throw new VersioningSyntaxException(LOCALSTRINGS.getLocalString(\"invalid.appname\", \"excepted version identifier after colon: {0}\", appName)); } return appName.substring(0, colonIndex); } return appName; } ",
        "test_tgt": "@Test public void testGetUntaggedName()throws VersioningSyntaxException { String expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR + \"RC-\" + VersioningService.EXPRESSION_WILDCARD; String result = VersioningService.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR + \"RC-1.0.0\"; result = VersioningService.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME; result = VersioningService.getUntaggedName(expression); assertEquals(APPLICATION_NAME, result); expression = APPLICATION_NAME + VersioningService.EXPRESSION_SEPARATOR; try { result = VersioningService.getUntaggedName(expression); fail(\"the getUntagged method did not throw a VersioningSyntaxException\"); } catch(VersioningSyntaxException e) { } } "
    },
    {
        "test_src": "@Test@RunTestInLooperThread public void findFirstAsync_retry()throws Throwable { final AtomicInteger numberOfIntercept = new AtomicInteger(0); final Realm realm = looperThread.realm; populateTestRealm(realm, 10); final Handler handler = new HandlerProxy(realm.handlerController) { @Override public boolean onInterceptInMessage(int what) { int intercepts = numberOfIntercept.incrementAndGet(); switch(what) { case HandlerController.COMPLETED_ASYNC_REALM_OBJECT : { if(intercepts == 1) { realm.beginTransaction(); realm.delete(AllTypes.class); AllTypes object = realm.createObject(AllTypes.class); object.setColumnString(\"The Endless River\"); object.setColumnLong(5); realm.commitTransaction(); } } } return false; } }; realm.setHandler(handler); final AllTypes realmResults = realm.where(AllTypes.class).between(\"columnLong\", 4, 6).findFirstAsync(); assertFalse(realmResults.isLoaded()); try { realmResults.getColumnString(); fail(\"Accessing property on an empty row\"); } catch(IllegalStateException ignored) { } realmResults.addChangeListener(new RealmChangeListener < AllTypes > () { @Override public void onChange(AllTypes object) { assertEquals(3, numberOfIntercept.get()); assertTrue(realmResults.isLoaded()); assertEquals(5, realmResults.getColumnLong()); assertEquals(\"The Endless River\", realmResults.getColumnString()); looperThread.testComplete(); } }); } ",
        "focal_tgt": "public E findFirstAsync() { checkQueryIsNotReused(); final WeakReference < Handler > weakHandler = getWeakReferenceHandler(); final long handoverQueryPointer = query.handoverQuery(realm.sharedGroupManager.getNativePointer()); argumentsHolder = new ArgumentsHolder(ArgumentsHolder.TYPE_FIND_FIRST); final RealmConfiguration realmConfiguration = realm.getConfiguration(); final E result; if(isDynamicQuery()) { result = (E)new DynamicRealmObject(className); } else { result = realm.getConfiguration().getSchemaMediator().newInstance(clazz, realm.getSchema().getColumnInfo(clazz)); } RealmObjectProxy proxy = (RealmObjectProxy)result; final WeakReference < RealmObjectProxy > realmObjectWeakReference = realm.handlerController.addToAsyncRealmObject(proxy, this); proxy.realmGet$proxyState().setRealm$realm(realm); proxy.realmGet$proxyState().setRow$realm(Row.EMPTY_ROW); final Future < Long > pendingQuery = Realm.asyncTaskExecutor.submitQuery(new Callable < Long > () { @Override public Long call()throws Exception { if( ! Thread.currentThread().isInterrupted()) { SharedGroup sharedGroup = null; try { sharedGroup = new SharedGroup(realmConfiguration.getPath(), SharedGroup.IMPLICIT_TRANSACTION, realmConfiguration.getDurability(), realmConfiguration.getEncryptionKey()); long handoverRowPointer = query.findWithHandover(sharedGroup.getNativePointer(), sharedGroup.getNativeReplicationPointer(), handoverQueryPointer); if(handoverRowPointer == 0) { realm.handlerController.addToEmptyAsyncRealmObject(realmObjectWeakReference, RealmQuery.this); realm.handlerController.removeFromAsyncRealmObject(realmObjectWeakReference); } QueryUpdateTask.Result result = QueryUpdateTask.Result.newRealmObjectResponse(); result.updatedRow.put(realmObjectWeakReference, handoverRowPointer); result.versionID = sharedGroup.getVersion(); closeSharedGroupAndSendMessageToHandler(sharedGroup, weakHandler, HandlerControllerConstants.COMPLETED_ASYNC_REALM_OBJECT, result); return handoverRowPointer; } catch(Throwable e) { RealmLog.e(e.getMessage(), e); closeSharedGroupAndSendMessageToHandler(sharedGroup, weakHandler, HandlerControllerConstants.REALM_ASYNC_BACKGROUND_EXCEPTION, new Error(e)); } finally { if(sharedGroup != null && ! sharedGroup.isClosed()) { sharedGroup.close(); } } } else { TableQuery.nativeCloseQueryHandover(handoverQueryPointer); } return INVALID_NATIVE_POINTER; } }); proxy.realmGet$proxyState().setPendingQuery$realm(pendingQuery); return result; } ",
        "focal_src": "public E findFirstAsync() { checkQueryIsNotReused(); final WeakReference < Handler > weakHandler = getWeakReferenceHandler(); final long handoverQueryPointer = query.handoverQuery(realm.sharedGroupManager.getNativePointer()); argumentsHolder = new ArgumentsHolder(ArgumentsHolder.TYPE_FIND_FIRST); final RealmConfiguration realmConfiguration = realm.getConfiguration(); final E result; if(isDynamicQuery()) { result = (E)new DynamicRealmObject(className); } else { result = realm.getConfiguration().getSchemaMediator().newInstance(clazz, realm.getSchema().getColumnInfo(clazz)); } RealmObjectProxy proxy = (RealmObjectProxy)result; final WeakReference < RealmObjectProxy > realmObjectWeakReference = realm.handlerController.addToAsyncRealmObject(proxy, this); proxy.realmGet$proxyState().setRealm$realm(realm); proxy.realmGet$proxyState().setRow$realm(Row.EMPTY_ROW); final Future < Long > pendingQuery = Realm.asyncTaskExecutor.submitQuery(new Callable < Long > () { @Override public Long call()throws Exception { if( ! Thread.currentThread().isInterrupted()) { SharedGroup sharedGroup = null; try { sharedGroup = new SharedGroup(realmConfiguration.getPath(), SharedGroup.IMPLICIT_TRANSACTION, realmConfiguration.getDurability(), realmConfiguration.getEncryptionKey()); long handoverRowPointer = query.findWithHandover(sharedGroup.getNativePointer(), sharedGroup.getNativeReplicationPointer(), handoverQueryPointer); if(handoverRowPointer == 0) { realm.handlerController.addToEmptyAsyncRealmObject(realmObjectWeakReference, RealmQuery.this); realm.handlerController.removeFromAsyncRealmObject(realmObjectWeakReference); } QueryUpdateTask.Result result = QueryUpdateTask.Result.newRealmObjectResponse(); result.updatedRow.put(realmObjectWeakReference, handoverRowPointer); result.versionID = sharedGroup.getVersion(); closeSharedGroupAndSendMessageToHandler(sharedGroup, weakHandler, HandlerController.COMPLETED_ASYNC_REALM_OBJECT, result); return handoverRowPointer; } catch(Exception e) { RealmLog.e(e.getMessage(), e); closeSharedGroupAndSendMessageToHandler(sharedGroup, weakHandler, HandlerController.REALM_ASYNC_BACKGROUND_EXCEPTION, new Error(e)); } finally { if(sharedGroup != null && ! sharedGroup.isClosed()) { sharedGroup.close(); } } } else { TableQuery.nativeCloseQueryHandover(handoverQueryPointer); } return INVALID_NATIVE_POINTER; } }); proxy.realmGet$proxyState().setPendingQuery$realm(pendingQuery); return result; } ",
        "test_tgt": "@Test@RunTestInLooperThread public void findFirstAsync_retry()throws Throwable { final AtomicInteger numberOfIntercept = new AtomicInteger(0); final Realm realm = looperThread.realm; populateTestRealm(realm, 10); final Handler handler = new HandlerProxy(realm.handlerController) { @Override public boolean onInterceptInMessage(int what) { int intercepts = numberOfIntercept.incrementAndGet(); switch(what) { case HandlerControllerConstants.COMPLETED_ASYNC_REALM_OBJECT : { if(intercepts == 1) { realm.beginTransaction(); realm.delete(AllTypes.class); AllTypes object = realm.createObject(AllTypes.class); object.setColumnString(\"The Endless River\"); object.setColumnLong(5); realm.commitTransaction(); } } } return false; } }; realm.setHandler(handler); final AllTypes realmResults = realm.where(AllTypes.class).between(\"columnLong\", 4, 6).findFirstAsync(); assertFalse(realmResults.isLoaded()); try { realmResults.getColumnString(); fail(\"Accessing property on an empty row\"); } catch(IllegalStateException ignored) { } realmResults.addChangeListener(new RealmChangeListener < AllTypes > () { @Override public void onChange(AllTypes object) { assertEquals(3, numberOfIntercept.get()); assertTrue(realmResults.isLoaded()); assertEquals(5, realmResults.getColumnLong()); assertEquals(\"The Endless River\", realmResults.getColumnString()); looperThread.testComplete(); } }); } "
    },
    {
        "test_src": "@Test public void assrt() { query(_XQUNIT_ASSERT.args(\"1\"), \"\"); query(_XQUNIT_ASSERT.args(\"(<a/>,<b/>)\"), \"\"); error(_XQUNIT_ASSERT.args(\"()\"), Err.BXUN_ASSERT); error(_XQUNIT_ASSERT.args(\"()\", \"X\"), Err.BXUN_ERROR); } ",
        "focal_tgt": "private Item assrt(final QueryContext ctx)throws QueryException { final byte[]str = expr.length < 2 ? null : checkStr(expr[1], ctx); if(expr[0].ebv(ctx, info).bool(info))return null; throw str == null ? UNIT_ASSERT.thrw(info) : UNIT_MESSAGE.thrw(info, str); } ",
        "focal_src": "private Item assrt(final QueryContext ctx)throws QueryException { final byte[]str = expr.length < 2 ? null : checkStr(expr[1], ctx); if(expr[0].ebv(ctx, info).bool(info))return null; throw str == null ? BXUN_ASSERT.thrw(info) : BXUN_ERROR.thrw(info, str); } ",
        "test_tgt": "@Test public void assrt() { query(_XQUNIT_ASSERT.args(\"1\"), \"\"); query(_XQUNIT_ASSERT.args(\"(<a/>,<b/>)\"), \"\"); error(_XQUNIT_ASSERT.args(\"()\"), Err.UNIT_ASSERT); error(_XQUNIT_ASSERT.args(\"()\", \"X\"), Err.UNIT_MESSAGE); } "
    },
    {
        "test_src": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorTrainingParameters(null); Modeler instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(trainingData); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); trainingData.delete(); validationData.delete(); } ",
        "focal_tgt": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(ML.AbstractTrainingParameters modelerTrainingParameters, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = Configuration.getConfiguration(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(dataset); instance.save(); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(TextClassifier.class, dbName, conf); Dataframe validationData; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "focal_src": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(Class < ML > modelerClass, ML.AbstractTrainingParameters modelerTrainingParameters, Class < FS > featureSelectorClass, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = Configuration.getConfiguration(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(dataset); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(TextClassifier.class, dbName, conf); Dataframe validationData = null; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "test_tgt": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorTrainingParameters(null); Modeler instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(trainingData); instance.save(); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); trainingData.delete(); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); validationData.delete(); } "
    },
    {
        "test_src": "@Test public void getCompressorInstance() { File file = new File(\"/test/test.zip\"); Decompressor result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.jar\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.apk\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.tar\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), TarDecompressor.class); file = new File(\"/test/test.tar.gz\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), GzipDecompressor.class); file = new File(\"/test/test.rar\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), RarDecompressor.class); file = new File(\"/test/test.7z\"); result = CompressedHelper.getCompressorInstance(context, file); assertEquals(result.getClass(), SevenZipDecompressor.class); } ",
        "focal_tgt": "public static Decompressor getCompressorInstance(@NonNull Context context, @NonNull File file, @Nullable String password) { Decompressor decompressor; String type = getExtension(file.getPath()); if(isZip(type)) { decompressor = new ZipDecompressor(context); } else if(isRar(type)) { decompressor = new RarDecompressor(context); } else if(isTar(type)) { decompressor = new TarDecompressor(context); } else if(isGzippedTar(type)) { decompressor = new GzipDecompressor(context); } else if(isBzippedTar(type)) { decompressor = new Bzip2Decompressor(context); } else if(isXzippedTar(type)) { decompressor = new XzDecompressor(context); } else if(isLzippedTar(type)) { decompressor = new LzmaDecompressor(context); } else if(is7zip(type)) { decompressor = new SevenZipDecompressor(context, password); } else { return null; } decompressor.setFilePath(file.getPath()); return decompressor; } ",
        "focal_src": "public static Decompressor getCompressorInstance(Context context, File file) { Decompressor decompressor; String type = getExtension(file.getPath()); if(isZip(type)) { decompressor = new ZipDecompressor(context); } else if(isRar(type)) { decompressor = new RarDecompressor(context); } else if(isTar(type)) { decompressor = new TarDecompressor(context); } else if(isGzippedTar(type)) { decompressor = new GzipDecompressor(context); } else if(isBzippedTar(type)) { decompressor = new Bzip2Decompressor(context); } else if(isXzippedTar(type)) { decompressor = new XzDecompressor(context); } else if(isLzippedTar(type)) { decompressor = new LzmaDecompressor(context); } else if(is7zip(type)) { decompressor = new SevenZipDecompressor(context); } else { return null; } decompressor.setFilePath(file.getPath()); return decompressor; } ",
        "test_tgt": "@Test public void getCompressorInstance() { File file = new File(\"/test/test.zip\"); Decompressor result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.jar\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.apk\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), ZipDecompressor.class); file = new File(\"/test/test.tar\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), TarDecompressor.class); file = new File(\"/test/test.tar.gz\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), GzipDecompressor.class); file = new File(\"/test/test.rar\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), RarDecompressor.class); file = new File(\"/test/test.7z\"); result = CompressedHelper.getCompressorInstance(context, file, null); assertEquals(result.getClass(), SevenZipDecompressor.class); } "
    },
    {
        "test_src": "@Test public void testDelete()throws BaseXException { new RepoInstall(REPO + \"pkg3.xar\", null).execute(ctx); assertNotNull(ctx.repo.pkgDict().id(token(\"pkg3-10.0\")) != 0); final File pkgDir1 = new File(REPO + \"pkg3\"); assertTrue(pkgDir1.exists()); assertTrue(pkgDir1.isDirectory()); final File pkgDesc1 = new File(REPO + \"pkg3/expath-pkg.xml\"); assertTrue(pkgDesc1.exists()); final File modDir1 = new File(REPO + \"pkg3/pkg3/mod\"); assertTrue(modDir1.exists()); assertTrue(modDir1.isDirectory()); final File modFile1 = new File(REPO + \"pkg3/pkg3/mod/pkg3mod1.xql\"); assertTrue(modFile1.exists()); new RepoInstall(REPO + \"pkg4.xar\", null).execute(ctx); assertNotNull(ctx.repo.pkgDict().id(token(\"pkg4-2.0\")) != 0); final File pkgDir2 = new File(REPO + \"pkg4\"); assertTrue(pkgDir2.exists()); assertTrue(pkgDir2.isDirectory()); final File pkgDesc2 = new File(REPO + \"pkg4/expath-pkg.xml\"); assertTrue(pkgDesc2.exists()); final File modDir2 = new File(REPO + \"pkg4/pkg4/mod\"); assertTrue(modDir2.exists()); assertTrue(modDir2.isDirectory()); final File modFile2 = new File(REPO + \"pkg4/pkg4/mod/pkg4mod1.xql\"); assertTrue(modFile2.exists()); try { new RepoManager(ctx).delete(\"pkg3\", null); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(ex, Err.PKGDEP); } new RepoDelete(\"http://www.pkg4.com\", null).execute(ctx); assertTrue(ctx.repo.pkgDict().id(token(\"pkg4-2.0\")) == 0); assertTrue( ! pkgDir2.exists()); new RepoDelete(\"pkg3\", null).execute(ctx); assertTrue(ctx.repo.pkgDict().id(token(\"pkg3-10.0\")) == 0); assertTrue( ! pkgDir1.exists()); } ",
        "focal_tgt": "public void delete(final String pkg, final InputInfo ii)throws QueryException { boolean found = false; for(final byte[]nextPkg : ctx.repo.pkgDict()) { if(nextPkg != null) { final byte[]dir = ctx.repo.pkgDict().get(nextPkg); if(eq(Package.getName(nextPkg), token(pkg)) || eq(dir, token(pkg))) { found = true; final byte[]primPkg = getPrimary(nextPkg, ii); if(primPkg == null) { final File f = new File(ctx.prop.get(Prop.REPOPATH), string(dir)); final File desc = new File(f, DESCRIPTOR); ctx.repo.remove(new PkgParser(ctx, ii).parse(new IOFile(desc))); deleteFromDisc(f, ii); } else PKGDEP.thrw(ii, string(primPkg), pkg); } } } if( ! found)PKGNOTINST.thrw(ii, pkg); } ",
        "focal_src": "public void delete(final String pkg, final InputInfo ii)throws QueryException { for(final byte[]nextPkg : ctx.repo.pkgDict()) { if(nextPkg != null) { final byte[]dir = ctx.repo.pkgDict().get(nextPkg); if(eq(Package.getName(nextPkg), token(pkg)) || eq(dir, token(pkg))) { final byte[]primPkg = getPrimary(nextPkg, ii); if(primPkg == null) { final File f = new File(ctx.prop.get(Prop.REPOPATH), string(dir)); final File desc = new File(f, DESCRIPTOR); ctx.repo.remove(new PkgParser(ctx, ii).parse(new IOFile(desc))); deleteFromDisc(f, ii); } else { PKGDEP.thrw(ii, string(primPkg), pkg); } } } } } ",
        "test_tgt": "@Test public void testDelete()throws BaseXException { try { new RepoManager(ctx).delete(\"xyz\", null); fail(\"Not installed package not detected.\"); } catch(QueryException ex) { check(ex, Err.PKGNOTINST); } new RepoInstall(REPO + \"pkg3.xar\", null).execute(ctx); assertNotNull(ctx.repo.pkgDict().id(token(\"pkg3-10.0\")) != 0); final File pkgDir1 = new File(REPO + \"pkg3\"); assertTrue(pkgDir1.exists()); assertTrue(pkgDir1.isDirectory()); final File pkgDesc1 = new File(REPO + \"pkg3/expath-pkg.xml\"); assertTrue(pkgDesc1.exists()); final File modDir1 = new File(REPO + \"pkg3/pkg3/mod\"); assertTrue(modDir1.exists()); assertTrue(modDir1.isDirectory()); final File modFile1 = new File(REPO + \"pkg3/pkg3/mod/pkg3mod1.xql\"); assertTrue(modFile1.exists()); new RepoInstall(REPO + \"pkg4.xar\", null).execute(ctx); assertNotNull(ctx.repo.pkgDict().id(token(\"pkg4-2.0\")) != 0); final File pkgDir2 = new File(REPO + \"pkg4\"); assertTrue(pkgDir2.exists()); assertTrue(pkgDir2.isDirectory()); final File pkgDesc2 = new File(REPO + \"pkg4/expath-pkg.xml\"); assertTrue(pkgDesc2.exists()); final File modDir2 = new File(REPO + \"pkg4/pkg4/mod\"); assertTrue(modDir2.exists()); assertTrue(modDir2.isDirectory()); final File modFile2 = new File(REPO + \"pkg4/pkg4/mod/pkg4mod1.xql\"); assertTrue(modFile2.exists()); try { new RepoManager(ctx).delete(\"pkg3\", null); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(ex, Err.PKGDEP); } new RepoDelete(\"http://www.pkg4.com\", null).execute(ctx); assertTrue(ctx.repo.pkgDict().id(token(\"pkg4-2.0\")) == 0); assertTrue( ! pkgDir2.exists()); new RepoDelete(\"pkg3\", null).execute(ctx); assertTrue(ctx.repo.pkgDict().id(token(\"pkg3-10.0\")) == 0); assertTrue( ! pkgDir1.exists()); } "
    },
    {
        "test_src": "@Test public void delete()throws BaseXException { try { new RepoManager(context).delete(\"xyz\"); fail(\"Not installed package not detected.\"); } catch(final QueryException ex) { check(ex, Err.PKGNOTEXIST); } new RepoInstall(REPO + \"pkg3.xar\", null).execute(context); assertTrue(context.repo.pkgDict().contains(token(PKG3ID))); final String pkg3Dir = normalize(PKG3ID); assertTrue(dir(pkg3Dir)); assertTrue(file(pkg3Dir + \"/expath-pkg.xml\")); assertTrue(dir(pkg3Dir + \"/pkg3\")); assertTrue(dir(pkg3Dir + \"/pkg3/mod\")); assertTrue(file(pkg3Dir + \"/pkg3/mod/pkg3mod1.xql\")); new RepoInstall(REPO + \"pkg4.xar\", null).execute(context); assertTrue(context.repo.pkgDict().contains(token(PKG4ID))); final String pkg4Dir = normalize(PKG4ID); assertTrue(dir(pkg4Dir)); assertTrue(file(pkg4Dir + \"/expath-pkg.xml\")); assertTrue(dir(pkg4Dir + \"/pkg4\")); assertTrue(dir(pkg4Dir + \"/pkg4/mod\")); assertTrue(file(pkg4Dir + \"/pkg4/mod/pkg4mod1.xql\")); try { new RepoManager(context).delete(PKG3ID); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(ex, Err.PKGDEP); } new RepoDelete(PKG4, null).execute(context); assertFalse(context.repo.pkgDict().contains(token(PKG4ID))); assertTrue( ! dir(pkg4Dir)); new RepoDelete(PKG3ID, null).execute(context); assertFalse(context.repo.pkgDict().contains(token(PKG3ID))); assertTrue( ! dir(pkg3Dir)); } ",
        "focal_tgt": "public void delete(final byte[]pkg)throws QueryException { boolean found = false; final TokenMap dict = repo.pkgDict(); for(final byte[]nextPkg : dict) { if(nextPkg == null)continue; if(eq(nextPkg, pkg) || eq(Package.name(nextPkg), pkg)) { final byte[]primPkg = primary(nextPkg); if(primPkg != null)PKGDEP.thrw(info, string(primPkg), pkg); final IOFile f = repo.path(string(dict.get(nextPkg))); repo.delete(new PkgParser(repo, info).parse(new IOFile(f, DESCRIPTOR))); if( ! f.delete())PKGDEL.thrw(info, f); found = true; } } final IOFile file = file(pkg, repo); if(file != null) { if( ! file.delete())PKGDEL.thrw(info, file); return; } if( ! found)PKGNOTEXIST.thrw(info, pkg); } ",
        "focal_src": "public void delete(final String pkg)throws QueryException { final byte[]pk = token(pkg); boolean found = false; final TokenMap dict = repo.pkgDict(); for(final byte[]nextPkg : dict) { if(nextPkg == null)continue; if(eq(nextPkg, pk) || eq(Package.name(nextPkg), pk)) { final byte[]primPkg = primary(nextPkg); if(primPkg != null)PKGDEP.thrw(info, string(primPkg), pkg); final IOFile f = repo.path(string(dict.get(nextPkg))); repo.delete(new PkgParser(repo, info).parse(new IOFile(f, DESCRIPTOR))); if( ! f.delete())PKGDEL.thrw(info, f); found = true; } } final IOFile file = file(pkg, repo); if(file != null) { if( ! file.delete())PKGDEL.thrw(info, file); return; } if( ! found)PKGNOTEXIST.thrw(info, pkg); } ",
        "test_tgt": "@Test public void delete()throws BaseXException { try { new RepoManager(context).delete(token(\"xyz\")); fail(\"Not installed package not detected.\"); } catch(final QueryException ex) { check(ex, Err.PKGNOTEXIST); } new RepoInstall(REPO + \"pkg3.xar\", null).execute(context); assertTrue(context.repo.pkgDict().contains(token(PKG3ID))); final String pkg3Dir = normalize(PKG3ID); assertTrue(dir(pkg3Dir)); assertTrue(file(pkg3Dir + \"/expath-pkg.xml\")); assertTrue(dir(pkg3Dir + \"/pkg3\")); assertTrue(dir(pkg3Dir + \"/pkg3/mod\")); assertTrue(file(pkg3Dir + \"/pkg3/mod/pkg3mod1.xql\")); new RepoInstall(REPO + \"pkg4.xar\", null).execute(context); assertTrue(context.repo.pkgDict().contains(token(PKG4ID))); final String pkg4Dir = normalize(PKG4ID); assertTrue(dir(pkg4Dir)); assertTrue(file(pkg4Dir + \"/expath-pkg.xml\")); assertTrue(dir(pkg4Dir + \"/pkg4\")); assertTrue(dir(pkg4Dir + \"/pkg4/mod\")); assertTrue(file(pkg4Dir + \"/pkg4/mod/pkg4mod1.xql\")); try { new RepoManager(context).delete(token(PKG3ID)); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(ex, Err.PKGDEP); } new RepoDelete(PKG4, null).execute(context); assertFalse(context.repo.pkgDict().contains(token(PKG4ID))); assertTrue( ! dir(pkg4Dir)); new RepoDelete(PKG3ID, null).execute(context); assertFalse(context.repo.pkgDict().contains(token(PKG3ID))); assertTrue( ! dir(pkg3Dir)); } "
    },
    {
        "test_src": "@Test public void saveEncounter_shouldCascadeSaveToContainedObs() { EncounterService es = Context.getEncounterService(); Encounter enc = buildEncounter(); Obs groupObs = new Obs(); Concept c = Context.getConceptService().getConcept(1); groupObs.setConcept(c); Obs childObs = new Obs(); childObs.setConcept(c); childObs.setValueNumeric(50d); groupObs.addGroupMember(childObs); enc.addObs(groupObs); assertNotNull(\"save succeeds without error\", es.saveEncounter(enc)); assertTrue(\"enc save succeeds\", enc.getId() > 0); assertNotNull(\"obs save succeeds\", groupObs.getObsId()); assertEquals(\"encounter id propogated\", groupObs.getEncounter().getId(), enc.getId()); assertEquals(\"encounter time propogated\", groupObs.getObsDatetime(), enc.getEncounterDatetime()); assertNotNull(\"obs save succeeds\", childObs.getObsId()); assertEquals(\"encounter id propogated\", childObs.getEncounter().getId(), enc.getId()); assertEquals(\"encounter time propogated\", childObs.getObsDatetime(), enc.getEncounterDatetime()); } ",
        "focal_tgt": "@Override public Encounter saveEncounter(Encounter encounter)throws APIException { failIfDeniedToEdit(encounter); createVisitForNewEncounter(encounter); boolean isNewEncounter = requirePrivilege(encounter); Patient p = encounter.getPatient(); Date originalDate; Location originalLocation = null; if( ! isNewEncounter) { originalDate = dao.getSavedEncounterDatetime(encounter); if(encounter.getLocation() != null) { originalLocation = dao.getSavedEncounterLocation(encounter); } Date newDate = encounter.getEncounterDatetime(); Location newLocation = encounter.getLocation(); for(Obs obs : encounter.getAllFlattenedObs(true)) { if(OpenmrsUtil.compare(originalDate, newDate) != 0 && OpenmrsUtil.compare(obs.getObsDatetime(), originalDate) == 0) { obs.setObsDatetime(newDate); } if( ! OpenmrsUtil.nullSafeEquals(newLocation, originalLocation) && obs.getLocation().equals(originalLocation)) { obs.setLocation(newLocation); } if( ! obs.getPerson().getPersonId().equals(p.getPatientId())) { obs.setPerson(p); } } } for(Order o : encounter.getOrders()) { if( ! p.equals(o.getPatient())) { o.setPatient(p); } } dao.saveEncounter(encounter); for(OrderGroup orderGroup : encounter.getOrderGroups()) { Context.getOrderService().saveOrderGroup(orderGroup); } for(Order o : encounter.getOrdersWithoutOrderGroups()) { if(o.getOrderId() == null) { Context.getOrderService().saveOrder(o, null); } } String changeMessage = Context.getMessageSourceService().getMessage(\"Obs.void.reason.default\"); ObsService os = Context.getObsService(); List < Obs > obsToRemove = new ArrayList < > (); List < Obs > obsToAdd = new ArrayList < > (); for(Obs o : encounter.getObsAtTopLevel(true)) { if(o.getId() == null) { os.saveObs(o, null); } else { Obs newObs = os.saveObs(o, changeMessage); obsToRemove.add(o); obsToAdd.add(os.getObs(o.getId())); obsToAdd.add(newObs); } } removeGivenObsAndTheirGroupMembersFromEncounter(obsToRemove, encounter); addGivenObsAndTheirGroupMembersToEncounter(obsToAdd, encounter); return encounter; } ",
        "focal_src": "@Override public Encounter saveEncounter(Encounter encounter)throws APIException { failIfDeniedToEdit(encounter); createVisitForNewEncounter(encounter); boolean isNewEncounter = requirePrivilege(encounter); Patient p = encounter.getPatient(); Date originalDate; Location originalLocation = null; if( ! isNewEncounter) { originalDate = dao.getSavedEncounterDatetime(encounter); if(encounter.getLocation() != null) { originalLocation = dao.getSavedEncounterLocation(encounter); } Date newDate = encounter.getEncounterDatetime(); Location newLocation = encounter.getLocation(); for(Obs obs : encounter.getAllObs(true)) { if(OpenmrsUtil.compare(originalDate, newDate) != 0 && OpenmrsUtil.compare(obs.getObsDatetime(), originalDate) == 0) { obs.setObsDatetime(newDate); } if( ! OpenmrsUtil.nullSafeEquals(newLocation, originalLocation) && obs.getLocation().equals(originalLocation)) { obs.setLocation(newLocation); } if( ! obs.getPerson().getPersonId().equals(p.getPatientId())) { obs.setPerson(p); } } } for(Order o : encounter.getOrders()) { if( ! p.equals(o.getPatient())) { o.setPatient(p); } } dao.saveEncounter(encounter); for(OrderGroup orderGroup : encounter.getOrderGroups()) { Context.getOrderService().saveOrderGroup(orderGroup); } for(Order o : encounter.getOrdersWithoutOrderGroups()) { if(o.getOrderId() == null) { Context.getOrderService().saveOrder(o, null); } } String changeMessage = Context.getMessageSourceService().getMessage(\"Obs.void.reason.default\"); ObsService os = Context.getObsService(); List < Obs > obsToRemove = new ArrayList < > (); List < Obs > obsToAdd = new ArrayList < > (); for(Obs o : encounter.getObsAtTopLevel(true)) { if(o.getId() == null) { os.saveObs(o, null); } else { Obs newObs = os.saveObs(o, changeMessage); obsToRemove.add(o); obsToAdd.add(os.getObs(o.getId())); obsToAdd.add(newObs); } } removeGivenObsAndTheirGroupMembersFromEncounter(obsToRemove, encounter); addGivenObsAndTheirGroupMembersToEncounter(obsToAdd, encounter); return encounter; } ",
        "test_tgt": "@Test public void saveEncounter_shouldCascadeSaveToContainedObs() { EncounterService es = Context.getEncounterService(); Encounter enc = buildEncounter(); Obs groupObs = new Obs(); Concept c = Context.getConceptService().getConcept(1); groupObs.setConcept(c); Obs childObs = new Obs(); childObs.setConcept(c); childObs.setValueNumeric(50d); groupObs.addGroupMember(childObs); enc.addObs(groupObs); assertNotNull(\"save succeeds without error\", es.saveEncounter(enc)); assertTrue(\"enc save succeeds\", enc.getId() > 0); assertNotNull(\"obs save succeeds\", groupObs.getObsId()); assertEquals(\"encounter id propogated\", groupObs.getEncounter().getId(), enc.getId()); assertEquals(\"encounter time propogated\", groupObs.getObsDatetime(), enc.getEncounterDatetime()); assertNotNull(\"obs save succeeds\", childObs.getObsId()); assertEquals(\"encounter id propogated\", childObs.getEncounter().getId(), enc.getId()); assertEquals(\"encounter time propogated\", childObs.getObsDatetime(), enc.getEncounterDatetime()); } "
    },
    {
        "test_src": "@Test public void resetTest()throws Exception { final int PORT_0 = 9000; Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, PORT_0); CorfuRuntime corfuRuntime = createDefaultRuntime(); incrementClusterEpoch(corfuRuntime); corfuRuntime.getRouter(\"localhost:9000\").getClient(BaseClient.class).reset().get(); corfuRuntime = createDefaultRuntime(); for(int i = 0; i < PARAMETERS.NUM_ITERATIONS_MODERATE; i ++ ) { if(corfuRuntime.getLayoutView().getLayout().getEpoch() == 0L) { break; } Thread.sleep(PARAMETERS.TIMEOUT_SHORT.toMillis()); corfuRuntime = createDefaultRuntime(); } assertThat(corfuRuntime.getLayoutView().getLayout().getEpoch()).isEqualTo(0L); assertThat(shutdownCorfuServer(corfuServer)).isTrue(); } ",
        "focal_tgt": "public CompletableFuture < Boolean > reset() { return router.sendMessageAndGetCompletable(new CorfuMsg(CorfuMsgType.RESET).setEpoch(epoch)); } ",
        "focal_src": "public CompletableFuture < Boolean > reset() { return router.sendMessageAndGetCompletable(new CorfuMsg(CorfuMsgType.RESET)); } ",
        "test_tgt": "@Test public void resetTest()throws Exception { final int PORT_0 = 9000; Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, PORT_0); CorfuRuntime corfuRuntime = createDefaultRuntime(); incrementClusterEpoch(corfuRuntime); corfuRuntime.getLayoutView().getEpochedClient().getBaseClient(\"localhost:9000\").reset().get(); corfuRuntime = createDefaultRuntime(); for(int i = 0; i < PARAMETERS.NUM_ITERATIONS_MODERATE; i ++ ) { if(corfuRuntime.getLayoutView().getLayout().getEpoch() == 0L) { break; } Thread.sleep(PARAMETERS.TIMEOUT_SHORT.toMillis()); corfuRuntime = createDefaultRuntime(); } assertThat(corfuRuntime.getLayoutView().getLayout().getEpoch()).isEqualTo(0L); assertThat(shutdownCorfuServer(corfuServer)).isTrue(); } "
    },
    {
        "test_src": "@Test public void testUpdate() { UpdatesStrategy < SmoothParametrized, SimpleGDParameterUpdate > updatesStgy = new UpdatesStrategy < > (new SimpleGDUpdateCalculator(0.2), SimpleGDParameterUpdate :: sumLocal, SimpleGDParameterUpdate :: avg); Map < Integer, double[][] > xorData = new HashMap < > (); xorData.put(0, new double[][] { { 0.0, 0.0 }, { 0.0 } }); xorData.put(1, new double[][] { { 0.0, 1.0 }, { 1.0 } }); xorData.put(2, new double[][] { { 1.0, 0.0 }, { 1.0 } }); xorData.put(3, new double[][] { { 1.0, 1.0 }, { 0.0 } }); MLPArchitecture arch = new MLPArchitecture(2).withAddedLayer(10, true, Activators.RELU).withAddedLayer(1, false, Activators.SIGMOID); MLPTrainer < SimpleGDParameterUpdate > trainer = new MLPTrainer < > (arch, LossFunctions.MSE, updatesStgy, 3000, batchSize, 50, 123L); MultilayerPerceptron originalMdl = trainer.fit(xorData, parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); MultilayerPerceptron updatedOnSameDS = trainer.update(originalMdl, xorData, parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); MultilayerPerceptron updatedOnEmptyDS = trainer.update(originalMdl, new HashMap < Integer, double[][] > (), parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); DenseMatrix matrix = new DenseMatrix(new double[][] { { 0.0, 0.0 }, { 0.0, 1.0 }, { 1.0, 0.0 }, { 1.0, 1.0 } }); TestUtils.checkIsInEpsilonNeighbourhood(originalMdl.apply(matrix).getRow(0), updatedOnSameDS.apply(matrix).getRow(0), 1E-1); TestUtils.checkIsInEpsilonNeighbourhood(originalMdl.apply(matrix).getRow(0), updatedOnEmptyDS.apply(matrix).getRow(0), 1E-1); } ",
        "focal_tgt": "public < K, V > List < IgniteModel < Vector, Double > > update(GDBTrainer.GDBModel mdlToUpdate, DatasetBuilder < K, V > datasetBuilder, IgniteBiFunction < K, V, Vector > featureExtractor, IgniteBiFunction < K, V, Double > lbExtractor) { if(trainerEnvironment == null)throw new IllegalStateException(\"Learning environment builder is not set.\"); List < IgniteModel < Vector, Double > > models = initLearningState(mdlToUpdate); ConvergenceChecker < K, V > convCheck = checkConvergenceStgyFactory.create(sampleSize, externalLbToInternalMapping, loss, datasetBuilder, featureExtractor, lbExtractor); DatasetTrainer < ? extends IgniteModel < Vector, Double > , Double > trainer = baseMdlTrainerBuilder.get(); for(int i = 0; i < cntOfIterations; i ++ ) { double[]weights = Arrays.copyOf(compositionWeights, models.size()); WeightedPredictionsAggregator aggregator = new WeightedPredictionsAggregator(weights, meanLbVal); ModelsComposition currComposition = new ModelsComposition(models, aggregator); if(convCheck.isConverged(envBuilder, datasetBuilder, currComposition))break; IgniteBiFunction < K, V, Double > lbExtractorWrap = (k, v) -> { Double realAnswer = externalLbToInternalMapping.apply(lbExtractor.apply(k, v)); Double mdlAnswer = currComposition.predict(featureExtractor.apply(k, v)); return - loss.gradient(sampleSize, realAnswer, mdlAnswer); }; long startTs = System.currentTimeMillis(); models.add(trainer.fit(datasetBuilder, featureExtractor, lbExtractorWrap)); double learningTime = (double)(System.currentTimeMillis() - startTs) / 1000.0; trainerEnvironment.logger(getClass()).log(MLLogger.VerboseLevel.LOW, \"One model training time was %.2fs\", learningTime); } return models; } ",
        "focal_src": "public < K, V > List < Model < Vector, Double > > update(GDBTrainer.GDBModel mdlToUpdate, DatasetBuilder < K, V > datasetBuilder, IgniteBiFunction < K, V, Vector > featureExtractor, IgniteBiFunction < K, V, Double > lbExtractor) { if(trainerEnvironment == null)throw new IllegalStateException(\"Learning environment builder is not set.\"); List < Model < Vector, Double > > models = initLearningState(mdlToUpdate); ConvergenceChecker < K, V > convCheck = checkConvergenceStgyFactory.create(sampleSize, externalLbToInternalMapping, loss, datasetBuilder, featureExtractor, lbExtractor); DatasetTrainer < ? extends Model < Vector, Double > , Double > trainer = baseMdlTrainerBuilder.get(); for(int i = 0; i < cntOfIterations; i ++ ) { double[]weights = Arrays.copyOf(compositionWeights, models.size()); WeightedPredictionsAggregator aggregator = new WeightedPredictionsAggregator(weights, meanLbVal); ModelsComposition currComposition = new ModelsComposition(models, aggregator); if(convCheck.isConverged(envBuilder, datasetBuilder, currComposition))break; IgniteBiFunction < K, V, Double > lbExtractorWrap = (k, v) -> { Double realAnswer = externalLbToInternalMapping.apply(lbExtractor.apply(k, v)); Double mdlAnswer = currComposition.apply(featureExtractor.apply(k, v)); return - loss.gradient(sampleSize, realAnswer, mdlAnswer); }; long startTs = System.currentTimeMillis(); models.add(trainer.fit(datasetBuilder, featureExtractor, lbExtractorWrap)); double learningTime = (double)(System.currentTimeMillis() - startTs) / 1000.0; trainerEnvironment.logger(getClass()).log(MLLogger.VerboseLevel.LOW, \"One model training time was %.2fs\", learningTime); } return models; } ",
        "test_tgt": "@Test public void testUpdate() { UpdatesStrategy < SmoothParametrized, SimpleGDParameterUpdate > updatesStgy = new UpdatesStrategy < > (new SimpleGDUpdateCalculator(0.2), SimpleGDParameterUpdate :: sumLocal, SimpleGDParameterUpdate :: avg); Map < Integer, double[][] > xorData = new HashMap < > (); xorData.put(0, new double[][] { { 0.0, 0.0 }, { 0.0 } }); xorData.put(1, new double[][] { { 0.0, 1.0 }, { 1.0 } }); xorData.put(2, new double[][] { { 1.0, 0.0 }, { 1.0 } }); xorData.put(3, new double[][] { { 1.0, 1.0 }, { 0.0 } }); MLPArchitecture arch = new MLPArchitecture(2).withAddedLayer(10, true, Activators.RELU).withAddedLayer(1, false, Activators.SIGMOID); MLPTrainer < SimpleGDParameterUpdate > trainer = new MLPTrainer < > (arch, LossFunctions.MSE, updatesStgy, 3000, batchSize, 50, 123L); MultilayerPerceptron originalMdl = trainer.fit(xorData, parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); MultilayerPerceptron updatedOnSameDS = trainer.update(originalMdl, xorData, parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); MultilayerPerceptron updatedOnEmptyDS = trainer.update(originalMdl, new HashMap < Integer, double[][] > (), parts, (k, v) -> VectorUtils.of(v[0]), (k, v) -> v[1]); DenseMatrix matrix = new DenseMatrix(new double[][] { { 0.0, 0.0 }, { 0.0, 1.0 }, { 1.0, 0.0 }, { 1.0, 1.0 } }); TestUtils.checkIsInEpsilonNeighbourhood(originalMdl.predict(matrix).getRow(0), updatedOnSameDS.predict(matrix).getRow(0), 1E-1); TestUtils.checkIsInEpsilonNeighbourhood(originalMdl.predict(matrix).getRow(0), updatedOnEmptyDS.predict(matrix).getRow(0), 1E-1); } "
    },
    {
        "test_src": "@Test@SuppressWarnings(\"unchecked\")public void testUpdateResources()throws Exception { Capture < AlertTargetEntity > entityCapture = new Capture < AlertTargetEntity > (); m_dao.createTargets(EasyMock.anyObject(List.class)); expectLastCall().times(1); AlertTargetEntity target = new AlertTargetEntity(); expect(m_dao.findTargetById(ALERT_TARGET_ID)).andReturn(target).times(1); expect(m_dao.merge(capture(entityCapture))).andReturn(target).once(); replay(m_amc, m_dao); AlertTargetResourceProvider provider = createProvider(m_amc); Map < String, Object > requestProps = getCreationProperties(); Request request = PropertyHelper.getCreateRequest(Collections.singleton(requestProps), null); provider.createResources(request); requestProps = new HashMap < String, Object > (); requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_ID, ALERT_TARGET_ID.toString()); String newName = ALERT_TARGET_NAME + \" Foo\"; requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_NAME, newName); requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_PROPERTIES + \"/foobar\", \"baz\"); Predicate predicate = new PredicateBuilder().property(AlertTargetResourceProvider.ALERT_TARGET_ID).equals(ALERT_TARGET_ID.toString()).toPredicate(); request = PropertyHelper.getUpdateRequest(requestProps, null); provider.updateResources(request, predicate); assertTrue(entityCapture.hasCaptured()); AlertTargetEntity entity = entityCapture.getValue(); assertEquals(newName, entity.getTargetName()); assertEquals(ALERT_TARGET_PROPS2, entity.getProperties()); verify(m_amc, m_dao); } ",
        "focal_tgt": "@Override public RequestStatus updateResources(Request request, Predicate predicate)throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException { Map < String, String > requestInfoProps = request.getRequestInfoProperties(); if(null != requestInfoProps && requestInfoProps.containsKey(AlertDefResourceDefinition.EXECUTE_IMMEDIATE_DIRECTIVE)) { Set < Map < String, Object > > predicateMaps = getPropertyMaps(predicate); for(Map < String, Object > propertyMap : predicateMaps) { scheduleImmediateAlert(propertyMap); } return getRequestStatus(null); } for(Map < String, Object > requestPropMap : request.getProperties()) { for(Map < String, Object > propertyMap : getPropertyMaps(requestPropMap, predicate)) { String stringId = (String)propertyMap.get(ALERT_DEF_ID); long id = Long.parseLong(stringId); AlertDefinitionEntity entity = alertDefinitionDAO.findById(id); if(null == entity) { continue; } boolean oldEnabled = entity.getEnabled(); try { populateEntity(entity, propertyMap); alertDefinitionDAO.merge(entity); Set < String > invalidatedHosts = alertDefinitionHash.invalidateHosts(entity); AlertHashInvalidationEvent event = new AlertHashInvalidationEvent(entity.getClusterId(), invalidatedHosts); eventPublisher.publish(event); } catch(AmbariException ae) { LOG.error(\"Unable to find cluster when updating alert definition\", ae); } if(oldEnabled && ! entity.getEnabled()) { AlertDefinitionDisabledEvent event = new AlertDefinitionDisabledEvent(entity.getClusterId(), entity.getDefinitionId()); eventPublisher.publish(event); } } } notifyUpdate(Resource.Type.AlertDefinition, request, predicate); return getRequestStatus(null); } ",
        "focal_src": "@Override public RequestStatus updateResources(Request request, Predicate predicate)throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException { if(null != predicate) { Set < Map < String, Object > > predicateMaps = getPropertyMaps(predicate); for(Map < String, Object > propertyMap : predicateMaps) { String runNow = (String)propertyMap.get(ALERT_DEF_ACTION_RUN_NOW); if(null != runNow) { if(Boolean.valueOf(runNow) == Boolean.TRUE) { scheduleImmediateAlert(propertyMap); } } } } for(Map < String, Object > requestPropMap : request.getProperties()) { for(Map < String, Object > propertyMap : getPropertyMaps(requestPropMap, predicate)) { String stringId = (String)propertyMap.get(ALERT_DEF_ID); long id = Long.parseLong(stringId); AlertDefinitionEntity entity = alertDefinitionDAO.findById(id); if(null == entity) { continue; } boolean oldEnabled = entity.getEnabled(); try { populateEntity(entity, propertyMap); alertDefinitionDAO.merge(entity); Set < String > invalidatedHosts = alertDefinitionHash.invalidateHosts(entity); AlertHashInvalidationEvent event = new AlertHashInvalidationEvent(entity.getClusterId(), invalidatedHosts); eventPublisher.publish(event); } catch(AmbariException ae) { LOG.error(\"Unable to find cluster when updating alert definition\", ae); } if(oldEnabled && ! entity.getEnabled()) { AlertDefinitionDisabledEvent event = new AlertDefinitionDisabledEvent(entity.getClusterId(), entity.getDefinitionId()); eventPublisher.publish(event); } } } notifyUpdate(Resource.Type.AlertDefinition, request, predicate); return getRequestStatus(null); } ",
        "test_tgt": "@Test@SuppressWarnings(\"unchecked\")public void testUpdateResources()throws Exception { Capture < AlertTargetEntity > entityCapture = new Capture < AlertTargetEntity > (); m_dao.create(capture(entityCapture)); expectLastCall().times(1); AlertTargetEntity target = new AlertTargetEntity(); expect(m_dao.findTargetById(ALERT_TARGET_ID)).andReturn(target).times(1); expect(m_dao.merge(capture(entityCapture))).andReturn(target).once(); replay(m_amc, m_dao); AlertTargetResourceProvider provider = createProvider(m_amc); Map < String, Object > requestProps = getCreationProperties(); Request request = PropertyHelper.getCreateRequest(Collections.singleton(requestProps), null); provider.createResources(request); requestProps = new HashMap < String, Object > (); requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_ID, ALERT_TARGET_ID.toString()); String newName = ALERT_TARGET_NAME + \" Foo\"; requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_NAME, newName); requestProps.put(AlertTargetResourceProvider.ALERT_TARGET_PROPERTIES + \"/foobar\", \"baz\"); Predicate predicate = new PredicateBuilder().property(AlertTargetResourceProvider.ALERT_TARGET_ID).equals(ALERT_TARGET_ID.toString()).toPredicate(); request = PropertyHelper.getUpdateRequest(requestProps, null); provider.updateResources(request, predicate); assertTrue(entityCapture.hasCaptured()); AlertTargetEntity entity = entityCapture.getValue(); assertEquals(newName, entity.getTargetName()); assertEquals(ALERT_TARGET_PROPS2, entity.getProperties()); verify(m_amc, m_dao); } "
    },
    {
        "test_src": "@Test public void testProcessRequest()throws IOException, SAXException { WebConversation conv = new WebConversation(); GetMethodWebRequest getRequest = new GetMethodWebRequest(\"http://localhost:8080/metadata-complete/TestServlet\"); WebResponse getResponse = conv.getResponse(getRequest); System.out.println(getResponse.getText()); } ",
        "focal_tgt": "protected void processRequest(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException { response.setContentType(\"text/html;charset=UTF-8\"); PrintWriter out = response.getWriter(); out.println(\"<!DOCTYPE html>\"); out.println(\"<html>\"); out.println(\"<head>\"); out.println(\"<title>Servlet url-pattern in web.xml</title>\"); out.println(\"</head>\"); out.println(\"<body>\"); out.println(\"<h1>Servlet url-pattern in web.xml</h1>\"); out.println(\"</body>\"); out.println(\"</html>\"); } ",
        "focal_src": "protected void processRequest(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException { response.setContentType(\"text/html;charset=UTF-8\"); PrintWriter out = response.getWriter(); out.println(\"<!DOCTYPE html>\"); out.println(\"<html>\"); out.println(\"<head>\"); out.println(\"<title>Servlet url-pattern in web.xml</title>\"); out.println(\"</head>\"); out.println(\"<body>\"); out.println(\"<h1>c</h1>\"); out.println(\"</body>\"); out.println(\"</html>\"); } ",
        "test_tgt": "@Test public void testProcessRequest()throws IOException, SAXException { WebConversation conv = new WebConversation(); GetMethodWebRequest getRequest = new GetMethodWebRequest(base + \"/TestServlet\"); WebResponse getResponse = conv.getResponse(getRequest); assertTrue(getResponse.getText().contains(\"<title>Servlet url-pattern in web.xml</title>\")); } "
    },
    {
        "test_src": "@Test public void testValidateCode_PreExpansionAgainstHugeValueSet()throws Exception { myDaoConfig.setPreExpandValueSets(true); CustomTerminologySet codesToAdd = new CustomTerminologySet(); for(int i = 0; i < 100; i ++ ) { codesToAdd.addRootConcept(\"CODE\" + i, \"Display \" + i); } myTermCodeSystemStorageSvc.applyDeltaCodeSystemsAdd(\"http://loinc.org\", codesToAdd); ValueSet vs = new ValueSet(); vs.setUrl(\"http://example.com/fhir/ValueSet/observation-vitalsignresult\"); vs.getCompose().addInclude().setSystem(\"http://loinc.org\"); myValueSetDao.create(vs); myTermReadSvc.preExpandDeferredValueSetsToTerminologyTables(); await().until(() -> myTermReadSvc.isValueSetPreExpandedForCodeValidation(vs)); StructureDefinition profile = loadResourceFromClasspath(StructureDefinition.class, \"/r4/profile-vitalsigns-all-loinc.json\"); myStructureDefinitionDao.create(profile, mySrd); Observation obs = new Observation(); obs.getMeta().addProfile(\"http://example.com/fhir/StructureDefinition/vitalsigns-2\"); obs.getText().setDivAsString(\"<div>Hello</div>\"); obs.getCategoryFirstRep().addCoding().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"vital-signs\"); obs.setSubject(new Reference(\"Patient/123\")); obs.addPerformer(new Reference(\"Practitioner/123\")); obs.setEffective(DateTimeType.now()); obs.setStatus(ObservationStatus.FINAL); obs.setValue(new StringType(\"This is the value\")); OperationOutcome oo; obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"No issues detected during validation\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"non-existing-code\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = http://loinc.org#non-existing-code)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(null).setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = null#CODE3)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://foo\").setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"Code http://foo/CODE3 was not validated because the code system is not present\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"vital-signs\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = http://terminology.hl7.org/CodeSystem/observation-category#vital-signs)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"CODE3\").setDisplay(\"Display 3\"); obs.getCategoryFirstRep().addCoding().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"FOO\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"Unknown code: http://terminology.hl7.org/CodeSystem/observation-category / FOO\", oo.getIssueFirstRep().getDiagnostics()); } ",
        "focal_tgt": "CodeValidationResult validateCode(FhirContext theContext, String theCodeSystem, String theCode, String theDisplay, String theValueSetUrl); ",
        "focal_src": "CodeValidationResult < CDCT, IST > validateCode(FhirContext theContext, String theCodeSystem, String theCode, String theDisplay, String theValueSetUrl); ",
        "test_tgt": "@Test public void testValidateCode_PreExpansionAgainstHugeValueSet()throws Exception { myDaoConfig.setPreExpandValueSets(true); CustomTerminologySet codesToAdd = new CustomTerminologySet(); for(int i = 0; i < 100; i ++ ) { codesToAdd.addRootConcept(\"CODE\" + i, \"Display \" + i); } myTermCodeSystemStorageSvc.applyDeltaCodeSystemsAdd(\"http://loinc.org\", codesToAdd); ValueSet vs = new ValueSet(); vs.setUrl(\"http://example.com/fhir/ValueSet/observation-vitalsignresult\"); vs.getCompose().addInclude().setSystem(\"http://loinc.org\"); myValueSetDao.create(vs); myTermReadSvc.preExpandDeferredValueSetsToTerminologyTables(); await().until(() -> myTermReadSvc.isValueSetPreExpandedForCodeValidation(vs)); StructureDefinition profile = loadResourceFromClasspath(StructureDefinition.class, \"/r4/profile-vitalsigns-all-loinc.json\"); myStructureDefinitionDao.create(profile, mySrd); Observation obs = new Observation(); obs.getMeta().addProfile(\"http://example.com/fhir/StructureDefinition/vitalsigns-2\"); obs.getText().setDivAsString(\"<div>Hello</div>\"); obs.getCategoryFirstRep().addCoding().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"vital-signs\"); obs.setSubject(new Reference(\"Patient/123\")); obs.addPerformer(new Reference(\"Practitioner/123\")); obs.setEffective(DateTimeType.now()); obs.setStatus(ObservationStatus.FINAL); obs.setValue(new StringType(\"This is the value\")); OperationOutcome oo; obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"No issues detected during validation\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"non-existing-code\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = http://loinc.org#non-existing-code)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(null).setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = null#CODE3)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://foo\").setCode(\"CODE3\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = http://foo#CODE3)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"vital-signs\").setDisplay(\"Display 3\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"None of the codes provided are in the value set http://example.com/fhir/ValueSet/observation-vitalsignresult (http://example.com/fhir/ValueSet/observation-vitalsignresult, and a code from this value set is required) (codes = http://terminology.hl7.org/CodeSystem/observation-category#vital-signs)\", oo.getIssueFirstRep().getDiagnostics()); obs.getText().setStatus(Narrative.NarrativeStatus.GENERATED); obs.getCode().getCodingFirstRep().setSystem(\"http://loinc.org\").setCode(\"CODE3\").setDisplay(\"Display 3\"); obs.getCategoryFirstRep().addCoding().setSystem(\"http://terminology.hl7.org/CodeSystem/observation-category\").setCode(\"FOO\"); oo = validateAndReturnOutcome(obs); assertEquals(encode(oo), \"Unknown code: http://terminology.hl7.org/CodeSystem/observation-category / FOO\", oo.getIssueFirstRep().getDiagnostics()); } "
    },
    {
        "test_src": "@Test public void testClassify() { Classification response = new Classification(); response.setId(\"testId\"); response.setText(\"is it sunny?\"); response.setUrl(\"http://www.ibm.com\"); response.setTopClass(\"conditions\"); List < ClassifiedClass > classes = new ArrayList < ClassifiedClass > (); ClassifiedClass c1 = new ClassifiedClass(); c1.setConfidence(0.98189); c1.setName(\"class1\"); ClassifiedClass c2 = new ClassifiedClass(); c2.setConfidence(0.98188); c2.setName(\"class2\"); classes.add(c1); classes.add(c2); response.setClasses(classes); System.out.println(GsonSingleton.getGson().toJson(response)); StringBuilder text = new StringBuilder().append(\"is it sunny?\"); JsonObject contentJson = new JsonObject(); contentJson.addProperty(\"text\", text.toString()); String path = String.format(LANGUAGE_CLASSIFY_PATH, classifierId); mockServer.when(request().withMethod(\"POST\").withPath(path).withBody(contentJson.toString())).respond(response().withHeaders(new Header(HttpHeaders.Names.CONTENT_TYPE, MediaType.APPLICATION_JSON)).withBody(GsonSingleton.getGson().toJson(response))); Classification c = service.classify(classifierId, text.toString()); Assert.assertNotNull(c); Assert.assertEquals(c, response); } ",
        "focal_tgt": "public Classification classify(final String classifierId, final String text) { if(classifierId == null || classifierId.isEmpty())throw new IllegalArgumentException(\"classifierId can not be null or empty\"); if(text == null || text.isEmpty())throw new IllegalArgumentException(\"text can not be null or empty\"); JsonObject contentJson = new JsonObject(); contentJson.addProperty(\"text\", text); String path = String.format(\"/v1/classifiers/%s/classify\", classifierId); HttpRequestBase request = Request.Post(path).withContent(contentJson).build(); try { HttpResponse response = execute(request); Classification classification = ResponseUtil.getObject(response, Classification.class); for(ClassifiedClass klass : classification.getClasses()) { if(klass.getName().equals(classification.getTopClass())) { classification.setTopConfidence(klass.getConfidence()); break; } } return classification; } catch(IOException e) { throw new RuntimeException(e); } } ",
        "focal_src": "public Classification classify(final String classifierId, final String text) { if(classifierId == null || classifierId.isEmpty())throw new IllegalArgumentException(\"classifierId can not be null or empty\"); if(text == null || text.isEmpty())throw new IllegalArgumentException(\"text can not be null or empty\"); JsonObject contentJson = new JsonObject(); contentJson.addProperty(\"text\", text); String path = String.format(\"/v1/classifiers/%s/classify\", classifierId); HttpRequestBase request = Request.Post(path).withContent(contentJson).build(); try { HttpResponse response = execute(request); return ResponseUtil.getObject(response, Classification.class); } catch(IOException e) { throw new RuntimeException(e); } } ",
        "test_tgt": "@Test public void testClassify() { Classification response = new Classification(); response.setId(\"testId\"); response.setText(\"is it sunny?\"); response.setUrl(\"http://www.ibm.com\"); response.setTopClass(\"class2\"); List < ClassifiedClass > classes = new ArrayList < ClassifiedClass > (); ClassifiedClass c1 = new ClassifiedClass(); c1.setConfidence(0.98189); c1.setName(\"class1\"); ClassifiedClass c2 = new ClassifiedClass(); c2.setConfidence(0.98188); c2.setName(\"class2\"); classes.add(c1); classes.add(c2); response.setClasses(classes); System.out.println(GsonSingleton.getGson().toJson(response)); StringBuilder text = new StringBuilder().append(\"is it sunny?\"); JsonObject contentJson = new JsonObject(); contentJson.addProperty(\"text\", text.toString()); String path = String.format(LANGUAGE_CLASSIFY_PATH, classifierId); mockServer.when(request().withMethod(\"POST\").withPath(path).withBody(contentJson.toString())).respond(response().withHeaders(new Header(HttpHeaders.Names.CONTENT_TYPE, MediaType.APPLICATION_JSON)).withBody(GsonSingleton.getGson().toJson(response))); Classification c = service.classify(classifierId, text.toString()); Assert.assertNotNull(c); Assert.assertEquals(c, response); } "
    },
    {
        "test_src": "@Test public void testGetEnvMapForLog() { LOGGER.debug(JsonUtil.format(SystemUtil.getEnvMapForLog())); } ",
        "focal_tgt": "public static Map < String, String > getEnvMap() { return new TreeMap < String, String > (System.getenv()); } ",
        "focal_src": "public static Map < String, String > getEnvMapForLog() { return new TreeMap < String, String > (System.getenv()); } ",
        "test_tgt": "@Test public void testGetEnvMap() { LOGGER.debug(JsonUtil.format(SystemUtil.getEnvMap())); } "
    },
    {
        "test_src": "@Test public void testGetWord() { model = createVoiceModel(); final List < CustomTranslation > expected = instantiateCustomTranslations(); service.addWords(model, expected.toArray(new CustomTranslation[] { })).execute(); final CustomTranslation word = service.getWord(model, expected.get(0).getWord()).execute(); assertEquals(expected.get(0).getTranslation(), word.getTranslation()); } ",
        "focal_tgt": "public ServiceCall < Translation > getWord(GetWordOptions getWordOptions) { Validator.notNull(getWordOptions, \"getWordOptions cannot be null\"); RequestBuilder builder = RequestBuilder.get(String.format(\"/v1/customizations/%s/words/%s\", getWordOptions.customizationId(), getWordOptions.word())); return createServiceCall(builder.build(), ResponseConverterUtils.getObject(Translation.class)); } ",
        "focal_src": "public ServiceCall < CustomTranslation > getWord(final CustomVoiceModel model, final String word) { Validator.notNull(model, \"model cannot be null\"); Validator.notEmpty(model.getId(), \"model id must not be empty\"); Validator.notNull(word, \"word cannot be null\"); final Request request = RequestBuilder.get(String.format(PATH_WORD, model.getId(), word)).build(); return createServiceCall(request, ResponseConverterUtils.getObject(CustomTranslation.class)); } ",
        "test_tgt": "@Test public void testGetWord() { model = createVoiceModel(); final List < CustomWord > expected = instantiateCustomWords(); AddWordsOptions addOptions = new AddWordsOptions.Builder().customizationId(model.getCustomizationId()).words(expected).build(); service.addWords(addOptions).execute(); GetWordOptions getOptions = new GetWordOptions.Builder().customizationId(model.getCustomizationId()).word(expected.get(0).getWord()).build(); final Translation translation = service.getWord(getOptions).execute(); assertEquals(expected.get(0).getTranslation(), translation.getTranslation()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should pass if the concept has a synonym that is also a short name\", method = \"validate(Object,Errors)\")public void validate_shouldPassIfTheConceptHasASynonymThatIsAlsoAShortName()throws Exception { Concept concept = new Concept(); concept.addName(new ConceptName(\"CD4\", Context.getLocale())); ConceptName name = new ConceptName(\"CD4\", Context.getLocale()); name.setConceptNameType(ConceptNameType.SHORT); concept.addName(name); Errors errors = new BindException(concept, \"concept\"); new ConceptValidator().validate(concept, errors); Assert.assertFalse(errors.hasErrors()); } ",
        "focal_tgt": "public void validate(Object obj, Errors errors)throws APIException, DuplicateConceptNameException { if(obj == null || ! (obj instanceof Concept))throw new IllegalArgumentException(\"The parameter obj should not be null and must be of type\" + Concept.class); Concept conceptToValidate = (Concept)obj; if(conceptToValidate.getNames().size() == 0) { errors.reject(\"Concept.name.atLeastOneRequired\"); return; } boolean hasFullySpecifiedName = false; for(Locale conceptNameLocale : conceptToValidate.getAllConceptNameLocales()) { boolean fullySpecifiedNameForLocaleFound = false; boolean preferredNameForLocaleFound = false; boolean shortNameForLocaleFound = false; Set < String > validNamesFoundInLocale = new HashSet < String > (); Collection < ConceptName > namesInLocale = conceptToValidate.getNames(conceptNameLocale); for(ConceptName nameInLocale : namesInLocale) { if(StringUtils.isBlank(nameInLocale.getName())) { log.debug(\"Name in locale '\" + conceptNameLocale.toString() + \"' cannot be an empty string or white space\"); errors.reject(\"Concept.name.empty\"); } if(nameInLocale.isLocalePreferred() != null) { if(nameInLocale.isLocalePreferred() && ! preferredNameForLocaleFound) { if(nameInLocale.isIndexTerm()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be an index term\"); errors.reject(\"Concept.error.preferredName.is.indexTerm\"); } else if(nameInLocale.isShort()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a short name\"); errors.reject(\"Concept.error.preferredName.is.shortName\"); } else if(nameInLocale.isVoided()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a voided name\"); errors.reject(\"Concept.error.preferredName.is.voided\"); } preferredNameForLocaleFound = true; } else if(nameInLocale.isLocalePreferred() && preferredNameForLocaleFound) { log.warn(\"Found multiple preferred names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleLocalePreferredNames\"); } } if(nameInLocale.isFullySpecifiedName()) { if( ! hasFullySpecifiedName)hasFullySpecifiedName = true; if( ! fullySpecifiedNameForLocaleFound)fullySpecifiedNameForLocaleFound = true; else { log.warn(\"Found multiple fully specified names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleFullySpecifiedNames\"); } if(nameInLocale.isVoided()) { log.warn(\"Fully Specified name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a voided name\"); errors.reject(\"Concept.error.fullySpecifiedName.is.voided\"); } } if(nameInLocale.isShort()) { if( ! shortNameForLocaleFound)shortNameForLocaleFound = true; else { log.warn(\"Found multiple short names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleShortNames\"); } } if( ! conceptToValidate.isRetired()) { if(nameInLocale.isLocalePreferred() || nameInLocale.isFullySpecifiedName()) { Locale languageLocale = new Locale(nameInLocale.getLocale().getLanguage()); List < Concept > conceptsWithPossibleDuplicateNames = Context.getConceptService().getConceptsByName(nameInLocale.getName(), languageLocale, false); if(conceptsWithPossibleDuplicateNames.size() > 0) { for(Concept concept : conceptsWithPossibleDuplicateNames) { if(concept.isRetired())continue; if(conceptToValidate.getConceptId() != null && conceptToValidate.getConceptId().equals(concept.getConceptId()))continue; if((concept.getFullySpecifiedName(conceptNameLocale) != null && concept.getFullySpecifiedName(conceptNameLocale).getName().equalsIgnoreCase(nameInLocale.getName())) || (concept.getPreferredName(conceptNameLocale) != null && concept.getPreferredName(conceptNameLocale).getName().equalsIgnoreCase(nameInLocale.getName()))) { throw new DuplicateConceptNameException(\"'\" + nameInLocale.getName() + \"' is a duplicate name in locale '\" + conceptNameLocale.toString() + \"'\"); } } } } } if(errors.hasErrors()) { log.debug(\"Concept name '\" + nameInLocale.getName() + \"' for locale '\" + conceptNameLocale + \"' is invalid\"); return; } if( ! nameInLocale.isShort()) { if( ! validNamesFoundInLocale.add(nameInLocale.getName().toLowerCase()))throw new DuplicateConceptNameException(\"'\" + nameInLocale.getName() + \"' is a duplicate name in locale '\" + conceptNameLocale.toString() + \"' for the same concept\"); } if(log.isDebugEnabled())log.debug(\"Valid name found: \" + nameInLocale.getName()); } } if( ! hasFullySpecifiedName) { log.debug(\"Concept has no fully specified name\"); errors.reject(\"Concept.error.no.FullySpecifiedName\"); } } ",
        "focal_src": "public void validate(Object obj, Errors errors)throws APIException, DuplicateConceptNameException { if(obj == null || ! (obj instanceof Concept))throw new IllegalArgumentException(\"The parameter obj should not be null and must be of type\" + Concept.class); Concept conceptToValidate = (Concept)obj; if(conceptToValidate.getNames().size() == 0) { errors.reject(\"Concept.name.atLeastOneRequired\"); return; } boolean hasFullySpecifiedName = false; for(Locale conceptNameLocale : conceptToValidate.getAllConceptNameLocales()) { boolean fullySpecifiedNameForLocaleFound = false; boolean preferredNameForLocaleFound = false; boolean shortNameForLocaleFound = false; Set < String > validNamesFoundInLocale = new HashSet < String > (); Collection < ConceptName > namesInLocale = conceptToValidate.getNames(conceptNameLocale); for(ConceptName nameInLocale : namesInLocale) { if(StringUtils.isBlank(nameInLocale.getName())) { log.debug(\"Name in locale '\" + conceptNameLocale.toString() + \"' cannot be an empty string or white space\"); errors.reject(\"Concept.name.empty\"); } if(nameInLocale.isLocalePreferred() != null) { if(nameInLocale.isLocalePreferred() && ! preferredNameForLocaleFound) { if(nameInLocale.isIndexTerm()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be an index term\"); errors.reject(\"Concept.error.preferredName.is.indexTerm\"); } else if(nameInLocale.isShort()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a short name\"); errors.reject(\"Concept.error.preferredName.is.shortName\"); } else if(nameInLocale.isVoided()) { log.warn(\"Preferred name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a voided name\"); errors.reject(\"Concept.error.preferredName.is.voided\"); } preferredNameForLocaleFound = true; } else if(nameInLocale.isLocalePreferred() && preferredNameForLocaleFound) { log.warn(\"Found multiple preferred names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleLocalePreferredNames\"); } } if(nameInLocale.isFullySpecifiedName()) { if( ! hasFullySpecifiedName)hasFullySpecifiedName = true; if( ! fullySpecifiedNameForLocaleFound)fullySpecifiedNameForLocaleFound = true; else { log.warn(\"Found multiple fully specified names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleFullySpecifiedNames\"); } if(nameInLocale.isVoided()) { log.warn(\"Fully Specified name in locale '\" + conceptNameLocale.toString() + \"' shouldn't be a voided name\"); errors.reject(\"Concept.error.fullySpecifiedName.is.voided\"); } } if(nameInLocale.isShort()) { if( ! shortNameForLocaleFound)shortNameForLocaleFound = true; else { log.warn(\"Found multiple short names in locale '\" + conceptNameLocale.toString() + \"'\"); errors.reject(\"Concept.error.multipleShortNames\"); } } if( ! conceptToValidate.isRetired()) { if(nameInLocale.isLocalePreferred() || nameInLocale.isFullySpecifiedName()) { List < Concept > conceptsWithPossibleDuplicateNames = Context.getConceptService().getConceptsByName(nameInLocale.getName()); if(conceptsWithPossibleDuplicateNames.size() > 0) { for(Concept concept : conceptsWithPossibleDuplicateNames) { if(concept.isRetired() || (conceptToValidate.getConceptId() != null && conceptToValidate.getConceptId().equals(concept.getConceptId())))continue; if((concept.getFullySpecifiedName(conceptNameLocale) != null && concept.getFullySpecifiedName(conceptNameLocale).getName().equalsIgnoreCase(nameInLocale.getName())) || (concept.getPreferredName(conceptNameLocale) != null && concept.getPreferredName(conceptNameLocale).getName().equalsIgnoreCase(nameInLocale.getName()))) { throw new DuplicateConceptNameException(\"'\" + nameInLocale.getName() + \"' is a duplicate name in locale '\" + conceptNameLocale.toString() + \"'\"); } } } } } if(errors.hasErrors()) { log.debug(\"Concept name '\" + nameInLocale.getName() + \"' for locale '\" + conceptNameLocale + \"' is invalid\"); return; } if( ! nameInLocale.isShort()) { if( ! validNamesFoundInLocale.add(nameInLocale.getName().toLowerCase()))throw new DuplicateConceptNameException(\"'\" + nameInLocale.getName() + \"' is a duplicate name in locale '\" + conceptNameLocale.toString() + \"' for the same concept\"); } if(log.isDebugEnabled())log.debug(\"Valid name found: \" + nameInLocale.getName()); } } if( ! hasFullySpecifiedName) { log.debug(\"Concept has no fully specified name\"); errors.reject(\"Concept.error.no.FullySpecifiedName\"); } } ",
        "test_tgt": "@Test@Verifies(value = \"should pass if the concept has a synonym that is also a short name\", method = \"validate(Object,Errors)\")public void validate_shouldPassIfTheConceptHasASynonymThatIsAlsoAShortName()throws Exception { Concept concept = new Concept(); concept.addName(new ConceptName(\"CD4\", Context.getLocale())); ConceptName name = new ConceptName(\"CD4\", Context.getLocale()); name.setConceptNameType(ConceptNameType.SHORT); concept.addName(name); Errors errors = new BindException(concept, \"concept\"); new ConceptValidator().validate(concept, errors); Assert.assertFalse(errors.hasErrors()); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.PARTIAL_COMPLETE, notes = \"\", method = \"getLogger\", args = { java.lang.String.class })public void test_init_logger()throws Exception { Properties p = new Properties(); p.put(\"testGetLogger_Normal_ANewLogger2.level\", \"ALL\"); LogManager.getLogManager().readConfiguration(EnvironmentHelper.PropertiesToInputStream(p)); assertNull(LogManager.getLogManager().getLogger(\"testGetLogger_Normal_ANewLogger2\")); SecurityManager originalSecurityManager = System.getSecurityManager(); try { Logger logger = Logger.getLogger(\"testGetLogger_Normal_ANewLogger2\"); System.setSecurityManager(new MockSecurityManager()); try { logger.setLevel(Level.ALL); fail(\"should throw SecurityException\"); } catch(SecurityException e) { } try { logger.setParent(Logger.getLogger(\"\")); fail(\"should throw SecurityException\"); } catch(SecurityException e) { } } finally { System.setSecurityManager(originalSecurityManager); } } ",
        "focal_tgt": "public void init(PrivateKey key) { try { if(signature != null) { signature.initSign(key); } else if(cipher != null) { cipher.init(Cipher.ENCRYPT_MODE, key); } } catch(InvalidKeyException e) { throw new AlertException(AlertProtocol.BAD_CERTIFICATE, new SSLException(\"init - invalid private key\", e)); } } ",
        "focal_src": "public void init(PrivateKey key) { try { if(signature != null) { signature.initSign(key); } else if(cipher != null) { cipher.init(Cipher.ENCRYPT_MODE, key); } } catch(Exception e) { e.printStackTrace(); } } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.PARTIAL_COMPLETE, notes = \"\", method = \"getLogger\", args = { java.lang.String.class })public void test_init_logger()throws Exception { Properties p = new Properties(); p.put(\"testGetLogger_Normal_ANewLogger2.level\", \"ALL\"); LogManager.getLogManager().readConfiguration(EnvironmentHelper.PropertiesToInputStream(p)); assertNull(LogManager.getLogManager().getLogger(\"testGetLogger_Normal_ANewLogger2\")); SecurityManager originalSecurityManager = System.getSecurityManager(); try { Logger logger = Logger.getLogger(\"testGetLogger_Normal_ANewLogger2\"); System.setSecurityManager(new MockSecurityManager()); try { logger.setLevel(Level.ALL); fail(\"should throw SecurityException\"); } catch(SecurityException e) { } try { logger.setParent(Logger.getLogger(\"\")); fail(\"should throw SecurityException\"); } catch(SecurityException e) { } } finally { System.setSecurityManager(originalSecurityManager); } } "
    },
    {
        "test_src": "@Test public void testSerialize() { RegisteredClient c = new RegisteredClient(); c.setClientId(\"s6BhdRkqt3\"); c.setClientSecret(\"ZJYCqe3GGRvdrudKyZS0XhGv_Z45DuKhCUk0gBR1vZk\"); c.setClientSecretExpiresAt(new Date(1577858400L * 1000L)); c.setRegistrationAccessToken(\"this.is.an.access.token.value.ffx83\"); c.setRegistrationClientUri(\"https://server.example.com/connect/register?client_id=s6BhdRkqt3\"); c.setApplicationType(ClientDetailsEntity.AppType.WEB); c.setRedirectUris(ImmutableSet.of(\"https://client.example.org/callback\", \"https://client.example.org/callback2\")); c.setClientName(\"My Example\"); c.setLogoUri(\"https://client.example.org/logo.png\"); c.setSubjectType(ClientDetailsEntity.SubjectType.PAIRWISE); c.setSectorIdentifierUri(\"https://other.example.net/file_of_redirect_uris.json\"); c.setTokenEndpointAuthMethod(ClientDetailsEntity.AuthMethod.SECRET_BASIC); c.setJwksUri(\"https://client.example.org/my_public_keys.jwks\"); c.setUserInfoEncryptedResponseAlg(new JWEAlgorithmEmbed(JWEAlgorithm.RSA1_5)); c.setUserInfoEncryptedResponseEnc(new JWEEncryptionMethodEmbed(EncryptionMethod.A128CBC_HS256)); c.setContacts(ImmutableSet.of(\"ve7jtb@example.org\", \"mary@example.org\")); c.setRequestUris(ImmutableSet.of(\"https://client.example.org/rf.txt#qpXaRLh_n93TTR9F252ValdatUQvQiJi5BDub2BeznA\")); JsonObject j = ClientDetailsEntityJsonProcessor.serialize(c); assertEquals(\"s6BhdRkqt3\", j.get(\"client_id\").getAsString()); assertEquals(\"ZJYCqe3GGRvdrudKyZS0XhGv_Z45DuKhCUk0gBR1vZk\", j.get(\"client_secret\").getAsString()); assertEquals(1577858400L, j.get(\"client_secret_expires_at\").getAsNumber()); assertEquals(\"this.is.an.access.token.value.ffx83\", j.get(\"registration_access_token\").getAsString()); assertEquals(\"https://server.example.com/connect/register?client_id=s6BhdRkqt3\", j.get(\"registration_client_uri\").getAsString()); assertEquals(ClientDetailsEntity.AppType.WEB.getValue(), j.get(\"application_type\").getAsString()); for(JsonElement e : j.get(\"redirect_uris\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"https://client.example.org/callback\", \"https://client.example.org/callback2\").contains(e.getAsString())); } assertEquals(\"My Example\", j.get(\"client_name\").getAsString()); assertEquals(\"https://client.example.org/logo.png\", j.get(\"logo_uri\").getAsString()); assertEquals(ClientDetailsEntity.SubjectType.PAIRWISE.getValue(), j.get(\"subject_type\").getAsString()); assertEquals(\"https://other.example.net/file_of_redirect_uris.json\", j.get(\"sector_identifier_uri\").getAsString()); assertEquals(ClientDetailsEntity.AuthMethod.SECRET_BASIC.getValue(), j.get(\"token_endpoint_auth_method\").getAsString()); assertEquals(\"https://client.example.org/my_public_keys.jwks\", j.get(\"jwks_uri\").getAsString()); assertEquals(JWEAlgorithm.RSA1_5.getName(), j.get(\"userinfo_encrypted_response_alg\").getAsString()); assertEquals(EncryptionMethod.A128CBC_HS256.getName(), j.get(\"userinfo_encrypted_response_enc\").getAsString()); for(JsonElement e : j.get(\"contacts\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"ve7jtb@example.org\", \"mary@example.org\").contains(e.getAsString())); } for(JsonElement e : j.get(\"request_uris\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"https://client.example.org/rf.txt#qpXaRLh_n93TTR9F252ValdatUQvQiJi5BDub2BeznA\").contains(e.getAsString())); } } ",
        "focal_tgt": "public static JsonObject serialize(RegisteredClient c) { JsonObject o = new JsonObject(); o.addProperty(\"client_id\", c.getClientId()); if(c.getClientSecret() != null) { o.addProperty(\"client_secret\", c.getClientSecret()); if(c.getClientSecretExpiresAt() == null) { o.addProperty(\"client_secret_expires_at\", 0); } else { o.addProperty(\"client_secret_expires_at\", c.getClientSecretExpiresAt().getTime() / 1000L); } } if(c.getClientIdIssuedAt() != null) { o.addProperty(\"client_id_issued_at\", c.getClientIdIssuedAt().getTime() / 1000L); } else if(c.getCreatedAt() != null) { o.addProperty(\"client_id_issued_at\", c.getCreatedAt().getTime() / 1000L); } if(c.getRegistrationAccessToken() != null) { o.addProperty(\"registration_access_token\", c.getRegistrationAccessToken()); } if(c.getRegistrationClientUri() != null) { o.addProperty(\"registration_client_uri\", c.getRegistrationClientUri()); } o.add(\"redirect_uris\", getAsArray(c.getRedirectUris())); o.addProperty(\"client_name\", c.getClientName()); o.addProperty(\"client_uri\", c.getClientUri()); o.addProperty(\"logo_uri\", c.getLogoUri()); o.add(\"contacts\", getAsArray(c.getContacts())); o.addProperty(\"tos_uri\", c.getTosUri()); o.addProperty(\"token_endpoint_auth_method\", c.getTokenEndpointAuthMethod() != null ? c.getTokenEndpointAuthMethod().getValue() : null); o.addProperty(\"scope\", c.getScope() != null ? Joiner.on(\" \").join(c.getScope()) : null); o.add(\"grant_types\", getAsArray(c.getGrantTypes())); o.add(\"response_types\", getAsArray(c.getResponseTypes())); o.addProperty(\"policy_uri\", c.getPolicyUri()); o.addProperty(\"jwks_uri\", c.getJwksUri()); o.addProperty(\"application_type\", c.getApplicationType() != null ? c.getApplicationType().getValue() : null); o.addProperty(\"sector_identifier_uri\", c.getSectorIdentifierUri()); o.addProperty(\"subject_type\", c.getSubjectType() != null ? c.getSubjectType().getValue() : null); o.addProperty(\"request_object_signing_alg\", c.getRequestObjectSigningAlg() != null ? c.getRequestObjectSigningAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_signed_response_alg\", c.getUserInfoSignedResponseAlg() != null ? c.getUserInfoSignedResponseAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_encrypted_response_alg\", c.getUserInfoEncryptedResponseAlg() != null ? c.getUserInfoEncryptedResponseAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_encrypted_response_enc\", c.getUserInfoEncryptedResponseEnc() != null ? c.getUserInfoEncryptedResponseEnc().getAlgorithmName() : null); o.addProperty(\"id_token_signed_response_alg\", c.getIdTokenSignedResponseAlg() != null ? c.getIdTokenSignedResponseAlg().getAlgorithmName() : null); o.addProperty(\"id_token_encrypted_response_alg\", c.getIdTokenEncryptedResponseAlg() != null ? c.getIdTokenEncryptedResponseAlg().getAlgorithmName() : null); o.addProperty(\"id_token_encrypted_response_enc\", c.getIdTokenEncryptedResponseEnc() != null ? c.getIdTokenEncryptedResponseEnc().getAlgorithmName() : null); o.addProperty(\"default_max_age\", c.getDefaultMaxAge()); o.addProperty(\"require_auth_time\", c.getRequireAuthTime()); o.add(\"default_acr_values\", getAsArray(c.getDefaultACRvalues())); o.addProperty(\"initiate_login_uri\", c.getInitiateLoginUri()); o.addProperty(\"post_logout_redirect_uri\", c.getPostLogoutRedirectUri()); o.add(\"request_uris\", getAsArray(c.getRequestUris())); return o; } ",
        "focal_src": "public static JsonObject serialize(RegisteredClient c) { JsonObject o = new JsonObject(); o.addProperty(\"client_id\", c.getClientId()); if(c.getClientSecret() != null) { o.addProperty(\"client_secret\", c.getClientSecret()); if(c.getClientSecretExpiresAt() == null) { o.addProperty(\"client_secret_expires_at\", 0); } else { o.addProperty(\"client_secret_expires_at\", c.getClientSecretExpiresAt().getTime() / 1000L); } } if(c.getClientIdIssuedAt() != null) { o.addProperty(\"client_id_issued_at\", c.getClientIdIssuedAt().getTime() / 1000L); } else if(c.getCreatedAt() != null) { o.addProperty(\"client_id_issued_at\", c.getCreatedAt().getTime() / 1000L); } if(c.getRegistrationAccessToken() != null) { o.addProperty(\"registration_access_token\", c.getRegistrationAccessToken()); } if(c.getRegistrationClientUri() != null) { o.addProperty(\"registration_client_uri\", c.getRegistrationClientUri()); } o.add(\"redirect_uris\", getAsArray(c.getRedirectUris())); o.addProperty(\"client_name\", c.getClientName()); o.addProperty(\"client_uri\", c.getClientUri()); o.addProperty(\"logo_uri\", c.getLogoUri()); o.add(\"contacts\", getAsArray(c.getContacts())); o.addProperty(\"tos_uri\", c.getTosUri()); o.addProperty(\"token_endpoint_auth_method\", c.getTokenEndpointAuthMethod() != null ? c.getTokenEndpointAuthMethod().getValue() : null); o.addProperty(\"scope\", c.getScope() != null ? Joiner.on(\" \").join(c.getScope()) : null); o.add(\"grant_types\", getAsArray(c.getGrantTypes())); o.addProperty(\"policy_uri\", c.getPolicyUri()); o.addProperty(\"jwks_uri\", c.getJwksUri()); o.addProperty(\"application_type\", c.getApplicationType() != null ? c.getApplicationType().getValue() : null); o.addProperty(\"sector_identifier_uri\", c.getSectorIdentifierUri()); o.addProperty(\"subject_type\", c.getSubjectType() != null ? c.getSubjectType().getValue() : null); o.addProperty(\"request_object_signing_alg\", c.getRequestObjectSigningAlg() != null ? c.getRequestObjectSigningAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_signed_response_alg\", c.getUserInfoSignedResponseAlg() != null ? c.getUserInfoSignedResponseAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_encrypted_response_alg\", c.getUserInfoEncryptedResponseAlg() != null ? c.getUserInfoEncryptedResponseAlg().getAlgorithmName() : null); o.addProperty(\"userinfo_encrypted_response_enc\", c.getUserInfoEncryptedResponseEnc() != null ? c.getUserInfoEncryptedResponseEnc().getAlgorithmName() : null); o.addProperty(\"id_token_signed_response_alg\", c.getIdTokenSignedResponseAlg() != null ? c.getIdTokenSignedResponseAlg().getAlgorithmName() : null); o.addProperty(\"id_token_encrypted_response_alg\", c.getIdTokenEncryptedResponseAlg() != null ? c.getIdTokenEncryptedResponseAlg().getAlgorithmName() : null); o.addProperty(\"id_token_encrypted_response_enc\", c.getIdTokenEncryptedResponseEnc() != null ? c.getIdTokenEncryptedResponseEnc().getAlgorithmName() : null); o.addProperty(\"default_max_age\", c.getDefaultMaxAge()); o.addProperty(\"require_auth_time\", c.getRequireAuthTime()); o.add(\"default_acr_values\", getAsArray(c.getDefaultACRvalues())); o.addProperty(\"initiate_login_uri\", c.getInitiateLoginUri()); o.addProperty(\"post_logout_redirect_uri\", c.getPostLogoutRedirectUri()); o.add(\"request_uris\", getAsArray(c.getRequestUris())); return o; } ",
        "test_tgt": "@Test public void testSerialize() { RegisteredClient c = new RegisteredClient(); c.setClientId(\"s6BhdRkqt3\"); c.setClientSecret(\"ZJYCqe3GGRvdrudKyZS0XhGv_Z45DuKhCUk0gBR1vZk\"); c.setClientSecretExpiresAt(new Date(1577858400L * 1000L)); c.setRegistrationAccessToken(\"this.is.an.access.token.value.ffx83\"); c.setRegistrationClientUri(\"https://server.example.com/connect/register?client_id=s6BhdRkqt3\"); c.setApplicationType(ClientDetailsEntity.AppType.WEB); c.setRedirectUris(ImmutableSet.of(\"https://client.example.org/callback\", \"https://client.example.org/callback2\")); c.setClientName(\"My Example\"); c.setResponseTypes(ImmutableSet.of(\"code\", \"token\")); c.setGrantTypes(ImmutableSet.of(\"authorization_code\", \"implicit\")); c.setLogoUri(\"https://client.example.org/logo.png\"); c.setSubjectType(ClientDetailsEntity.SubjectType.PAIRWISE); c.setSectorIdentifierUri(\"https://other.example.net/file_of_redirect_uris.json\"); c.setTokenEndpointAuthMethod(ClientDetailsEntity.AuthMethod.SECRET_BASIC); c.setJwksUri(\"https://client.example.org/my_public_keys.jwks\"); c.setUserInfoEncryptedResponseAlg(new JWEAlgorithmEmbed(JWEAlgorithm.RSA1_5)); c.setUserInfoEncryptedResponseEnc(new JWEEncryptionMethodEmbed(EncryptionMethod.A128CBC_HS256)); c.setContacts(ImmutableSet.of(\"ve7jtb@example.org\", \"mary@example.org\")); c.setRequestUris(ImmutableSet.of(\"https://client.example.org/rf.txt#qpXaRLh_n93TTR9F252ValdatUQvQiJi5BDub2BeznA\")); JsonObject j = ClientDetailsEntityJsonProcessor.serialize(c); assertEquals(\"s6BhdRkqt3\", j.get(\"client_id\").getAsString()); assertEquals(\"ZJYCqe3GGRvdrudKyZS0XhGv_Z45DuKhCUk0gBR1vZk\", j.get(\"client_secret\").getAsString()); assertEquals(1577858400L, j.get(\"client_secret_expires_at\").getAsNumber()); assertEquals(\"this.is.an.access.token.value.ffx83\", j.get(\"registration_access_token\").getAsString()); assertEquals(\"https://server.example.com/connect/register?client_id=s6BhdRkqt3\", j.get(\"registration_client_uri\").getAsString()); assertEquals(ClientDetailsEntity.AppType.WEB.getValue(), j.get(\"application_type\").getAsString()); for(JsonElement e : j.get(\"redirect_uris\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"https://client.example.org/callback\", \"https://client.example.org/callback2\").contains(e.getAsString())); } assertEquals(\"My Example\", j.get(\"client_name\").getAsString()); for(JsonElement e : j.get(\"response_types\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"code\", \"token\").contains(e.getAsString())); } for(JsonElement e : j.get(\"grant_types\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"authorization_code\", \"implicit\").contains(e.getAsString())); } assertEquals(\"https://client.example.org/logo.png\", j.get(\"logo_uri\").getAsString()); assertEquals(ClientDetailsEntity.SubjectType.PAIRWISE.getValue(), j.get(\"subject_type\").getAsString()); assertEquals(\"https://other.example.net/file_of_redirect_uris.json\", j.get(\"sector_identifier_uri\").getAsString()); assertEquals(ClientDetailsEntity.AuthMethod.SECRET_BASIC.getValue(), j.get(\"token_endpoint_auth_method\").getAsString()); assertEquals(\"https://client.example.org/my_public_keys.jwks\", j.get(\"jwks_uri\").getAsString()); assertEquals(JWEAlgorithm.RSA1_5.getName(), j.get(\"userinfo_encrypted_response_alg\").getAsString()); assertEquals(EncryptionMethod.A128CBC_HS256.getName(), j.get(\"userinfo_encrypted_response_enc\").getAsString()); for(JsonElement e : j.get(\"contacts\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"ve7jtb@example.org\", \"mary@example.org\").contains(e.getAsString())); } for(JsonElement e : j.get(\"request_uris\").getAsJsonArray()) { assertTrue(ImmutableSet.of(\"https://client.example.org/rf.txt#qpXaRLh_n93TTR9F252ValdatUQvQiJi5BDub2BeznA\").contains(e.getAsString())); } } "
    },
    {
        "test_src": "@Test@Category(Smoke.class)public void getUser() { GetUserResponse response = accountWebServiceClient.getUser(1L); assertEquals(\"admin\", response.getUser().getLoginName()); } ",
        "focal_tgt": "@Override public GetUserResult getUser(Long id) { GetUserResult result = new GetUserResult(); try { Validate.notNull(id, \"id\"); User user = accountService.getUser(id); Validate.notNull(user, \"(id:\" + id + \")\"); UserDTO dto = BeanMapper.map(user, UserDTO.class); result.setUser(dto); return result; } catch(IllegalArgumentException e) { return handleParameterError(result, e); } catch(RuntimeException e) { return handleGeneralError(result, e); } } ",
        "focal_src": "@Override public GetUserResponse getUser(Long id) { GetUserResponse response = new GetUserResponse(); try { Validate.notNull(id, \"id\"); User user = accountService.getUser(id); Validate.notNull(user, \"(id:\" + id + \")\"); UserDTO dto = BeanMapper.map(user, UserDTO.class); response.setUser(dto); return response; } catch(IllegalArgumentException e) { return handleParameterError(response, e); } catch(RuntimeException e) { return handleGeneralError(response, e); } } ",
        "test_tgt": "@Test@Category(Smoke.class)public void getUser() { GetUserResult response = accountWebServiceClient.getUser(1L); assertEquals(\"admin\", response.getUser().getLoginName()); } "
    },
    {
        "test_src": "@Test public void create() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname)); query(_DB_EXISTS.args(dbname), true); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(dbname) + \",\" + _DB_CREATE.args(dbname), Err.BXDB_CREATE); query(_DB_CREATE.args(dbname, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(dbname + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(dbname, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(dbname + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(dbname, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(dbname, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + dbname + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + dbname + \"' || $i\")); error(_DB_CREATE.args(dbname, \"\"), Err.WHICHRES); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(dbname)); error(_DB_CREATE.args(dbname) + \",\" + _DB_DROP.args(dbname), Err.BXDB_OPEN); query(_DB_CREATE.args(dbname, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(dbname)); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(dbname) + \",\" + _DB_DROP.args(dbname)); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(dbname)); } ",
        "focal_tgt": "private Item create(final QueryContext ctx)throws QueryException { final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))BXDB_NAME.thrw(info, name); final TokenList paths = new TokenList(); if(expr.length > 2) { final Iter ir = ctx.iter(expr[2]); for(Item it; (it = ir.next()) != null; ) { final String path = string(checkStr(it)); final String norm = MetaData.normPath(path); if(norm == null)RESINV.thrw(info, path); paths.add(norm); } } final int ps = paths.size(); final List < NewInput > inputs = new ArrayList < NewInput > (ps); if(expr.length > 1) { final Value val = ctx.value(expr[1]); final long is = val.size(); if(ps != 0 && is != ps)BXDB_CREATEARGS.thrw(info, is, ps); for(int i = 0; i < is; i ++ ) { final byte[]path = i < ps ? paths.get(i) : Token.EMPTY; inputs.add(checkInput(val.itemAt(i), path)); } } final Item opt = expr.length > 3 ? expr[3].item(ctx, info) : null; final TokenMap map = new FuncParams(Q_OPTIONS, info).parse(opt); ctx.updates.add(new DBCreate(info, name, inputs, map, ctx), ctx); return null; } ",
        "focal_src": "private Item create(final QueryContext ctx)throws QueryException { final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))BXDB_NAME.thrw(info, name); final TokenList paths = new TokenList(); if(expr.length > 2) { final Iter ir = ctx.iter(expr[2]); for(Item it; (it = ir.next()) != null; ) { final String path = string(checkStr(it)); final String norm = MetaData.normPath(path); if(norm == null)RESINV.thrw(info, path); paths.add(norm); } } final int ps = paths.size(); final List < NewInput > inputs = new ArrayList < NewInput > (ps); if(expr.length > 1) { final Value val = ctx.value(expr[1]); final long is = val.size(); if(ps != 0 && is != ps)BXDB_CREATEARGS.thrw(info, is, ps); for(int i = 0; i < is; i ++ ) { final byte[]path = i < ps ? paths.get(i) : Token.EMPTY; inputs.add(checkInput(val.itemAt(i), path)); } } ctx.updates.add(new DBCreate(info, name, inputs, ctx), ctx); return null; } ",
        "test_tgt": "@Test public void create() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname)); query(_DB_EXISTS.args(dbname), true); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(dbname) + \",\" + _DB_CREATE.args(dbname), Err.BXDB_CREATE); query(_DB_CREATE.args(dbname, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(dbname + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(dbname, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(dbname + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(dbname, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(dbname, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + dbname + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + dbname + \"' || $i\")); error(_DB_CREATE.args(dbname, \"\"), Err.WHICHRES); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(dbname)); error(_DB_CREATE.args(dbname) + \",\" + _DB_DROP.args(dbname), Err.BXDB_OPEN); query(_DB_CREATE.args(dbname, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(dbname)); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(dbname) + \",\" + _DB_DROP.args(dbname)); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(dbname)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { 'updindex':=\" + b + \"() }\")); query(_DB_INFO.args(dbname) + \"//updindex/text()\", b ? \"ON\" : \"OFF\"); } assertEquals(context.prop.is(Prop.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { '\" + k + \"':=1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { '\" + k + \"':=\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { '\" + k + \"':='' }\")); } error(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { 'xyz':='abc' }\"), Err.BASX_OPTIONS); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { 'maxlen':=-1 }\"), Err.BASX_VALUE); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" map { 'maxlen':='a' }\"), Err.BASX_VALUE); } "
    },
    {
        "test_src": "@Test public void testGetCurrentSession() { Session current = sessionRequestService.getCurrentSession(); assertNull(current); Session session = sessionRequestService.startSession(\"aaronz\"); assertNotNull(session); assertEquals(\"aaronz\", session.getId()); current = sessionRequestService.getCurrentSession(); assertNotNull(current); assertEquals(\"aaronz\", current.getId()); assertEquals(current, session); } ",
        "focal_tgt": "public Session getCurrentSession() { Request req = requests.getCurrent(); if(req != null) { return req.getSession(); } return null; } ",
        "focal_src": "public Session getCurrentSession() { String sessionId = getCurrentSessionId(); Session session = getSessionImpl(sessionId); return session; } ",
        "test_tgt": "@Test public void testGetCurrentSession() { Session current = sessionRequestService.getCurrentSession(); assertNull(current); } "
    },
    {
        "test_src": "@Test public void readBinary() { error(_FILE_READ_BINARY.args(PATH1), Err.FILE_NF); error(_FILE_READ_BINARY.args(PATH), Err.FILE_ID); query(_FILE_WRITE.args(PATH1, \"0\")); query(_FILE_READ_BINARY.args(PATH1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0, 1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 1), \"\"); query(_FILE_READ_BINARY.args(PATH1, 1, 0), \"\"); query(_FILE_READ_BINARY.args(PATH1, 0, 0), \"\"); error(_FILE_READ_BINARY.args(PATH1, - 1), Err.FILE_OOR); error(_FILE_READ_BINARY.args(PATH1, 2), Err.FILE_OOR); error(_FILE_READ_BINARY.args(PATH1, 0, - 1), Err.FILE_OOR); error(_FILE_READ_BINARY.args(PATH1, 0, 2), Err.FILE_OOR); error(_FILE_READ_BINARY.args(PATH1, 2, 1), Err.FILE_OOR); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_WRITE_BINARY.args(PATH1, _CONVERT_STRING_TO_BASE64.args(\"a\"))); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_DELETE.args(PATH1)); } ",
        "focal_tgt": "private B64 readBinary(final QueryContext ctx)throws QueryException, IOException { final Path path = checkPath(0, ctx); final long off = expr.length > 1 ? checkItr(expr[1], ctx) : 0; long len = expr.length > 2 ? checkItr(expr[2], ctx) : 0; if( ! Files.exists(path))throw FILE_NOT_FOUND.get(info, path); if(Files.isDirectory(path))throw FILE_IS_DIR.get(info, path); if(expr.length == 1)return new B64Stream(new IOFile(path.toFile()), FILE_IO_ERROR); try(final DataAccess da = new DataAccess(new IOFile(path.toFile()))) { final long dlen = da.length(); if(expr.length == 2)len = dlen - off; if(off < 0 || off > dlen || len < 0 || off + len > dlen)throw FILE_OUT_OF_RANGE.get(info, off, off + len); da.cursor(off); return new B64(da.readBytes((int)len)); } } ",
        "focal_src": "private B64 readBinary(final QueryContext ctx)throws QueryException, IOException { final File path = checkFile(0, ctx); final long off = expr.length > 1 ? checkItr(expr[1], ctx) : 0; long len = expr.length > 2 ? checkItr(expr[2], ctx) : 0; if( ! path.exists())throw FILE_NF.get(info, path.getAbsolutePath()); if(path.isDirectory())throw FILE_ID.get(info, path.getAbsolutePath()); if(expr.length == 1)return new B64Stream(new IOFile(path), FILE_IE); final DataAccess da = new DataAccess(new IOFile(path)); try { final long dlen = da.length(); if(expr.length == 2)len = dlen - off; if(off < 0 || off > dlen || len < 0 || off + len > dlen)throw FILE_OOR.get(info, off, off + len); da.cursor(off); return new B64(da.readBytes((int)len)); } finally { da.close(); } } ",
        "test_tgt": "@Test public void readBinary() { error(_FILE_READ_BINARY.args(PATH1), Err.FILE_NOT_FOUND); error(_FILE_READ_BINARY.args(PATH), Err.FILE_IS_DIR); query(_FILE_WRITE.args(PATH1, \"0\")); query(_FILE_READ_BINARY.args(PATH1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0, 1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 1), \"\"); query(_FILE_READ_BINARY.args(PATH1, 1, 0), \"\"); query(_FILE_READ_BINARY.args(PATH1, 0, 0), \"\"); error(_FILE_READ_BINARY.args(PATH1, - 1), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 2), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 0, - 1), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 0, 2), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 2, 1), Err.FILE_OUT_OF_RANGE); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_WRITE_BINARY.args(PATH1, _CONVERT_STRING_TO_BASE64.args(\"a\"))); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_DELETE.args(PATH1)); } "
    },
    {
        "test_src": "@Test public void testGetErrorCode_invalidErrorObject() { Mockito.when(responseException.getContent()).thenReturn(\"{\\\"type\\\":\\\"other\\\",\\\"message\\\":\\\"some other object\\\"}\"); try { ErrorResponseUtil.getErrorCode(responseException); Assert.fail(); } catch(HttpResponseException ex) { Assert.assertSame(responseException, ex); } } ",
        "focal_tgt": "public static ErrorCodes getErrorCode(ResponseException responseException)throws ResponseException { String errorContent = responseException.getContent(); if(errorContent == null) { throw responseException; } try { ErrorResponseTemplate errorResponse = JsonTemplateMapper.readJson(errorContent, ErrorResponseTemplate.class); List < ErrorEntryTemplate > errors = errorResponse.getErrors(); if(errors.size() == 1) { String errorCodeString = errors.get(0).getCode(); if(errorCodeString != null) { return ErrorCodes.valueOf(errorCodeString); } } } catch(IOException | IllegalArgumentException ex) { } throw responseException; } ",
        "focal_src": "public static ErrorCodes getErrorCode(HttpResponseException responseException)throws HttpResponseException { String errorContent = responseException.getContent(); if(errorContent == null) { throw responseException; } try { ErrorResponseTemplate errorResponse = JsonTemplateMapper.readJson(errorContent, ErrorResponseTemplate.class); List < ErrorEntryTemplate > errors = errorResponse.getErrors(); if(errors.size() == 1) { String errorCodeString = errors.get(0).getCode(); if(errorCodeString != null) { return ErrorCodes.valueOf(errorCodeString); } } } catch(IOException | IllegalArgumentException ex) { } throw responseException; } ",
        "test_tgt": "@Test public void testGetErrorCode_invalidErrorObject() { Mockito.when(responseException.getContent()).thenReturn(\"{\\\"type\\\":\\\"other\\\",\\\"message\\\":\\\"some other object\\\"}\"); try { ErrorResponseUtil.getErrorCode(responseException); Assert.fail(); } catch(ResponseException ex) { Assert.assertSame(responseException, ex); } } "
    },
    {
        "test_src": "@Test public void testDestroy() { RegistryDirectory registryDirectory = getRegistryDirectory(); List < URL > serviceUrls = new ArrayList < URL > (); serviceUrls.add(SERVICEURL.addParameter(\"methods\", \"getXXX1\")); serviceUrls.add(SERVICEURL2.addParameter(\"methods\", \"getXXX1,getXXX2\")); serviceUrls.add(SERVICEURL3.addParameter(\"methods\", \"getXXX1,getXXX2,getXXX3\")); registryDirectory.notify(serviceUrls); List < Invoker > invokers = registryDirectory.list(invocation); Assertions.assertEquals(true, registryDirectory.isAvailable()); Assertions.assertEquals(true, invokers.get(0).isAvailable()); registryDirectory.destroy(); Assertions.assertEquals(false, registryDirectory.isAvailable()); Assertions.assertEquals(false, invokers.get(0).isAvailable()); registryDirectory.destroy(); List < Invoker < RegistryDirectoryTest > > cachedInvokers = registryDirectory.getInvokers(); Map < String, Invoker < RegistryDirectoryTest > > urlInvokerMap = registryDirectory.getUrlInvokerMap(); Assertions.assertTrue(cachedInvokers == null); Assertions.assertEquals(0, urlInvokerMap.size()); RpcInvocation inv = new RpcInvocation(); try { registryDirectory.list(inv); fail(); } catch(RpcException e) { Assertions.assertTrue(e.getMessage().contains(\"already destroyed\")); } } ",
        "focal_tgt": "@Override public void destroy() { super.destroy(); try { if(cleanFuture != null) { cleanFuture.cancel(true); } } catch(Throwable t) { logger.warn(t.getMessage(), t); } try { multicastSocket.leaveGroup(multicastAddress); multicastSocket.close(); } catch(Throwable t) { logger.warn(t.getMessage(), t); } ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod); } ",
        "focal_src": "@Override public void destroy() { super.destroy(); try { ExecutorUtil.cancelScheduledFuture(cleanFuture); } catch(Throwable t) { logger.warn(t.getMessage(), t); } try { multicastSocket.leaveGroup(multicastAddress); multicastSocket.close(); } catch(Throwable t) { logger.warn(t.getMessage(), t); } ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod); } ",
        "test_tgt": "@Test public void testDestroy() { RegistryDirectory registryDirectory = getRegistryDirectory(); List < URL > serviceUrls = new ArrayList < URL > (); serviceUrls.add(SERVICEURL.addParameter(\"methods\", \"getXXX1\")); serviceUrls.add(SERVICEURL2.addParameter(\"methods\", \"getXXX1,getXXX2\")); serviceUrls.add(SERVICEURL3.addParameter(\"methods\", \"getXXX1,getXXX2,getXXX3\")); registryDirectory.notify(serviceUrls); List < Invoker > invokers = registryDirectory.list(invocation); Assert.assertEquals(true, registryDirectory.isAvailable()); Assert.assertEquals(true, invokers.get(0).isAvailable()); registryDirectory.destroy(); Assert.assertEquals(false, registryDirectory.isAvailable()); Assert.assertEquals(false, invokers.get(0).isAvailable()); registryDirectory.destroy(); List < Invoker < RegistryDirectoryTest > > cachedInvokers = registryDirectory.getInvokers(); Map < String, Invoker < RegistryDirectoryTest > > urlInvokerMap = registryDirectory.getUrlInvokerMap(); Assert.assertTrue(cachedInvokers == null); Assert.assertEquals(0, urlInvokerMap.size()); RpcInvocation inv = new RpcInvocation(); try { registryDirectory.list(inv); fail(); } catch(RpcException e) { Assert.assertTrue(e.getMessage().contains(\"already destroyed\")); } } "
    },
    {
        "test_src": "@Test public void testOpenPre()throws QueryException { final String fun = check(Function.OPENPRE); query(fun + \"('db', 0)//title/text()\", \"XML\"); error(fun + \"('db', -1)\", Err.IDINVALID); } ",
        "focal_tgt": "static String openPre(final Nodes n, final int i) { System.out.println(\"? \"); return Function.DBOPENPRE.get(null, Str.get(n.data.meta.name), Itr.get(n.list[i])).toString(); } ",
        "focal_src": "static String openPre(final Nodes n, final int i) { return \"db:open-pre('\" + n.data.meta.name + \"', \" + n.list[i] + \")\"; } ",
        "test_tgt": "@Test public void testOpenPre()throws QueryException { final String fun = check(Function.DBOPENPRE); query(fun + \"('db', 0)//title/text()\", \"XML\"); error(fun + \"('db', -1)\", Err.IDINVALID); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_minusHours_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.toLocalDate(); for(int i = 0; i < 50; i ++ ) { t = t.minusHours(1); if(i % 24 == 0) { d = d.minusDays(1); } assertEquals(t.toLocalDate(), d); assertEquals(t.getHour(), ((( - i + 23) % 24) + 24) % 24); } } ",
        "focal_tgt": "ChronoZonedDateTime < C > minusHours(long hours) { ChronoDateTime newDT = dateTime.getDateTime().minusHours(hours); return(newDT == dateTime.getDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "focal_src": "ChronoZonedDateTime < C > minusHours(long hours) { ChronoDateTime newDT = dateTime.toDateTime().minusHours(hours); return(newDT == dateTime.toDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_minusHours_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.getDate(); for(int i = 0; i < 50; i ++ ) { t = t.minusHours(1); if(i % 24 == 0) { d = d.minusDays(1); } assertEquals(t.getDate(), d); assertEquals(t.getHour(), ((( - i + 23) % 24) + 24) % 24); } } "
    },
    {
        "test_src": "@Test public void testDeploy()throws Exception { HttpResponse response = deploy(\"WordCount.jar\"); Assert.assertEquals(200, response.getStatusLine().getStatusCode()); } ",
        "focal_tgt": "private HttpResponse deploy(Class < ? extends Application > application)throws Exception { Manifest manifest = new Manifest(); manifest.getMainAttributes().put(ManifestFields.MANIFEST_VERSION, \"1.0\"); manifest.getMainAttributes().put(ManifestFields.MAIN_CLASS, application.getName()); ByteArrayOutputStream bos = new ByteArrayOutputStream(); final JarOutputStream jarOut = new JarOutputStream(bos, manifest); final String pkgName = application.getPackage().getName(); try { Dependencies.findClassDependencies(application.getClassLoader(), new Dependencies.ClassAcceptor() { @Override public boolean accept(String className, URL classUrl, URL classPathUrl) { try { if(className.startsWith(pkgName)) { jarOut.putNextEntry(new JarEntry(className.replace('.', '/') + \".class\")); InputStream in = classUrl.openStream(); try { ByteStreams.copy(in, jarOut); } finally { in.close(); } return true; } return false; } catch(Exception e) { throw Throwables.propagate(e); } } }, application.getName()); } finally { jarOut.close(); } HttpPut put = GatewayFastTestsSuite.getPUT(\"/v2/apps\"); put.setHeader(GatewayAuthenticator.CONTINUUITY_API_KEY, \"api-key-example\"); put.setHeader(\"X-Archive-Name\", application.getSimpleName() + \".jar\"); put.setEntity(new ByteArrayEntity(bos.toByteArray())); return GatewayFastTestsSuite.PUT(put); } ",
        "focal_src": "private HttpResponse deploy(String filename)throws Exception { File archive = FileUtils.toFile(getClass().getResource(\"/\" + filename)); ByteArrayOutputStream bos = new ByteArrayOutputStream(); try { ByteStreams.copy(new FileInputStream(archive), bos); } finally { bos.close(); } HttpPut put = GatewayFastTestsSuite.getPUT(\"/v2/apps\"); put.setHeader(GatewayAuthenticator.CONTINUUITY_API_KEY, \"api-key-example\"); put.setHeader(\"X-Archive-Name\", filename); put.setEntity(new ByteArrayEntity(bos.toByteArray())); return GatewayFastTestsSuite.PUT(put); } ",
        "test_tgt": "@Test public void testDeploy()throws Exception { HttpResponse response = deploy(WordCount.class); Assert.assertEquals(200, response.getStatusLine().getStatusCode()); } "
    },
    {
        "test_src": "@Test(description = \"PUT /vApp/{id}\", dependsOnMethods = { \"testGetVApp\" })public void testModifyVApp() { VApp newVApp = VApp.builder().name(name(\"new-name-\")).description(\"New Description\").build(); vAppNames.add(newVApp.getName()); Task modifyVApp = vAppApi.modifyVApp(vApp.getHref(), newVApp); assertTrue(retryTaskSuccess.apply(modifyVApp), String.format(TASK_COMPLETE_TIMELY, \"modifyVApp\")); vApp = vAppApi.getVApp(vApp.getHref()); assertEquals(vApp.getName(), newVApp.getName(), String.format(OBJ_FIELD_EQ, VAPP, \"Name\", newVApp.getName(), vApp.getName())); assertEquals(vApp.getDescription(), newVApp.getDescription(), String.format(OBJ_FIELD_EQ, VAPP, \"Description\", newVApp.getDescription(), vApp.getDescription())); } ",
        "focal_tgt": "Task editVApp(URI vAppURI, VApp vApp); ",
        "focal_src": "Task modifyVApp(URI vAppURI, VApp vApp); ",
        "test_tgt": "@Test(description = \"PUT /vApp/{id}\", dependsOnMethods = { \"testGetVApp\" })public void testEditVApp() { VApp newVApp = VApp.builder().name(name(\"new-name-\")).description(\"New Description\").build(); vAppNames.add(newVApp.getName()); Task editVApp = vAppApi.editVApp(vApp.getHref(), newVApp); assertTrue(retryTaskSuccess.apply(editVApp), String.format(TASK_COMPLETE_TIMELY, \"editVApp\")); vApp = vAppApi.getVApp(vApp.getHref()); assertEquals(vApp.getName(), newVApp.getName(), String.format(OBJ_FIELD_EQ, VAPP, \"Name\", newVApp.getName(), vApp.getName())); assertEquals(vApp.getDescription(), newVApp.getDescription(), String.format(OBJ_FIELD_EQ, VAPP, \"Description\", newVApp.getDescription(), vApp.getDescription())); } "
    },
    {
        "test_src": "@Test public void equiToNorm() { EquirectangularTools_F64 tools = new EquirectangularTools_F64(); tools.configure(300, 250); Vector3D_F64 found = new Vector3D_F64(); tools.equiToNorm(300.0 / 2.0, 250.0 / 2.0, found); assertEquals(1.0, found.x, GrlConstants.DOUBLE_TEST_TOL); assertEquals(0.0, found.y, GrlConstants.DOUBLE_TEST_TOL); assertEquals(0.0, found.z, GrlConstants.DOUBLE_TEST_TOL); } ",
        "focal_tgt": "public void equiToNorm(float x, float y, Point3D_F32 norm) { equiToLonlat(x, y, temp); ConvertCoordinates3D_F32.latlonToUnitVector(temp.y, temp.x, norm); } ",
        "focal_src": "public void equiToNorm(float x, float y, Vector3D_F32 norm) { equiToLonlat(x, y, temp); ConvertCoordinates3D_F32.latlonToUnitVector(temp.y, temp.x, norm); } ",
        "test_tgt": "@Test public void equiToNorm() { EquirectangularTools_F64 tools = new EquirectangularTools_F64(); tools.configure(300, 250); Point3D_F64 found = new Point3D_F64(); tools.equiToNorm(300.0 / 2.0, 250.0 / 2.0, found); assertEquals(1.0, found.x, GrlConstants.DOUBLE_TEST_TOL); assertEquals(0.0, found.y, GrlConstants.DOUBLE_TEST_TOL); assertEquals(0.0, found.z, GrlConstants.DOUBLE_TEST_TOL); } "
    },
    {
        "test_src": "@Test public void testSaveOrUpdateUserDetail() { ModelMap model = new ModelMap(); User currUser = getTestUser(); currUser.setUserName(\"new name\"); userController.saveUser(currUser, model, currUser); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); User user = (User)model.get(\"user\"); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userController.saveUser(admin, model, temp); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userController.saveUser(admin, model, temp); model.clear(); currUser.setFollowersStr(\"temp1, temp2\"); userController.saveUser(currUser, model, currUser); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); user = (User)model.get(\"user\"); assertThat(user.getFollowers().size(), is(2)); assertThat(user.getFollowers().get(0).getUserId(), is(\"temp1\")); } ",
        "focal_tgt": "@RequestMapping(\"/save\")public String saveOrUpdateUserDetail(@ModelAttribute(\"user\")User newUser) { checkArgument(newUser.getRole().equals(Role.USER), \"User role must be General user !\"); userService.createUser(newUser); return \"redirect:/home\"; } ",
        "focal_src": "@RequestMapping(\"/save\")public String saveOrUpdateUserDetail(ModelMap model, @ModelAttribute(\"user\")User newUser) { checkArgument(newUser.getRole().equals(Role.USER), \"User role must be General user !\"); userService.createUser(newUser); return \"redirect:/home\"; } ",
        "test_tgt": "@Test public void testSaveOrUpdateUserDetail() { ModelMap model = new ModelMap(); User currUser = getTestUser(); currUser.setUserName(\"new name\"); userController.save(currUser, currUser, model); userController.getOne(getTestUser(), model, currUser.getUserId()); User user = (User)model.get(\"user\"); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userController.save(admin, temp, model); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userController.save(admin, temp, model); model.clear(); currUser.setFollowersStr(\"temp1, temp2\"); userController.save(currUser, currUser, model); userController.getOne(getTestUser(), model, currUser.getUserId()); user = (User)model.get(\"user\"); assertThat(user.getFollowers().size(), is(2)); assertThat(user.getFollowers().get(0).getUserId(), is(\"temp1\")); } "
    },
    {
        "test_src": "@Test public void stop()throws IOException { final String id = query(_JOBS_SCHEDULE.args(VERY_SLOW_QUERY)); query(_JOBS_STOP.args(id)); while(true) { try { eval(_JOBS_RESULT.args(id)); fail(\"Query was not stopped.\"); } catch(final QueryException ex) { if(ex.error() == JOBS_UNKNOWN_X)break; assertSame(JOBS_RUNNING_X, ex.error()); } } } ",
        "focal_tgt": "public static boolean stop(final Context ctx, final String id) { final TimerTask task = ctx.jobs.tasks.remove(id); if(task != null)task.cancel(); final Job job = ctx.jobs.active.get(id); if(job != null)job.stop(); ctx.jobs.results.remove(id); return job != null || task != null; } ",
        "focal_src": "public static boolean stop(final Context ctx, final String id) { final TimerTask task = ctx.jobs.tasks.get(id); if(task != null)task.cancel(); final Job job = ctx.jobs.active.get(id); if(job != null)job.stop(); ctx.jobs.results.remove(id); return job != null || task != null; } ",
        "test_tgt": "@Test public void stop()throws IOException { final String id = wait(query(_JOBS_SCHEDULE.args(VERY_SLOW_QUERY))); query(_JOBS_STOP.args(id)); while(true) { try { eval(_JOBS_RESULT.args(id)); fail(\"Query was not stopped.\"); } catch(final QueryException ex) { if(ex.error() == JOBS_UNKNOWN_X)break; assertSame(JOBS_RUNNING_X, ex.error()); } } } "
    },
    {
        "test_src": "@Test public void readBinary() { error(_FILE_READ_BINARY.args(PATH1), Err.FILE_NOT_FOUND); error(_FILE_READ_BINARY.args(PATH), Err.FILE_IS_DIR); query(_FILE_WRITE.args(PATH1, \"0\")); query(_FILE_READ_BINARY.args(PATH1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0, 1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 1), \"\"); query(_FILE_READ_BINARY.args(PATH1, 1, 0), \"\"); query(_FILE_READ_BINARY.args(PATH1, 0, 0), \"\"); error(_FILE_READ_BINARY.args(PATH1, - 1), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 2), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 0, - 1), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 0, 2), Err.FILE_OUT_OF_RANGE); error(_FILE_READ_BINARY.args(PATH1, 2, 1), Err.FILE_OUT_OF_RANGE); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_WRITE_BINARY.args(PATH1, _CONVERT_STRING_TO_BASE64.args(\"a\"))); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_DELETE.args(PATH1)); } ",
        "focal_tgt": "private B64 readBinary(final QueryContext qc)throws QueryException, IOException { final Path path = toPath(0, qc); final long off = exprs.length > 1 ? toLong(exprs[1], qc) : 0; long len = exprs.length > 2 ? toLong(exprs[2], qc) : 0; if( ! Files.exists(path))throw FILE_NOT_FOUND_X.get(info, path); if(Files.isDirectory(path))throw FILE_IS_DIR_X.get(info, path); if(exprs.length == 1)return new B64Stream(new IOFile(path.toFile()), FILE_IO_ERROR_X); try(final DataAccess da = new DataAccess(new IOFile(path.toFile()))) { final long dlen = da.length(); if(exprs.length == 2)len = dlen - off; if(off < 0 || off > dlen || len < 0 || off + len > dlen)throw FILE_OUT_OF_RANGE_X_X.get(info, off, off + len); da.cursor(off); return new B64(da.readBytes((int)len)); } } ",
        "focal_src": "private B64 readBinary(final QueryContext qc)throws QueryException, IOException { final Path path = checkPath(0, qc); final long off = exprs.length > 1 ? checkItr(exprs[1], qc) : 0; long len = exprs.length > 2 ? checkItr(exprs[2], qc) : 0; if( ! Files.exists(path))throw FILE_NOT_FOUND.get(info, path); if(Files.isDirectory(path))throw FILE_IS_DIR.get(info, path); if(exprs.length == 1)return new B64Stream(new IOFile(path.toFile()), FILE_IO_ERROR); try(final DataAccess da = new DataAccess(new IOFile(path.toFile()))) { final long dlen = da.length(); if(exprs.length == 2)len = dlen - off; if(off < 0 || off > dlen || len < 0 || off + len > dlen)throw FILE_OUT_OF_RANGE.get(info, off, off + len); da.cursor(off); return new B64(da.readBytes((int)len)); } } ",
        "test_tgt": "@Test public void readBinary() { error(_FILE_READ_BINARY.args(PATH1), Err.FILE_NOT_FOUND_X); error(_FILE_READ_BINARY.args(PATH), Err.FILE_IS_DIR_X); query(_FILE_WRITE.args(PATH1, \"0\")); query(_FILE_READ_BINARY.args(PATH1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 0, 1), \"MA==\"); query(_FILE_READ_BINARY.args(PATH1, 1), \"\"); query(_FILE_READ_BINARY.args(PATH1, 1, 0), \"\"); query(_FILE_READ_BINARY.args(PATH1, 0, 0), \"\"); error(_FILE_READ_BINARY.args(PATH1, - 1), Err.FILE_OUT_OF_RANGE_X_X); error(_FILE_READ_BINARY.args(PATH1, 2), Err.FILE_OUT_OF_RANGE_X_X); error(_FILE_READ_BINARY.args(PATH1, 0, - 1), Err.FILE_OUT_OF_RANGE_X_X); error(_FILE_READ_BINARY.args(PATH1, 0, 2), Err.FILE_OUT_OF_RANGE_X_X); error(_FILE_READ_BINARY.args(PATH1, 2, 1), Err.FILE_OUT_OF_RANGE_X_X); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_WRITE_BINARY.args(PATH1, _CONVERT_STRING_TO_BASE64.args(\"a\"))); query(_FILE_READ_BINARY.args(PATH1), \"YcOk\"); query(_FILE_DELETE.args(PATH1)); } "
    },
    {
        "test_src": "@Test public void testChangeProtectionKey()throws NoPeerConnectionException, IOException { KeyPair keypair1 = EncryptionUtil.generateRSAKeyPair(); KeyPair keypair2 = EncryptionUtil.generateRSAKeyPair(); Number160 locationKey = Number160.createHash(NetworkTestUtil.randomString()); Number160 domainKey = H2HConstants.TOMP2P_DEFAULT_KEY; Number160 contentKey = Number160.createHash(NetworkTestUtil.randomString()); NetworkManager node = network.get(random.nextInt(networkSize)); H2HTestData data1v0 = new H2HTestData(NetworkTestUtil.randomString()); data1v0.generateVersionKey(); data1v0.setBasedOnKey(Number160.ZERO); FuturePut putFuture1 = node.getDataManager().put(locationKey, domainKey, contentKey, data1v0, keypair1); putFuture1.awaitUninterruptibly(); Assert.assertTrue(putFuture1.isSuccess()); H2HTestData data1v1 = new H2HTestData(NetworkTestUtil.randomString()); data1v1.generateVersionKey(); data1v1.setBasedOnKey(data1v0.getVersionKey()); FuturePut putFuture2 = node.getDataManager().put(locationKey, domainKey, contentKey, data1v1, keypair1); putFuture2.awaitUninterruptibly(); Assert.assertTrue(putFuture2.isSuccess()); H2HTestData data1v2 = new H2HTestData(NetworkTestUtil.randomString()); data1v2.generateVersionKey(); data1v2.setBasedOnKey(data1v1.getVersionKey()); FuturePut changeFuture1 = node.getDataManager().changeProtectionKey(locationKey, domainKey, contentKey, data1v2.getTimeToLive(), keypair1, keypair2); changeFuture1.awaitUninterruptibly(); Assert.assertTrue(changeFuture1.isSuccess()); H2HTestData data1v3 = new H2HTestData(NetworkTestUtil.randomString()); data1v3.generateVersionKey(); data1v3.setBasedOnKey(data1v2.getVersionKey()); FuturePut changeFuture2 = node.getDataManager().put(locationKey, domainKey, contentKey, data1v3, keypair1); changeFuture2.awaitUninterruptibly(); Assert.assertFalse(changeFuture2.isSuccess()); } ",
        "focal_tgt": "public FuturePut changeProtectionKey(Number160 locationKey, Number160 domainKey, Number160 contentKey, Number160 versionKey, Number160 basedOnKey, int ttl, KeyPair oldProtectionKey, KeyPair newProtectionKey, byte[]hash) { logger.debug(String.format(\"change content protection key location key = '%s' domain key = '%s' content key = '%s' version key '%s'\", locationKey, domainKey, contentKey, versionKey)); try { Data data = new Data().ttlSeconds(ttl).basedOn(basedOnKey); Cipher rsa = Cipher.getInstance(\"RSA\"); rsa.init(Cipher.ENCRYPT_MODE, newProtectionKey.getPrivate()); byte[]newSignature = rsa.doFinal(hash); data = data.signature(signatureCodec.decode(newSignature)).signed(true).duplicateMeta(); return getPeer().put(locationKey).setDomainKey(domainKey).putMeta().setData(contentKey, data).setVersionKey(versionKey).keyPair(oldProtectionKey).start(); } catch(IOException | InvalidKeyException | NoSuchAlgorithmException | NoSuchPaddingException | IllegalBlockSizeException | BadPaddingException e) { logger.error(String.format(\"Change protection key failed. location key = '%s' domain key = '%s' content key = '%s' version key = '%s' exception = '%s'\", locationKey, domainKey, contentKey, versionKey, e.getMessage())); return null; } } ",
        "focal_src": "public FuturePut changeProtectionKey(Number160 locationKey, Number160 domainKey, Number160 contentKey, int ttl, KeyPair oldProtectionKey, KeyPair newProtectionKey) { logger.debug(String.format(\"change protection key; location key = '%s' domain key = '%s' content key = '%s'\", locationKey, domainKey, contentKey)); try { if(newProtectionKey == null) { logger.error(\"Cannot change the protection key to null value\"); return null; } else { Data data = new Data(); data.ttlSeconds(ttl); data = data.setProtectedEntry().sign(newProtectionKey, signatureFactory).duplicateMeta(); if(oldProtectionKey == null) { return getPeer().put(locationKey).setData(contentKey, data).setDomainKey(domainKey).keyPair(newProtectionKey).start(); } else { return getPeer().put(locationKey).setData(contentKey, data).setDomainKey(domainKey).keyPair(oldProtectionKey).start(); } } } catch(IOException | InvalidKeyException | SignatureException e) { logger.error(String.format(\"Change the protection key failed. location key = '%s' domain key = '%s' content key = '%s' exception = '%s'\", locationKey, domainKey, contentKey, e.getMessage())); return null; } } ",
        "test_tgt": "@Test public void testChangeProtectionKey()throws NoPeerConnectionException, IOException, InvalidKeyException, SignatureException { KeyPair keypairOld = EncryptionUtil.generateRSAKeyPair(); KeyPair keypairNew = EncryptionUtil.generateRSAKeyPair(); Number160 locationKey = Number160.createHash(NetworkTestUtil.randomString()); Number160 domainKey = H2HConstants.TOMP2P_DEFAULT_KEY; Number160 contentKey = Number160.createHash(NetworkTestUtil.randomString()); NetworkManager node = network.get(random.nextInt(networkSize)); H2HSharableTestData data = new H2HSharableTestData(NetworkTestUtil.randomString()); data.generateVersionKey(); data.setBasedOnKey(Number160.ZERO); FuturePut putFuture1 = node.getDataManager().put(locationKey, domainKey, contentKey, data, keypairOld); putFuture1.awaitUninterruptibly(); Assert.assertTrue(putFuture1.isSuccess()); FuturePut changeFuture = node.getDataManager().changeProtectionKey(locationKey, domainKey, contentKey, data.getVersionKey(), data.getBasedOnKey(), data.getTimeToLive(), keypairOld, keypairNew, data.getHash()); changeFuture.awaitUninterruptibly(); Assert.assertTrue(changeFuture.isSuccess()); Data resData = node.getDataManager().get(locationKey, domainKey, contentKey, data.getVersionKey()).awaitUninterruptibly().getData(); Assert.assertTrue(resData.verify(keypairNew.getPublic(), new H2HSignatureFactory())); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_minusMinutes_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.toLocalDate().minusDays(1); int hour = 0; int min = 0; for(int i = 0; i < 70; i ++ ) { t = t.minusMinutes(1); min -- ; if(min == - 1) { hour -- ; min = 59; if(hour == - 1) { hour = 23; } } assertEquals(t.toLocalDate(), d); assertEquals(t.getHour(), hour); assertEquals(t.getMinute(), min); } } ",
        "focal_tgt": "ChronoZonedDateTime < C > minusMinutes(long minutes) { ChronoDateTime newDT = dateTime.getDateTime().minusMinutes(minutes); return(newDT == dateTime.getDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "focal_src": "ChronoZonedDateTime < C > minusMinutes(long minutes) { ChronoDateTime newDT = dateTime.toDateTime().minusMinutes(minutes); return(newDT == dateTime.toDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_minusMinutes_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.getDate().minusDays(1); int hour = 0; int min = 0; for(int i = 0; i < 70; i ++ ) { t = t.minusMinutes(1); min -- ; if(min == - 1) { hour -- ; min = 59; if(hour == - 1) { hour = 23; } } assertEquals(t.getDate(), d); assertEquals(t.getHour(), hour); assertEquals(t.getMinute(), min); } } "
    },
    {
        "test_src": "@Test public final void add() { no(new Add(FILE)); ok(new CreateDB(NAME)); ok(new Add(FILE, \"input\")); ok(new Add(FILE, \"input\", \"target\")); ok(new Add(FLDR, \"xml\")); no(new Add(FILE, \":\")); no(new Add(FILE, \"\\\\\")); no(new Add(FILE, \"/\")); } ",
        "focal_tgt": "void add(final Data d) { list.add(new PData(d)); } ",
        "focal_src": "void add(final Data d) { if(size == data.length) { data = Arrays.copyOf(data, size << 1); pins = Arrays.copyOf(pins, size << 1); } data[size] = d; pins[size ++ ] = 1; } ",
        "test_tgt": "@Test public final void add() { no(new Add(FILE)); ok(new CreateDB(NAME)); ok(new Add(FILE, \"input\")); ok(new Add(FILE, \"input\", \"target\")); ok(new Add(FLDR, \"xml\")); no(new Add(FILE, \"\\\\\")); no(new Add(FILE, \"/\")); } "
    },
    {
        "test_src": "@Test public void testRecommend2() { LongList recs = extractIds(recommender.recommend(6, 4)); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); recs = extractIds(recommender.recommend(6, 3)); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); recs = extractIds(recommender.recommend(6, 2)); assertEquals(2, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); recs = extractIds(recommender.recommend(6, 1)); assertEquals(1, recs.size()); assertTrue(recs.contains(6)); recs = extractIds(recommender.recommend(6, 0)); assertTrue(recs.isEmpty()); recs = extractIds(recommender.recommend(6, - 1)); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); } ",
        "focal_tgt": "protected abstract ScoredLongList recommend(long user, SparseVector ratings, int n, @Nullable LongSet candidates, @Nonnull LongSet exclude); ",
        "focal_src": "protected abstract List < ScoredId > recommend(long user, SparseVector ratings, int n, @Nullable LongSet candidates, @Nonnull LongSet exclude); ",
        "test_tgt": "@Test public void testRecommend2() { LongList recs = recommender.recommend(6, 4); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); recs = recommender.recommend(6, 3); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); recs = recommender.recommend(6, 2); assertEquals(2, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); recs = recommender.recommend(6, 1); assertEquals(1, recs.size()); assertTrue(recs.contains(6)); recs = recommender.recommend(6, 0); assertTrue(recs.isEmpty()); recs = recommender.recommend(6, - 1); assertEquals(3, recs.size()); assertEquals(6, recs.getLong(0)); assertEquals(7, recs.getLong(1)); assertEquals(9, recs.getLong(2)); } "
    },
    {
        "test_src": "@Ignore(\"https://issues.apache.org/jira/browse/IGNITE-7265\")@Test public void testIterateConcurrentPutRemove_1()throws Exception { MAX_PER_PAGE = 1; iterateConcurrentPutRemove(); } ",
        "focal_tgt": "private void iterateConcurrentPutRemove()throws Exception { final TestTree tree = createTestTree(true); final int KEYS = MAX_PER_PAGE == 1 ? 26 : 10_000; ThreadLocalRandom rnd = ThreadLocalRandom.current(); for(int i = 0; i < 10; i ++ ) { for(long idx = 0L; idx < KEYS; ++ idx)tree.put(idx); final Long findKey; if(MAX_PER_PAGE > 0) { switch(i) { case 0 : findKey = 1L; break; case 1 : findKey = (long)MAX_PER_PAGE; break; case 2 : findKey = (long)MAX_PER_PAGE - 1; break; case 3 : findKey = (long)MAX_PER_PAGE + 1; break; case 4 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE; break; case 5 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE - 1; break; case 6 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE + 1; break; case 7 : findKey = (long)KEYS - 1; break; default : findKey = rnd.nextLong(KEYS); } } else findKey = rnd.nextLong(KEYS); info(\"Iteration [iter=\" + i + \", key=\" + findKey + ']'); assertEquals(findKey, tree.findOne(findKey)); checkIterate(tree, findKey, findKey, findKey, true); IgniteInternalFuture getFut = GridTestUtils.runMultiThreadedAsync(new Callable < Void > () { @Override public Void call()throws Exception { ThreadLocalRandom rnd = ThreadLocalRandom.current(); TestTreeRowClosure p = new TestTreeRowClosure(findKey); TestTreeRowClosure falseP = new TestTreeRowClosure( - 1L); int cnt = 0; while( ! stop.get()) { int shift = MAX_PER_PAGE > 0 ? rnd.nextInt(MAX_PER_PAGE * 2) : rnd.nextInt(100); checkIterateC(tree, findKey, findKey, p, true); checkIterateC(tree, findKey - shift, findKey, p, true); checkIterateC(tree, findKey - shift, findKey + shift, p, true); checkIterateC(tree, findKey, findKey + shift, p, true); checkIterateC(tree, - 100L, KEYS + 100L, falseP, false); cnt ++ ; } info(\"Done, read count: \" + cnt); return null; } }, 10, \"find\"); asyncRunFut = new GridCompoundFuture < > (); asyncRunFut.add(getFut); asyncRunFut.markInitialized(); try { U.sleep(100); for(int j = 0; j < 20; j ++ ) { for(long idx = 0L; idx < KEYS / 2; ++ idx) { long toRmv = rnd.nextLong(KEYS); if(toRmv != findKey)tree.remove(toRmv); } for(long idx = 0L; idx < KEYS / 2; ++ idx) { long put = rnd.nextLong(KEYS); tree.put(put); } } } finally { stop.set(true); } asyncRunFut.get(); stop.set(false); } } ",
        "focal_src": "private void iterateConcurrentPutRemove()throws Exception { final TestTree tree = createTestTree(true); final int KEYS = 10_000; ThreadLocalRandom rnd = ThreadLocalRandom.current(); for(int i = 0; i < 10; i ++ ) { for(long idx = 0L; idx < KEYS; ++ idx)tree.put(idx); final Long findKey; if(MAX_PER_PAGE > 0) { switch(i) { case 0 : findKey = 1L; break; case 1 : findKey = (long)MAX_PER_PAGE; break; case 2 : findKey = (long)MAX_PER_PAGE - 1; break; case 3 : findKey = (long)MAX_PER_PAGE + 1; break; case 4 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE; break; case 5 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE - 1; break; case 6 : findKey = (long)(KEYS / MAX_PER_PAGE / 2) * MAX_PER_PAGE + 1; break; case 7 : findKey = (long)KEYS - 1; break; default : findKey = rnd.nextLong(KEYS); } } else findKey = rnd.nextLong(KEYS); info(\"Iteration [iter=\" + i + \", key=\" + findKey + ']'); assertEquals(findKey, tree.findOne(findKey)); checkIterate(tree, findKey, findKey, findKey, true); IgniteInternalFuture getFut = GridTestUtils.runMultiThreadedAsync(new Callable < Void > () { @Override public Void call()throws Exception { ThreadLocalRandom rnd = ThreadLocalRandom.current(); TestTreeRowClosure p = new TestTreeRowClosure(findKey); TestTreeRowClosure falseP = new TestTreeRowClosure( - 1L); int cnt = 0; while( ! stop.get()) { int shift = MAX_PER_PAGE > 0 ? rnd.nextInt(MAX_PER_PAGE * 2) : rnd.nextInt(100); checkIterateC(tree, findKey, findKey, p, true); checkIterateC(tree, findKey - shift, findKey, p, true); checkIterateC(tree, findKey - shift, findKey + shift, p, true); checkIterateC(tree, findKey, findKey + shift, p, true); checkIterateC(tree, - 100L, KEYS + 100L, falseP, false); cnt ++ ; } info(\"Done, read count: \" + cnt); return null; } }, 10, \"find\"); asyncRunFut = new GridCompoundFuture < > (); asyncRunFut.add(getFut); asyncRunFut.markInitialized(); try { U.sleep(100); for(int j = 0; j < 20; j ++ ) { for(long idx = 0L; idx < KEYS / 2; ++ idx) { long toRmv = rnd.nextLong(KEYS); if(toRmv != findKey)tree.remove(toRmv); } for(long idx = 0L; idx < KEYS / 2; ++ idx) { long put = rnd.nextLong(KEYS); tree.put(put); } } } finally { stop.set(true); } asyncRunFut.get(); stop.set(false); } } ",
        "test_tgt": "@Test public void testIterateConcurrentPutRemove_1()throws Exception { MAX_PER_PAGE = 1; iterateConcurrentPutRemove(); } "
    },
    {
        "test_src": "@Test public void testOnCreateOrUpdateCommand()throws GenieException { this.c = new Command(NAME, USER, CommandStatus.ACTIVE, EXECUTABLE, VERSION); this.c.onCreateOrUpdateCommand(); } ",
        "focal_tgt": "@PrePersist@PreUpdate protected void onCreateOrUpdateCommand()throws GeniePreconditionException { validate(this.status, this.executable, null); if(this.tags == null) { this.tags = new HashSet < > (); } this.tags.add(this.getId()); this.tags.add(this.getName()); } ",
        "focal_src": "@PrePersist@PreUpdate protected void onCreateOrUpdateCommand()throws GenieException { validate(this.status, this.executable); if(this.tags == null) { this.tags = new HashSet < > (); } this.tags.add(this.getId()); this.tags.add(this.getName()); } ",
        "test_tgt": "@Test public void testOnCreateOrUpdateCommand()throws GeniePreconditionException { this.c = new Command(NAME, USER, CommandStatus.ACTIVE, EXECUTABLE, VERSION); this.c.onCreateOrUpdateCommand(); } "
    },
    {
        "test_src": "@Test public void getExtractorInstance() { File file = new File(\"/test/test.zip\"); Extractor result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.jar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.apk\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.tar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), TarExtractor.class); file = new File(\"/test/test.tar.gz\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), GzipExtractor.class); file = new File(\"/test/test.rar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertEquals(result.getClass(), RarExtractor.class); file = new File(\"/test/test.7z\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener); assertNull(result); } ",
        "focal_tgt": "public static Extractor getExtractorInstance(@NonNull Context context, @NonNull File file, @NonNull String outputPath, @NonNull Extractor.OnUpdate listener, @Nullable String password) { Extractor extractor; String type = getExtension(file.getPath()); if(isZip(type)) { extractor = new ZipExtractor(context, file.getPath(), outputPath, listener, null); } else if(isRar(type)) { extractor = new RarExtractor(context, file.getPath(), outputPath, listener, null); } else if(isTar(type)) { extractor = new TarExtractor(context, file.getPath(), outputPath, listener, null); } else if(isGzippedTar(type)) { extractor = new GzipExtractor(context, file.getPath(), outputPath, listener, null); } else if(isBzippedTar(type)) { extractor = new Bzip2Extractor(context, file.getPath(), outputPath, listener, null); } else if(isXzippedTar(type)) { extractor = new XzExtractor(context, file.getPath(), outputPath, listener, null); } else if(isLzippedTar(type)) { extractor = new LzmaExtractor(context, file.getPath(), outputPath, listener, null); } else if(is7zip(type)) { extractor = new SevenZipExtractor(context, file.getPath(), outputPath, listener, null); } else { return null; } return extractor; } ",
        "focal_src": "public static Extractor getExtractorInstance(Context context, File file, String outputPath, Extractor.OnUpdate listener) { Extractor extractor; String type = getExtension(file.getPath()); if(isZip(type)) { extractor = new ZipExtractor(context, file.getPath(), outputPath, listener); } else if(isRar(type)) { extractor = new RarExtractor(context, file.getPath(), outputPath, listener); } else if(isTar(type)) { extractor = new TarExtractor(context, file.getPath(), outputPath, listener); } else if(isGzippedTar(type)) { extractor = new GzipExtractor(context, file.getPath(), outputPath, listener); } else if(isBzippedTar(type)) { extractor = new Bzip2Extractor(context, file.getPath(), outputPath, listener); } else if(isXzippedTar(type)) { extractor = new XzExtractor(context, file.getPath(), outputPath, listener); } else if(isLzippedTar(type)) { extractor = new LzmaExtractor(context, file.getPath(), outputPath, listener); } else if(is7zip(type)) { extractor = new SevenZipExtractor(context, file.getPath(), outputPath, listener); } else { return null; } return extractor; } ",
        "test_tgt": "@Test public void getExtractorInstance() { File file = new File(\"/test/test.zip\"); Extractor result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.jar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.apk\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), ZipExtractor.class); file = new File(\"/test/test.tar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), TarExtractor.class); file = new File(\"/test/test.tar.gz\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), GzipExtractor.class); file = new File(\"/test/test.rar\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), RarExtractor.class); file = new File(\"/test/test.7z\"); result = CompressedHelper.getExtractorInstance(context, file, \"/test2\", emptyUpdateListener, null); assertEquals(result.getClass(), SevenZipExtractor.class); } "
    },
    {
        "test_src": "@Test public void deleteFileTest()throws IOException { String uniqPath = PathUtils.uniqPath(); for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = TachyonFSTestUtils.createByteFile(sTfs, fileURI.getPath(), sWriteBoth, k); Assert.assertTrue(sTfs.getInfo(f).getInMemoryPercentage() == 100); Assert.assertNotNull(sTfs.getInfo(f)); } for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = sTfs.open(fileURI); sTfs.delete(f); Assert.assertNull(sTfs.getInfo(f)); } } ",
        "focal_tgt": "public synchronized boolean deleteFile(long fileId, boolean recursive)throws IOException, FileDoesNotExistException { int retry = 0; while( ! mClosed && (retry ++ ) <= RPC_MAX_NUM_RETRY) { connect(); try { return mClient.deleteFile(fileId, recursive); } catch(FileDoesNotExistException e) { throw e; } catch(TException e) { LOG.error(e.getMessage(), e); mConnected = false; } } throw new IOException(\"Failed after \" + retry + \" retries.\"); } ",
        "focal_src": "public synchronized boolean deleteFile(long fileId, boolean recursive)throws IOException { int retry = 0; while( ! mClosed && (retry ++ ) <= RPC_MAX_NUM_RETRY) { connect(); try { return mClient.deleteFile(fileId, recursive); } catch(FileDoesNotExistException e) { throw new IOException(e); } catch(TException e) { LOG.error(e.getMessage(), e); mConnected = false; } } throw new IOException(\"Failed after \" + retry + \" retries.\"); } ",
        "test_tgt": "@Test public void deleteFileTest()throws IOException, TException { String uniqPath = PathUtils.uniqPath(); for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = TachyonFSTestUtils.createByteFile(sTfs, fileURI.getPath(), sWriteBoth, k); Assert.assertTrue(sTfs.getInfo(f).getInMemoryPercentage() == 100); Assert.assertNotNull(sTfs.getInfo(f)); } for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = sTfs.open(fileURI); sTfs.delete(f); Assert.assertNull(sTfs.getInfo(f)); } } "
    },
    {
        "test_src": "@Test public void testUserRatingVector() { Collection < Rating > ratings = Lists.newArrayList(Rating.create(5, 7, 3.5), Rating.create(5, 3, 1.5), Rating.create(5, 8, 2)); SparseVector v = Ratings.userRatingVector(ratings); assertEquals(3, v.size()); assertEquals(7, v.sum(), EPSILON); long[]keys = { 3, 7, 8 }; double[]values = { 1.5, 3.5, 2 }; SparseVector sv = MutableSparseVector.wrap(keys, values); assertEquals(sv, v); } ",
        "focal_tgt": "public static Long2DoubleMap userRatingVector(@Nonnull Collection < ? extends Rating > ratings) { return extractVector(ratings, IdExtractor.ITEM); } ",
        "focal_src": "public static MutableSparseVector userRatingVector(@Nonnull Collection < ? extends Rating > ratings) { return extractVector(ratings, IdExtractor.ITEM); } ",
        "test_tgt": "@Test public void testUserRatingVector() { Collection < Rating > ratings = Lists.newArrayList(Rating.create(5, 7, 3.5), Rating.create(5, 3, 1.5), Rating.create(5, 8, 2)); Long2DoubleMap v = Ratings.userRatingVector(ratings); assertEquals(3, v.size()); assertEquals(7, Vectors.sum(v), EPSILON); long[]keys = { 3, 7, 8 }; double[]values = { 1.5, 3.5, 2 }; Long2DoubleSortedArrayMap sv = Long2DoubleSortedArrayMap.wrap(SortedKeyIndex.create(keys), values); assertEquals(sv, v); } "
    },
    {
        "test_src": "@Test public void parseFileLog()throws Exception { String output = \"//Path/To/Folder/In/Workspace/Filename\\n\" + \"\\n\" + \"... #4 change 1234 edit on 2008/08/19 by User@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change number 4\\n\" + \"\\n\" + \"... #3 change 5678 edit on 2008/08/19 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\\n\" + \"\\n\" + \"... #2 change 8765 edit on 2008/08/01 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\\n\" + \"\\n\" + \"... #1 change 1 add on 2008/07/30 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\"; History result = PerforceHistoryParser.parseFileLog(new StringReader(output)); assertNotNull(result); assertEquals(4, result.getHistoryEntries().size()); HistoryEntry e1 = result.getHistoryEntries().get(0); assertEquals(\"4\", e1.getRevision()); assertEquals(\"User\", e1.getAuthor()); assertEquals(0, e1.getFiles().size()); assertTrue(e1.getMessage().contains(\"number 4\")); HistoryEntry e2 = result.getHistoryEntries().get(1); assertNotNull(e2); HistoryEntry e3 = result.getHistoryEntries().get(2); assertNotNull(e3); HistoryEntry e4 = result.getHistoryEntries().get(3); assertEquals(\"1\", e4.getRevision()); assertDate(e1, 2008, Calendar.AUGUST, 19); assertDate(e2, 2008, Calendar.AUGUST, 19); assertDate(e3, 2008, Calendar.AUGUST, 1); assertDate(e4, 2008, Calendar.JULY, 30); } ",
        "focal_tgt": "protected static History parseFileLog(Reader fileLog)throws IOException { BufferedReader reader = new BufferedReader(fileLog); List < HistoryEntry > entries = new ArrayList < HistoryEntry > (); String line; HistoryEntry entry = null; while((line = reader.readLine()) != null) { Matcher matcher = REVISION_PATTERN.matcher(line); if(matcher.find()) { if(entry != null) { entries.add(entry); entry = null; } entry = new HistoryEntry(); entry.setRevision(matcher.group(1)); int year = Integer.parseInt(matcher.group(2)); int month = Integer.parseInt(matcher.group(3)); int day = Integer.parseInt(matcher.group(4)); int hour = Integer.parseInt(matcher.group(5)); int minute = Integer.parseInt(matcher.group(6)); int second = Integer.parseInt(matcher.group(7)); entry.setDate(newDate(year, month, day, hour, minute, second)); entry.setAuthor(matcher.group(8)); entry.setActive(true); } else { if(entry != null) { if(line.startsWith(\"... ...\")) { entries.add(entry); entry = null; } else { entry.appendMessage(line); } } } } reader.close(); if(entry != null) { entries.add(entry); } History history = new History(); history.setHistoryEntries(entries); return history; } ",
        "focal_src": "protected static History parseFileLog(Reader fileLog)throws IOException { BufferedReader reader = new BufferedReader(fileLog); List < HistoryEntry > entries = new ArrayList < HistoryEntry > (); String line; HistoryEntry entry = null; while((line = reader.readLine()) != null) { Matcher matcher = REVISION_PATTERN.matcher(line); if(matcher.find()) { if(entry != null) { entries.add(entry); entry = null; } entry = new HistoryEntry(); entry.setRevision(matcher.group(1)); int year = Integer.parseInt(matcher.group(2)); int month = Integer.parseInt(matcher.group(3)); int day = Integer.parseInt(matcher.group(4)); entry.setDate(newDate(year, month, day)); entry.setAuthor(matcher.group(5)); entry.setActive(true); } else { if(entry != null) { if(line.startsWith(\"... ...\")) { entries.add(entry); entry = null; } else { entry.appendMessage(line); } } } } reader.close(); if(entry != null) { entries.add(entry); } History history = new History(); history.setHistoryEntries(entries); return history; } ",
        "test_tgt": "@Test public void parseFileLog()throws Exception { String output = \"//Path/To/Folder/In/Workspace/Filename\\n\" + \"\\n\" + \"... #4 change 1234 edit on 2008/08/19 11:30:00 by User@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change number 4\\n\" + \"\\n\" + \"... #3 change 5678 edit on 2008/08/19 18:25:38 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\\n\" + \"\\n\" + \"... #2 change 8765 edit on 2008/08/01 01:00:01 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\\n\" + \"\\n\" + \"... #1 change 1 add on 2008/07/30 17:45:33 by ADMIN@UserWorkspaceName (text)\\n\" + \"\\n\" + \" Comment for the change\"; History result = PerforceHistoryParser.parseFileLog(new StringReader(output)); assertNotNull(result); assertEquals(4, result.getHistoryEntries().size()); HistoryEntry e1 = result.getHistoryEntries().get(0); assertEquals(\"4\", e1.getRevision()); assertEquals(\"User\", e1.getAuthor()); assertEquals(0, e1.getFiles().size()); assertTrue(e1.getMessage().contains(\"number 4\")); HistoryEntry e2 = result.getHistoryEntries().get(1); assertNotNull(e2); HistoryEntry e3 = result.getHistoryEntries().get(2); assertNotNull(e3); HistoryEntry e4 = result.getHistoryEntries().get(3); assertEquals(\"1\", e4.getRevision()); assertDate(e1, 2008, Calendar.AUGUST, 19); assertDate(e2, 2008, Calendar.AUGUST, 19); assertDate(e3, 2008, Calendar.AUGUST, 1); assertDate(e4, 2008, Calendar.JULY, 30); } "
    },
    {
        "test_src": "@Override public final List < TestExecutionListener > getTestExecutionListeners() { Class < ? > clazz = getBootstrapContext().getTestClass(); Class < TestExecutionListeners > annotationType = TestExecutionListeners.class; List < Class < ? extends TestExecutionListener > > classesList = new ArrayList < > (); boolean usingDefaults = false; AnnotationDescriptor < TestExecutionListeners > descriptor = MetaAnnotationUtils.findAnnotationDescriptor(clazz, annotationType); if(descriptor == null) { if(logger.isDebugEnabled()) { logger.debug(String.format(\"@TestExecutionListeners is not present for class [%s]: using defaults.\", clazz.getName())); } usingDefaults = true; classesList.addAll(getDefaultTestExecutionListenerClasses()); } else { while(descriptor != null) { Class < ? > declaringClass = descriptor.getDeclaringClass(); TestExecutionListeners testExecutionListeners = descriptor.synthesizeAnnotation(); if(logger.isTraceEnabled()) { logger.trace(String.format(\"Retrieved @TestExecutionListeners [%s] for declaring class [%s].\", testExecutionListeners, declaringClass.getName())); } boolean inheritListeners = testExecutionListeners.inheritListeners(); AnnotationDescriptor < TestExecutionListeners > superDescriptor = MetaAnnotationUtils.findAnnotationDescriptor(descriptor.getRootDeclaringClass().getSuperclass(), annotationType); if(( ! inheritListeners || superDescriptor == null) && testExecutionListeners.mergeMode() == MergeMode.MERGE_WITH_DEFAULTS) { if(logger.isDebugEnabled()) { logger.debug(String.format(\"Merging default listeners with listeners configured via \" + \"@TestExecutionListeners for class [%s].\", descriptor.getRootDeclaringClass().getName())); } usingDefaults = true; classesList.addAll(getDefaultTestExecutionListenerClasses()); } classesList.addAll(0, Arrays.asList(testExecutionListeners.listeners())); descriptor = (inheritListeners ? superDescriptor : null); } } if(usingDefaults) { Set < Class < ? extends TestExecutionListener > > classesSet = new HashSet < > (); classesSet.addAll(classesList); classesList.clear(); classesList.addAll(classesSet); } List < TestExecutionListener > listeners = instantiateListeners(classesList); if(usingDefaults) { AnnotationAwareOrderComparator.sort(listeners); } if(logger.isInfoEnabled()) { logger.info(String.format(\"Using TestExecutionListeners: %s\", listeners)); } return listeners; } ",
        "focal_tgt": "@Nullable public static WildcardBounds get(ResolvableType type) { ResolvableType resolveToWildcard = type; while( ! (resolveToWildcard.getType()instanceof WildcardType)) { if(resolveToWildcard == NONE) { return null; } resolveToWildcard = resolveToWildcard.resolveType(); } WildcardType wildcardType = (WildcardType)resolveToWildcard.type; Kind boundsType = (wildcardType.getLowerBounds().length > 0 ? Kind.LOWER : Kind.UPPER); Type[]bounds = boundsType == Kind.UPPER ? wildcardType.getUpperBounds() : wildcardType.getLowerBounds(); ResolvableType[]resolvableBounds = new ResolvableType[bounds.length]; for(int i = 0; i < bounds.length; i ++ ) { resolvableBounds[i] = ResolvableType.forType(bounds[i], type.variableResolver); } return new WildcardBounds(boundsType, resolvableBounds); } ",
        "focal_src": "@Nullable public static WildcardBounds get(ResolvableType type) { ResolvableType resolveToWildcard = type; while( ! (resolveToWildcard.getType()instanceof WildcardType)) { if(resolveToWildcard == NONE) { return null; } resolveToWildcard = resolveToWildcard.resolveType(); } WildcardType wildcardType = (WildcardType)resolveToWildcard.type; Assert.state(wildcardType != null, \"Wildcard type not resolved\"); Kind boundsType = (wildcardType.getLowerBounds().length > 0 ? Kind.LOWER : Kind.UPPER); Type[]bounds = boundsType == Kind.UPPER ? wildcardType.getUpperBounds() : wildcardType.getLowerBounds(); ResolvableType[]resolvableBounds = new ResolvableType[bounds.length]; for(int i = 0; i < bounds.length; i ++ ) { resolvableBounds[i] = ResolvableType.forType(bounds[i], type.variableResolver); } return new WildcardBounds(boundsType, resolvableBounds); } ",
        "test_tgt": "@Override public final List < TestExecutionListener > getTestExecutionListeners() { Class < ? > clazz = getBootstrapContext().getTestClass(); Class < TestExecutionListeners > annotationType = TestExecutionListeners.class; List < Class < ? extends TestExecutionListener > > classesList = new ArrayList < > (); boolean usingDefaults = false; AnnotationDescriptor < TestExecutionListeners > descriptor = MetaAnnotationUtils.findAnnotationDescriptor(clazz, annotationType); if(descriptor == null) { if(logger.isDebugEnabled()) { logger.debug(String.format(\"@TestExecutionListeners is not present for class [%s]: using defaults.\", clazz.getName())); } usingDefaults = true; classesList.addAll(getDefaultTestExecutionListenerClasses()); } else { while(descriptor != null) { Class < ? > declaringClass = descriptor.getDeclaringClass(); TestExecutionListeners testExecutionListeners = descriptor.synthesizeAnnotation(); if(logger.isTraceEnabled()) { logger.trace(String.format(\"Retrieved @TestExecutionListeners [%s] for declaring class [%s].\", testExecutionListeners, declaringClass.getName())); } boolean inheritListeners = testExecutionListeners.inheritListeners(); AnnotationDescriptor < TestExecutionListeners > superDescriptor = MetaAnnotationUtils.findAnnotationDescriptor(descriptor.getRootDeclaringClass().getSuperclass(), annotationType); if(( ! inheritListeners || superDescriptor == null) && testExecutionListeners.mergeMode() == MergeMode.MERGE_WITH_DEFAULTS) { if(logger.isDebugEnabled()) { logger.debug(String.format(\"Merging default listeners with listeners configured via \" + \"@TestExecutionListeners for class [%s].\", descriptor.getRootDeclaringClass().getName())); } usingDefaults = true; classesList.addAll(getDefaultTestExecutionListenerClasses()); } classesList.addAll(0, Arrays.asList(testExecutionListeners.listeners())); descriptor = (inheritListeners ? superDescriptor : null); } } if(usingDefaults) { Set < Class < ? extends TestExecutionListener > > classesSet = new HashSet < > (); classesSet.addAll(classesList); classesList.clear(); classesList.addAll(classesSet); } List < TestExecutionListener > listeners = instantiateListeners(classesList); if(usingDefaults) { AnnotationAwareOrderComparator.sort(listeners); } if(logger.isInfoEnabled()) { logger.info(String.format(\"Using TestExecutionListeners: %s\", listeners)); } return listeners; } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should escape sql wildcards in searchPhrase\", method = \"getUsers(String, List, Boolean)\")public void getUsers_shouldEscapeSqlWildcardsInSearchPhrase()throws Exception { User u = new User(); u.setPerson(new Person()); u.getPerson().setGender(\"M\"); String wildcards[] = new String[] { \"%\", \"_\" }; for(String wildcard : wildcards) { PersonName name = new PersonName(\"\\\\\" + wildcard + \"cats\", wildcard + \"and\", wildcard + \"dogs\"); name.setDateCreated(new Date()); u.addName(name); u.setUsername(wildcard + \"test\" + wildcard); Context.getUserService().saveUser(u, \"Openmr5xy\"); int size = dao.getUsers(wildcard + \"ca\", null, false).size(); Assert.assertEquals(1, size); String userName = (dao.getUsers(wildcard + \"ca\", null, false).get(0).getUsername()); Assert.assertEquals(\"Test failed since no user containing the character \" + wildcard + \" was found, \", wildcard + \"test\" + wildcard, userName); } } ",
        "focal_tgt": "@SuppressWarnings(\"unchecked\")public List < User > getUsers(String name, List < Role > roles, boolean includeRetired) { log.debug(\"name: \" + name); name = HibernateUtil.escapeSqlWildcards(name, sessionFactory); List < String > criteria = new ArrayList < String > (); int counter = 0; Map < String, String > namesMap = new HashMap < String, String > (); if(name != null) { name = name.replace(\", \", \" \"); String[]names = name.split(\" \"); for(String n : names) { if(n != null && n.length() > 0) { String key = \"name\" + ++ counter; String value = n + \"%\"; namesMap.put(key, value); criteria.add(\"(user.username like :\" + key + \" or user.systemId like :\" + key + \" or name.givenName like :\" + key + \" or name.middleName like :\" + key + \" or name.familyName like :\" + key + \" or name.familyName2 like :\" + key + \")\"); } } } if(includeRetired == false)criteria.add(\"user.retired = false\"); String hql = \"select distinct user from User as user inner join user.person.names as name \"; if(criteria.size() > 0)hql += \"where \"; for(Iterator < String > i = criteria.iterator(); i.hasNext(); ) { hql += i.next() + \" \"; if(i.hasNext())hql += \"and \"; } hql += \" order by user.username asc\"; Query query = sessionFactory.getCurrentSession().createQuery(hql); for(Map.Entry < String, String > e : namesMap.entrySet())query.setString(e.getKey(), e.getValue()); if(roles != null && roles.size() > 0) { List returnList = new Vector(); log.debug(\"looping through to find matching roles\"); for(Object o : query.list()) { User u = (User)o; for(Role r : roles)if(u.hasRole(r.getRole(), true)) { returnList.add(u); break; } } return returnList; } else { log.debug(\"not looping because there appears to be no roles\"); return query.list(); } } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public List < User > getUsers(String name, List < Role > roles, boolean includeRetired) { log.debug(\"name: \" + name); name = HibernateUtil.escapeSqlWildcards(name, sessionFactory); List < String > criteria = new ArrayList < String > (); int counter = 0; Map < String, String > namesMap = new HashMap < String, String > (); if(name != null) { name = name.replace(\", \", \" \"); String[]names = name.split(\" \"); for(String n : names) { if(n != null && n.length() > 0) { String key = \"name\" + ++ counter; String value = n + \"%\"; namesMap.put(key, value); criteria.add(\"(user.username like :\" + key + \" or user.systemId like :\" + key + \" or name.givenName like :\" + key + \" or name.middleName like :\" + key + \" or name.familyName like :\" + key + \" or name.familyName2 like :\" + key + \")\"); } } } if(includeRetired == false)criteria.add(\"user.retired = false\"); String hql = \"select distinct user from User as user inner join user.person.names as name \"; if(criteria.size() > 0)hql += \"where \"; for(Iterator < String > i = criteria.iterator(); i.hasNext(); ) { hql += i.next() + \" \"; if(i.hasNext())hql += \"and \"; } hql += \" order by username asc\"; Query query = sessionFactory.getCurrentSession().createQuery(hql); for(Map.Entry < String, String > e : namesMap.entrySet())query.setString(e.getKey(), e.getValue()); if(roles != null && roles.size() > 0) { List returnList = new Vector(); log.debug(\"looping through to find matching roles\"); for(Object o : query.list()) { User u = (User)o; for(Role r : roles)if(u.hasRole(r.getRole(), true)) { returnList.add(u); break; } } return returnList; } else { log.debug(\"not looping because there appears to be no roles\"); return query.list(); } } ",
        "test_tgt": "@Test@Verifies(value = \"should escape sql wildcards in searchPhrase\", method = \"getUsers(String, List, Boolean)\")public void getUsers_shouldEscapeSqlWildcardsInSearchPhrase()throws Exception { User u = new User(); u.setPerson(new Person()); u.getPerson().setGender(\"M\"); String wildcards[] = new String[] { \"%\", \"_\" }; for(String wildcard : wildcards) { PersonName name = new PersonName(wildcard + \"cats\", wildcard + \"and\", wildcard + \"dogs\"); name.setDateCreated(new Date()); u.addName(name); u.setUsername(wildcard + \"test\" + wildcard); Context.getUserService().saveUser(u, \"Openmr5xy\"); int size = dao.getUsers(wildcard + \"ca\", null, false).size(); Assert.assertEquals(1, size); String userName = (dao.getUsers(wildcard + \"ca\", null, false).get(0).getUsername()); Assert.assertEquals(\"Test failed since no user containing the character \" + wildcard + \" was found, \", wildcard + \"test\" + wildcard, userName); } } "
    },
    {
        "test_src": "@Test(dependsOnMethods = \"init\")public void updatePreference()throws Exception { final PreferenceMgmtService preferenceMgmtService = getPreferenceMgmtService(); final PreferenceQueryService preferenceQueryService = getPreferenceQueryService(); JSONObject preference = preferenceQueryService.getPreference(); Assert.assertEquals(preference.getString(Preference.BLOG_TITLE), Preference.Default.DEFAULT_BLOG_TITLE); preference.put(Preference.BLOG_TITLE, \"updated blog title\"); preferenceMgmtService.updatePreference(preference); preference = preferenceQueryService.getPreference(); Assert.assertEquals(preference.getString(Preference.BLOG_TITLE), \"updated blog title\"); } ",
        "focal_tgt": "public void updatePreference(final JSONObject preference)throws ServiceException { @SuppressWarnings(\"unchecked\")final Iterator < String > keys = preference.keys(); while(keys.hasNext()) { final String key = keys.next(); if(preference.isNull(key)) { throw new ServiceException(\"A value is null of preference[key=\" + key + \"]\"); } } final Transaction transaction = optionRepository.beginTransaction(); try { final String skinDirName = preference.getString(Skin.SKIN_DIR_NAME); final String skinName = Latkes.getSkinName(skinDirName); preference.put(Skin.SKIN_NAME, skinName); final Set < String > skinDirNames = Skins.getSkinDirNames(); final JSONArray skinArray = new JSONArray(); for(final String dirName : skinDirNames) { final JSONObject skin = new JSONObject(); skinArray.put(skin); final String name = Latkes.getSkinName(dirName); skin.put(Skin.SKIN_NAME, name); skin.put(Skin.SKIN_DIR_NAME, dirName); } preference.put(Skin.SKINS, skinArray.toString()); final String timeZoneId = preference.getString(Option.ID_C_TIME_ZONE_ID); TimeZones.setTimeZone(timeZoneId); preference.put(Option.ID_C_SIGNS, preference.get(Option.ID_C_SIGNS).toString()); final JSONObject oldPreference = preferenceQueryService.getPreference(); final String adminEmail = oldPreference.getString(Option.ID_C_ADMIN_EMAIL); preference.put(Option.ID_C_ADMIN_EMAIL, adminEmail); final String version = oldPreference.optString(Option.ID_C_VERSION); preference.put(Option.ID_C_VERSION, version); final String localeString = preference.getString(Option.ID_C_LOCALE_STRING); LOGGER.log(Level.DEBUG, \"Current locale[string={0}]\", localeString); Latkes.setLocale(new Locale(Locales.getLanguage(localeString), Locales.getCountry(localeString))); final JSONObject adminEmailOpt = optionRepository.get(Option.ID_C_ADMIN_EMAIL); adminEmailOpt.put(Option.OPTION_VALUE, adminEmail); optionRepository.update(Option.ID_C_ADMIN_EMAIL, adminEmailOpt); final JSONObject allowVisitDraftViaPermalinkOpt = optionRepository.get(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK); allowVisitDraftViaPermalinkOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK)); optionRepository.update(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK, allowVisitDraftViaPermalinkOpt); final JSONObject allowRegisterOpt = optionRepository.get(Option.ID_C_ALLOW_REGISTER); allowRegisterOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ALLOW_REGISTER)); optionRepository.update(Option.ID_C_ALLOW_REGISTER, allowRegisterOpt); final JSONObject articleListDisplayCountOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT); articleListDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT)); optionRepository.update(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT, articleListDisplayCountOpt); final JSONObject articleListPaginationWindowSizeOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE); articleListPaginationWindowSizeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE)); optionRepository.update(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE, articleListPaginationWindowSizeOpt); final JSONObject articleListStyleOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_STYLE); articleListStyleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_STYLE)); optionRepository.update(Option.ID_C_ARTICLE_LIST_STYLE, articleListStyleOpt); final JSONObject blogSubtitleOpt = optionRepository.get(Option.ID_C_BLOG_SUBTITLE); blogSubtitleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_BLOG_SUBTITLE)); optionRepository.update(Option.ID_C_BLOG_SUBTITLE, blogSubtitleOpt); final JSONObject blogTitleOpt = optionRepository.get(Option.ID_C_BLOG_TITLE); blogTitleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_BLOG_TITLE)); optionRepository.update(Option.ID_C_BLOG_TITLE, blogTitleOpt); final JSONObject commentableOpt = optionRepository.get(Option.ID_C_COMMENTABLE); commentableOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_COMMENTABLE)); optionRepository.update(Option.ID_C_COMMENTABLE, commentableOpt); final JSONObject editorTypeOpt = optionRepository.get(Option.ID_C_EDITOR_TYPE); editorTypeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_EDITOR_TYPE)); optionRepository.update(Option.ID_C_EDITOR_TYPE, editorTypeOpt); final JSONObject enableArticleUpdateHintOpt = optionRepository.get(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT); enableArticleUpdateHintOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT)); optionRepository.update(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT, enableArticleUpdateHintOpt); final JSONObject externalRelevantArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT); externalRelevantArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT, externalRelevantArticlesDisplayCountOpt); final JSONObject feedOutputCntOpt = optionRepository.get(Option.ID_C_FEED_OUTPUT_CNT); feedOutputCntOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FEED_OUTPUT_CNT)); optionRepository.update(Option.ID_C_FEED_OUTPUT_CNT, feedOutputCntOpt); final JSONObject feedOutputModeOpt = optionRepository.get(Option.ID_C_FEED_OUTPUT_MODE); feedOutputModeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FEED_OUTPUT_MODE)); optionRepository.update(Option.ID_C_FEED_OUTPUT_MODE, feedOutputModeOpt); final JSONObject footerContentOpt = optionRepository.get(Option.ID_C_FOOTER_CONTENT); footerContentOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FOOTER_CONTENT)); optionRepository.update(Option.ID_C_FOOTER_CONTENT, footerContentOpt); final JSONObject htmlHeadOpt = optionRepository.get(Option.ID_C_HTML_HEAD); htmlHeadOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_HTML_HEAD)); optionRepository.update(Option.ID_C_HTML_HEAD, htmlHeadOpt); final JSONObject keyOfSoloOpt = optionRepository.get(Option.ID_C_KEY_OF_SOLO); keyOfSoloOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_KEY_OF_SOLO)); optionRepository.update(Option.ID_C_KEY_OF_SOLO, keyOfSoloOpt); final JSONObject localeStringOpt = optionRepository.get(Option.ID_C_LOCALE_STRING); localeStringOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_LOCALE_STRING)); optionRepository.update(Option.ID_C_LOCALE_STRING, localeStringOpt); final JSONObject metaDescriptionOpt = optionRepository.get(Option.ID_C_META_DESCRIPTION); metaDescriptionOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_META_DESCRIPTION)); optionRepository.update(Option.ID_C_META_DESCRIPTION, metaDescriptionOpt); final JSONObject metaKeywordsOpt = optionRepository.get(Option.ID_C_META_KEYWORDS); metaKeywordsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_META_KEYWORDS)); optionRepository.update(Option.ID_C_META_KEYWORDS, metaKeywordsOpt); final JSONObject mostCommentArticleDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT); mostCommentArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT, mostCommentArticleDisplayCountOpt); final JSONObject mostUsedTagDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT); mostUsedTagDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT, mostUsedTagDisplayCountOpt); final JSONObject mostViewArticleDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT); mostViewArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT, mostViewArticleDisplayCountOpt); final JSONObject noticeBoardOpt = optionRepository.get(Option.ID_C_NOTICE_BOARD); noticeBoardOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_NOTICE_BOARD)); optionRepository.update(Option.ID_C_NOTICE_BOARD, noticeBoardOpt); final JSONObject randomArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT); randomArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT, randomArticlesDisplayCountOpt); final JSONObject recentArticleDisplayCountOpt = optionRepository.get(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT); recentArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT, recentArticleDisplayCountOpt); final JSONObject recentCommentDisplayCountOpt = optionRepository.get(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT); recentCommentDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT, recentCommentDisplayCountOpt); final JSONObject relevantArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT); relevantArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT, relevantArticlesDisplayCountOpt); final JSONObject replyNotiTplBodyOpt = optionRepository.get(Option.ID_C_REPLY_NOTI_TPL_BODY); replyNotiTplBodyOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_REPLY_NOTI_TPL_BODY)); optionRepository.update(Option.ID_C_REPLY_NOTI_TPL_BODY, replyNotiTplBodyOpt); final JSONObject replyNotiTplSubjectOpt = optionRepository.get(Option.ID_C_REPLY_NOTI_TPL_SUBJECT); replyNotiTplSubjectOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_REPLY_NOTI_TPL_SUBJECT)); optionRepository.update(Option.ID_C_REPLY_NOTI_TPL_SUBJECT, replyNotiTplSubjectOpt); final JSONObject signsOpt = optionRepository.get(Option.ID_C_SIGNS); signsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SIGNS)); optionRepository.update(Option.ID_C_SIGNS, signsOpt); final JSONObject skinDirNameOpt = optionRepository.get(Option.ID_C_SKIN_DIR_NAME); skinDirNameOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKIN_DIR_NAME)); optionRepository.update(Option.ID_C_SKIN_DIR_NAME, skinDirNameOpt); final JSONObject skinNameOpt = optionRepository.get(Option.ID_C_SKIN_NAME); skinNameOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKIN_NAME)); optionRepository.update(Option.ID_C_SKIN_NAME, skinNameOpt); final JSONObject skinsOpt = optionRepository.get(Option.ID_C_SKINS); skinsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKINS)); optionRepository.update(Option.ID_C_SKINS, skinsOpt); final JSONObject timeZoneIdOpt = optionRepository.get(Option.ID_C_TIME_ZONE_ID); timeZoneIdOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_TIME_ZONE_ID)); optionRepository.update(Option.ID_C_TIME_ZONE_ID, timeZoneIdOpt); final JSONObject versionOpt = optionRepository.get(Option.ID_C_VERSION); versionOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_VERSION)); optionRepository.update(Option.ID_C_VERSION, versionOpt); transaction.commit(); final ServletContext servletContext = SoloServletListener.getServletContext(); Templates.MAIN_CFG.setServletContextForTemplateLoading(servletContext, \"/skins/\" + skinDirName); } catch(final Exception e) { if(transaction.isActive()) { transaction.rollback(); } LOGGER.log(Level.ERROR, \"Updates preference failed\", e); throw new ServiceException(langPropsService.get(\"updateFailLabel\")); } LOGGER.log(Level.DEBUG, \"Updates preference successfully\"); } ",
        "focal_src": "public void updatePreference(final JSONObject preference)throws ServiceException { @SuppressWarnings(\"unchecked\")final Iterator < String > keys = preference.keys(); while(keys.hasNext()) { final String key = keys.next(); if(preference.isNull(key)) { throw new ServiceException(\"A value is null of preference[key=\" + key + \"]\"); } } final Transaction transaction = optionRepository.beginTransaction(); try { final String skinDirName = preference.getString(Skin.SKIN_DIR_NAME); final String skinName = Latkes.getSkinName(skinDirName); preference.put(Skin.SKIN_NAME, skinName); final Set < String > skinDirNames = Skins.getSkinDirNames(); final JSONArray skinArray = new JSONArray(); for(final String dirName : skinDirNames) { final JSONObject skin = new JSONObject(); skinArray.put(skin); final String name = Latkes.getSkinName(dirName); skin.put(Skin.SKIN_NAME, name); skin.put(Skin.SKIN_DIR_NAME, dirName); } preference.put(Skin.SKINS, skinArray.toString()); final String timeZoneId = preference.getString(TIME_ZONE_ID); TimeZones.setTimeZone(timeZoneId); preference.put(Preference.SIGNS, preference.get(Preference.SIGNS).toString()); final JSONObject oldPreference = preferenceQueryService.getPreference(); final String adminEmail = oldPreference.getString(ADMIN_EMAIL); preference.put(ADMIN_EMAIL, adminEmail); final String version = oldPreference.optString(VERSION); preference.put(VERSION, version); final String localeString = preference.getString(Preference.LOCALE_STRING); LOGGER.log(Level.DEBUG, \"Current locale[string={0}]\", localeString); Latkes.setLocale(new Locale(Locales.getLanguage(localeString), Locales.getCountry(localeString))); final JSONObject adminEmailOpt = optionRepository.get(Option.ID_C_ADMIN_EMAIL); adminEmailOpt.put(Option.OPTION_VALUE, adminEmail); optionRepository.update(Option.ID_C_ADMIN_EMAIL, adminEmailOpt); final JSONObject allowVisitDraftViaPermalinkOpt = optionRepository.get(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK); allowVisitDraftViaPermalinkOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK)); optionRepository.update(Option.ID_C_ALLOW_VISIT_DRAFT_VIA_PERMALINK, allowVisitDraftViaPermalinkOpt); final JSONObject allowRegisterOpt = optionRepository.get(Option.ID_C_ALLOW_REGISTER); allowRegisterOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ALLOW_REGISTER)); optionRepository.update(Option.ID_C_ALLOW_REGISTER, allowRegisterOpt); final JSONObject articleListDisplayCountOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT); articleListDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT)); optionRepository.update(Option.ID_C_ARTICLE_LIST_DISPLAY_COUNT, articleListDisplayCountOpt); final JSONObject articleListPaginationWindowSizeOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE); articleListPaginationWindowSizeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE)); optionRepository.update(Option.ID_C_ARTICLE_LIST_PAGINATION_WINDOW_SIZE, articleListPaginationWindowSizeOpt); final JSONObject articleListStyleOpt = optionRepository.get(Option.ID_C_ARTICLE_LIST_STYLE); articleListStyleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ARTICLE_LIST_STYLE)); optionRepository.update(Option.ID_C_ARTICLE_LIST_STYLE, articleListStyleOpt); final JSONObject blogSubtitleOpt = optionRepository.get(Option.ID_C_BLOG_SUBTITLE); blogSubtitleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_BLOG_SUBTITLE)); optionRepository.update(Option.ID_C_BLOG_SUBTITLE, blogSubtitleOpt); final JSONObject blogTitleOpt = optionRepository.get(Option.ID_C_BLOG_TITLE); blogTitleOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_BLOG_TITLE)); optionRepository.update(Option.ID_C_BLOG_TITLE, blogTitleOpt); final JSONObject commentableOpt = optionRepository.get(Option.ID_C_COMMENTABLE); commentableOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_COMMENTABLE)); optionRepository.update(Option.ID_C_COMMENTABLE, commentableOpt); final JSONObject editorTypeOpt = optionRepository.get(Option.ID_C_EDITOR_TYPE); editorTypeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_EDITOR_TYPE)); optionRepository.update(Option.ID_C_EDITOR_TYPE, editorTypeOpt); final JSONObject enableArticleUpdateHintOpt = optionRepository.get(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT); enableArticleUpdateHintOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT)); optionRepository.update(Option.ID_C_ENABLE_ARTICLE_UPDATE_HINT, enableArticleUpdateHintOpt); final JSONObject externalRelevantArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT); externalRelevantArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_EXTERNAL_RELEVANT_ARTICLES_DISPLAY_CNT, externalRelevantArticlesDisplayCountOpt); final JSONObject feedOutputCntOpt = optionRepository.get(Option.ID_C_FEED_OUTPUT_CNT); feedOutputCntOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FEED_OUTPUT_CNT)); optionRepository.update(Option.ID_C_FEED_OUTPUT_CNT, feedOutputCntOpt); final JSONObject feedOutputModeOpt = optionRepository.get(Option.ID_C_FEED_OUTPUT_MODE); feedOutputModeOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FEED_OUTPUT_MODE)); optionRepository.update(Option.ID_C_FEED_OUTPUT_MODE, feedOutputModeOpt); final JSONObject footerContentOpt = optionRepository.get(Option.ID_C_FOOTER_CONTENT); footerContentOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_FOOTER_CONTENT)); optionRepository.update(Option.ID_C_FOOTER_CONTENT, footerContentOpt); final JSONObject htmlHeadOpt = optionRepository.get(Option.ID_C_HTML_HEAD); htmlHeadOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_HTML_HEAD)); optionRepository.update(Option.ID_C_HTML_HEAD, htmlHeadOpt); final JSONObject keyOfSoloOpt = optionRepository.get(Option.ID_C_KEY_OF_SOLO); keyOfSoloOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_KEY_OF_SOLO)); optionRepository.update(Option.ID_C_KEY_OF_SOLO, keyOfSoloOpt); final JSONObject localeStringOpt = optionRepository.get(Option.ID_C_LOCALE_STRING); localeStringOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_LOCALE_STRING)); optionRepository.update(Option.ID_C_LOCALE_STRING, localeStringOpt); final JSONObject metaDescriptionOpt = optionRepository.get(Option.ID_C_META_DESCRIPTION); metaDescriptionOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_META_DESCRIPTION)); optionRepository.update(Option.ID_C_META_DESCRIPTION, metaDescriptionOpt); final JSONObject metaKeywordsOpt = optionRepository.get(Option.ID_C_META_KEYWORDS); metaKeywordsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_META_KEYWORDS)); optionRepository.update(Option.ID_C_META_KEYWORDS, metaKeywordsOpt); final JSONObject mostCommentArticleDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT); mostCommentArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_COMMENT_ARTICLE_DISPLAY_CNT, mostCommentArticleDisplayCountOpt); final JSONObject mostUsedTagDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT); mostUsedTagDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_USED_TAG_DISPLAY_CNT, mostUsedTagDisplayCountOpt); final JSONObject mostViewArticleDisplayCountOpt = optionRepository.get(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT); mostViewArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_MOST_VIEW_ARTICLE_DISPLAY_CNT, mostViewArticleDisplayCountOpt); final JSONObject noticeBoardOpt = optionRepository.get(Option.ID_C_NOTICE_BOARD); noticeBoardOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_NOTICE_BOARD)); optionRepository.update(Option.ID_C_NOTICE_BOARD, noticeBoardOpt); final JSONObject randomArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT); randomArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RANDOM_ARTICLES_DISPLAY_CNT, randomArticlesDisplayCountOpt); final JSONObject recentArticleDisplayCountOpt = optionRepository.get(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT); recentArticleDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RECENT_ARTICLE_DISPLAY_CNT, recentArticleDisplayCountOpt); final JSONObject recentCommentDisplayCountOpt = optionRepository.get(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT); recentCommentDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RECENT_COMMENT_DISPLAY_CNT, recentCommentDisplayCountOpt); final JSONObject relevantArticlesDisplayCountOpt = optionRepository.get(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT); relevantArticlesDisplayCountOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT)); optionRepository.update(Option.ID_C_RELEVANT_ARTICLES_DISPLAY_CNT, relevantArticlesDisplayCountOpt); final JSONObject replyNotiTplBodyOpt = optionRepository.get(Option.ID_C_REPLY_NOTI_TPL_BODY); replyNotiTplBodyOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_REPLY_NOTI_TPL_BODY)); optionRepository.update(Option.ID_C_REPLY_NOTI_TPL_BODY, replyNotiTplBodyOpt); final JSONObject replyNotiTplSubjectOpt = optionRepository.get(Option.ID_C_REPLY_NOTI_TPL_SUBJECT); replyNotiTplSubjectOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_REPLY_NOTI_TPL_SUBJECT)); optionRepository.update(Option.ID_C_REPLY_NOTI_TPL_SUBJECT, replyNotiTplSubjectOpt); final JSONObject signsOpt = optionRepository.get(Option.ID_C_SIGNS); signsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SIGNS)); optionRepository.update(Option.ID_C_SIGNS, signsOpt); final JSONObject skinDirNameOpt = optionRepository.get(Option.ID_C_SKIN_DIR_NAME); skinDirNameOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKIN_DIR_NAME)); optionRepository.update(Option.ID_C_SKIN_DIR_NAME, skinDirNameOpt); final JSONObject skinNameOpt = optionRepository.get(Option.ID_C_SKIN_NAME); skinNameOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKIN_NAME)); optionRepository.update(Option.ID_C_SKIN_NAME, skinNameOpt); final JSONObject skinsOpt = optionRepository.get(Option.ID_C_SKINS); skinsOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_SKINS)); optionRepository.update(Option.ID_C_SKINS, skinsOpt); final JSONObject timeZoneIdOpt = optionRepository.get(Option.ID_C_TIME_ZONE_ID); timeZoneIdOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_TIME_ZONE_ID)); optionRepository.update(Option.ID_C_TIME_ZONE_ID, timeZoneIdOpt); final JSONObject versionOpt = optionRepository.get(Option.ID_C_VERSION); versionOpt.put(Option.OPTION_VALUE, preference.optString(Option.ID_C_VERSION)); optionRepository.update(Option.ID_C_VERSION, versionOpt); transaction.commit(); final ServletContext servletContext = SoloServletListener.getServletContext(); Templates.MAIN_CFG.setServletContextForTemplateLoading(servletContext, \"/skins/\" + skinDirName); } catch(final Exception e) { if(transaction.isActive()) { transaction.rollback(); } LOGGER.log(Level.ERROR, \"Updates preference failed\", e); throw new ServiceException(langPropsService.get(\"updateFailLabel\")); } LOGGER.log(Level.DEBUG, \"Updates preference successfully\"); } ",
        "test_tgt": "@Test(dependsOnMethods = \"init\")public void updatePreference()throws Exception { final PreferenceMgmtService preferenceMgmtService = getPreferenceMgmtService(); final PreferenceQueryService preferenceQueryService = getPreferenceQueryService(); JSONObject preference = preferenceQueryService.getPreference(); Assert.assertEquals(preference.getString(Option.ID_C_BLOG_TITLE), Preference.Default.DEFAULT_BLOG_TITLE); preference.put(Option.ID_C_BLOG_TITLE, \"updated blog title\"); preferenceMgmtService.updatePreference(preference); preference = preferenceQueryService.getPreference(); Assert.assertEquals(preference.getString(Option.ID_C_BLOG_TITLE), \"updated blog title\"); } "
    },
    {
        "test_src": "@Test public void copyTest()throws IOException, StoreException { storeCopier.copy(new StoreFindTokenFactory(STORE_KEY_FACTORY).getNewFindToken()); storeCopier.close(); StoreMetrics storeMetrics = new StoreMetrics(new MetricRegistry()); Files.copy(new File(srcDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), new File(tgtDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), StandardCopyOption.REPLACE_EXISTING); BlobStore tgt = new BlobStore(STORE_ID, storeConfig, null, null, DISK_IO_SCHEDULER, StoreTestUtils.DEFAULT_DISK_SPACE_ALLOCATOR, storeMetrics, storeMetrics, tgtDir.getAbsolutePath(), STORE_CAPACITY, STORE_KEY_FACTORY, null, null, time); tgt.start(); try { StoreKey[]failKeys = { expiredId, deletedId }; for(StoreKey key : failKeys) { try { tgt.get(Collections.singletonList(key), EnumSet.allOf(StoreGetOptions.class)); fail(\"Should have failed to get \" + key); } catch(StoreException e) { assertEquals(\"Unexpected StoreErrorCode\", StoreErrorCodes.ID_Not_Found, e.getErrorCode()); } } StoreInfo storeInfo = tgt.get(Collections.singletonList(putId), EnumSet.noneOf(StoreGetOptions.class)); MessageInfo messageInfo = storeInfo.getMessageReadSetInfo().get(0); assertEquals(\"Size does not match\", putData.length, messageInfo.getSize()); assertEquals(\"Size does not match\", putData.length, storeInfo.getMessageReadSet().sizeInBytes(0)); assertFalse(\"Should not be deleted or expired\", messageInfo.isDeleted() || messageInfo.isExpired()); ByteBufferChannel channel = new ByteBufferChannel(ByteBuffer.allocate(putData.length)); storeInfo.getMessageReadSet().writeTo(0, channel, 0, putData.length); assertArrayEquals(\"Data put does not match data copied\", putData, channel.getBuffer().array()); } finally { tgt.shutdown(); } } ",
        "focal_tgt": "public Pair < FindToken, Boolean > copy(FindToken startToken)throws Exception { boolean sourceHasProblems = false; FindToken lastToken; FindToken token = startToken; do { lastToken = token; FindInfo findInfo = src.findEntriesSince(lastToken, fetchSizeInBytes); List < MessageInfo > messageInfos = findInfo.getMessageEntries(); for(MessageInfo messageInfo : messageInfos) { logger.trace(\"Processing {} - isDeleted: {}, isExpired {}\", messageInfo.getStoreKey(), messageInfo.isDeleted(), messageInfo.isExpired()); if( ! messageInfo.isExpired() && ! messageInfo.isDeleted()) { if(messageInfo.getSize() > Integer.MAX_VALUE) { throw new IllegalStateException(\"Cannot copy blobs whose size > Integer.MAX_VALUE\"); } if(tgt.findMissingKeys(Collections.singletonList(messageInfo.getStoreKey())).size() == 1) { int size = (int)messageInfo.getSize(); StoreInfo storeInfo = src.get(Collections.singletonList(messageInfo.getStoreKey()), EnumSet.allOf(StoreGetOptions.class)); MessageReadSet readSet = storeInfo.getMessageReadSet(); byte[]buf = new byte[size]; readSet.writeTo(0, new ByteBufferChannel(ByteBuffer.wrap(buf)), 0, size); Message message = new Message(messageInfo, new ByteArrayInputStream(buf)); for(Transformer transformer : transformers) { message = transformer.transform(message); } MessageFormatWriteSet writeSet = new MessageFormatWriteSet(message.getStream(), Collections.singletonList(message.getMessageInfo()), false); tgt.put(writeSet); logger.trace(\"Copied {} as {}\", messageInfo.getStoreKey(), message.getMessageInfo().getStoreKey()); } else { logger.warn(\"Found a duplicate entry for {} while copying data\", messageInfo.getStoreKey()); sourceHasProblems = true; } } } token = findInfo.getFindToken(); logger.info(\"[{}] [{}] {}% copied\", Thread.currentThread().getName(), storeId, df.format(token.getBytesRead() * 100.0 / src.getSizeInBytes())); } while( ! token.equals(lastToken)); return new Pair < > (token, sourceHasProblems); } ",
        "focal_src": "public Pair < FindToken, Boolean > copy(FindToken startToken)throws IOException, StoreException { boolean sourceHasProblems = false; FindToken lastToken; FindToken token = startToken; do { lastToken = token; FindInfo findInfo = src.findEntriesSince(lastToken, fetchSizeInBytes); List < MessageInfo > messageInfos = findInfo.getMessageEntries(); for(MessageInfo messageInfo : messageInfos) { logger.trace(\"Processing {} - isDeleted: {}, isExpired {}\", messageInfo.getStoreKey(), messageInfo.isDeleted(), messageInfo.isExpired()); if( ! messageInfo.isExpired() && ! messageInfo.isDeleted()) { if(messageInfo.getSize() > Integer.MAX_VALUE) { throw new IllegalStateException(\"Cannot copy blobs whose size > Integer.MAX_VALUE\"); } if(tgt.findMissingKeys(Collections.singletonList(messageInfo.getStoreKey())).size() == 1) { int size = (int)messageInfo.getSize(); StoreInfo storeInfo = src.get(Collections.singletonList(messageInfo.getStoreKey()), EnumSet.allOf(StoreGetOptions.class)); MessageReadSet readSet = storeInfo.getMessageReadSet(); byte[]buf = new byte[size]; readSet.writeTo(0, new ByteBufferChannel(ByteBuffer.wrap(buf)), 0, size); Message message = new Message(messageInfo, new ByteArrayInputStream(buf)); for(Transformer transformer : transformers) { message = transformer.transform(message); } MessageFormatWriteSet writeSet = new MessageFormatWriteSet(message.getStream(), Collections.singletonList(message.getMessageInfo()), false); tgt.put(writeSet); logger.trace(\"Copied {} as {}\", messageInfo.getStoreKey(), message.getMessageInfo().getStoreKey()); } else { logger.warn(\"Found a duplicate entry for {} while copying data\", messageInfo.getStoreKey()); sourceHasProblems = true; } } } token = findInfo.getFindToken(); logger.info(\"[{}] [{}] {}% copied\", Thread.currentThread().getName(), storeId, df.format(token.getBytesRead() * 100.0 / src.getSizeInBytes())); } while( ! token.equals(lastToken)); return new Pair < > (token, sourceHasProblems); } ",
        "test_tgt": "@Test public void copyTest()throws Exception { storeCopier.copy(new StoreFindTokenFactory(STORE_KEY_FACTORY).getNewFindToken()); storeCopier.close(); StoreMetrics storeMetrics = new StoreMetrics(new MetricRegistry()); Files.copy(new File(srcDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), new File(tgtDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), StandardCopyOption.REPLACE_EXISTING); BlobStore tgt = new BlobStore(STORE_ID, storeConfig, null, null, DISK_IO_SCHEDULER, StoreTestUtils.DEFAULT_DISK_SPACE_ALLOCATOR, storeMetrics, storeMetrics, tgtDir.getAbsolutePath(), STORE_CAPACITY, STORE_KEY_FACTORY, null, null, time); tgt.start(); try { StoreKey[]failKeys = { expiredId, deletedId }; for(StoreKey key : failKeys) { try { tgt.get(Collections.singletonList(key), EnumSet.allOf(StoreGetOptions.class)); fail(\"Should have failed to get \" + key); } catch(StoreException e) { assertEquals(\"Unexpected StoreErrorCode\", StoreErrorCodes.ID_Not_Found, e.getErrorCode()); } } StoreInfo storeInfo = tgt.get(Collections.singletonList(putId), EnumSet.noneOf(StoreGetOptions.class)); MessageInfo messageInfo = storeInfo.getMessageReadSetInfo().get(0); assertEquals(\"Size does not match\", putData.length, messageInfo.getSize()); assertEquals(\"Size does not match\", putData.length, storeInfo.getMessageReadSet().sizeInBytes(0)); assertFalse(\"Should not be deleted or expired\", messageInfo.isDeleted() || messageInfo.isExpired()); ByteBufferChannel channel = new ByteBufferChannel(ByteBuffer.allocate(putData.length)); storeInfo.getMessageReadSet().writeTo(0, channel, 0, putData.length); assertArrayEquals(\"Data put does not match data copied\", putData, channel.getBuffer().array()); } finally { tgt.shutdown(); } } "
    },
    {
        "test_src": "@Test public void eval() { query(_XQUERY_EVAL.args(\"1\"), 1); query(_XQUERY_EVAL.args(\"1 + 2\"), 3); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { '$a': 'b' }\"), \"b\"); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { 'a': 'b' }\"), \"b\"); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { 'a': (1,2) }\"), \"1\\n2\"); query(_XQUERY_EVAL.args(\"declare variable $local:a external; $local:a\", \" map { xs:QName('local:a'): 1 }\"), 1); query(_XQUERY_EVAL.args(\".\", \" map { '': 1 }\"), 1); error(_XQUERY_EVAL.args(\"1+\"), CALCEXPR); error(\"declare variable $a:=1;\" + _XQUERY_EVAL.args(\"$a\"), VARUNDEF_X); error(\"for $a in (1,2) return \" + _XQUERY_EVAL.args(\"$a\"), VARUNDEF_X); error(_XQUERY_EVAL.args(\"delete node ()\"), BXXQ_UPDATING); error(_XQUERY_EVAL.args(\"declare %updating function local:x() {()}; local:x()\"), BXXQ_UPDATING); query(_XQUERY_EVAL.args(\"declare %updating function local:x() {()}; 1\")); query(_XQUERY_EVAL.args(DOC.args(PATH).trim())); query(_DB_CREATE.args(NAME)); query(\"try { \" + _XQUERY_EVAL.args(\"(1 to 10000000000000)[. = 0]\", \" map { }\", \" map { 'timeout': 1 }\") + \" } catch * { () }\", \"\"); query(_XQUERY_EVAL.args(\"static-base-uri()\", \" map { }\", \" map { 'base-uri': 'http://x.x/' }\"), \"http://x.x/\"); error(_XQUERY_EVAL.args(DOC.args(NAME).trim(), \" map { }\", \" map { 'permission': 'none' }\"), BXXQ_PERM_X); error(_XQUERY_EVAL.args(_DB_OPEN.args(NAME).trim(), \" map { }\", \" map { 'permission': 'none' }\"), BXDB_OPEN_X); error(_XQUERY_EVAL.args(_FILE_EXISTS.args(\"x\").trim(), \" map { }\", \" map { 'permission': 'none' }\"), BXXQ_PERM_X); error(_XQUERY_EVAL.args(\"(1 to 10000000000000)[. = 0]\", \" map { }\", \" map { 'timeout': 1 }\"), BXXQ_TIMEOUT); error(_XQUERY_EVAL.args(\"(1 to 10000000000000) ! <a/>\", \" map { }\", \" map { 'memory': 10 }\"), BXXQ_MEMORY); } ",
        "focal_tgt": "final ItemList eval(final QueryContext qc, final String query, final String path, final boolean updating)throws QueryException { final HashMap < String, Value > bindings = toBindings(1, qc); final Options opts = new XQueryOptions(); if(exprs.length > 2)toOptions(2, opts, qc); QueryContext qcAnc = qc; for(int c = 5; qcAnc != null && c > 0; c -- )qcAnc = qcAnc.parent; if(qcAnc != null)throw XQUERY_NESTED.get(info); final User user = qc.context.user(); final Perm tmp = user.perm(\"\"); Timer to = null; final Perm perm = Perm.get(opts.get(XQueryOptions.PERMISSION).toString()); if( ! user.has(perm))throw XQUERY_PERMISSION2_X.get(info, perm); user.perm(perm); try(QueryContext qctx = new QueryContext(qc)) { final long mb = opts.get(XQueryOptions.MEMORY); if(mb != 0) { Performance.gc(2); final long limit = Performance.memory() + (mb << 20); to = new Timer(true); to.schedule(new TimerTask() { @Override public void run() { if(Performance.memory() > limit)qctx.memory(); } }, 500, 500); } final long ms = opts.get(XQueryOptions.TIMEOUT) * 1000L; if(ms != 0) { if(to == null)to = new Timer(true); to.schedule(new TimerTask() { @Override public void run() { qctx.timeout(); } }, ms); } final String bu = opts.get(XQueryOptions.BASE_URI); final String uri = bu != null ? bu : path != null ? path : string(sc.baseURI().string()); try { final StaticContext sctx = new StaticContext(qctx); sctx.baseURI(uri); for(final Entry < String, Value > it : bindings.entrySet()) { final String key = it.getKey(); final Value val = it.getValue(); if(key.isEmpty())qctx.context(val, sctx); else qctx.bind(key, val, sctx); } qctx.parseMain(query, null, sctx); if(updating) { if( ! sc.mixUpdates && ! qctx.updating && ! qctx.root.expr.isVacuous())throw XQUERY_UPDATE2.get(info); } else { if(qctx.updating)throw XQUERY_UPDATE1.get(info); } final ItemList cache = new ItemList(); final Iter iter = qctx.iter(); for(Item it; (it = iter.next()) != null; ) { qctx.checkStop(); qc.checkStop(); cache.add(it); } return cache; } catch(final JobException ex) { if(qctx.state == JobState.TIMEOUT)throw XQUERY_TIMEOUT.get(info); if(qctx.state == JobState.MEMORY)throw XQUERY_MEMORY.get(info); throw ex; } catch(final QueryException ex) { if(ex.error() == BASX_PERM_X) { Util.debug(ex); throw XQUERY_PERMISSION1_X.get(info, ex.getLocalizedMessage()); } if( ! opts.get(XQueryOptions.PASS))ex.info(info); throw ex; } } finally { if(to != null)to.cancel(); user.perm(tmp, \"\"); } } ",
        "focal_src": "final ItemList eval(final QueryContext qc, final String query, final String path, final boolean updating)throws QueryException { final HashMap < String, Value > bindings = toBindings(1, qc); final Options opts = new XQueryOptions(); if(exprs.length > 2)toOptions(2, opts, qc); QueryContext qcAnc = qc; for(int c = 5; qcAnc != null && c > 0; c -- )qcAnc = qcAnc.parent; if(qcAnc != null)throw BXXQ_NESTED.get(info); final User user = qc.context.user(); final Perm tmp = user.perm(\"\"); Timer to = null; final Perm perm = Perm.get(opts.get(XQueryOptions.PERMISSION).toString()); if( ! user.has(perm))throw BXXQ_PERM2_X.get(info, perm); user.perm(perm); try(QueryContext qctx = new QueryContext(qc)) { final long mb = opts.get(XQueryOptions.MEMORY); if(mb != 0) { Performance.gc(2); final long limit = Performance.memory() + (mb << 20); to = new Timer(true); to.schedule(new TimerTask() { @Override public void run() { if(Performance.memory() > limit)qctx.memory(); } }, 500, 500); } final long ms = opts.get(XQueryOptions.TIMEOUT) * 1000L; if(ms != 0) { if(to == null)to = new Timer(true); to.schedule(new TimerTask() { @Override public void run() { qctx.timeout(); } }, ms); } final String bu = opts.get(XQueryOptions.BASE_URI); final String uri = bu != null ? bu : path != null ? path : string(sc.baseURI().string()); try { final StaticContext sctx = new StaticContext(qctx); sctx.baseURI(uri); for(final Entry < String, Value > it : bindings.entrySet()) { final String key = it.getKey(); final Value val = it.getValue(); if(key.isEmpty())qctx.context(val, sctx); else qctx.bind(key, val, sctx); } qctx.parseMain(query, null, sctx); if(updating) { if( ! sc.mixUpdates && ! qctx.updating && ! qctx.root.expr.isVacuous())throw BXXQ_NOUPDATE.get(info); } else { if(qctx.updating)throw BXXQ_UPDATING.get(info); } final ItemList cache = new ItemList(); final Iter iter = qctx.iter(); for(Item it; (it = iter.next()) != null; ) { qctx.checkStop(); qc.checkStop(); cache.add(it); } return cache; } catch(final JobException ex) { if(qctx.state == JobState.TIMEOUT)throw BXXQ_TIMEOUT.get(info); if(qctx.state == JobState.MEMORY)throw BXXQ_MEMORY.get(info); throw ex; } catch(final QueryException ex) { if(ex.error() == BASX_PERM_X)throw BXXQ_PERM_X.get(info, ex.getLocalizedMessage()); if( ! opts.get(XQueryOptions.PASS))ex.info(info); throw ex; } } finally { if(to != null)to.cancel(); user.perm(tmp, \"\"); } } ",
        "test_tgt": "@Test public void eval() { query(_XQUERY_EVAL.args(\"1\"), 1); query(_XQUERY_EVAL.args(\"1 + 2\"), 3); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { '$a': 'b' }\"), \"b\"); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { 'a': 'b' }\"), \"b\"); query(_XQUERY_EVAL.args(\"declare variable $a external; $a\", \" map { 'a': (1,2) }\"), \"1\\n2\"); query(_XQUERY_EVAL.args(\"declare variable $local:a external; $local:a\", \" map { xs:QName('local:a'): 1 }\"), 1); query(_XQUERY_EVAL.args(\".\", \" map { '': 1 }\"), 1); error(_XQUERY_EVAL.args(\"1+\"), CALCEXPR); error(\"declare variable $a:=1;\" + _XQUERY_EVAL.args(\"$a\"), VARUNDEF_X); error(\"for $a in (1,2) return \" + _XQUERY_EVAL.args(\"$a\"), VARUNDEF_X); error(_XQUERY_EVAL.args(\"delete node ()\"), XQUERY_UPDATE1); error(_XQUERY_EVAL.args(\"declare %updating function local:x() {()}; local:x()\"), XQUERY_UPDATE1); query(_XQUERY_EVAL.args(\"declare %updating function local:x() {()}; 1\")); query(_XQUERY_EVAL.args(DOC.args(PATH).trim())); query(_DB_CREATE.args(NAME)); query(\"try { \" + _XQUERY_EVAL.args(\"(1 to 10000000000000)[. = 0]\", \" map { }\", \" map { 'timeout': 1 }\") + \" } catch * { () }\", \"\"); query(_XQUERY_EVAL.args(\"static-base-uri()\", \" map { }\", \" map { 'base-uri': 'http://x.x/' }\"), \"http://x.x/\"); error(_XQUERY_EVAL.args(DOC.args(NAME).trim(), \" map { }\", \" map { 'permission': 'none' }\"), XQUERY_PERMISSION1_X); error(_XQUERY_EVAL.args(_DB_OPEN.args(NAME).trim(), \" map { }\", \" map { 'permission': 'none' }\"), DB_OPEN2_X); error(_XQUERY_EVAL.args(_FILE_EXISTS.args(\"x\").trim(), \" map { }\", \" map { 'permission': 'none' }\"), XQUERY_PERMISSION1_X); error(_XQUERY_EVAL.args(\"(1 to 10000000000000)[. = 0]\", \" map { }\", \" map { 'timeout': 1 }\"), XQUERY_TIMEOUT); error(_XQUERY_EVAL.args(\"(1 to 10000000000000) ! <a/>\", \" map { }\", \" map { 'memory': 10 }\"), XQUERY_MEMORY); } "
    },
    {
        "test_src": "@Test public void markMerge_quick() { int expected[] = new int[] { 1, - 1, - 1, 2, 2, 3, 5 }; RegionMergeTree alg = new RegionMergeTree(); alg.mergeList.resize(7); alg.mergeList.data = new int[] { 1, - 1, - 1, 2, 2, 3, 5 }; alg.markMerge(3, 4); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); alg.markMerge(3, 2); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); alg.markMerge(2, 3); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); } ",
        "focal_tgt": "protected void markMerge(int regionA, int regionB) { int dA = mergeList.data[regionA]; int dB = mergeList.data[regionB]; if(dA == dB) { return; } int rootA = regionA; while(dA != rootA) { rootA = dA; dA = mergeList.data[rootA]; } int rootB = regionB; while(dB != rootB) { rootB = dB; dB = mergeList.data[rootB]; } mergeList.data[regionA] = rootA; mergeList.data[regionB] = rootA; mergeList.data[rootB] = rootA; } ",
        "focal_src": "protected void markMerge(int regionA, int regionB) { int dA = mergeList.data[regionA]; int dB = mergeList.data[regionB]; if(dA != - 1 && dB != - 1) { if(dA == dB)return; } else if(dA != - 1) { if(dA == regionB)return; } else if(dB != - 1) { if(dB == regionA)return; } int rootA = regionA; while(dA != - 1) { rootA = dA; dA = mergeList.data[rootA]; } int rootB = regionB; while(dB != - 1) { rootB = dB; dB = mergeList.data[rootB]; } if(rootA != rootB) { mergeList.data[rootB] = rootA; } if(regionB != rootA) { mergeList.data[regionB] = rootA; } if(mergeList.data[regionA] != - 1) { mergeList.data[regionA] = rootA; } } ",
        "test_tgt": "@Test public void markMerge_quick() { int expected[] = new int[] { 1, 1, 2, 2, 2, 3, 5 }; RegionMergeTree alg = new RegionMergeTree(); alg.mergeList.resize(7); alg.mergeList.data = new int[] { 1, 1, 2, 2, 2, 3, 5 }; alg.markMerge(3, 4); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); alg.markMerge(3, 2); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); alg.markMerge(2, 3); for(int i = 0; i < expected.length; i ++ )assertEquals(expected[i], alg.mergeList.data[i]); } "
    },
    {
        "test_src": "@Test public void head() { query(_ARRAY_HEAD.args(\" [1]\"), \"1\"); query(_ARRAY_HEAD.args(\" array { 1 to 5 }\"), \"1\"); query(_ARRAY_HEAD.args(\" [1 to 2, 3]\"), \"1 2\"); error(_ARRAY_HEAD.args(\" []\"), Err.ARRAYBOUNDS); } ",
        "focal_tgt": "private Value head(final QueryContext qc)throws QueryException { final Array array = toArray(exprs[0], qc); return array.get(checkPos(array, 1)); } ",
        "focal_src": "private Value head(final QueryContext qc)throws QueryException { final Array array = array(0, qc); return array.get(checkPos(array, 1)); } ",
        "test_tgt": "@Test public void head() { query(_ARRAY_HEAD.args(\" [1]\"), \"1\"); query(_ARRAY_HEAD.args(\" array { 1 to 5 }\"), \"1\"); query(_ARRAY_HEAD.args(\" [1 to 2, 3]\"), \"1 2\"); error(_ARRAY_HEAD.args(\" []\"), Err.ARRAYBOUNDS_X_X); } "
    },
    {
        "test_src": "@Test public void testCreateClassifier()throws InterruptedException { server.enqueue(jsonResponse(classifier)); final Classifier response = service.createClassifier(classifierId, \"en\", new File(\"src/test/resources/natural_language_classifier/weather_data_train.csv\")).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(CLASSIFIERS_PATH, request.getPath()); assertEquals(classifier, response); } ",
        "focal_tgt": "public ServiceCall < Classifier > createClassifier(CreateClassifierOptions createClassifierOptions) { Validator.notNull(createClassifierOptions, \"createClassifierOptions cannot be null\"); RequestBuilder builder = RequestBuilder.post(\"/v1/classifiers\"); MultipartBody.Builder multipartBuilder = new MultipartBody.Builder(); multipartBuilder.setType(MultipartBody.FORM); RequestBody trainingMetadataBody = RequestUtils.inputStreamBody(createClassifierOptions.metadata(), \"application/json\"); multipartBuilder.addFormDataPart(\"training_metadata\", createClassifierOptions.metadataFilename(), trainingMetadataBody); RequestBody trainingDataBody = RequestUtils.inputStreamBody(createClassifierOptions.trainingData(), \"text/csv\"); multipartBuilder.addFormDataPart(\"training_data\", createClassifierOptions.trainingDataFilename(), trainingDataBody); builder.body(multipartBuilder.build()); return createServiceCall(builder.build(), ResponseConverterUtils.getObject(Classifier.class)); } ",
        "focal_src": "public ServiceCall < Classifier > createClassifier(final String name, final String language, final File trainingData) { Validator.isTrue((trainingData != null) && trainingData.exists(), \"trainingData cannot be null or not be found\"); Validator.isTrue((language != null) && ! language.isEmpty(), \"language cannot be null or empty\"); final JsonObject contentJson = new JsonObject(); contentJson.addProperty(LANGUAGE, language); if((name != null) && ! name.isEmpty()) { contentJson.addProperty(NAME, name); } final RequestBody body = new MultipartBody.Builder().setType(MultipartBody.FORM).addPart(Headers.of(HttpHeaders.CONTENT_DISPOSITION, FORM_DATA_TRAINING_DATA), RequestBody.create(HttpMediaType.BINARY_FILE, trainingData)).addFormDataPart(TRAINING_METADATA, contentJson.toString()).build(); final Request request = RequestBuilder.post(PATH_CLASSIFIERS).body(body).build(); return createServiceCall(request, ResponseConverterUtils.getObject(Classifier.class)); } ",
        "test_tgt": "@Test public void testCreateClassifier()throws InterruptedException, FileNotFoundException { server.enqueue(jsonResponse(classifier)); File metadata = new File(RESOURCE + \"metadata.json\"); File trainingData = new File(RESOURCE + \"weather_data_train.csv\"); CreateClassifierOptions createOptions = new CreateClassifierOptions.Builder().metadata(metadata).trainingData(trainingData).trainingDataFilename(\"weather_data_train.csv\").build(); final Classifier response = service.createClassifier(createOptions).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(CLASSIFIERS_PATH, request.getPath()); assertEquals(classifier, response); } "
    },
    {
        "test_src": "@Test public void testRename()throws QueryException, BaseXException { final String fun = check(Function.RENAME); new Add(\"etc/test/dir\", \"docs\", \"test\").execute(CONTEXT); query(fun + \"('db/test', 'newtest')\", \"\"); query(\"count(collection('db/newtest')) gt 0\", \"true\"); } ",
        "focal_tgt": "private Item rename(final QueryContext ctx)throws QueryException { checkWrite(ctx); final Data data = data(0, ctx); final byte[]source = path(checkStr(expr[1], ctx)); final byte[]target = path(checkStr(expr[2], ctx)); for(final int pre : data.doc(string(source))) { final byte[]trg = ACreate.newName(data, pre, source, target); if(trg.length == 0)EMPTYPATH.thrw(input, this); ctx.updates.add(new ReplaceValue(pre, data, input, trg), ctx); } return null; } ",
        "focal_src": "private Item rename(final QueryContext ctx)throws QueryException { checkWrite(ctx); final String path = path(string(checkStr(expr[0], ctx))); final int pos = path.indexOf('/'); if(pos <= 0)NODB.thrw(input, path); final byte[]db = token(path.substring(0, pos)); final Data data = ctx.resource.data(db, input); final byte[]src = token(path.substring(pos + 1)); final byte[]trg = token(path(string(checkStr(expr[1], ctx)))); final int[]docs = data.doc(string(src)); for(final int pre : docs) { final byte[]nm = newName(data, pre, src, trg); ctx.updates.add(new ReplaceValue(pre, data, input, nm), ctx); } return null; } ",
        "test_tgt": "@Test public void testRename()throws QueryException, BaseXException { final String fun = check(Function.DBRENAME); new Add(\"etc/test/dir\", \"docs\", \"test\").execute(CONTEXT); query(fun + \"('db', 'test', 'newtest')\", \"\"); query(\"count(collection('db/newtest')) gt 0\", \"true\"); } "
    },
    {
        "test_src": "@Test public void testGetSeq() { seq.add(2, 'c'); try { getSecuredSeq().getSeq(2); if( ! securityEvaluator.evaluate(Action.Read)) { Assert.fail(\"Should have thrown AccessDenied Exception\"); } } catch(final AccessDeniedException e) { if(securityEvaluator.evaluate(Action.Read)) { Assert.fail(String.format(\"Should not have thrown AccessDenied Exception: %s - %s\", e, e.getTriple())); } } } ",
        "focal_tgt": "@Override public SecuredSeq getSeq(final Resource r)throws ReadDeniedException; ",
        "focal_src": "@Override public SecuredSeq getSeq(final Resource r)throws AccessDeniedException; ",
        "test_tgt": "@Test public void testGetSeq() { seq.add(2, 'c'); try { getSecuredSeq().getSeq(2); if( ! securityEvaluator.evaluate(Action.Read)) { Assert.fail(\"Should have thrown ReadDeniedException Exception\"); } } catch(final ReadDeniedException e) { if(securityEvaluator.evaluate(Action.Read)) { Assert.fail(String.format(\"Should not have thrown ReadDeniedException Exception: %s - %s\", e, e.getTriple())); } } } "
    },
    {
        "test_src": "@Test public void x() { runQuery(\"geo:x(<gml:Point><gml:coordinates>2,1</gml:coordinates></gml:Point>)\", \"2\"); runError(\"geo:x(<gml:MultiPoint><gml:Point><gml:coordinates>1,1\" + \"</gml:coordinates></gml:Point><gml:Point><gml:coordinates>1,2\" + \"</gml:coordinates></gml:Point></gml:MultiPoint>)\", GeoErrors.qname(5)); runError(\"geo:x(\" + \"<gml:LinearRing><gml:coordinates>0,0 20,0 0,20 0,0</gml:coordinates>\" + \"</gml:LinearRing>)\", GeoErrors.qname(5)); runError(\"geo:x(<gml:Point><gml:coordinates></gml:coordinates></gml:Point>)\", GeoErrors.qname(2)); runError(\"geo:x(<gml:geo><gml:coordinates>2,1</gml:coordinates></gml:geo>)\", GeoErrors.qname(1)); runError(\"geo:x(text {'a'})\", FUNCMP.qname()); } ",
        "focal_tgt": "public Dbl x(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_POINT); if(geo == null && checkGeo(node) != null)throw GeoErrors.geoType(node.qname().local(), \"Point\"); return Dbl.get(geo.getCoordinate().x); } ",
        "focal_src": "public Dbl x(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_POINT); if(geo == null && checkGeo(node) != null)throw GeoErrors.pointNeeded(node.qname().local()); return Dbl.get(geo.getCoordinate().x); } ",
        "test_tgt": "@Test public void x() { runQuery(\"geo:x(<gml:Point><gml:coordinates>2,1</gml:coordinates></gml:Point>)\", \"2\"); runError(\"geo:x(<gml:MultiPoint><gml:Point><gml:coordinates>1,1\" + \"</gml:coordinates></gml:Point><gml:Point><gml:coordinates>1,2\" + \"</gml:coordinates></gml:Point></gml:MultiPoint>)\", GeoErrors.qname(3)); runError(\"geo:x(\" + \"<gml:LinearRing><gml:coordinates>0,0 20,0 0,20 0,0</gml:coordinates>\" + \"</gml:LinearRing>)\", GeoErrors.qname(3)); runError(\"geo:x(<gml:Point><gml:coordinates></gml:coordinates></gml:Point>)\", GeoErrors.qname(2)); runError(\"geo:x(<gml:geo><gml:coordinates>2,1</gml:coordinates></gml:geo>)\", GeoErrors.qname(1)); runError(\"geo:x(text {'a'})\", FUNCMP.qname()); } "
    },
    {
        "test_src": "@Test public void testCopy() { Matrix ACopy = A.copy(); assertEquals(A, ACopy); assertEquals(A.multiply(B), ACopy.multiply(B)); } ",
        "focal_tgt": "public CategoricalResults clone() { CategoricalResults copy = new CategoricalResults(n); copy.probabilities = Arrays.copyOf(probabilities, probabilities.length); return copy; } ",
        "focal_src": "public CategoricalResults copy() { CategoricalResults copy = new CategoricalResults(n); copy.probabilities = Arrays.copyOf(probabilities, probabilities.length); return copy; } ",
        "test_tgt": "@Test public void testCopy() { Matrix ACopy = A.clone(); assertEquals(A, ACopy); assertEquals(A.multiply(B), ACopy.multiply(B)); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_withDateTime() { LocalDateTime ldt = LocalDateTime.of(2008, 6, 30, 23, 30, 59, 0); ZonedDateTime base = ZonedDateTime.of(ldt, ZONE_0100); LocalDateTime dt = LocalDateTime.of(2008, 6, 30, 11, 31, 0); ZonedDateTime test = base.withDateTime(dt); assertEquals(test.toLocalDateTime(), dt); } ",
        "focal_tgt": "public ZonedDateTime withDateTime(LocalDateTime dateTime, ZoneResolver resolver) { Objects.requireNonNull(dateTime, \"LocalDateTime\"); Objects.requireNonNull(resolver, \"ZoneResolver\"); return this.getDateTime().equals(dateTime) ? this : ZonedDateTime.resolve(dateTime, zone, this.dateTime, resolver); } ",
        "focal_src": "public ZonedDateTime withDateTime(LocalDateTime dateTime, ZoneResolver resolver) { Objects.requireNonNull(dateTime, \"LocalDateTime\"); Objects.requireNonNull(resolver, \"ZoneResolver\"); return this.toLocalDateTime().equals(dateTime) ? this : ZonedDateTime.resolve(dateTime, zone, this.dateTime, resolver); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_withDateTime() { LocalDateTime ldt = LocalDateTime.of(2008, 6, 30, 23, 30, 59, 0); ZonedDateTime base = ZonedDateTime.of(ldt, ZONE_0100); LocalDateTime dt = LocalDateTime.of(2008, 6, 30, 11, 31, 0); ZonedDateTime test = base.withDateTime(dt); assertEquals(test.getDateTime(), dt); } "
    },
    {
        "test_src": "@Test public void reportOrphanedSpans_whenReporterDies() { PendingSpans map = new PendingSpans(endpoint, () -> 0, span -> { throw new RuntimeException(\"die!\"); }, new AtomicBoolean(true)); map.getOrCreate(context.toBuilder().build(), false); blockOnGC(); assertThat(map.delegate.keySet()).extracting(o -> ((Reference)o).get()).hasSize(1).containsNull(); map.remove(context); assertThat(map.delegate.keySet()).isEmpty(); } ",
        "focal_tgt": "void reportOrphanedSpans() { RealKey contextKey; long flushTime = 0L; boolean noop = zipkinHandler == FirehoseHandler.NOOP || this.noop.get(); while((contextKey = (RealKey)poll()) != null) { PendingSpan value = delegate.remove(contextKey); if(noop || value == null || ! contextKey.sampled)continue; if(flushTime == 0L)flushTime = clock.currentTimeMicroseconds(); TraceContext context = InternalPropagation.instance.newTraceContext(InternalPropagation.FLAG_SAMPLED, contextKey.traceIdHigh, contextKey.traceId, 0L, contextKey.spanId, Collections.emptyList()); value.state.annotate(flushTime, \"brave.flush\"); try { zipkinHandler.handle(context, value.state); } catch(RuntimeException e) { Platform.get().log(\"error reporting {0}\", context, e); } } } ",
        "focal_src": "void reportOrphanedSpans() { RealKey contextKey; Span.Builder builder = null; long flushTime = 0L; while((contextKey = (RealKey)poll()) != null) { PendingSpan value = delegate.remove(contextKey); if(value == null || noop.get() || ! contextKey.sampled)continue; if(builder != null) { builder.clear(); } else { builder = Span.newBuilder(); flushTime = clock.currentTimeMicroseconds(); } zipkin2.Span.Builder builderWithContextData = zipkin2.Span.newBuilder().traceId(contextKey.traceIdHigh, contextKey.traceId).id(contextKey.spanId).localEndpoint(localEndpoint).addAnnotation(flushTime, \"brave.flush\"); converter.convert(value.state, builderWithContextData); reporter.report(builderWithContextData.build()); } } ",
        "test_tgt": "@Test public void reportOrphanedSpans_whenReporterDies()throws Exception { init(new FirehoseHandler() { @Override public boolean handle(TraceContext context, MutableSpan span) { throw new RuntimeException(); } }); pendingSpans.getOrCreate(context.toBuilder().build(), false); blockOnGC(); assertThat(pendingSpans.delegate.keySet()).extracting(o -> ((Reference)o).get()).hasSize(1).containsNull(); pendingSpans.remove(context); assertThat(pendingSpans.delegate.keySet()).isEmpty(); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_next_serialization()throws IOException, ClassNotFoundException { DateTimeAdjuster next = DateTimeAdjusters.next(SUNDAY); assertTrue(next instanceof Serializable); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(next); oos.close(); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(baos.toByteArray())); assertEquals(ois.readObject(), next); } ",
        "focal_tgt": "public static WithAdjuster next(DayOfWeek dow) { if(dow == null) { throw new NullPointerException(\"DayOfWeek must not be null\"); } return new RelativeDayOfWeek(2, dow); } ",
        "focal_src": "public static DateTimeAdjuster next(DayOfWeek dow) { if(dow == null) { throw new NullPointerException(\"DayOfWeek must not be null\"); } return new RelativeDayOfWeek(2, dow); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_next_serialization()throws IOException, ClassNotFoundException { WithAdjuster next = DateTimeAdjusters.next(SUNDAY); assertTrue(next instanceof Serializable); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(next); oos.close(); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(baos.toByteArray())); assertEquals(ois.readObject(), next); } "
    },
    {
        "test_src": "@Test public void testPerform()throws Exception { final HostsHeartbeatCheck hostHeartbeatCheck = new HostsHeartbeatCheck(); hostHeartbeatCheck.clustersProvider = new Provider < Clusters > () { @Override public Clusters get() { return clusters; } }; final Cluster cluster = Mockito.mock(Cluster.class); Mockito.when(cluster.getClusterId()).thenReturn(1L); Mockito.when(cluster.getCurrentStackVersion()).thenReturn(new StackId(\"HDP\", \"2.2\")); Mockito.when(clusters.getCluster(\"cluster\")).thenReturn(cluster); final List < Host > hosts = new ArrayList < > (); final Host host1 = Mockito.mock(Host.class); final Host host2 = Mockito.mock(Host.class); final Host host3 = Mockito.mock(Host.class); final HostHealthStatus status1 = Mockito.mock(HostHealthStatus.class); final HostHealthStatus status2 = Mockito.mock(HostHealthStatus.class); final HostHealthStatus status3 = Mockito.mock(HostHealthStatus.class); Mockito.when(host1.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host2.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host1.getHealthStatus()).thenReturn(status1); Mockito.when(host2.getHealthStatus()).thenReturn(status2); Mockito.when(host3.getHealthStatus()).thenReturn(status3); Mockito.when(status1.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); Mockito.when(status2.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); Mockito.when(status3.getHealthStatus()).thenReturn(HealthStatus.UNKNOWN); hosts.add(host1); hosts.add(host2); hosts.add(host3); Mockito.when(cluster.getHosts()).thenReturn(hosts); PrerequisiteCheck check = new PrerequisiteCheck(null, null); hostHeartbeatCheck.perform(check, new PrereqCheckRequest(\"cluster\")); Assert.assertEquals(PrereqCheckStatus.FAIL, check.getStatus()); Assert.assertFalse(check.getFailedDetail().isEmpty()); check = new PrerequisiteCheck(null, null); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.ON); hostHeartbeatCheck.perform(check, new PrereqCheckRequest(\"cluster\")); Assert.assertEquals(PrereqCheckStatus.PASS, check.getStatus()); Assert.assertTrue(check.getFailedDetail().isEmpty()); Mockito.when(status3.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); check = new PrerequisiteCheck(null, null); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); hostHeartbeatCheck.perform(check, new PrereqCheckRequest(\"cluster\")); Assert.assertEquals(PrereqCheckStatus.PASS, check.getStatus()); Assert.assertTrue(check.getFailedDetail().isEmpty()); } ",
        "focal_tgt": "@Override public UpgradeCheckResult perform(PrereqCheckRequest request)throws AmbariException { String autoStartEnabled = getProperty(request, CLUSTER_ENV_TYPE, RECOVERY_ENABLED_KEY); UpgradeCheckResult result = new UpgradeCheckResult(this); if( ! Boolean.valueOf(autoStartEnabled)) { return result; } String recoveryType = getProperty(request, CLUSTER_ENV_TYPE, RECOVERY_TYPE_KEY); if(StringUtils.equals(recoveryType, RECOVERY_AUTO_START)) { result.setFailReason(getFailReason(result, request)); result.setStatus(PrereqCheckStatus.FAIL); result.getFailedOn().add(request.getClusterName()); } return result; } ",
        "focal_src": "@Override public void perform(PrerequisiteCheck prerequisiteCheck, PrereqCheckRequest request)throws AmbariException { String autoStartEnabled = getProperty(request, CLUSTER_ENV_TYPE, RECOVERY_ENABLED_KEY); if( ! Boolean.valueOf(autoStartEnabled)) { return; } String recoveryType = getProperty(request, CLUSTER_ENV_TYPE, RECOVERY_TYPE_KEY); if(StringUtils.equals(recoveryType, RECOVERY_AUTO_START)) { prerequisiteCheck.setFailReason(getFailReason(prerequisiteCheck, request)); prerequisiteCheck.setStatus(PrereqCheckStatus.FAIL); prerequisiteCheck.getFailedOn().add(request.getClusterName()); } } ",
        "test_tgt": "@Test public void testPerform()throws Exception { final HostsHeartbeatCheck hostHeartbeatCheck = new HostsHeartbeatCheck(); hostHeartbeatCheck.clustersProvider = new Provider < Clusters > () { @Override public Clusters get() { return clusters; } }; final Cluster cluster = Mockito.mock(Cluster.class); Mockito.when(cluster.getClusterId()).thenReturn(1L); Mockito.when(cluster.getCurrentStackVersion()).thenReturn(new StackId(\"HDP\", \"2.2\")); Mockito.when(clusters.getCluster(\"cluster\")).thenReturn(cluster); final List < Host > hosts = new ArrayList < > (); final Host host1 = Mockito.mock(Host.class); final Host host2 = Mockito.mock(Host.class); final Host host3 = Mockito.mock(Host.class); final HostHealthStatus status1 = Mockito.mock(HostHealthStatus.class); final HostHealthStatus status2 = Mockito.mock(HostHealthStatus.class); final HostHealthStatus status3 = Mockito.mock(HostHealthStatus.class); Mockito.when(host1.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host2.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); Mockito.when(host1.getHealthStatus()).thenReturn(status1); Mockito.when(host2.getHealthStatus()).thenReturn(status2); Mockito.when(host3.getHealthStatus()).thenReturn(status3); Mockito.when(status1.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); Mockito.when(status2.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); Mockito.when(status3.getHealthStatus()).thenReturn(HealthStatus.UNKNOWN); hosts.add(host1); hosts.add(host2); hosts.add(host3); Mockito.when(cluster.getHosts()).thenReturn(hosts); UpgradePlanEntity upgradePlan = Mockito.mock(UpgradePlanEntity.class); UpgradeCheckResult result = hostHeartbeatCheck.perform(new PrereqCheckRequest(upgradePlan)); Assert.assertEquals(PrereqCheckStatus.FAIL, result.getStatus()); Assert.assertFalse(result.getFailedDetail().isEmpty()); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.ON); result = hostHeartbeatCheck.perform(new PrereqCheckRequest(upgradePlan)); Assert.assertEquals(PrereqCheckStatus.PASS, result.getStatus()); Assert.assertTrue(result.getFailedDetail().isEmpty()); Mockito.when(status3.getHealthStatus()).thenReturn(HealthStatus.HEALTHY); Mockito.when(host3.getMaintenanceState(1L)).thenReturn(MaintenanceState.OFF); result = hostHeartbeatCheck.perform(new PrereqCheckRequest(upgradePlan)); Assert.assertEquals(PrereqCheckStatus.PASS, result.getStatus()); Assert.assertTrue(result.getFailedDetail().isEmpty()); } "
    },
    {
        "test_src": "@Test public void testSendPostData_FileAsBody()throws IOException { sampler.setMethod(HTTPConstants.POST); setupFilepart(sampler, \"\", temporaryFile, \"\"); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentLength(connection, TEST_FILE_CONTENT.length); checkArraysHaveSameContent(TEST_FILE_CONTENT, connection.getOutputStreamContent()); connection.disconnect(); String otherEncoding; final String fileEncoding = System.getProperty(\"file.encoding\"); log.info(\"file.encoding: {}\", fileEncoding); if(UTF_8.equalsIgnoreCase(fileEncoding) || \"UTF8\".equalsIgnoreCase(fileEncoding)) { otherEncoding = \"ISO-8859-1\"; } else { otherEncoding = UTF_8; } log.info(\"Using other encoding: {}\", otherEncoding); establishConnection(); sampler.setContentEncoding(otherEncoding); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentLength(connection, TEST_FILE_CONTENT.length); checkArraysHaveSameContent(TEST_FILE_CONTENT, connection.getOutputStreamContent()); checkArraysHaveDifferentContent(new String(TEST_FILE_CONTENT).getBytes(otherEncoding), connection.getOutputStreamContent()); setupFormData(sampler); establishConnection(); sampler.setContentEncoding(\"\"); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentTypeUrlEncoded(connection); byte[]expectedUrl = \"title=mytitle&description=mydescription\".getBytes(); checkContentLength(connection, expectedUrl.length); checkArraysHaveSameContent(expectedUrl, connection.getOutputStreamContent()); } ",
        "focal_tgt": "public String sendPostData(URLConnection connection, HTTPSamplerBase sampler)throws IOException { StringBuilder postedBody = new StringBuilder(1000); HTTPFileArg[]files = sampler.getHTTPFiles(); String contentEncoding = sampler.getContentEncoding(); if(contentEncoding == null || contentEncoding.length() == 0) { contentEncoding = ENCODING; } if(sampler.getUseMultipart()) { OutputStream out = connection.getOutputStream(); out.write(formDataPostBody); postedBody.append(new String(formDataPostBody, contentEncoding)); for(int i = 0; i < files.length; i ++ ) { HTTPFileArg file = files[i]; byte[]header = file.getHeader().getBytes(); out.write(header); postedBody.append(new String(header)); writeFileToStream(file.getPath(), out); postedBody.append(\"<actual file content, not shown here>\"); byte[]fileMultipartEndDivider = getFileMultipartEndDivider(); out.write(fileMultipartEndDivider); postedBody.append(new String(fileMultipartEndDivider, ENCODING)); if(i + 1 < files.length) { out.write(CRLF); postedBody.append(new String(CRLF, SampleResult.DEFAULT_HTTP_ENCODING)); } } byte[]multipartEndDivider = getMultipartEndDivider(); out.write(multipartEndDivider); postedBody.append(new String(multipartEndDivider, ENCODING)); out.flush(); out.close(); } else { if(sampler.getArguments() != null && ! sampler.hasArguments() && sampler.getSendFileAsPostBody()) { OutputStream out = connection.getOutputStream(); HTTPFileArg file = files[0]; writeFileToStream(file.getPath(), out); out.flush(); out.close(); postedBody.append(\"<actual file content, not shown here>\"); } else if(formDataUrlEncoded != null) { OutputStream out = connection.getOutputStream(); out.write(formDataUrlEncoded); out.flush(); out.close(); postedBody.append(new String(formDataUrlEncoded, contentEncoding)); } } return postedBody.toString(); } ",
        "focal_src": "public String sendPostData(URLConnection connection, HTTPSamplerBase sampler)throws IOException { StringBuilder postedBody = new StringBuilder(1000); HTTPFileArg[]files = sampler.getHTTPFiles(); String contentEncoding = sampler.getContentEncoding(); if(contentEncoding == null || contentEncoding.length() == 0) { contentEncoding = ENCODING; } if(sampler.getUseMultipartForPost()) { OutputStream out = connection.getOutputStream(); out.write(formDataPostBody); postedBody.append(new String(formDataPostBody, contentEncoding)); for(int i = 0; i < files.length; i ++ ) { HTTPFileArg file = files[i]; byte[]header = file.getHeader().getBytes(); out.write(header); postedBody.append(new String(header)); writeFileToStream(file.getPath(), out); postedBody.append(\"<actual file content, not shown here>\"); byte[]fileMultipartEndDivider = getFileMultipartEndDivider(); out.write(fileMultipartEndDivider); postedBody.append(new String(fileMultipartEndDivider, ENCODING)); if(i + 1 < files.length) { out.write(CRLF); postedBody.append(new String(CRLF, SampleResult.DEFAULT_HTTP_ENCODING)); } } byte[]multipartEndDivider = getMultipartEndDivider(); out.write(multipartEndDivider); postedBody.append(new String(multipartEndDivider, ENCODING)); out.flush(); out.close(); } else { if(sampler.getArguments() != null && ! sampler.hasArguments() && sampler.getSendFileAsPostBody()) { OutputStream out = connection.getOutputStream(); HTTPFileArg file = files[0]; writeFileToStream(file.getPath(), out); out.flush(); out.close(); postedBody.append(\"<actual file content, not shown here>\"); } else if(formDataUrlEncoded != null) { OutputStream out = connection.getOutputStream(); out.write(formDataUrlEncoded); out.flush(); out.close(); postedBody.append(new String(formDataUrlEncoded, contentEncoding)); } } return postedBody.toString(); } ",
        "test_tgt": "@Test public void testSendPostData_FileAsBody()throws IOException { sampler.setMethod(HTTPConstants.POST); setupFilepart(sampler, \"\", temporaryFile, \"\"); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentLength(connection, TEST_FILE_CONTENT.length); checkArraysHaveSameContent(TEST_FILE_CONTENT, connection.getOutputStreamContent()); connection.disconnect(); String otherEncoding; final String fileEncoding = System.getProperty(\"file.encoding\"); log.info(\"file.encoding: {}\", fileEncoding); if(UTF_8.equalsIgnoreCase(fileEncoding) || \"UTF8\".equalsIgnoreCase(fileEncoding)) { otherEncoding = \"ISO-8859-1\"; } else { otherEncoding = UTF_8; } log.info(\"Using other encoding: {}\", otherEncoding); establishConnection(); sampler.setContentEncoding(otherEncoding); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentLength(connection, TEST_FILE_CONTENT.length); checkArraysHaveSameContent(TEST_FILE_CONTENT, connection.getOutputStreamContent()); checkArraysHaveDifferentContent(new String(TEST_FILE_CONTENT).getBytes(otherEncoding), connection.getOutputStreamContent()); setupFormData(sampler); establishConnection(); sampler.setContentEncoding(\"\"); postWriter.setHeaders(connection, sampler); postWriter.sendPostData(connection, sampler); checkContentTypeUrlEncoded(connection); byte[]expectedUrl = \"title=mytitle&description=mydescription\".getBytes(); checkContentLength(connection, expectedUrl.length); checkArraysHaveSameContent(expectedUrl, connection.getOutputStreamContent()); } "
    },
    {
        "test_src": "@Test public void getConstructorTest() { JavaAttributeInfo testAttr = getTestAttribute(); String method = getConstructor(CLASS_NAME, testAttr, GENERATE_SERVICE_AND_MANAGER); assertThat(true, is(method.contains(THIS + PERIOD + CLASS_NAME + SPACE + EQUAL + SPACE + \"builder\" + OBJECT + PERIOD + GET_METHOD_PREFIX + \"Testname\" + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN))); } ",
        "focal_tgt": "public static String getConstructor(String yangName, JavaAttributeInfo attr, int generatedJavaFiles, YangPluginConfig pluginConfig) { String attributeName = attr.getAttributeName(); String constructor; if((generatedJavaFiles & GENERATE_SERVICE_AND_MANAGER) != 0) { constructor = EIGHT_SPACE_INDENTATION + THIS + PERIOD + getCamelCase(attributeName, pluginConfig.getConflictResolver()) + SPACE + EQUAL + SPACE + BUILDER.toLowerCase() + OBJECT + PERIOD + GET_METHOD_PREFIX + getCapitalCase(getCamelCase(attributeName, pluginConfig.getConflictResolver())) + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN + NEW_LINE; } else { constructor = EIGHT_SPACE_INDENTATION + THIS + PERIOD + getCamelCase(attributeName, pluginConfig.getConflictResolver()) + SPACE + EQUAL + SPACE + BUILDER.toLowerCase() + OBJECT + PERIOD + getCamelCase(attributeName, pluginConfig.getConflictResolver()) + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN + NEW_LINE; } return constructor; } ",
        "focal_src": "public static String getConstructor(String yangName, JavaAttributeInfo attr, int generatedJavaFiles) { String attributeName = attr.getAttributeName(); String constructor; if((generatedJavaFiles & GENERATE_SERVICE_AND_MANAGER) != 0) { constructor = EIGHT_SPACE_INDENTATION + THIS + PERIOD + getCamelCase(attributeName, null) + SPACE + EQUAL + SPACE + BUILDER.toLowerCase() + OBJECT + PERIOD + GET_METHOD_PREFIX + getCapitalCase(getCamelCase(attributeName, null)) + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN + NEW_LINE; } else { constructor = EIGHT_SPACE_INDENTATION + THIS + PERIOD + getCamelCase(attributeName, null) + SPACE + EQUAL + SPACE + BUILDER.toLowerCase() + OBJECT + PERIOD + getCamelCase(attributeName, null) + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN + NEW_LINE; } return constructor; } ",
        "test_tgt": "@Test public void getConstructorTest() { JavaAttributeInfo testAttr = getTestAttribute(); YangPluginConfig pluginConfig = new YangPluginConfig(); String method = getConstructor(CLASS_NAME, testAttr, GENERATE_SERVICE_AND_MANAGER, pluginConfig); assertThat(true, is(method.contains(THIS + PERIOD + CLASS_NAME + SPACE + EQUAL + SPACE + \"builder\" + OBJECT + PERIOD + GET_METHOD_PREFIX + \"Testname\" + OPEN_PARENTHESIS + CLOSE_PARENTHESIS + SEMI_COLAN))); } "
    },
    {
        "test_src": "@Test public void isRing() { runQuery(\"geo:isRing(<gml:LinearRing><gml:coordinates>2,3 20,1 20,20 2,3\" + \"</gml:coordinates></gml:LinearRing>)\", \"true\"); runQuery(\"geo:isRing(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>)\", \"false\"); runError(\"geo:isRing(<gml:MultiLineString><gml:LineString><gml:coordinates>\" + \"1,1 0,0 2,1</gml:coordinates></gml:LineString><gml:LineString>\" + \"<gml:coordinates>2,1 3,3 4,4</gml:coordinates></gml:LineString>\" + \"</gml:MultiLineString>)\", GeoErrors.qname(4)); runError(\"geo:isClosed(\" + \"<gml:Point><gml:coordinates>2,3</gml:coordinates></gml:Point>)\", GeoErrors.qname(4)); runError(\"geo:isRing(\" + \"<gml:LineString><gml:coordinates>1,1</gml:coordinates></gml:LineString>)\", GeoErrors.qname(2)); runError(\"geo:isRing()\", XPARGS.qname()); runError(\"geo:isRing(text {'gml:Point'})\", FUNCMP.qname()); runError(\"geo:isRing(<Point><gml:coordinates>2,1</gml:coordinates></Point>)\", GeoErrors.qname(1)); } ",
        "focal_tgt": "public Bln isRing(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_LINEARRING, Q_GML_LINESTRING); if(geo == null && checkGeo(node) != null)throw GeoErrors.geoType(node.qname().local(), \"Line\"); return Bln.get(geo instanceof LineString ? ((LineString)geo).isRing() : ((LinearRing)geo).isRing()); } ",
        "focal_src": "public Bln isRing(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_LINEARRING, Q_GML_LINESTRING); if(geo == null && checkGeo(node) != null)throw GeoErrors.lineNeeded(node.qname().local()); return Bln.get(geo instanceof LineString ? ((LineString)geo).isRing() : ((LinearRing)geo).isRing()); } ",
        "test_tgt": "@Test public void isRing() { runQuery(\"geo:isRing(<gml:LinearRing><gml:coordinates>2,3 20,1 20,20 2,3\" + \"</gml:coordinates></gml:LinearRing>)\", \"true\"); runQuery(\"geo:isRing(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>)\", \"false\"); runError(\"geo:isRing(<gml:MultiLineString><gml:LineString><gml:coordinates>\" + \"1,1 0,0 2,1</gml:coordinates></gml:LineString><gml:LineString>\" + \"<gml:coordinates>2,1 3,3 4,4</gml:coordinates></gml:LineString>\" + \"</gml:MultiLineString>)\", GeoErrors.qname(3)); runError(\"geo:isClosed(\" + \"<gml:Point><gml:coordinates>2,3</gml:coordinates></gml:Point>)\", GeoErrors.qname(3)); runError(\"geo:isRing(\" + \"<gml:LineString><gml:coordinates>1,1</gml:coordinates></gml:LineString>)\", GeoErrors.qname(2)); runError(\"geo:isRing()\", XPARGS.qname()); runError(\"geo:isRing(text {'gml:Point'})\", FUNCMP.qname()); runError(\"geo:isRing(<Point><gml:coordinates>2,1</gml:coordinates></Point>)\", GeoErrors.qname(1)); } "
    },
    {
        "test_src": "@Test public void testAddWords()throws InterruptedException { final CustomVoiceModel model = instantiateVoiceModel(); final List < CustomTranslation > expected = instantiateWords(); server.enqueue(new MockResponse().setResponseCode(201)); service.addWords(model, expected.toArray(new CustomTranslation[] { })).execute(); RecordedRequest request = server.takeRequest(); assertEquals(String.format(WORDS_PATH, model.getId()), request.getPath()); assertEquals(\"POST\", request.getMethod()); server.enqueue(new MockResponse().setResponseCode(201)); service.addWords(model, expected.get(0)).execute(); request = server.takeRequest(); assertEquals(String.format(WORDS_PATH, model.getId()), request.getPath()); assertEquals(\"POST\", request.getMethod()); } ",
        "focal_tgt": "public ServiceCall < Void > addWords(AddWordsOptions addWordsOptions) { Validator.notNull(addWordsOptions, \"addWordsOptions cannot be null\"); RequestBuilder builder = RequestBuilder.post(String.format(\"/v1/customizations/%s/words\", addWordsOptions.customizationId())); final JsonObject contentJson = new JsonObject(); contentJson.add(\"words\", GsonSingleton.getGson().toJsonTree(addWordsOptions.words())); builder.bodyJson(contentJson); return createServiceCall(builder.build(), ResponseConverterUtils.getVoid()); } ",
        "focal_src": "public ServiceCall < Void > addWords(final CustomVoiceModel model, final CustomTranslation ... translations) { Validator.notNull(model, \"model cannot be null\"); Validator.notEmpty(model.getId(), \"model id must not be empty\"); Validator.notNull(translations, \"translations cannot be null\"); final String json = GSON.toJson(Collections.singletonMap(\"words\", translations)); final String path = String.format(PATH_WORDS, model.getId()); final RequestBody body = RequestBody.create(HttpMediaType.JSON, json); final Request request = RequestBuilder.post(path).body(body).build(); return createServiceCall(request, ResponseConverterUtils.getVoid()); } ",
        "test_tgt": "@Test public void testAddWords()throws InterruptedException { final VoiceModel model = instantiateVoiceModel(); final List < CustomWord > expected = instantiateCustomWords(); server.enqueue(new MockResponse().setResponseCode(201)); AddWordsOptions addOptions = new AddWordsOptions.Builder().customizationId(model.getCustomizationId()).words(expected).build(); service.addWords(addOptions).execute(); RecordedRequest request = server.takeRequest(); assertEquals(String.format(WORDS_PATH, model.getCustomizationId()), request.getPath()); assertEquals(\"POST\", request.getMethod()); } "
    },
    {
        "test_src": "@SuppressWarnings(\"unchecked\")@Test public void testReleaseConnection()throws SQLException, IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException, InterruptedException { Field field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, false); expect(mockConnection.isPossiblyBroken()).andReturn(false).once(); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.offer(mockConnection)).andReturn(false).anyTimes(); mockConnectionHandles.put(mockConnection); expectLastCall().once(); mockConnection.setConnectionLastUsed(anyLong()); expectLastCall().once(); replay(mockConnection, mockPartition, mockConnectionHandles); testClass.releaseConnection(mockConnection); verify(mockConnection, mockPartition, mockConnectionHandles); reset(mockConnection, mockPartition, mockConnectionHandles); field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, false); expect(mockConnection.isPossiblyBroken()).andReturn(false).once(); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.offer(mockConnection)).andReturn(false).anyTimes(); mockConnectionHandles.put(mockConnection); expectLastCall().andThrow(new InterruptedException()).once(); mockConnection.setConnectionLastUsed(anyLong()); expectLastCall().once(); replay(mockConnection, mockPartition, mockConnectionHandles); try { testClass.releaseConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } verify(mockConnection, mockPartition, mockConnectionHandles); reset(mockConnection, mockPartition, mockConnectionHandles); field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, true); ArrayBlockingQueue < ConnectionHandle > mockPendingRelease = createNiceMock(ArrayBlockingQueue.class); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); expect(mockPartition.getConnectionsPendingRelease()).andReturn(mockPendingRelease).anyTimes(); mockPendingRelease.put(mockConnection); expectLastCall().once(); replay(mockConnection, mockPartition, mockConnectionHandles, mockPendingRelease); testClass.releaseConnection(mockConnection); verify(mockConnection, mockPartition, mockConnectionHandles, mockPendingRelease); } ",
        "focal_tgt": "protected void releaseConnection(Connection connection)throws SQLException { ConnectionHandle handle = (ConnectionHandle)connection; if(handle.getConnectionHook() != null) { handle.getConnectionHook().onCheckIn(handle); } if( ! this.poolShuttingDown && this.releaseHelperThreadsConfigured) { handle.getOriginatingPartition().getConnectionsPendingRelease().put(handle); } else { internalReleaseConnection(handle); } } ",
        "focal_src": "protected void releaseConnection(Connection connection)throws SQLException { try { ConnectionHandle handle = (ConnectionHandle)connection; if(handle.getConnectionHook() != null) { handle.getConnectionHook().onCheckIn(handle); } if( ! this.poolShuttingDown && this.releaseHelperThreadsConfigured) { handle.getOriginatingPartition().getConnectionsPendingRelease().put(handle); } else { internalReleaseConnection(handle); } } catch(InterruptedException e) { throw new SQLException(e); } } ",
        "test_tgt": "@SuppressWarnings(\"unchecked\")@Test public void testReleaseConnection()throws SQLException, IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException, InterruptedException { Field field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, false); expect(mockConnection.isPossiblyBroken()).andReturn(false).once(); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockPartition.getAvailableConnections()).andReturn(new AtomicInteger(1)).anyTimes(); expect(mockConnectionHandles.offer(mockConnection)).andReturn(false).anyTimes(); mockConnectionHandles.put(mockConnection); expectLastCall().once(); mockConnection.setConnectionLastUsed(anyLong()); expectLastCall().once(); replay(mockConnection, mockPartition, mockConnectionHandles); testClass.releaseConnection(mockConnection); verify(mockConnection, mockPartition, mockConnectionHandles); reset(mockConnection, mockPartition, mockConnectionHandles); field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, false); reset(mockConnection, mockPartition, mockConnectionHandles); field = testClass.getClass().getDeclaredField(\"releaseHelperThreadsConfigured\"); field.setAccessible(true); field.setBoolean(testClass, true); LinkedTransferQueue < ConnectionHandle > mockPendingRelease = createNiceMock(LinkedTransferQueue.class); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); expect(mockPartition.getConnectionsPendingRelease()).andReturn(mockPendingRelease).anyTimes(); mockPendingRelease.put(mockConnection); expectLastCall().once(); replay(mockConnection, mockPartition, mockConnectionHandles, mockPendingRelease); testClass.releaseConnection(mockConnection); verify(mockConnection, mockPartition, mockConnectionHandles, mockPendingRelease); } "
    },
    {
        "test_src": "@Test public void testGetVoices() { List < Voice > voices = service.getVoices(); Assert.assertNotNull(voices); Assert.assertTrue( ! voices.isEmpty()); } ",
        "focal_tgt": "public ServiceCall < List < Voice > > getVoices() { final okhttp3.Request request = RequestBuilder.get(\"/v1/voices\").build3(); return createServiceCall(createCall(request), ResponseUtil.getVoiceListConverter(listVoiceType)); } ",
        "focal_src": "public List < Voice > getVoices() { final Request request = RequestBuilder.get(\"/v1/voices\").build(); final Response response = execute(request); final JsonObject jsonObject = ResponseUtil.getJsonObject(response); final List < Voice > voices = GsonSingleton.getGsonWithoutPrettyPrinting().fromJson(jsonObject.get(\"voices\"), listVoiceType); return voices; } ",
        "test_tgt": "@Test public void testGetVoices() { List < Voice > voices = service.getVoices().execute(); Assert.assertNotNull(voices); Assert.assertTrue( ! voices.isEmpty()); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_parse_basicIsoDate() { LocalDate expected = LocalDate.of(2008, 6, 3); assertEquals(DateTimeFormatters.basicIsoDate().parse(\"20080603\", LocalDate :: from), expected); } ",
        "focal_tgt": "public static Duration parse(CharSequence text) { Objects.requireNonNull(text, \"text\"); Matcher matcher = PATTERN.matcher(text); if(matcher.matches()) { if(\"T\".equals(matcher.group(3)) == false) { boolean negate = \"-\".equals(matcher.group(1)); String dayMatch = matcher.group(2); String hourMatch = matcher.group(4); String minuteMatch = matcher.group(5); String secondMatch = matcher.group(6); String fractionMatch = matcher.group(7); if(dayMatch != null || hourMatch != null || minuteMatch != null || secondMatch != null) { long daysAsSecs = parseNumber(text, dayMatch, SECONDS_PER_DAY, \"days\"); long hoursAsSecs = parseNumber(text, hourMatch, SECONDS_PER_HOUR, \"hours\"); long minsAsSecs = parseNumber(text, minuteMatch, SECONDS_PER_MINUTE, \"minutes\"); long seconds = parseNumber(text, secondMatch, 1, \"seconds\"); int nanos = parseFraction(text, fractionMatch, seconds < 0 ? - 1 : 1); try { return create(negate, daysAsSecs, hoursAsSecs, minsAsSecs, seconds, nanos); } catch(ArithmeticException ex) { throw(DateTimeParseException)new DateTimeParseException(\"Text cannot be parsed to a Duration: overflow\", text, 0).initCause(ex); } } } } throw new DateTimeParseException(\"Text cannot be parsed to a Duration\", text, 0); } ",
        "focal_src": "public static Duration parse(final CharSequence text) { Objects.requireNonNull(text, \"text\"); int len = text.length(); if(len < 4 || (text.charAt(0) != 'P' && text.charAt(0) != 'p') || (text.charAt(1) != 'T' && text.charAt(1) != 't') || (text.charAt(len - 1) != 'S' && text.charAt(len - 1) != 's') || (len == 5 && text.charAt(2) == '-' && text.charAt(3) == '0')) { throw new DateTimeParseException(\"Duration could not be parsed: \" + text, text, 0); } String numberText = text.subSequence(2, len - 1).toString().replace(',', '.'); if(numberText.charAt(0) == '+') { throw new DateTimeParseException(\"Duration could not be parsed: \" + text, text, 2); } int dot = numberText.indexOf('.'); try { if(dot == - 1) { if(numberText.startsWith(\"-0\")) { throw new DateTimeParseException(\"Duration could not be parsed: \" + text, text, 2); } return create(Long.parseLong(numberText), 0); } boolean negative = false; if(numberText.charAt(0) == '-') { negative = true; } long secs = Long.parseLong(numberText.substring(0, dot)); numberText = numberText.substring(dot + 1); len = numberText.length(); if(len == 0 || len > 9 || numberText.charAt(0) == '-' || numberText.charAt(0) == '+') { throw new DateTimeParseException(\"Duration could not be parsed: \" + text, text, 2); } int nanos = Integer.parseInt(numberText); switch(len) { case 1 : nanos *= 100000000; break; case 2 : nanos *= 10000000; break; case 3 : nanos *= 1000000; break; case 4 : nanos *= 100000; break; case 5 : nanos *= 10000; break; case 6 : nanos *= 1000; break; case 7 : nanos *= 100; break; case 8 : nanos *= 10; break; } return negative ? ofSeconds(secs, - nanos) : create(secs, nanos); } catch(ArithmeticException | NumberFormatException ex) { throw new DateTimeParseException(\"Duration could not be parsed: \" + text, text, 2, ex); } } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_parse_basicIsoDate() { LocalDate expected = LocalDate.of(2008, 6, 3); assertEquals(DateTimeFormatter.BASIC_ISO_DATE.parse(\"20080603\", LocalDate :: from), expected); } "
    },
    {
        "test_src": "@Test public void testTransact_getsNewTimestampOnEachTry() { ofy().transact(new VoidWork() { DateTime firstAttemptTime; @Override public void vrun() { if(firstAttemptTime == null) { firstAttemptTime = ofy().getTransactionTime(); sleepUninterruptibly(10, MILLISECONDS); throw new ConcurrentModificationException(); } assertThat(ofy().getTransactionTime()).isGreaterThan(firstAttemptTime); } }); } ",
        "focal_tgt": "void transact(Runnable work) { transact(() -> { work.run(); return null; }); } ",
        "focal_src": "public void transact(Runnable work) { transact(() -> { work.run(); return null; }); } ",
        "test_tgt": "@Test public void testTransact_getsNewTimestampOnEachTry() { tm().transact(new Runnable() { DateTime firstAttemptTime; @Override public void run() { if(firstAttemptTime == null) { firstAttemptTime = tm().getTransactionTime(); sleepUninterruptibly(10, MILLISECONDS); throw new ConcurrentModificationException(); } assertThat(tm().getTransactionTime()).isGreaterThan(firstAttemptTime); } }); } "
    },
    {
        "test_src": "@Test public void testProcess()throws Exception { logger.info(\"process\"); InputStream inStream = this.getClass().getResourceAsStream(\"/PF00104_small.fasta\"); assertNotNull(inStream); FastaReader < ProteinSequence, AminoAcidCompound > fastaReader = new FastaReader < ProteinSequence, AminoAcidCompound > (inStream, new GenericFastaHeaderParser < ProteinSequence, AminoAcidCompound > (), new ProteinSequenceCreator(AminoAcidCompoundSet.getAminoAcidCompoundSet())); LinkedHashMap < String, ProteinSequence > proteinSequences = fastaReader.process(); inStream.close(); assertEquals(proteinSequences.size(), 283); int seqNum = 0; for(String id : proteinSequences.keySet()) { ProteinSequence proteinSequence = proteinSequences.get(id); switch(seqNum) { case 0 : assertEquals(proteinSequence.getAccession().getID(), \"A2D504_ATEGE/1-46\"); assertEquals(proteinSequence.getSequenceAsString(), \"-----------------FK-N----LP-LED----------------Q----ITL--IQY-----------SWM----------------------CL-SSFA------LSWRSYK---HTNSQFLYFAPDLVF-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\"); break; case 281 : assertEquals(proteinSequence.getAccession().getID(), \"Q9PU76_CRONI/141-323\"); assertEquals(proteinSequence.getSequenceAsString(), \"VETVTELTEFAKSI-PGFS-N----LD-LND----------------Q----VTL--LKY-----------GVY----------------------EA-IFAM------LASVMNK---DGMPVAYGNGFITRE------------------------------------------------------------------------------------------------------------------------------------------------------------FLKSLRKPFCDIMEPKFDFA-MKF-NSL-E-LDDSDI--------------------SLFVA-AIIC-CGDRPG-------------------------------------------LVNV--GHIEKMQESIVHVLKL-H-----LQN---------NH---PD----------------------------DI------F--------LFP-KLLQKMAD-LRQLV-----------------TEH-AQLV--QIIKK---TESDAHLHPLL-------QEI---\"); break; case 282 : assertEquals(proteinSequence.getAccession().getID(), \"Q98SJ1_CHICK/15-61\"); assertEquals(proteinSequence.getSequenceAsString(), \"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Q-----------------NW------Q--------RFY-QLTKLLDS-MHDVV-----------------ENL-LSFC--FQTFLDKSM--SIEFPEML-------AEI---\"); break; } seqNum ++ ; } assertEquals(seqNum, 283); } ",
        "focal_tgt": "public LinkedHashMap < String, S > process(int max)throws IOException { String line = \"\"; if(this.line != null && this.line.length() > 0) { line = this.line; } String header = \"\"; if(this.header != null && this.header.length() > 0) { header = this.header; } StringBuilder sb = new StringBuilder(); int processedSequences = 0; boolean keepGoing = true; LinkedHashMap < String, S > sequences = new LinkedHashMap < String, S > (); do { line = line.trim(); if(line.length() != 0) { if(line.startsWith(\">\")) { if(sb.length() > 0) { try { @SuppressWarnings(\"unchecked\")S sequence = (S)sequenceCreator.getSequence(sb.toString(), sequenceIndex); headerParser.parseHeader(header, sequence); sequences.put(sequence.getAccession().getID(), sequence); processedSequences ++ ; } catch(CompoundNotFoundException e) { logger.warn(\"Sequence with header '{}' has unrecognised compounds ({}), it will be ignored\", header, e.getMessage()); } sb.setLength(0); } header = line.substring(1); } else if(line.startsWith(\";\")) { } else { if(sb.length() == 0) { sequenceIndex = fileIndex; } sb.append(line); } } fileIndex = br.getBytesRead(); line = br.readLine(); if(line == null) { if(sequences.size() == 0 && max != - 1) { return null; } String seq = sb.toString(); if(seq.length() == 0) { logger.warn(\"Can't parse sequence {}. Got sequence of length 0!\", sequenceIndex); logger.warn(\"header: {}\", header); } try { @SuppressWarnings(\"unchecked\")S sequence = (S)sequenceCreator.getSequence(seq, sequenceIndex); headerParser.parseHeader(header, sequence); sequences.put(sequence.getAccession().getID(), sequence); processedSequences ++ ; } catch(CompoundNotFoundException e) { logger.warn(\"Sequence with header '{}' has unrecognised compounds ({}), it will be ignored\", header, e.getMessage()); } keepGoing = false; } if(max > - 1 && processedSequences >= max) { keepGoing = false; } if(this.line == null)keepGoing = false; } while(keepGoing); this.line = line; this.header = header; return sequences; } ",
        "focal_src": "public LinkedHashMap < String, S > process(int max)throws IOException { LinkedHashMap < String, S > sequences = new LinkedHashMap < String, S > (); String line = \"\"; if(this.line != null && this.line.length() > 0) { line = this.line; } String header = \"\"; if(this.header != null && this.header.length() > 0) { header = this.header; } StringBuilder sb = new StringBuilder(); int processedSequences = 0; boolean keepGoing = true; do { line = line.trim(); if(line.length() != 0) { if(line.startsWith(\">\")) { if(sb.length() > 0) { try { @SuppressWarnings(\"unchecked\")S sequence = (S)sequenceCreator.getSequence(sb.toString(), sequenceIndex); headerParser.parseHeader(header, sequence); sequences.put(sequence.getAccession().getID(), sequence); processedSequences ++ ; } catch(CompoundNotFoundException e) { logger.warn(\"Sequence with header '{}' has unrecognised compounds ({}), it will be ignored\", header, e.getMessage()); } sb.setLength(0); } header = line.substring(1); } else if(line.startsWith(\";\")) { } else { if(sb.length() == 0) { sequenceIndex = fileIndex; } sb.append(line); } } fileIndex = br.getBytesRead(); line = br.readLine(); if(line == null) { String seq = sb.toString(); if(seq.length() == 0) { logger.warn(\"Can't parse sequence {}. Got sequence of length 0!\", sequenceIndex); logger.warn(\"header: {}\", header); } try { @SuppressWarnings(\"unchecked\")S sequence = (S)sequenceCreator.getSequence(seq, sequenceIndex); headerParser.parseHeader(header, sequence); sequences.put(sequence.getAccession().getID(), sequence); processedSequences ++ ; } catch(CompoundNotFoundException e) { logger.warn(\"Sequence with header '{}' has unrecognised compounds ({}), it will be ignored\", header, e.getMessage()); } keepGoing = false; } if(max > - 1 && processedSequences >= max) { keepGoing = false; } } while(keepGoing); this.line = line; this.header = header; return sequences; } ",
        "test_tgt": "@Test public void testProcess()throws Exception { logger.info(\"process\"); InputStream inStream = this.getClass().getResourceAsStream(\"/PF00104_small.fasta\"); assertNotNull(inStream); FastaReader < ProteinSequence, AminoAcidCompound > fastaReader = new FastaReader < ProteinSequence, AminoAcidCompound > (inStream, new GenericFastaHeaderParser < ProteinSequence, AminoAcidCompound > (), new ProteinSequenceCreator(AminoAcidCompoundSet.getAminoAcidCompoundSet())); LinkedHashMap < String, ProteinSequence > proteinSequences = fastaReader.process(); inStream.close(); assertEquals(proteinSequences.size(), 283); int seqNum = 0; for(String id : proteinSequences.keySet()) { ProteinSequence proteinSequence = proteinSequences.get(id); switch(seqNum) { case 0 : assertEquals(proteinSequence.getAccession().getID(), \"A2D504_ATEGE/1-46\"); assertEquals(proteinSequence.getSequenceAsString(), \"-----------------FK-N----LP-LED----------------Q----ITL--IQY-----------SWM----------------------CL-SSFA------LSWRSYK---HTNSQFLYFAPDLVF-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\"); break; case 281 : assertEquals(proteinSequence.getAccession().getID(), \"Q9PU76_CRONI/141-323\"); assertEquals(proteinSequence.getSequenceAsString(), \"VETVTELTEFAKSI-PGFS-N----LD-LND----------------Q----VTL--LKY-----------GVY----------------------EA-IFAM------LASVMNK---DGMPVAYGNGFITRE------------------------------------------------------------------------------------------------------------------------------------------------------------FLKSLRKPFCDIMEPKFDFA-MKF-NSL-E-LDDSDI--------------------SLFVA-AIIC-CGDRPG-------------------------------------------LVNV--GHIEKMQESIVHVLKL-H-----LQN---------NH---PD----------------------------DI------F--------LFP-KLLQKMAD-LRQLV-----------------TEH-AQLV--QIIKK---TESDAHLHPLL-------QEI---\"); break; case 282 : assertEquals(proteinSequence.getAccession().getID(), \"Q98SJ1_CHICK/15-61\"); assertEquals(proteinSequence.getSequenceAsString(), \"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Q-----------------NW------Q--------RFY-QLTKLLDS-MHDVV-----------------ENL-LSFC--FQTFLDKSM--SIEFPEML-------AEI---\"); break; } seqNum ++ ; } assertEquals(seqNum, 283); } "
    },
    {
        "test_src": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorTrainingParameters(null); Modeler instance = new Modeler(dbName, conf, trainingParameters); instance.fit(trainingData); instance.close(); instance = new Modeler(dbName, conf); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = new Modeler(dbName, conf); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); trainingData.delete(); validationData.delete(); } ",
        "focal_tgt": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(Class < ML > modelerClass, ML.AbstractTrainingParameters modelerTrainingParameters, Class < FS > featureSelectorClass, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = Configuration.getConfiguration(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(dataset); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(TextClassifier.class, dbName, conf); Dataframe validationData = null; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "focal_src": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(Class < ML > modelerClass, ML.AbstractTrainingParameters modelerTrainingParameters, Class < FS > featureSelectorClass, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = Configuration.getConfiguration(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = new TextClassifier(dbName, conf, trainingParameters); instance.fit(dataset); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = new TextClassifier(dbName, conf); Dataframe validationData = null; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "test_tgt": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorTrainingParameters(null); Modeler instance = MLBuilder.create(trainingParameters, dbName, conf); instance.fit(trainingData); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(Modeler.class, dbName, conf); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); trainingData.delete(); validationData.delete(); } "
    },
    {
        "test_src": "@Test public void testHexDigitToBoolArray() { assertBoolArrayEquals(new boolean[] { false, false, false, false }, Conversion.hexDigitToBoolArray('0')); assertBoolArrayEquals(new boolean[] { true, false, false, false }, Conversion.hexDigitToBoolArray('1')); assertBoolArrayEquals(new boolean[] { false, true, false, false }, Conversion.hexDigitToBoolArray('2')); assertBoolArrayEquals(new boolean[] { true, true, false, false }, Conversion.hexDigitToBoolArray('3')); assertBoolArrayEquals(new boolean[] { false, false, true, false }, Conversion.hexDigitToBoolArray('4')); assertBoolArrayEquals(new boolean[] { true, false, true, false }, Conversion.hexDigitToBoolArray('5')); assertBoolArrayEquals(new boolean[] { false, true, true, false }, Conversion.hexDigitToBoolArray('6')); assertBoolArrayEquals(new boolean[] { true, true, true, false }, Conversion.hexDigitToBoolArray('7')); assertBoolArrayEquals(new boolean[] { false, false, false, true }, Conversion.hexDigitToBoolArray('8')); assertBoolArrayEquals(new boolean[] { true, false, false, true }, Conversion.hexDigitToBoolArray('9')); assertBoolArrayEquals(new boolean[] { false, true, false, true }, Conversion.hexDigitToBoolArray('A')); assertBoolArrayEquals(new boolean[] { false, true, false, true }, Conversion.hexDigitToBoolArray('a')); assertBoolArrayEquals(new boolean[] { true, true, false, true }, Conversion.hexDigitToBoolArray('B')); assertBoolArrayEquals(new boolean[] { true, true, false, true }, Conversion.hexDigitToBoolArray('b')); assertBoolArrayEquals(new boolean[] { false, false, true, true }, Conversion.hexDigitToBoolArray('C')); assertBoolArrayEquals(new boolean[] { false, false, true, true }, Conversion.hexDigitToBoolArray('c')); assertBoolArrayEquals(new boolean[] { true, false, true, true }, Conversion.hexDigitToBoolArray('D')); assertBoolArrayEquals(new boolean[] { true, false, true, true }, Conversion.hexDigitToBoolArray('d')); assertBoolArrayEquals(new boolean[] { false, true, true, true }, Conversion.hexDigitToBoolArray('E')); assertBoolArrayEquals(new boolean[] { false, true, true, true }, Conversion.hexDigitToBoolArray('e')); assertBoolArrayEquals(new boolean[] { true, true, true, true }, Conversion.hexDigitToBoolArray('F')); assertBoolArrayEquals(new boolean[] { true, true, true, true }, Conversion.hexDigitToBoolArray('f')); try { Conversion.hexDigitToBoolArray('G'); fail(\"Thrown \" + IllegalArgumentException.class.getName() + \" expected\"); } catch(final IllegalArgumentException e) { } } ",
        "focal_tgt": "public static boolean[]hexDigitToBinary(char hexDigit) { switch(hexDigit) { case '0' : return new boolean[] { false, false, false, false }; case '1' : return new boolean[] { true, false, false, false }; case '2' : return new boolean[] { false, true, false, false }; case '3' : return new boolean[] { true, true, false, false }; case '4' : return new boolean[] { false, false, true, false }; case '5' : return new boolean[] { true, false, true, false }; case '6' : return new boolean[] { false, true, true, false }; case '7' : return new boolean[] { true, true, true, false }; case '8' : return new boolean[] { false, false, false, true }; case '9' : return new boolean[] { true, false, false, true }; case 'a' : case 'A' : return new boolean[] { false, true, false, true }; case 'b' : case 'B' : return new boolean[] { true, true, false, true }; case 'c' : case 'C' : return new boolean[] { false, false, true, true }; case 'd' : case 'D' : return new boolean[] { true, false, true, true }; case 'e' : case 'E' : return new boolean[] { false, true, true, true }; case 'f' : case 'F' : return new boolean[] { true, true, true, true }; default : throw new IllegalArgumentException(\"Cannot interpret '\" + hexDigit + \"' as a hexadecimal digit\"); } } ",
        "focal_src": "public static boolean[]hexDigitToBoolArray(char hexDigit) { switch(hexDigit) { case '0' : return new boolean[] { false, false, false, false }; case '1' : return new boolean[] { true, false, false, false }; case '2' : return new boolean[] { false, true, false, false }; case '3' : return new boolean[] { true, true, false, false }; case '4' : return new boolean[] { false, false, true, false }; case '5' : return new boolean[] { true, false, true, false }; case '6' : return new boolean[] { false, true, true, false }; case '7' : return new boolean[] { true, true, true, false }; case '8' : return new boolean[] { false, false, false, true }; case '9' : return new boolean[] { true, false, false, true }; case 'a' : case 'A' : return new boolean[] { false, true, false, true }; case 'b' : case 'B' : return new boolean[] { true, true, false, true }; case 'c' : case 'C' : return new boolean[] { false, false, true, true }; case 'd' : case 'D' : return new boolean[] { true, false, true, true }; case 'e' : case 'E' : return new boolean[] { false, true, true, true }; case 'f' : case 'F' : return new boolean[] { true, true, true, true }; default : throw new IllegalArgumentException(\"Cannot interpret '\" + hexDigit + \"' as a hexadecimal digit\"); } } ",
        "test_tgt": "@Test public void testHexDigitToBinary() { assertBinaryEquals(new boolean[] { false, false, false, false }, Conversion.hexDigitToBinary('0')); assertBinaryEquals(new boolean[] { true, false, false, false }, Conversion.hexDigitToBinary('1')); assertBinaryEquals(new boolean[] { false, true, false, false }, Conversion.hexDigitToBinary('2')); assertBinaryEquals(new boolean[] { true, true, false, false }, Conversion.hexDigitToBinary('3')); assertBinaryEquals(new boolean[] { false, false, true, false }, Conversion.hexDigitToBinary('4')); assertBinaryEquals(new boolean[] { true, false, true, false }, Conversion.hexDigitToBinary('5')); assertBinaryEquals(new boolean[] { false, true, true, false }, Conversion.hexDigitToBinary('6')); assertBinaryEquals(new boolean[] { true, true, true, false }, Conversion.hexDigitToBinary('7')); assertBinaryEquals(new boolean[] { false, false, false, true }, Conversion.hexDigitToBinary('8')); assertBinaryEquals(new boolean[] { true, false, false, true }, Conversion.hexDigitToBinary('9')); assertBinaryEquals(new boolean[] { false, true, false, true }, Conversion.hexDigitToBinary('A')); assertBinaryEquals(new boolean[] { false, true, false, true }, Conversion.hexDigitToBinary('a')); assertBinaryEquals(new boolean[] { true, true, false, true }, Conversion.hexDigitToBinary('B')); assertBinaryEquals(new boolean[] { true, true, false, true }, Conversion.hexDigitToBinary('b')); assertBinaryEquals(new boolean[] { false, false, true, true }, Conversion.hexDigitToBinary('C')); assertBinaryEquals(new boolean[] { false, false, true, true }, Conversion.hexDigitToBinary('c')); assertBinaryEquals(new boolean[] { true, false, true, true }, Conversion.hexDigitToBinary('D')); assertBinaryEquals(new boolean[] { true, false, true, true }, Conversion.hexDigitToBinary('d')); assertBinaryEquals(new boolean[] { false, true, true, true }, Conversion.hexDigitToBinary('E')); assertBinaryEquals(new boolean[] { false, true, true, true }, Conversion.hexDigitToBinary('e')); assertBinaryEquals(new boolean[] { true, true, true, true }, Conversion.hexDigitToBinary('F')); assertBinaryEquals(new boolean[] { true, true, true, true }, Conversion.hexDigitToBinary('f')); try { Conversion.hexDigitToBinary('G'); fail(\"Thrown \" + IllegalArgumentException.class.getName() + \" expected\"); } catch(final IllegalArgumentException e) { } } "
    },
    {
        "test_src": "@Test public void createUfsFile()throws Exception { mManager.createFile(SESSION_ID, mUri, Permission.defaults()); Mockito.verify(mMockUfs).create(Mockito.contains(mUri.toString()), Mockito.any(CreateOptions.class)); Mockito.verify(mMockUfs).connectFromWorker(Mockito.anyString()); } ",
        "focal_tgt": "long createUfsFile(long sessionId, AlluxioURI ufsUri, CreateUfsFileOptions options)throws FileAlreadyExistsException, IOException; ",
        "focal_src": "long createUfsFile(long sessionId, AlluxioURI ufsUri, Permission perm)throws FileAlreadyExistsException, IOException; ",
        "test_tgt": "@Test public void createUfsFile()throws Exception { mManager.createFile(SESSION_ID, mUri, CreateUfsFileOptions.defaults()); Mockito.verify(mMockUfs).create(Mockito.contains(mUri.toString()), Mockito.any(CreateOptions.class)); Mockito.verify(mMockUfs).connectFromWorker(Mockito.anyString()); } "
    },
    {
        "test_src": "@Test public void testgetComparedMarker() { ScanMarker l; ScanMarker r; l = new ScanMarker(new byte[] { 1, 2 }, INCLUSIVE); r = new ScanMarker(new byte[] { 1, 2 }, INCLUSIVE); assertFirstGreater(l, r); l = new ScanMarker(new byte[] { 1, 2 }, ! INCLUSIVE); r = new ScanMarker(new byte[] { 1, 2 }, ! INCLUSIVE); assertFirstGreater(l, r); l = new ScanMarker(null, ! INCLUSIVE); r = new ScanMarker(null, ! INCLUSIVE); assertFirstGreater(l, r); l = new ScanMarker(new byte[] { 1, 2 }, ! INCLUSIVE); r = new ScanMarker(null, ! INCLUSIVE); Assert.assertEquals(l, ScanPlan.getComparedMarker(l, r, true)); Assert.assertEquals(l, ScanPlan.getComparedMarker(r, l, true)); Assert.assertEquals(l, ScanPlan.getComparedMarker(l, r, false)); Assert.assertEquals(l, ScanPlan.getComparedMarker(r, l, false)); l = new ScanMarker(new byte[] { 1, 2, 0 }, INCLUSIVE); r = new ScanMarker(new byte[] { 1, 2 }, INCLUSIVE); assertFirstGreater(l, r); } ",
        "focal_tgt": "@VisibleForTesting static ScanMarker getComparedMarker(ScanMarker lStartMarker, ScanMarker rStartMarker, boolean getGreater) { if(lStartMarker == null) { return rStartMarker; } else if(rStartMarker == null) { return lStartMarker; } TypeInfo expectedType = TypeInfoUtils.getTypeInfoFromTypeString(lStartMarker.type); ObjectInspector outputOI = TypeInfoUtils.getStandardWritableObjectInspectorFromTypeInfo(expectedType); Converter lConverter = ObjectInspectorConverters.getConverter(PrimitiveObjectInspectorFactory.javaStringObjectInspector, outputOI); Converter rConverter = ObjectInspectorConverters.getConverter(PrimitiveObjectInspectorFactory.javaStringObjectInspector, outputOI); Comparable lValue = (Comparable)lConverter.convert(lStartMarker.value); Comparable rValue = (Comparable)rConverter.convert(rStartMarker.value); int compareRes = lValue.compareTo(rValue); if(compareRes == 0) { if(lStartMarker.isInclusive == rStartMarker.isInclusive) { return lStartMarker; } boolean isInclusive = true; if(getGreater) { isInclusive = false; } return new ScanMarker(lStartMarker.value, isInclusive, lStartMarker.type); } if(getGreater) { return compareRes == 1 ? lStartMarker : rStartMarker; } return compareRes == - 1 ? lStartMarker : rStartMarker; } ",
        "focal_src": "@VisibleForTesting static ScanMarker getComparedMarker(ScanMarker lStartMarker, ScanMarker rStartMarker, boolean getGreater) { if(lStartMarker.bytes == null) { return rStartMarker; } else if(rStartMarker.bytes == null) { return lStartMarker; } int compareRes = compare(lStartMarker.bytes, rStartMarker.bytes); if(compareRes == 0) { if(lStartMarker.isInclusive == rStartMarker.isInclusive) { return lStartMarker; } boolean isInclusive = true; if(getGreater) { isInclusive = false; } return new ScanMarker(lStartMarker.bytes, isInclusive); } if(getGreater) { return compareRes == 1 ? lStartMarker : rStartMarker; } return compareRes == - 1 ? lStartMarker : rStartMarker; } ",
        "test_tgt": "@Test public void testgetComparedMarker() { ScanMarker l; ScanMarker r; l = new ScanMarker(\"1\", INCLUSIVE, \"int\"); r = new ScanMarker(\"1\", INCLUSIVE, \"int\"); assertFirstGreater(l, r); l = new ScanMarker(\"1\", ! INCLUSIVE, \"int\"); r = new ScanMarker(\"1\", ! INCLUSIVE, \"int\"); assertFirstGreater(l, r); assertFirstGreater(null, null); l = new ScanMarker(\"1\", ! INCLUSIVE, \"int\"); Assert.assertEquals(l, ScanPlan.getComparedMarker(l, null, true)); Assert.assertEquals(l, ScanPlan.getComparedMarker(null, l, true)); Assert.assertEquals(l, ScanPlan.getComparedMarker(l, null, false)); Assert.assertEquals(l, ScanPlan.getComparedMarker(null, l, false)); l = new ScanMarker(\"2\", INCLUSIVE, \"int\"); r = new ScanMarker(\"1\", INCLUSIVE, \"int\"); assertFirstGreater(l, r); } "
    },
    {
        "test_src": "@Test public void testGetConverterPropertyNameForBranch() { WorkUnitState workUnitState = new WorkUnitState(); workUnitState.setProp(PROPERTY_FOO, PATH_FOO); Assert.assertEquals(ForkOperatorUtils.getConverterPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO); workUnitState.setProp(ConfigurationKeys.FORK_BRANCH_ID_KEY, - 1); Assert.assertEquals(ForkOperatorUtils.getConverterPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO); workUnitState.setProp(ConfigurationKeys.FORK_BRANCH_ID_KEY, 0); Assert.assertEquals(ForkOperatorUtils.getConverterPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO + \".0\"); } ",
        "focal_tgt": "public static String getPropertyNameForBranch(WorkUnitState workUnitState, String key) { Preconditions.checkNotNull(workUnitState, \"Cannot get a property from a null WorkUnit\"); Preconditions.checkNotNull(key, \"Cannot get a the value for a null key\"); if( ! workUnitState.contains(ConfigurationKeys.FORK_BRANCH_ID_KEY)) { return key; } else { return workUnitState.getPropAsInt(ConfigurationKeys.FORK_BRANCH_ID_KEY) == - 1 ? key : key + \".\" + workUnitState.getPropAsInt(ConfigurationKeys.FORK_BRANCH_ID_KEY); } } ",
        "focal_src": "public static String getConverterPropertyNameForBranch(WorkUnitState workUnitState, String key) { Preconditions.checkNotNull(workUnitState, \"Cannot get a property from a null WorkUnit\"); Preconditions.checkNotNull(key, \"Cannot get a the value for a null key\"); if( ! workUnitState.contains(ConfigurationKeys.FORK_BRANCH_ID_KEY)) { return key; } else { return workUnitState.getPropAsInt(ConfigurationKeys.FORK_BRANCH_ID_KEY) == - 1 ? key : key + \".\" + workUnitState.getPropAsInt(ConfigurationKeys.FORK_BRANCH_ID_KEY); } } ",
        "test_tgt": "@Test public void testGetPropertyNameForBranchWithWorkUnitState() { WorkUnitState workUnitState = new WorkUnitState(); workUnitState.setProp(PROPERTY_FOO, PATH_FOO); Assert.assertEquals(ForkOperatorUtils.getPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO); workUnitState.setProp(ConfigurationKeys.FORK_BRANCH_ID_KEY, - 1); Assert.assertEquals(ForkOperatorUtils.getPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO); workUnitState.setProp(ConfigurationKeys.FORK_BRANCH_ID_KEY, 0); Assert.assertEquals(ForkOperatorUtils.getPropertyNameForBranch(workUnitState, PROPERTY_FOO), PROPERTY_FOO + \".0\"); } "
    },
    {
        "test_src": "@Test public void getMountInfo()throws Exception { MountInfo info1 = new MountInfo(new AlluxioURI(\"hdfs://localhost:5678/foo\"), 1L, MountOptions.defaults()); MountInfo info2 = new MountInfo(new AlluxioURI(\"hdfs://localhost:5678/bar\"), 2L, MountOptions.defaults()); mMountTable.add(new AlluxioURI(\"/mnt/foo\"), info1.getUfsUri(), info1.getUfsId(), info1.getOptions()); mMountTable.add(new AlluxioURI(\"/mnt/bar\"), info2.getUfsUri(), info2.getUfsId(), info2.getOptions()); Assert.assertEquals(info1, mMountTable.getMountInfo(info1.getUfsId())); Assert.assertEquals(info2, mMountTable.getMountInfo(info2.getUfsId())); Assert.assertEquals(null, mMountTable.getMountInfo(3L)); } ",
        "focal_tgt": "public MountInfo getMountInfo(long mountId) { try(LockResource r = new LockResource(mReadLock)) { for(Map.Entry < String, MountInfo > entry : mMountTable.entrySet()) { if(entry.getValue().getMountId() == mountId) { return entry.getValue(); } } } return null; } ",
        "focal_src": "public MountInfo getMountInfo(long id) { try(LockResource r = new LockResource(mReadLock)) { for(Map.Entry < String, MountInfo > entry : mMountTable.entrySet()) { if(entry.getValue().getUfsId() == id) { return entry.getValue(); } } } return null; } ",
        "test_tgt": "@Test public void getMountInfo()throws Exception { MountInfo info1 = new MountInfo(new AlluxioURI(\"hdfs://localhost:5678/foo\"), 1L, MountOptions.defaults()); MountInfo info2 = new MountInfo(new AlluxioURI(\"hdfs://localhost:5678/bar\"), 2L, MountOptions.defaults()); mMountTable.add(new AlluxioURI(\"/mnt/foo\"), info1.getUfsUri(), info1.getMountId(), info1.getOptions()); mMountTable.add(new AlluxioURI(\"/mnt/bar\"), info2.getUfsUri(), info2.getMountId(), info2.getOptions()); Assert.assertEquals(info1, mMountTable.getMountInfo(info1.getMountId())); Assert.assertEquals(info2, mMountTable.getMountInfo(info2.getMountId())); Assert.assertEquals(null, mMountTable.getMountInfo(3L)); } "
    },
    {
        "test_src": "@Test public void startNewSpan() { state.setCurrentServerSpan(ServerSpan.create(PARENT_SPAN_ID, \"name\")); PowerMockito.when(System.currentTimeMillis()).thenReturn(1L); PowerMockito.when(System.nanoTime()).thenReturn(500L); SpanId expectedSpanId = PARENT_SPAN_ID.toBuilder().spanId(555L).parentId(PARENT_SPAN_ID.spanId).build(); assertEquals(expectedSpanId, localTracer.startNewSpan(COMPONENT_NAME, OPERATION_NAME)); Span started = state.getCurrentLocalSpan(); assertEquals(1000L, started.getTimestamp().longValue()); assertEquals(500L, started.startTick.longValue()); assertEquals(\"lc\", started.getBinary_annotations().get(0).getKey()); assertEquals(COMPONENT_NAME, new String(started.getBinary_annotations().get(0).getValue(), Util.UTF_8)); assertEquals(state.endpoint(), started.getBinary_annotations().get(0).host); assertEquals(OPERATION_NAME, started.getName()); } ",
        "focal_tgt": "public SpanId startNewSpan(String component, String operation) { return startNewSpan(component, operation, clock().currentTimeMicroseconds()); } ",
        "focal_src": "public SpanId startNewSpan(String component, String operation) { SpanId spanId = startNewSpan(component, operation, clock().currentTimeMicroseconds()); if(spanId == null)return null; Span span = spanAndEndpoint().span(); synchronized(span) { span.startTick = System.nanoTime(); } return spanId; } ",
        "test_tgt": "@Test public void startNewSpan() { state.setCurrentServerSpan(ServerSpan.create(PARENT_SPAN_ID, \"name\")); PowerMockito.when(System.nanoTime()).thenReturn(500L); SpanId expectedSpanId = PARENT_SPAN_ID.toBuilder().spanId(555L).parentId(PARENT_SPAN_ID.spanId).build(); assertEquals(expectedSpanId, localTracer.startNewSpan(COMPONENT_NAME, OPERATION_NAME)); Span started = state.getCurrentLocalSpan(); assertEquals(START_TIME_MICROSECONDS, started.getTimestamp().longValue()); assertEquals(\"lc\", started.getBinary_annotations().get(0).getKey()); assertEquals(COMPONENT_NAME, new String(started.getBinary_annotations().get(0).getValue(), Util.UTF_8)); assertEquals(state.endpoint(), started.getBinary_annotations().get(0).host); assertEquals(OPERATION_NAME, started.getName()); } "
    },
    {
        "test_src": "@Test public void testGetCurrentSessionId() { String current = sessionRequestService.getCurrentSessionId(); assertNull(current); Session session = sessionRequestService.startSession(\"aaronz\"); assertNotNull(session); assertEquals(\"aaronz\", session.getId()); current = sessionRequestService.getCurrentSessionId(); assertNotNull(current); assertEquals(\"aaronz\", current); assertEquals(current, session.getId()); } ",
        "focal_tgt": "public String getCurrentSessionId() { Request req = requests.getCurrent(); if(req != null) { Session session = req.getSession(); if(session != null) { return session.getSessionId(); } } return null; } ",
        "focal_src": "public String getCurrentSessionId() { String sessionId = (String)getRequestCache().get(CachingService.SESSION_ID_KEY); return sessionId; } ",
        "test_tgt": "@Test public void testGetCurrentSessionId() { String current = sessionRequestService.getCurrentSessionId(); assertNull(current); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should fail validation if discontinued is null\", method = \"validate(Object,Errors)\")public void validate_shouldFailValidationIfDiscontinuedIsNull()throws Exception { Order order = new Order(); order.setDiscontinued(null); order.setConcept(Context.getConceptService().getConcept(88)); order.setPatient(Context.getPatientService().getPatient(2)); order.setOrderType(Context.getOrderService().getOrderType(1)); Errors errors = new BindException(order, \"order\"); new OrderValidator().validate(order, errors); Assert.assertTrue(errors.hasFieldErrors(\"discontinued\")); Assert.assertFalse(errors.hasFieldErrors(\"concept\")); Assert.assertFalse(errors.hasFieldErrors(\"patient\")); Assert.assertFalse(errors.hasFieldErrors(\"orderType\")); } ",
        "focal_tgt": "public void validate(Object obj, Errors errors) { super.validate(obj, errors); DrugOrder order = (DrugOrder)obj; if(order == null) { errors.rejectValue(\"order\", \"error.general\"); } else { if(order.getDuration() != null)ValidationUtils.rejectIfEmpty(errors, \"durationUnits\", \"DrugOrder.add.error.missingDurationUnits\"); if(order.getQuantity() != null)ValidationUtils.rejectIfEmpty(errors, \"quantityUnits\", \"DrugOrder.add.error.missingQuantityUnits\"); if(order.getStrength() != null)ValidationUtils.rejectIfEmpty(errors, \"strengthUnits\", \"DrugOrder.add.error.missingStrengthUnits\"); if(order.getDose() != null)ValidationUtils.rejectIfEmpty(errors, \"doseUnits\", \"DrugOrder.add.error.missingDoseUnits\"); ValidationUtils.rejectIfEmpty(errors, \"drug\", \"error.null\"); if(order.getDrug() != null)ValidationUtils.rejectIfEmpty(errors, \"drug.concept\", \"error.null\"); } } ",
        "focal_src": "public void validate(Object obj, Errors errors) { super.validate(obj, errors); DrugOrder order = (DrugOrder)obj; if(order == null) { errors.rejectValue(\"order\", \"error.general\"); } else { ValidationUtils.rejectIfEmpty(errors, \"prn\", \"error.null\"); ValidationUtils.rejectIfEmpty(errors, \"complex\", \"error.null\"); ValidationUtils.rejectIfEmpty(errors, \"drug\", \"error.null\"); if(order.getDrug() != null) { ValidationUtils.rejectIfEmpty(errors, \"drug.concept\", \"error.null\"); } if(order.getDose() != null || order.getEquivalentDailyDose() != null || order.getQuantity() != null) { ValidationUtils.rejectIfEmpty(errors, \"units\", \"DrugOrder.error.unitsNotSetWhenDoseOrQuantitySpecified\"); } } } ",
        "test_tgt": "@Test@Verifies(value = \"should fail validation if discontinued is null\", method = \"validate(Object,Errors)\")public void validate_shouldFailValidationIfDiscontinuedIsNull()throws Exception { Order order = new Order(); order.setDiscontinued(null); order.setConcept(Context.getConceptService().getConcept(88)); order.setPatient(Context.getPatientService().getPatient(2)); Errors errors = new BindException(order, \"order\"); new OrderValidator().validate(order, errors); Assert.assertTrue(errors.hasFieldErrors(\"discontinued\")); Assert.assertFalse(errors.hasFieldErrors(\"concept\")); Assert.assertFalse(errors.hasFieldErrors(\"patient\")); } "
    },
    {
        "test_src": "@Test@PrepareForTest(KodoOutputStream.class)public void testWrite2()throws Exception { PowerMockito.whenNew(BufferedOutputStream.class).withArguments(Mockito.any(DigestOutputStream.class)).thenReturn(mLocalOutputStream); PowerMockito.whenNew(BufferedOutputStream.class).withArguments(Mockito.any(FileOutputStream.class)).thenReturn(mLocalOutputStream); KodoOutputStream stream = new KodoOutputStream(\"testKey\", mKodoClient); byte[]b = new byte[1]; stream.write(b, 0, 1); stream.close(); Mockito.verify(mLocalOutputStream).write(b, 0, 1); } ",
        "focal_tgt": "@POST@Path(ID_PARAM + WRITE)@ReturnType(\"java.lang.Long\")@Consumes(MediaType.APPLICATION_OCTET_STREAM)public Response write(@PathParam(\"id\")final Integer id, final InputStream is) { return RestUtils.call(new RestUtils.RestCallable < Long > () { @Override public Long call()throws Exception { FileOutStream os = mStreamCache.getOutStream(id); if(os != null) { return ByteStreams.copy(is, os); } throw new IllegalArgumentException(\"stream does not exist\"); } }, ServerConfiguration.global()); } ",
        "focal_src": "@POST@Path(ID_PARAM + WRITE)@ReturnType(\"java.lang.Long\")@Consumes(MediaType.APPLICATION_OCTET_STREAM)public Response write(@PathParam(\"id\")final Integer id, final InputStream is) { return RestUtils.call(new RestUtils.RestCallable < Long > () { @Override public Long call()throws Exception { FileOutStream os = mStreamCache.getOutStream(id); if(os != null) { return ByteStreams.copy(is, os); } throw new IllegalArgumentException(\"stream does not exist\"); } }); } ",
        "test_tgt": "@Test@PrepareForTest(KodoOutputStream.class)public void testWrite2()throws Exception { PowerMockito.whenNew(BufferedOutputStream.class).withArguments(Mockito.any(DigestOutputStream.class)).thenReturn(mLocalOutputStream); PowerMockito.whenNew(BufferedOutputStream.class).withArguments(Mockito.any(FileOutputStream.class)).thenReturn(mLocalOutputStream); KodoOutputStream stream = new KodoOutputStream(\"testKey\", mKodoClient, sTmpDirs); byte[]b = new byte[1]; stream.write(b, 0, 1); stream.close(); Mockito.verify(mLocalOutputStream).write(b, 0, 1); } "
    },
    {
        "test_src": "@Test(expected = IllegalArgumentException.class)public void checkNearCacheConfig_NATIVE() { checkNearCacheConfig(getNearCacheConfig(NATIVE), false); } ",
        "focal_tgt": "public static void checkNearCacheConfig(String mapName, NearCacheConfig nearCacheConfig, boolean isClient) { checkLocalUpdatePolicy(mapName, nearCacheConfig); checkNotNative(nearCacheConfig.getInMemoryFormat()); checkEvictionConfig(nearCacheConfig.getEvictionConfig(), true); if(isClient && nearCacheConfig.isCacheLocalEntries()) { throw new IllegalArgumentException(\"The Near Cache option `cache-local-entries` is not supported in client configurations!\"); } checkPreloaderConfig(nearCacheConfig, isClient); } ",
        "focal_src": "public static void checkNearCacheConfig(NearCacheConfig nearCacheConfig, boolean isClient) { checkNotNative(nearCacheConfig.getInMemoryFormat()); checkEvictionConfig(nearCacheConfig.getEvictionConfig(), true); if(isClient && nearCacheConfig.isCacheLocalEntries()) { throw new IllegalArgumentException(\"The Near Cache option `cache-local-entries` is not supported in client configurations!\"); } checkPreloaderConfig(nearCacheConfig, isClient); } ",
        "test_tgt": "@Test(expected = IllegalArgumentException.class)public void checkNearCacheConfig_NATIVE() { checkNearCacheConfig(MAP_NAME, getNearCacheConfig(NATIVE), false); } "
    },
    {
        "test_src": "@Test public void testSeekWithCachingIncompleteBlocks()throws IOException { mTestStream = new FileInStream(mStatus, InStreamOptions.defaults().setReadType(ReadType.CACHE_PROMOTE).enableCacheIncompleteBlock()); int seekAmount = (int)(BLOCK_LENGTH / 2); mTestStream.seek(seekAmount); mTestStream.seek(seekAmount * 5); mTestStream.seek(seekAmount * 3); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray(0, (int)BLOCK_LENGTH), mCacheStreams.get(0).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)(2 * BLOCK_LENGTH), (int)BLOCK_LENGTH), mCacheStreams.get(2).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH / 2), mCacheStreams.get(1).getWrittenData()); for(int i = 0; i <= seekAmount / 2; ++ i) { mTestStream.seek(seekAmount * 3 + i); } Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH / 4 * 3), mCacheStreams.get(1).getWrittenData()); for(int i = seekAmount / 2; i >= 0; -- i) { mTestStream.seek(seekAmount * 3 + i); } Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH), mCacheStreams.get(1).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray(0, (int)BLOCK_LENGTH), mCacheStreams.get(0).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)(2 * BLOCK_LENGTH), (int)BLOCK_LENGTH), mCacheStreams.get(2).getWrittenData()); } ",
        "focal_tgt": "private void seekInternalWithCachingIncompleteBlock(long pos)throws IOException { boolean isInCurrentBlock = pos / mBlockSize == mPos / mBlockSize; if(mShouldCacheCurrentBlock) { readCurrentBlockTill(pos > mPos ? pos : mFileLength); } if(mPos == pos) { return; } if(isInCurrentBlock) { seekBlockInStream(pos); mCurrentBlockInStream.seek(mPos % mBlockSize); } else { seekBlockInStream(pos / mBlockSize * mBlockSize); checkAndAdvanceBlockInStream(); readCurrentBlockTill(pos); } } ",
        "focal_src": "private void seekWithCachingIncompleteBlocks(long pos)throws IOException { boolean isInCurrentBlock = pos / mBlockSize == mPos / mBlockSize; if(mShouldCacheCurrentBlock) { readCurrentBlockTill(pos > mPos ? pos : mFileLength); } if(mPos == pos) { return; } if(isInCurrentBlock) { seekBlockInStream(pos); mCurrentBlockInStream.seek(mPos % mBlockSize); } else { seekBlockInStream(pos / mBlockSize * mBlockSize); checkAndAdvanceBlockInStream(); readCurrentBlockTill(pos); } } ",
        "test_tgt": "@Test public void seekWithCachingIncompleteBlocksTest()throws IOException { mTestStream = new FileInStream(mStatus, InStreamOptions.defaults().setReadType(ReadType.CACHE_PROMOTE).setCacheIncompleteBlock()); int seekAmount = (int)(BLOCK_LENGTH / 2); mTestStream.seek(seekAmount); mTestStream.seek(seekAmount * 5); mTestStream.seek(seekAmount * 3); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray(0, (int)BLOCK_LENGTH), mCacheStreams.get(0).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)(2 * BLOCK_LENGTH), (int)BLOCK_LENGTH), mCacheStreams.get(2).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH / 2), mCacheStreams.get(1).getWrittenData()); for(int i = 0; i <= seekAmount / 2; i ++ ) { mTestStream.seek(seekAmount * 3 + i); } Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH / 4 * 3), mCacheStreams.get(1).getWrittenData()); for(int i = seekAmount / 2; i >= 0; i -- ) { mTestStream.seek(seekAmount * 3 + i); } Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)BLOCK_LENGTH, (int)BLOCK_LENGTH), mCacheStreams.get(1).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray(0, (int)BLOCK_LENGTH), mCacheStreams.get(0).getWrittenData()); Assert.assertArrayEquals(BufferUtils.getIncreasingByteArray((int)(2 * BLOCK_LENGTH), (int)BLOCK_LENGTH), mCacheStreams.get(2).getWrittenData()); } "
    },
    {
        "test_src": "@Test public void testGetMuleHomeFile() { File muleHome = MuleContainerBootstrapUtils.getMuleHomeFile(); assertNotNull(muleHome.getAbsolutePath()); } ",
        "focal_tgt": "public static File getMuleHome() { return isStandalone() ? new File(MULE_HOME) : null; } ",
        "focal_src": "public static File getMuleHomeFile() { return isStandalone() ? new File(MULE_HOME) : null; } ",
        "test_tgt": "@Test public void testGetMuleHomeFile() { File muleHome = MuleContainerBootstrapUtils.getMuleHome(); assertNotNull(muleHome.getAbsolutePath()); } "
    },
    {
        "test_src": "@Test public void testUsage()throws Exception { String[][]goodArgsList = { { \"--help\" }, { \"read\", \"--key\", \"cat\" }, { \"read\", \"--key\", \"ky\", \"--encoding\", \"Latin1\" }, { \"read\", \"--key\", \"636174\", \"--hex\" }, { \"read\", \"--key\", \"6beb79\", \"--hex\" }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost:\" + port + prefix + path }, { \"read\", \"--key\", \"cat\", \"--host\", \"localhost\" }, { \"read\", \"--key\", \"cat\", \"--connector\", name }, { \"list\" }, { \"list\", \"--url\" }, { \"list\", \"--hex\" }, { \"list\", \"--encoding\", \"Latin1\" }, { \"write\", \"--key\", \"pfunk\", \"--value\", \"the cat\" }, { \"write\", \"--key\", \"ct\", \"--value\", \"pfnk\", \"--encoding\", \"Latin1\" }, { \"write\", \"--key\", \"cafebabe\", \"--value\", \"deadbeef\", \"--hex\" }, { \"delete\", \"--key\", \"pfunk\" }, { \"delete\", \"--key\", \"ct\", \"--encoding\", \"Latin1\" }, { \"delete\", \"--key\", \"cafebabe\", \"--hex\" }, }; String[][]badArgsList = { { }, { \"read\", \"--key\" }, { \"read\", \"--garble\" }, { \"read\", \"--encoding\" }, { \"read\", \"--key-file\" }, { \"read\", \"--value-file\" }, { \"read\", \"--base\" }, { \"read\", \"--host\" }, { \"read\", \"--connector\" }, { \"read\", \"--connector\", \"fantasy.name\" }, { \"read\", \"--key\", \"funk\", \"--hex\" }, { \"read\", \"--key\", \"babed\", \"--hex\" }, { \"read\", \"--key\", \"pfunk\", \"--encoding\", \"fantasy string\" }, { \"read\", \"--key\", \"ky\", \"--ascii\" }, { \"read\", \"--key\", \"key with blanks\", \"--url\" }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost\" + prefix + path }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost:\" + port + \"/gataca\" + path }, { \"read\", \"--key\", \"cat\", \"--host\", \"my.fantasy.hostname\" }, { \"read\", \"--host\", \"localhost\" }, { \"list\", \"--encoding\" }, { \"list\", \"--key\", \"pfunk\" }, { \"list\", \"--value\", \"the cat\" }, { \"delete\" }, { \"delete\", \"--key\", \"pfunks\", \"--hex\" }, { \"delete\", \"--key\", \"cafebab\", \"--hex\" }, { \"delete\", \"--key\", \"cafe babe\", \"--url\" }, { \"delete\", \"--value\", \"cafe babe\" }, }; for(String[]args : goodArgsList) { LOG.info(\"Testing: \" + Arrays.toString(args)); Assert.assertNotNull(new DataClient().execute(args, configuration)); } for(String[]args : badArgsList) { LOG.info(\"Testing: \" + Arrays.toString(args)); Assert.assertNull(new DataClient().execute(args, configuration)); } } ",
        "focal_tgt": "void usage(boolean error) { PrintStream out = (error ? System.err : System.out); String name = this.getClass().getSimpleName(); Copyright.print(out); out.println(\"Usage: \"); out.println(\" \" + name + \" read --key <string> [ <options> ]\"); out.println(\" \" + name + \" write --key <string> --value value [ <options> ]\"); out.println(\" \" + name + \" delete --key <string> [ <options> ]\"); out.println(\" \" + name + \" list [ <options> ]\"); out.println(\" \" + name + \" format ( --all | --data | --queues | --streams )\"); out.println(\"Additional options:\"); out.println(\" --base <url> \" + \"To specify the base url to send to\"); out.println(\" --host <name> \" + \"To specify the hostname to send to\"); out.println(\" --connector <name> \" + \"To specify the name of the rest connector\"); out.println(\" --key <string> To specify the key\"); out.println(\" --key-file <path> To read the binary key from a file\"); out.println(\" --value <string> To specify the value\"); out.println(\" --value-file <path> \" + \"To read/write the binary value from/to a file\"); out.println(\" --hex \" + \"To use hexadecimal encoding for key and value\"); out.println(\" --ascii \" + \"To use ASCII encoding for key and value\"); out.println(\" --url \" + \"To use URL encoding for key and value\"); out.println(\" --counter \" + \"To interpret value as a long counter\"); out.println(\" --start <n> \" + \"To start at the nth element - only for list\"); out.println(\" --limit <k> \" + \"To list at most k elements - only for list\"); out.println(\" --all To format all data\"); out.println(\" --data To format all table data\"); out.println(\" --streams To format all event streams\"); out.println(\" --queues To format all intra-flow queues\"); out.println(\" --encoding <name> \" + \"To use this encoding for key and value\"); out.println(\" --verbose To see more verbose output\"); out.println(\" --help To print this message\"); if(error) { throw new IllegalArgumentException(); } } ",
        "focal_src": "void usage(boolean error) { PrintStream out = (error ? System.err : System.out); String name = this.getClass().getSimpleName(); Copyright.print(out); out.println(\"Usage: \"); out.println(\" \" + name + \" read --key <string> [ <options> ]\"); out.println(\" \" + name + \" write --key <string> --value value [ <options> ]\"); out.println(\" \" + name + \" delete --key <string> [ <options> ]\"); out.println(\" \" + name + \" list [ <options> ]\"); out.println(\" \" + name + \" format ( --all | --data | --queues | --streams )\"); out.println(\"Additional options:\"); out.println(\" --base <url> To specify the base url to send to\"); out.println(\" --host <name> To specify the hostname to send to\"); out.println(\" --connector <name> To specify the name of the rest connector\"); out.println(\" --key <string> To specify the key\"); out.println(\" --key-file <path> To read the binary key from a file\"); out.println(\" --value <string> To specify the value\"); out.println(\" --value-file <path> To read/write the binary value from/to a file\"); out.println(\" --hex To use hexadecimal encoding for key and value\"); out.println(\" --ascii To use ASCII encoding for key and value\"); out.println(\" --url To use URL encoding for key and value\"); out.println(\" --counter To interpret value as a long counter\"); out.println(\" --start <n> To start at the nth element - only for list\"); out.println(\" --limit <k> To list at most k elements - only for list\"); out.println(\" --all To format all data\"); out.println(\" --data To format all table data\"); out.println(\" --streams To format all event streams\"); out.println(\" --queues To format all intra-flow queues\"); out.println(\" --encoding <name> To use this encoding for key and value\"); out.println(\" --verbose To see more verbose output\"); out.println(\" --help To print this message\"); if(error) { throw new IllegalArgumentException(); } } ",
        "test_tgt": "@Test public void testUsage()throws Exception { String[][]goodArgsList = { { \"--help\" }, { \"read\", \"--key\", \"cat\" }, { \"read\", \"--key\", \"ky\", \"--encoding\", \"Latin1\" }, { \"read\", \"--key\", \"636174\", \"--hex\" }, { \"read\", \"--key\", \"6beb79\", \"--hex\" }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost:\" + port + prefix + path }, { \"read\", \"--key\", \"cat\", \"--host\", \"localhost\" }, { \"read\", \"--key\", \"cat\", \"--connector\", name }, { \"list\" }, { \"list\", \"--url\" }, { \"list\", \"--hex\" }, { \"list\", \"--encoding\", \"Latin1\" }, { \"write\", \"--key\", \"pfunk\", \"--value\", \"the cat\" }, { \"write\", \"--key\", \"ct\", \"--value\", \"pfnk\", \"--encoding\", \"Latin1\" }, { \"write\", \"--key\", \"cafebabe\", \"--value\", \"deadbeef\", \"--hex\" }, { \"delete\", \"--key\", \"pfunk\" }, { \"delete\", \"--key\", \"ct\", \"--encoding\", \"Latin1\" }, { \"delete\", \"--key\", \"cafebabe\", \"--hex\" }, }; String[][]badArgsList = { { }, { \"read\", \"--key\" }, { \"read\", \"--garble\" }, { \"read\", \"--encoding\" }, { \"read\", \"--key-file\" }, { \"read\", \"--value-file\" }, { \"read\", \"--base\" }, { \"read\", \"--host\" }, { \"read\", \"--connector\" }, { \"read\", \"--connector\", \"fantasy.name\" }, { \"read\", \"--key\", \"funk\", \"--hex\" }, { \"read\", \"--key\", \"babed\", \"--hex\" }, { \"read\", \"--key\", \"pfunk\", \"--encoding\", \"fantasy string\" }, { \"read\", \"--key\", \"ky\", \"--ascii\" }, { \"read\", \"--key\", \"key with blanks\", \"--url\" }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost\" + prefix + path }, { \"read\", \"--key\", \"cat\", \"--base\", \"http://localhost:\" + port + \"/gataca\" + path }, { \"read\", \"--key\", \"cat\", \"--host\", \"my.fantasy.hostname\" }, { \"read\", \"--host\", \"localhost\" }, { \"list\", \"--encoding\" }, { \"list\", \"--key\", \"pfunk\" }, { \"list\", \"--value\", \"the cat\" }, { \"delete\" }, { \"delete\", \"--key\", \"pfunks\", \"--hex\" }, { \"delete\", \"--key\", \"cafebab\", \"--hex\" }, { \"delete\", \"--key\", \"cafe babe\", \"--url\" }, { \"delete\", \"--value\", \"cafe babe\" }, }; for(String[]args : goodArgsList) { LOG.info(\"Testing: \" + Arrays.toString(args)); Assert.assertNotNull(new DataClient().execute(args, configuration)); } for(String[]args : badArgsList) { LOG.info(\"Testing: \" + Arrays.toString(args)); Assert.assertNull(new DataClient().execute(args, configuration)); } } "
    },
    {
        "test_src": "@Test public void testRemovePartition()throws MetadataServiceException, URISyntaxException { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/mydb/clicks/?datastamp=12&region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServerEndPoint() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency, false); assertFalse(missingPartitions.getPartitionsMap().containsKey(hcatUri.getPartitionMap())); pdms.addMissingPartition(newHCatDependency, actionId); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency); assertFalse(pdms.getHCatMap().containsKey(hcatUri.getTable())); } ",
        "focal_tgt": "public boolean removePartition(PartitionWrapper partition, boolean cascade)throws MetadataServiceException { log.debug(\"Removing partition \" + partition + \" with cascade :\" + cascade); String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); if(hcatInstanceMap.containsKey(prefix)) { Map < String, PartitionsGroup > tableMap = hcatInstanceMap.get(prefix); String tableName = partition.getTableName(); if(tableMap.containsKey(tableName)) { PartitionsGroup missingPartitions = tableMap.get(tableName); if(missingPartitions != null) { missingPartitions.getPartitionsMap().remove(partition); if(cascade) { if(missingPartitions.getPartitionsMap().size() == 0) { tableMap.remove(tableName); if(tableMap.size() == 0) { hcatInstanceMap.remove(prefix); } _deregisterMessageReceiver(partition); } } return true; } else { log.warn(\"No partition entries for table [{0}]\", tableName); } } else { log.warn(\"HCat table [{0}] not found\", tableName); } } else { log.warn(\"HCat instance entry [{0}] not found\", prefix); } return false; } ",
        "focal_src": "public boolean removePartition(PartitionWrapper partition, boolean cascade) { log.debug(\"Removing partition \" + partition + \" with cascade :\" + cascade); String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); if(hcatInstanceMap.containsKey(prefix)) { Map < String, PartitionsGroup > tableMap = hcatInstanceMap.get(prefix); String tableName = partition.getTableName(); if(tableMap.containsKey(tableName)) { PartitionsGroup missingPartitions = tableMap.get(tableName); if(missingPartitions != null) { missingPartitions.getPartitionsMap().remove(partition); if(cascade) { if(missingPartitions.getPartitionsMap().size() == 0) { tableMap.remove(tableName); if(tableMap.size() == 0) { hcatInstanceMap.remove(prefix); } } } return true; } else { log.warn(\"No partition entries for table [{0}]\", tableName); } } else { log.warn(\"HCat table [{0}] not found\", tableName); } } else { log.warn(\"HCat instance entry [{0}] not found\", prefix); } return false; } ",
        "test_tgt": "@Test public void testRemovePartition()throws Exception { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/database/mydb/table/clicks/partition/datastamp=12,region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServerEndPoint() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency, false); assertFalse(missingPartitions.getPartitionsMap().containsKey(hcatUri.getPartitionMap())); pdms.addMissingPartition(newHCatDependency, actionId); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency); assertFalse(pdms.getHCatMap().containsKey(hcatUri.getTable())); } "
    },
    {
        "test_src": "@Test public void testGet_readGroup() { assertFF4J.assertThatGroupExist(G1); assertFF4J.assertThatGroupHasSize(2, G1); assertFF4J.assertThatFeatureIsInGroup(F3, G1); assertFF4J.assertThatFeatureIsInGroup(F4, G1); WebResource wrsc = resourceGroups().path(G1); ClientResponse resHttp = wrsc.get(ClientResponse.class); String resEntity = resHttp.getEntity(String.class); Assert.assertEquals(\"Expected status is 200\", Status.OK.getStatusCode(), resHttp.getStatus()); Assert.assertNotNull(resEntity); Feature[]f = FeatureJsonMarshaller.unMarshallFeatureArray(resEntity); Set < String > features = new HashSet < String > (); for(Feature feature : f) { features.add(feature.getUid()); } Assert.assertEquals(2, features.size()); Assert.assertTrue(features.contains(F3)); Assert.assertTrue(features.contains(F4)); } ",
        "focal_tgt": "@Override public Feature get(String uid) { if(uid == null || uid.isEmpty()) { throw new IllegalArgumentException(\"Feature identifier (param#0) cannot be null nor empty\"); } String value = jedis.get(uid); if(value != null) { return FeatureJsonParser.parseFeature(value); } return null; } ",
        "focal_src": "@Override public Feature get(String uid) { if(uid == null || uid.isEmpty()) { throw new IllegalArgumentException(\"Feature identifier (param#0) cannot be null nor empty\"); } String value = jedis.get(uid); if(value != null) { return FeatureJsonMarshaller.unMarshallFeature(value); } return null; } ",
        "test_tgt": "@Test public void testGet_readGroup() { assertFF4J.assertThatGroupExist(G1); assertFF4J.assertThatGroupHasSize(2, G1); assertFF4J.assertThatFeatureIsInGroup(F3, G1); assertFF4J.assertThatFeatureIsInGroup(F4, G1); WebResource wrsc = resourceGroups().path(G1); ClientResponse resHttp = wrsc.get(ClientResponse.class); String resEntity = resHttp.getEntity(String.class); Assert.assertEquals(\"Expected status is 200\", Status.OK.getStatusCode(), resHttp.getStatus()); Assert.assertNotNull(resEntity); Feature[]f = parseFeatureArray(resEntity); Set < String > features = new HashSet < String > (); for(Feature feature : f) { features.add(feature.getUid()); } Assert.assertEquals(2, features.size()); Assert.assertTrue(features.contains(F3)); Assert.assertTrue(features.contains(F4)); } "
    },
    {
        "test_src": "@Test public void testRemoveFinishedWrites() { final int timeIncrement = 1234 * 1000; AtomicLong time = new AtomicLong(); val q = new WriteQueue(MAX_PARALLELISM, time :: get); val writes = new ArrayDeque < Write > (); for(int i = 0; i < ITEM_COUNT; i ++ ) { time.addAndGet(timeIncrement); val w = new Write(new ByteArraySegment(new byte[i]), new TestWriteLedger(i), new CompletableFuture < > ()); if(i % 2 == 0) { w.setEntryId(i); w.complete(); } q.add(w); writes.addLast(w); } while( ! writes.isEmpty()) { val write = writes.pollFirst(); if( ! write.isDone()) { val result1 = q.removeFinishedWrites(); AssertExtensions.assertContainsSameElements(\"Unexpected value from removeFinishedWrites when there were writes left in the queue.\", EnumSet.of(WriteQueue.CleanupStatus.QueueNotEmpty), result1); val stats1 = q.getStatistics(); Assert.assertEquals(\"Unexpected size after removeFinishedWrites with no effect.\", writes.size() + 1, stats1.getSize()); write.setEntryId(time.get()); write.complete(); } long expectedElapsed = write.getTimestamp(); int removed = 1; while( ! writes.isEmpty() && writes.peekFirst().isDone()) { expectedElapsed += writes.pollFirst().getTimestamp(); removed ++ ; } expectedElapsed = (time.get() * removed - expectedElapsed) / AbstractTimer.NANOS_TO_MILLIS / removed; val result2 = q.removeFinishedWrites(); val expectedResult = EnumSet.of(writes.isEmpty() ? WriteQueue.CleanupStatus.QueueEmpty : WriteQueue.CleanupStatus.QueueNotEmpty); AssertExtensions.assertContainsSameElements(\"Unexpected result from removeFinishedWrites.\", expectedResult, result2); val stats2 = q.getStatistics(); Assert.assertEquals(\"Unexpected size after removeFinishedWrites.\", writes.size(), stats2.getSize()); Assert.assertEquals(\"Unexpected getExpectedProcessingTimeMillis after clear.\", expectedElapsed, stats2.getExpectedProcessingTimeMillis()); } val w3 = new Write(new ByteArraySegment(new byte[1]), new TestWriteLedger(0), new CompletableFuture < > ()); q.add(w3); w3.fail(new IntentionalException(), true); val result3 = q.removeFinishedWrites(); AssertExtensions.assertContainsSameElements(\"Unexpected value from removeFinishedWrites when there were failed writes.\", EnumSet.of(WriteQueue.CleanupStatus.QueueEmpty, WriteQueue.CleanupStatus.WriteFailed), result3); } ",
        "focal_tgt": "synchronized EnumSet < CleanupStatus > removeFinishedWrites() { Exceptions.checkNotClosed(this.closed, this); long currentTime = this.timeSupplier.get(); long totalElapsed = 0; int removedCount = 0; boolean failedWrite = false; while( ! this.writes.isEmpty() && this.writes.peekFirst().isDone()) { Write w = this.writes.removeFirst(); this.totalLength = Math.max(0, this.totalLength - w.data.getLength()); removedCount ++ ; totalElapsed += currentTime - w.getQueueAddedTimestamp(); failedWrite |= w.getFailureCause() != null; } if(removedCount > 0) { this.lastDurationMillis = (int)(totalElapsed / removedCount / AbstractTimer.NANOS_TO_MILLIS); } CleanupStatus empty = this.writes.isEmpty() ? CleanupStatus.QueueEmpty : CleanupStatus.QueueNotEmpty; return failedWrite ? EnumSet.of(CleanupStatus.WriteFailed, empty) : EnumSet.of(empty); } ",
        "focal_src": "synchronized EnumSet < CleanupStatus > removeFinishedWrites() { Exceptions.checkNotClosed(this.closed, this); long currentTime = this.timeSupplier.get(); long totalElapsed = 0; int removedCount = 0; boolean failedWrite = false; while( ! this.writes.isEmpty() && this.writes.peekFirst().isDone()) { Write w = this.writes.removeFirst(); this.totalLength = Math.max(0, this.totalLength - w.data.getLength()); removedCount ++ ; totalElapsed += currentTime - w.getTimestamp(); failedWrite |= w.getFailureCause() != null; } if(removedCount > 0) { this.lastDurationMillis = (int)(totalElapsed / removedCount / AbstractTimer.NANOS_TO_MILLIS); } CleanupStatus empty = this.writes.isEmpty() ? CleanupStatus.QueueEmpty : CleanupStatus.QueueNotEmpty; return failedWrite ? EnumSet.of(CleanupStatus.WriteFailed, empty) : EnumSet.of(empty); } ",
        "test_tgt": "@Test public void testRemoveFinishedWrites() { final int timeIncrement = 1234 * 1000; AtomicLong time = new AtomicLong(); val q = new WriteQueue(MAX_PARALLELISM, time :: get); val writes = new ArrayDeque < Write > (); for(int i = 0; i < ITEM_COUNT; i ++ ) { time.addAndGet(timeIncrement); val w = new Write(new ByteArraySegment(new byte[i]), new TestWriteLedger(i), new CompletableFuture < > ()); if(i % 2 == 0) { w.setEntryId(i); w.complete(); } q.add(w); writes.addLast(w); } while( ! writes.isEmpty()) { val write = writes.pollFirst(); if( ! write.isDone()) { val result1 = q.removeFinishedWrites(); AssertExtensions.assertContainsSameElements(\"Unexpected value from removeFinishedWrites when there were writes left in the queue.\", EnumSet.of(WriteQueue.CleanupStatus.QueueNotEmpty), result1); val stats1 = q.getStatistics(); Assert.assertEquals(\"Unexpected size after removeFinishedWrites with no effect.\", writes.size() + 1, stats1.getSize()); write.setEntryId(time.get()); write.complete(); } long expectedElapsed = write.getQueueAddedTimestamp(); int removed = 1; while( ! writes.isEmpty() && writes.peekFirst().isDone()) { expectedElapsed += writes.pollFirst().getQueueAddedTimestamp(); removed ++ ; } expectedElapsed = (time.get() * removed - expectedElapsed) / AbstractTimer.NANOS_TO_MILLIS / removed; val result2 = q.removeFinishedWrites(); val expectedResult = EnumSet.of(writes.isEmpty() ? WriteQueue.CleanupStatus.QueueEmpty : WriteQueue.CleanupStatus.QueueNotEmpty); AssertExtensions.assertContainsSameElements(\"Unexpected result from removeFinishedWrites.\", expectedResult, result2); val stats2 = q.getStatistics(); Assert.assertEquals(\"Unexpected size after removeFinishedWrites.\", writes.size(), stats2.getSize()); Assert.assertEquals(\"Unexpected getExpectedProcessingTimeMillis after clear.\", expectedElapsed, stats2.getExpectedProcessingTimeMillis()); } val w3 = new Write(new ByteArraySegment(new byte[1]), new TestWriteLedger(0), new CompletableFuture < > ()); q.add(w3); w3.fail(new IntentionalException(), true); val result3 = q.removeFinishedWrites(); AssertExtensions.assertContainsSameElements(\"Unexpected value from removeFinishedWrites when there were failed writes.\", EnumSet.of(WriteQueue.CleanupStatus.QueueEmpty, WriteQueue.CleanupStatus.WriteFailed), result3); } "
    },
    {
        "test_src": "@Test public void testExportStacktrace()throws ClassNotFoundException, IOException { setupSystem(); File allStacktracesFile = workDirectory.newFile(\"allStackTraces.txt\"); CommandStringBuilder csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, allStacktracesFile.getCanonicalPath()); String commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); CommandResult commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File mgrStacktraceFile = workDirectory.newFile(\"managerStacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, mgrStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.EXPORT_STACKTRACE__MEMBER, \"Manager\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File serverStacktraceFile = workDirectory.newFile(\"serverStacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, serverStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.EXPORT_STACKTRACE__MEMBER, \"Server\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File groupStacktraceFile = workDirectory.newFile(\"groupstacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, groupStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.EXPORT_STACKTRACE__GROUP, \"G2\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File wrongStackTraceFile = workDirectory.newFile(\"wrongStackTrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, wrongStackTraceFile.getCanonicalPath()); csb.addOption(CliStrings.EXPORT_STACKTRACE__MEMBER, \"WrongMember\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertFalse(commandResult.getStatus().equals(Status.OK)); } ",
        "focal_tgt": "@CliCommand(value = CliStrings.EXPORT_STACKTRACE, help = CliStrings.EXPORT_STACKTRACE__HELP)@CliMetaData(shellOnly = false, relatedTopic = { CliStrings.TOPIC_GEODE_DEBUG_UTIL })@ResourceOperation(resource = Resource.CLUSTER, operation = Operation.READ)public Result exportStackTrace(@CliOption(key = { CliStrings.MEMBER, CliStrings.MEMBERS }, optionContext = ConverterHint.ALL_MEMBER_IDNAME, help = CliStrings.EXPORT_STACKTRACE__HELP)String[]memberNameOrId, @CliOption(key = { CliStrings.GROUP, CliStrings.GROUPS }, optionContext = ConverterHint.ALL_MEMBER_IDNAME, help = CliStrings.GROUP)String[]group, @CliOption(key = CliStrings.EXPORT_STACKTRACE__FILE, help = CliStrings.EXPORT_STACKTRACE__FILE__HELP)String fileName, @CliOption(key = CliStrings.EXPORT_STACKTRACE__FAIL__IF__FILE__PRESENT, unspecifiedDefaultValue = \"false\", help = CliStrings.EXPORT_STACKTRACE__FAIL__IF__FILE__PRESENT__HELP)boolean failIfFilePresent) { Result result = null; StringBuffer filePrefix = new StringBuffer(\"stacktrace\"); if(fileName == null) { fileName = filePrefix.append(\"_\").append(System.currentTimeMillis()).toString(); } final File outFile = new File(fileName); try { if(outFile.exists() && failIfFilePresent) { return ResultBuilder.createShellClientErrorResult(CliStrings.format(CliStrings.EXPORT_STACKTRACE__ERROR__FILE__PRESENT, outFile.getCanonicalPath())); } InternalCache cache = getCache(); InternalDistributedSystem ads = cache.getInternalDistributedSystem(); InfoResultData resultData = ResultBuilder.createInfoResultData(); Map < String, byte[] > dumps = new HashMap < String, byte[] > (); Set < DistributedMember > targetMembers = CliUtil.findMembers(group, memberNameOrId); if(targetMembers.isEmpty()) { return ResultBuilder.createUserErrorResult(CliStrings.NO_MEMBERS_FOUND_MESSAGE); } ResultCollector < ? , ? > rc = CliUtil.executeFunction(getStackTracesFunction, null, targetMembers); ArrayList < Object > resultList = (ArrayList < Object > )rc.getResult(); for(Object resultObj : resultList) { if(resultObj instanceof StackTracesPerMember) { StackTracesPerMember stackTracePerMember = (StackTracesPerMember)resultObj; dumps.put(stackTracePerMember.getMemberNameOrId(), stackTracePerMember.getStackTraces()); } } String filePath = writeStacksToFile(dumps, fileName); resultData.addLine(CliStrings.format(CliStrings.EXPORT_STACKTRACE__SUCCESS, filePath)); resultData.addLine(CliStrings.EXPORT_STACKTRACE__HOST + ads.getDistributedMember().getHost()); result = ResultBuilder.buildResult(resultData); } catch(IOException ex) { result = ResultBuilder.createGemFireErrorResult(CliStrings.EXPORT_STACKTRACE__ERROR + ex.getMessage()); } return result; } ",
        "focal_src": "@CliCommand(value = CliStrings.EXPORT_STACKTRACE, help = CliStrings.EXPORT_STACKTRACE__HELP)@CliMetaData(shellOnly = false, relatedTopic = { CliStrings.TOPIC_GEODE_DEBUG_UTIL })@ResourceOperation(resource = Resource.CLUSTER, operation = Operation.READ)public Result exportStackTrace(@CliOption(key = CliStrings.EXPORT_STACKTRACE__MEMBER, optionContext = ConverterHint.ALL_MEMBER_IDNAME, help = CliStrings.EXPORT_STACKTRACE__HELP)String[]memberNameOrId, @CliOption(key = CliStrings.EXPORT_STACKTRACE__GROUP, optionContext = ConverterHint.ALL_MEMBER_IDNAME, help = CliStrings.EXPORT_STACKTRACE__GROUP)String[]group, @CliOption(key = CliStrings.EXPORT_STACKTRACE__FILE, help = CliStrings.EXPORT_STACKTRACE__FILE__HELP)String fileName, @CliOption(key = CliStrings.EXPORT_STACKTRACE__FAIL__IF__FILE__PRESENT, unspecifiedDefaultValue = \"false\", help = CliStrings.EXPORT_STACKTRACE__FAIL__IF__FILE__PRESENT__HELP)boolean failIfFilePresent) { Result result = null; StringBuffer filePrefix = new StringBuffer(\"stacktrace\"); if(fileName == null) { fileName = filePrefix.append(\"_\").append(System.currentTimeMillis()).toString(); } final File outFile = new File(fileName); try { if(outFile.exists() && failIfFilePresent) { return ResultBuilder.createShellClientErrorResult(CliStrings.format(CliStrings.EXPORT_STACKTRACE__ERROR__FILE__PRESENT, outFile.getCanonicalPath())); } InternalCache cache = getCache(); InternalDistributedSystem ads = cache.getInternalDistributedSystem(); InfoResultData resultData = ResultBuilder.createInfoResultData(); Map < String, byte[] > dumps = new HashMap < String, byte[] > (); Set < DistributedMember > targetMembers = CliUtil.findMembers(group, memberNameOrId); if(targetMembers.isEmpty()) { return ResultBuilder.createUserErrorResult(CliStrings.NO_MEMBERS_FOUND_MESSAGE); } ResultCollector < ? , ? > rc = CliUtil.executeFunction(getStackTracesFunction, null, targetMembers); ArrayList < Object > resultList = (ArrayList < Object > )rc.getResult(); for(Object resultObj : resultList) { if(resultObj instanceof StackTracesPerMember) { StackTracesPerMember stackTracePerMember = (StackTracesPerMember)resultObj; dumps.put(stackTracePerMember.getMemberNameOrId(), stackTracePerMember.getStackTraces()); } } String filePath = writeStacksToFile(dumps, fileName); resultData.addLine(CliStrings.format(CliStrings.EXPORT_STACKTRACE__SUCCESS, filePath)); resultData.addLine(CliStrings.EXPORT_STACKTRACE__HOST + ads.getDistributedMember().getHost()); result = ResultBuilder.buildResult(resultData); } catch(IOException ex) { result = ResultBuilder.createGemFireErrorResult(CliStrings.EXPORT_STACKTRACE__ERROR + ex.getMessage()); } return result; } ",
        "test_tgt": "@Test public void testExportStacktrace()throws ClassNotFoundException, IOException { setupSystem(); File allStacktracesFile = workDirectory.newFile(\"allStackTraces.txt\"); CommandStringBuilder csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, allStacktracesFile.getCanonicalPath()); String commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); CommandResult commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File mgrStacktraceFile = workDirectory.newFile(\"managerStacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, mgrStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.MEMBER, \"Manager\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File serverStacktraceFile = workDirectory.newFile(\"serverStacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, serverStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.MEMBER, \"Server\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File groupStacktraceFile = workDirectory.newFile(\"groupstacktrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, groupStacktraceFile.getCanonicalPath()); csb.addOption(CliStrings.GROUP, \"G2\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertTrue(commandResult.getStatus().equals(Status.OK)); File wrongStackTraceFile = workDirectory.newFile(\"wrongStackTrace.txt\"); csb = new CommandStringBuilder(CliStrings.EXPORT_STACKTRACE); csb.addOption(CliStrings.EXPORT_STACKTRACE__FILE, wrongStackTraceFile.getCanonicalPath()); csb.addOption(CliStrings.MEMBER, \"WrongMember\"); commandString = csb.toString(); getLogWriter().info(\"CommandString : \" + commandString); commandResult = executeCommand(commandString); getLogWriter().info(\"Output : \\n\" + commandResultToString(commandResult)); assertFalse(commandResult.getStatus().equals(Status.OK)); } "
    },
    {
        "test_src": "@Test public void testReplace()throws QueryException, BaseXException { final String fun = check(Function.DBREPLACE); new Add(\"etc/test/input.xml\", null, \"test\").execute(CONTEXT); query(fun + \"('db', 'test/input.xml', document { <root/> })\"); query(\"count(collection('db/test/input.xml')/html) eq 0\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 1\", \"true\"); query(fun + \"('db', 'test/input.xml', 'etc/test/input.xml')\"); query(\"count(collection('db/test/input.xml')/html) eq 1\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 0\", \"true\"); } ",
        "focal_tgt": "public final void replace(final int rpre, final Data data) { meta.update(); docindex.replace(rpre, data); final int dsize = data.meta.size; buffer(dsize); final int rkind = kind(rpre); final int rsize = size(rpre, rkind); final int rpar = parent(rpre, rkind); for(int dpre = 0; dpre < dsize; dpre ++ ) { final int dkind = data.kind(dpre); final int dpar = data.parent(dpre, dkind); final int pre = rpre + dpre; final int dis = dpar >= 0 ? dpre - dpar : pre - parent(rpre, rkind); switch(dkind) { case DOC : doc(pre, data.size(dpre, dkind), data.text(dpre, true)); meta.ndocs ++ ; break; case ELEM : byte[]nm = data.name(dpre, dkind); elem(dis, tagindex.index(nm, null, false), data.attSize(dpre, dkind), data.size(dpre, dkind), ns.uri(nm, true), false); break; case TEXT : case COMM : case PI : text(pre, dis, data.text(dpre, true), dkind); break; case ATTR : nm = data.name(dpre, dkind); attr(pre, dis, atnindex.index(nm, null, false), data.text(dpre, false), ns.uri(nm, false), false); break; } } table.replace(rpre, buffer(), rsize); buffer(1); final int diff = dsize - rsize; if(diff == 0)return; int p = rpar; while(p >= 0) { final int k = kind(p); size(p, k, size(p, k) + diff); p = parent(p, k); } updateDist(rpre + dsize, diff); if(data.kind(0) == ATTR) { int d = 0, i = 0; while(i < dsize && data.kind(i ++ ) == ATTR)d ++ ; if(d > 1)attSize(rpar, kind(rpar), d + 1); } } ",
        "focal_src": "public final void replace(final int rpre, final Data data) { meta.update(); meta.docindex = false; final int dsize = data.meta.size; buffer(dsize); final int rkind = kind(rpre); final int rsize = size(rpre, rkind); final int rpar = parent(rpre, rkind); for(int dpre = 0; dpre < dsize; dpre ++ ) { final int dkind = data.kind(dpre); final int dpar = data.parent(dpre, dkind); final int pre = rpre + dpre; final int dis = dpar >= 0 ? dpre - dpar : pre - parent(rpre, rkind); switch(dkind) { case DOC : doc(pre, data.size(dpre, dkind), data.text(dpre, true)); meta.ndocs ++ ; break; case ELEM : byte[]nm = data.name(dpre, dkind); elem(dis, tagindex.index(nm, null, false), data.attSize(dpre, dkind), data.size(dpre, dkind), ns.uri(nm, true), false); break; case TEXT : case COMM : case PI : text(pre, dis, data.text(dpre, true), dkind); break; case ATTR : nm = data.name(dpre, dkind); attr(pre, dis, atnindex.index(nm, null, false), data.text(dpre, false), ns.uri(nm, false), false); break; } } table.replace(rpre, buffer(), rsize); buffer(1); final int diff = dsize - rsize; if(diff == 0)return; int p = rpar; while(p >= 0) { final int k = kind(p); size(p, k, size(p, k) + diff); p = parent(p, k); } updateDist(rpre + dsize, diff); if(data.kind(0) == ATTR) { int d = 0, i = 0; while(i < dsize && data.kind(i ++ ) == ATTR)d ++ ; if(d > 1)attSize(rpar, kind(rpar), d + 1); } } ",
        "test_tgt": "@Test public void testReplace()throws QueryException, BaseXException { final String fun = check(Function.DBREPLACE); new Add(\"etc/test/input.xml\", null, \"test\").execute(CONTEXT); query(fun + \"('db', 'test/input.xml', document { <root/> })\"); query(\"count(collection('db/test/input.xml')/html)\", \"0\"); query(\"count(collection('db/test/input.xml')/root)\", \"1\"); query(fun + \"('db', 'test/input.xml', 'etc/test/input.xml')\"); query(\"count(collection('db/test/input.xml')/html)\", \"1\"); query(\"count(collection('db/test/input.xml')/root)\", \"0\"); } "
    },
    {
        "test_src": "@Test public void create()throws BaseXException { new Close().execute(context); query(_DB_CREATE.args(NAME)); query(_DB_EXISTS.args(NAME), true); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(NAME) + ',' + _DB_CREATE.args(NAME), Err.BXDB_ONCE); query(_DB_CREATE.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(NAME, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(NAME, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + NAME + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + NAME + \"' || $i\")); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(NAME)); error(_DB_CREATE.args(NAME) + ',' + _DB_DROP.args(NAME), Err.BXDB_WHICH); query(_DB_CREATE.args(NAME, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(NAME)); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(NAME) + ',' + _DB_DROP.args(NAME)); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(NAME)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(NAME) + \"//updindex/text()\", b); } assertEquals(context.options.get(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':'' }\")); } error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'xyz':'abc' }\"), Err.BASX_OPTIONS); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':-1 }\"), Err.BASX_VALUE); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':'a' }\"), Err.BASX_VALUE); } ",
        "focal_tgt": "private Item create(final QueryContext ctx)throws QueryException { final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))throw BXDB_NAME.get(info, name); final TokenList paths = new TokenList(); if(expr.length > 2) { final Iter ir = ctx.iter(expr[2]); for(Item it; (it = ir.next()) != null; ) { final String path = string(checkStr(it)); final String norm = MetaData.normPath(path); if(norm == null)throw RESINV.get(info, path); paths.add(norm); } } final int ps = paths.size(); final List < NewInput > inputs = new ArrayList < NewInput > (ps); if(expr.length > 1) { final Value val = ctx.value(expr[1]); final long is = val.size(); if(ps != 0 && is != ps)throw BXDB_CREATEARGS.get(info, is, ps); for(int i = 0; i < is; i ++ ) { final byte[]path = i < ps ? paths.get(i) : Token.EMPTY; inputs.add(checkInput(val.itemAt(i), path)); } } final Options opts = checkOptions(3, Q_OPTIONS, new Options(), ctx); ctx.updates.add(new DBCreate(name, inputs, opts, ctx, info), ctx); return null; } ",
        "focal_src": "private Item create(final QueryContext ctx)throws QueryException { final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))throw BXDB_NAME.get(info, name); final TokenList paths = new TokenList(); if(expr.length > 2) { final Iter ir = ctx.iter(expr[2]); for(Item it; (it = ir.next()) != null; ) { final String path = string(checkStr(it)); final String norm = MetaData.normPath(path); if(norm == null)throw RESINV.get(info, path); paths.add(norm); } } final int ps = paths.size(); final List < NewInput > inputs = new ArrayList < NewInput > (ps); if(expr.length > 1) { final Value val = ctx.value(expr[1]); final long is = val.size(); if(ps != 0 && is != ps)throw BXDB_CREATEARGS.get(info, is, ps); for(int i = 0; i < is; i ++ ) { final byte[]path = i < ps ? paths.get(i) : Token.EMPTY; inputs.add(checkInput(val.itemAt(i), path)); } } final Options opts = checkOptions(3, Q_OPTIONS, new Options(), ctx); ctx.updates.add(new DBCreate(info, name, inputs, opts, ctx), ctx); return null; } ",
        "test_tgt": "@Test public void create()throws BaseXException { new Close().execute(context); query(_DB_CREATE.args(NAME)); query(_DB_EXISTS.args(NAME), true); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(NAME) + ',' + _DB_CREATE.args(NAME), Err.BXDB_ONCE); query(_DB_CREATE.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(NAME, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(NAME, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + NAME + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + NAME + \"' || $i\")); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(NAME)); error(_DB_CREATE.args(NAME) + ',' + _DB_DROP.args(NAME), Err.BXDB_WHICH); query(_DB_CREATE.args(NAME, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(NAME)); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(NAME) + ',' + _DB_DROP.args(NAME)); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(NAME)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(NAME) + \"//updindex/text()\", b); } assertEquals(context.options.get(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':'' }\")); } query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':true() }\")); query(_DB_OPEN.args(NAME), \"<a/>\"); query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':false() }\")); query(_DB_OPEN.args(NAME), \"<a> </a>\"); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'xyz':'abc' }\"), Err.BASX_OPTIONS); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':-1 }\"), Err.BASX_VALUE); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':'a' }\"), Err.BASX_VALUE); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'textindex':'nope' }\"), Err.BASX_VALUE); } "
    },
    {
        "test_src": "@Test public void testParseServiceRequestPath() { ServiceRequestPathInfo info = GatewayServlet.parseServiceRequestPath(null); info = GatewayServlet.parseServiceRequestPath(\"/invalidpath\"); Assert.assertNull(info.orgId); Assert.assertNull(info.serviceId); Assert.assertNull(info.serviceVersion); Assert.assertNull(info.resource); info = GatewayServlet.parseServiceRequestPath(\"/invalid/path\"); Assert.assertNull(info.orgId); Assert.assertNull(info.serviceId); Assert.assertNull(info.serviceVersion); Assert.assertNull(info.resource); info = GatewayServlet.parseServiceRequestPath(\"/Org1/Service1/1.0\"); Assert.assertEquals(\"Org1\", info.orgId); Assert.assertEquals(\"Service1\", info.serviceId); Assert.assertEquals(\"1.0\", info.serviceVersion); Assert.assertNull(info.resource); info = GatewayServlet.parseServiceRequestPath(\"/MyOrg/Service-99/2.7\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertNull(info.resource); info = GatewayServlet.parseServiceRequestPath(\"/MyOrg/Service-99/2.7/resource\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/resource\", info.resource); info = GatewayServlet.parseServiceRequestPath(\"/MyOrg/Service-99/2.7/path/to/resource\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource\", info.resource); info = GatewayServlet.parseServiceRequestPath(\"/MyOrg/Service-99/2.7/path/to/resource?query=1234\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource?query=1234\", info.resource); } ",
        "focal_tgt": "protected static final ServiceRequestPathInfo parseServiceRequestPath(HttpServletRequest request) { String pathInfo = request.getPathInfo(); ServiceRequestPathInfo info = new ServiceRequestPathInfo(); boolean versionFound = false; String apiVersionHeader = request.getHeader(\"X-API-Version\"); if(apiVersionHeader != null && apiVersionHeader.trim().length() > 0) { info.serviceVersion = apiVersionHeader; versionFound = true; } else { String acceptHeader = request.getHeader(\"Accept\"); if(acceptHeader != null && acceptHeader.startsWith(\"application/apiman.\")) { String[]split = acceptHeader.split(\"\\\\+\"); info.serviceVersion = split[0].substring(\"application/apiman.\".length()); versionFound = true; } } int minParts = versionFound ? 3 : 4; if(pathInfo != null) { String[]split = pathInfo.split(\"/\"); if(split.length >= minParts) { info.orgId = split[1]; info.serviceId = split[2]; if( ! versionFound) { info.serviceVersion = split[3]; } if(split.length > minParts) { StringBuilder resource = new StringBuilder(); for(int idx = minParts; idx < split.length; idx ++ ) { resource.append('/'); resource.append(split[idx]); } if(pathInfo.endsWith(\"/\")) { resource.append('/'); } info.resource = resource.toString(); } } } return info; } ",
        "focal_src": "protected static final ServiceRequestPathInfo parseServiceRequestPath(String pathInfo) { ServiceRequestPathInfo info = new ServiceRequestPathInfo(); if(pathInfo != null) { String[]split = pathInfo.split(\"/\"); if(split.length >= 4) { info.orgId = split[1]; info.serviceId = split[2]; info.serviceVersion = split[3]; if(split.length > 4) { StringBuilder resource = new StringBuilder(); for(int idx = 4; idx < split.length; idx ++ ) { resource.append('/'); resource.append(split[idx]); } if(pathInfo.endsWith(\"/\")) { resource.append('/'); } info.resource = resource.toString(); } } } return info; } ",
        "test_tgt": "@Test public void testParseServiceRequestPath() { ServiceRequestPathInfo info = parseServiceRequestPath(null); info = parseServiceRequestPath(\"/invalidpath\"); Assert.assertNull(info.orgId); Assert.assertNull(info.serviceId); Assert.assertNull(info.serviceVersion); Assert.assertNull(info.resource); info = parseServiceRequestPath(\"/invalid/path\"); Assert.assertNull(info.orgId); Assert.assertNull(info.serviceId); Assert.assertNull(info.serviceVersion); Assert.assertNull(info.resource); info = parseServiceRequestPath(\"/Org1/Service1/1.0\"); Assert.assertEquals(\"Org1\", info.orgId); Assert.assertEquals(\"Service1\", info.serviceId); Assert.assertEquals(\"1.0\", info.serviceVersion); Assert.assertNull(info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/2.7\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertNull(info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/2.7/resource\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/resource\", info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/2.7/path/to/resource\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource\", info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/2.7/path/to/resource?query=1234\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource?query=1234\", info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/path/to/resource?query=1234\", null, \"2.7\"); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource?query=1234\", info.resource); info = parseServiceRequestPath(\"/MyOrg/Service-99/path/to/resource?query=1234\", \"application/apiman.2.7+json\", null); Assert.assertEquals(\"MyOrg\", info.orgId); Assert.assertEquals(\"Service-99\", info.serviceId); Assert.assertEquals(\"2.7\", info.serviceVersion); Assert.assertEquals(\"/path/to/resource?query=1234\", info.resource); } "
    },
    {
        "test_src": "@Test public void deleteFileTest()throws IOException, TachyonException { String uniqPath = PathUtils.uniqPath(); for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = TachyonFSTestUtils.createByteFile(sTfs, fileURI.getPath(), k, sWriteBoth); Assert.assertTrue(sTfs.getInfo(f).getInMemoryPercentage() == 100); Assert.assertNotNull(sTfs.getInfo(f)); } for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = sTfs.open(fileURI); sTfs.delete(f); Assert.assertNull(sTfs.getInfo(f)); } } ",
        "focal_tgt": "public synchronized boolean deleteFile(long fileId, boolean recursive)throws IOException, TachyonException { int retry = 0; while( ! mClosed && (retry ++ ) <= RPC_MAX_NUM_RETRY) { connect(); try { return mClient.deleteFile(fileId, recursive); } catch(TachyonTException e) { throw new TachyonException(e); } catch(TException e) { LOG.error(e.getMessage(), e); mConnected = false; } } throw new IOException(\"Failed after \" + retry + \" retries.\"); } ",
        "focal_src": "public synchronized boolean deleteFile(long fileId, boolean recursive)throws IOException, TachyonException { int retry = 0; while( ! mClosed && (retry ++ ) <= RPC_MAX_NUM_RETRY) { connect(); try { return mClient.deleteFile(fileId, recursive); } catch(TachyonTException e) { throw new TachyonException(e); } catch(ThriftIOException e) { throw new IOException(e); } catch(TException e) { LOG.error(e.getMessage(), e); mConnected = false; } } throw new IOException(\"Failed after \" + retry + \" retries.\"); } ",
        "test_tgt": "@Test public void deleteFileTest()throws IOException, TachyonException { String uniqPath = PathUtils.uniqPath(); for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = TachyonFSTestUtils.createByteFile(sTfs, fileURI.getPath(), k, sWriteBoth); Assert.assertTrue(sTfs.getInfo(f).getInMemoryPercentage() == 100); Assert.assertNotNull(sTfs.getInfo(f)); } for(int k = 0; k < 5; k ++ ) { TachyonURI fileURI = new TachyonURI(uniqPath + k); TachyonFile f = sTfs.open(fileURI); sTfs.delete(f); mThrown.expect(FileDoesNotExistException.class); sTfs.getInfo(f); } } "
    },
    {
        "test_src": "@Test public void testGetChecksum_FileNotFound()throws Exception { System.out.println(\"getChecksum (invalid path)\"); String algorithm = \"MD5\"; File file = new File(\"not a valid file\"); boolean exceptionThrown = false; try { byte[]result = Checksum.getChecksum(algorithm, file); } catch(FileNotFoundException ex) { exceptionThrown = true; } assertTrue(exceptionThrown); } ",
        "focal_tgt": "public static byte[]getChecksum(String algorithm, File file)throws NoSuchAlgorithmException, IOException { InputStream fis = null; byte[]buffer = new byte[1024]; MessageDigest complete = MessageDigest.getInstance(algorithm); int numRead; try { fis = new FileInputStream(file); do { numRead = fis.read(buffer); if(numRead > 0) { complete.update(buffer, 0, numRead); } } while(numRead != - 1); } finally { if(fis != null) { try { fis.close(); } catch(IOException ex) { Logger.getLogger(Checksum.class.getName()).log(Level.SEVERE, null, ex); } } } return complete.digest(); } ",
        "focal_src": "public static byte[]getChecksum(String algorithm, File file)throws FileNotFoundException, NoSuchAlgorithmException { InputStream fis = new FileInputStream(file); byte[]buffer = new byte[1024]; MessageDigest complete = MessageDigest.getInstance(algorithm); int numRead; try { do { numRead = fis.read(buffer); if(numRead > 0) { complete.update(buffer, 0, numRead); } } while(numRead != - 1); } catch(IOException ex) { Logger.getLogger(Checksum.class.getName()).log(Level.SEVERE, null, ex); } finally { try { fis.close(); } catch(IOException ex) { Logger.getLogger(Checksum.class.getName()).log(Level.SEVERE, null, ex); } } return complete.digest(); } ",
        "test_tgt": "@Test public void testGetChecksum_FileNotFound()throws Exception { System.out.println(\"getChecksum (invalid path)\"); String algorithm = \"MD5\"; File file = new File(\"not a valid file\"); boolean exceptionThrown = false; try { byte[]result = Checksum.getChecksum(algorithm, file); } catch(IOException ex) { exceptionThrown = true; } assertTrue(exceptionThrown); } "
    },
    {
        "test_src": "@Test public void removeParameterList() { uri = \"http://www.feilong.com:8888/search.htm?keyword=&page=&categoryCode=2-5-3-11&label=TopSeller\"; List < String > paramNameList = new ArrayList < String > (); paramNameList.add(\"label\"); paramNameList.add(\"keyword\"); LOGGER.info(ParamUtil.removeParameterList(uri, paramNameList, CharsetType.UTF8)); } ",
        "focal_tgt": "public static String removeParameterList(URI uri, List < String > paramNameList, String charsetType) { if(null == uri) { return StringUtils.EMPTY; } String uriString = uri.toString(); if(Validator.isNullOrEmpty(paramNameList)) { return uriString; } String queryString = uri.getRawQuery(); return removeParameterList(uri.toString(), queryString, paramNameList, charsetType); } ",
        "focal_src": "public static String removeParameterList(URI uri, List < String > paramNameList, String charsetType) { if(null == uri) { return StringUtils.EMPTY; } String uriString = uri.toString(); if(Validator.isNullOrEmpty(paramNameList)) { return uriString; } String queryString = uri.getRawQuery(); return removeParameterList(uriString, queryString, paramNameList, charsetType); } ",
        "test_tgt": "@Test public void removeParameterList() { uriString = \"http://www.feilong.com:8888/search.htm?keyword=&page=&categoryCode=2-5-3-11&label=TopSeller\"; List < String > paramNameList = new ArrayList < String > (); paramNameList.add(\"label\"); paramNameList.add(\"keyword\"); LOGGER.info(ParamUtil.removeParameterList(uriString, paramNameList, CharsetType.UTF8)); } "
    },
    {
        "test_src": "@Test public void testIsValidCCN() { System.out.println(\"isValidCCN\"); CreditCardValidator validator = new CreditCardValidator(); assertEquals(false, validator.isValidCCN(\"123456789031\")); assertEquals(false, validator.isValidCCN(\"623 974794 78395 186\")); assertEquals(false, validator.isValidCCN(\"12 5678-90-31834\")); assertEquals(false, validator.isValidCCN(\"12345678903183426\")); assertEquals(false, validator.isValidCCN(\"12342387t8373092570375025678902\")); assertEquals(true, validator.isValidCCN(\"1234-5678-9031-8342\")); assertEquals(true, validator.isValidCCN(\"1234 5678 9031 8342\")); assertEquals(false, validator.isValidCCN(\"1234-5678-9031 8342\")); assertEquals(false, validator.isValidCCN(\"1234-5678-90-318342\")); assertEquals(false, validator.isValidCCN(\"1234 5678 90 318342\")); assertEquals(false, validator.isValidCCN(\"1-2-3-4-5-6-7-8-9-0-3-1-8-3-4-2\")); assertEquals(true, validator.isValidCCN(\"3431 136294 58529\")); assertEquals(true, validator.isValidCCN(\"3431-136294-58529\")); assertEquals(true, validator.isValidCCN(\"343113629458529\")); assertEquals(false, validator.isValidCCN(\"3431 13629458 529\")); assertEquals(true, validator.isValidCCN(\"377585291285489\")); assertEquals(true, validator.isValidCCN(\"3775-852912-85489\")); assertEquals(true, validator.isValidCCN(\"3775 852912 85489\")); assertEquals(false, validator.isValidCCN(\"3775-852912 85489\")); assertEquals(false, validator.isValidCCN(\"37-7585-29-1285489\")); assertEquals(false, validator.isValidCCN(\"377585 29128548 9\")); assertEquals(true, validator.isValidCCN(\"1409 56201 545229\")); assertEquals(true, validator.isValidCCN(\"1409-56201-545229\")); assertEquals(true, validator.isValidCCN(\"140956201545229\")); assertEquals(false, validator.isValidCCN(\"140 9562015 45229\")); assertEquals(false, validator.isValidCCN(\"1409-56201 545229\")); assertEquals(true, validator.isValidCCN(\"4539747947839518654\")); assertEquals(true, validator.isValidCCN(\"4539-7479-4783-9518-654\")); assertEquals(true, validator.isValidCCN(\"4539 7479 4783 9518 654\")); assertEquals(false, validator.isValidCCN(\"4539-7479 4783 9518 654\")); assertEquals(false, validator.isValidCCN(\"45374 79 4783 9518 654\")); assertEquals(true, validator.isValidCCN(\"6239747947839518659\")); assertEquals(true, validator.isValidCCN(\"623974 7947839518659\")); assertEquals(true, validator.isValidCCN(\"623974-7947839518659\")); assertEquals(false, validator.isValidCCN(\"623974-79478395 18659\")); assertEquals(false, validator.isValidCCN(\"62397-47947839518659\")); assertEquals(true, validator.isValidCCN(\"5140 2100 1014 4744\")); } ",
        "focal_tgt": "public boolean isValidCCN(String rawCCN) { boolean hasSpace = StringUtils.contains(rawCCN, ' '); boolean hasDash = StringUtils.contains(rawCCN, '-'); if(hasSpace && hasDash) { return false; } Character separator = null; if(hasSpace) { separator = ' '; } else if(hasDash) { separator = '-'; } final String cannonicalCCN; String[]splitCCN; if(separator != null) { cannonicalCCN = CharMatcher.anyOf(separator.toString()).removeFrom(rawCCN); splitCCN = rawCCN.split(separator.toString()); } else { cannonicalCCN = rawCCN; splitCCN = new String[] { cannonicalCCN }; } switch(cannonicalCCN.length()) { case 15 : if(false == isValid15DigitGrouping(splitCCN)) { return false; } break; case 16 : if(false == isValid16DigitGrouping(splitCCN)) { return false; } break; case 19 : if(false == isValid19DigitGrouping(splitCCN)) { return false; } break; } return CREDIT_CARD_NUM_LUHN_CHECK.isValid(cannonicalCCN); } ",
        "focal_src": "public boolean isValidCCN(String rawCCN) { boolean hasSpace = StringUtils.contains(rawCCN, ' '); boolean hasDash = StringUtils.contains(rawCCN, '-'); if(hasSpace && hasDash) { return false; } Character separator = null; if(hasSpace) { separator = ' '; } else if(hasDash) { separator = '-'; } final String cannonicalCCN; String[]splitCCN; if(separator != null) { cannonicalCCN = CharMatcher.anyOf(separator.toString()).removeFrom(rawCCN); splitCCN = rawCCN.split(separator.toString()); } else { cannonicalCCN = rawCCN; splitCCN = new String[] { cannonicalCCN }; } switch(cannonicalCCN.length()) { case 15 : if(false == isValid15DigitGrouping(splitCCN)) { return false; } break; case 16 : if(false == isValid16DigitGrouping(splitCCN)) { return false; } break; case 19 : if(false == isValid19DigitGrouping(splitCCN)) { return false; } break; default : return false; } return CREDIT_CARD_NUM_LUHN_CHECK.isValid(cannonicalCCN); } ",
        "test_tgt": "@Test public void testIsValidCCN() { System.out.println(\"isValidCCN\"); CreditCardValidator validator = new CreditCardValidator(); assertEquals(true, validator.isValidCCN(\"1234-5678-9031-8342\")); assertEquals(true, validator.isValidCCN(\"1234 5678 9031 8342\")); assertEquals(false, validator.isValidCCN(\"1234-5678-9031 8342\")); assertEquals(false, validator.isValidCCN(\"1234-5678-90-318342\")); assertEquals(false, validator.isValidCCN(\"1234 5678 90 318342\")); assertEquals(false, validator.isValidCCN(\"1-2-3-4-5-6-7-8-9-0-3-1-8-3-4-2\")); assertEquals(true, validator.isValidCCN(\"3431 136294 58529\")); assertEquals(true, validator.isValidCCN(\"3431-136294-58529\")); assertEquals(true, validator.isValidCCN(\"343113629458529\")); assertEquals(false, validator.isValidCCN(\"3431 13629458 529\")); assertEquals(true, validator.isValidCCN(\"377585291285489\")); assertEquals(true, validator.isValidCCN(\"3775-852912-85489\")); assertEquals(true, validator.isValidCCN(\"3775 852912 85489\")); assertEquals(false, validator.isValidCCN(\"3775-852912 85489\")); assertEquals(false, validator.isValidCCN(\"37-7585-29-1285489\")); assertEquals(false, validator.isValidCCN(\"377585 29128548 9\")); assertEquals(true, validator.isValidCCN(\"4539747947839518654\")); assertEquals(true, validator.isValidCCN(\"4539-7479-4783-9518-654\")); assertEquals(true, validator.isValidCCN(\"4539 7479 4783 9518 654\")); assertEquals(false, validator.isValidCCN(\"4539-7479 4783 9518 654\")); assertEquals(false, validator.isValidCCN(\"45374 79 4783 9518 654\")); assertEquals(true, validator.isValidCCN(\"6239747947839518659\")); assertEquals(true, validator.isValidCCN(\"623974 7947839518659\")); assertEquals(true, validator.isValidCCN(\"623974-7947839518659\")); assertEquals(false, validator.isValidCCN(\"623974-79478395 18659\")); assertEquals(false, validator.isValidCCN(\"62397-47947839518659\")); } "
    },
    {
        "test_src": "@Test public void assignCoordinates() { Symbol symbol = new Symbol(0, \"test\", \"test\"); assertNull(symbol.getFrom()); assertNull(symbol.getTo()); symbol.assignCoordinates(1, 2, 3, 4); assertNotNull(symbol.getFrom()); assertNotNull(symbol.getTo()); assertEquals(1, symbol.getFrom().x); assertEquals(2, symbol.getFrom().y); assertEquals(3, symbol.getTo().x); assertEquals(4, symbol.getTo().y); } ",
        "focal_tgt": "public void assignCoordinates(int x1, int x2, int x3, int x4) { rectangle = new Rectangle(x1, x2, x3 - x1, x4 - x2); } ",
        "focal_src": "public void assignCoordinates(int x1, int x2, int x3, int x4) { from = new Point(x1, x2); to = new Point(x3, x4); } ",
        "test_tgt": "@Test public void assignCoordinates() { Symbol symbol = new Symbol(0, \"test\", \"test\"); assertNull(symbol.getRectangle()); symbol.assignCoordinates(1, 2, 3, 4); Rectangle rectangle = symbol.getRectangle(); assertNotNull(rectangle); assertEquals(1, rectangle.x); assertEquals(2, rectangle.y); assertEquals(2, rectangle.width); assertEquals(2, rectangle.height); } "
    },
    {
        "test_src": "@Test public void testKnn() { System.out.println(\"knn\"); long time = System.currentTimeMillis(); double recall = 0.0; for(int i = 0; i < testx.length; i ++ ) { int k = 3; Neighbor[]n1 = lsh.knn(testx[i], k); Neighbor[]n2 = naive.knn(testx[i], k); int hit = 0; for(int m = 0; m < n1.length && n1[m] != null; m ++ ) { for(int n = 0; n < n2.length && n2[n] != null; n ++ ) { if(n1[m].index == n2[n].index) { hit ++ ; break; } } } recall += 1.0 * hit / k; } recall /= testx.length; System.out.println(\"recall is \" + recall); System.out.println(\"time is \" + (System.currentTimeMillis() - time) / 1000.0); } ",
        "focal_tgt": "Neighbor < K, V > []knn(K q, int k); ",
        "focal_src": "public Neighbor < K, V > []knn(K q, int k); ",
        "test_tgt": "@Test public void testKnn() { System.out.println(\"knn\"); int[]recall = new int[testx.length]; for(int i = 0; i < testx.length; i ++ ) { int k = 7; Neighbor[]n1 = lsh.knn(testx[i], k); Neighbor[]n2 = naive.knn(testx[i], k); for(Neighbor m2 : n2) { for(Neighbor m1 : n1) { if(m1.index == m2.index) { recall[i] ++ ; break; } } } } System.out.format(\"q1 of recall is %d%n\", MathEx.q1(recall)); System.out.format(\"median of recall is %d%n\", MathEx.median(recall)); System.out.format(\"q3 of recall is %d%n\", MathEx.q3(recall)); } "
    },
    {
        "test_src": "@Test public void testGetTunnelInfos() { testAddTunnelInfo(); Map < TunnelId, PceccTunnelInfo > tunnelInfoMap = distrPceStore.getTunnelInfos(); assertThat(tunnelInfoMap, is(notNullValue())); assertThat(tunnelInfoMap.isEmpty(), is(false)); assertThat(tunnelInfoMap.size(), is(2)); } ",
        "focal_tgt": "Map < TunnelId, ResourceConsumer > getTunnelInfos(); ",
        "focal_src": "Map < TunnelId, PceccTunnelInfo > getTunnelInfos(); ",
        "test_tgt": "@Test public void testGetTunnelInfos() { testAddTunnelInfo(); Map < TunnelId, ResourceConsumer > tunnelInfoMap = distrPceStore.getTunnelInfos(); assertThat(tunnelInfoMap, is(notNullValue())); assertThat(tunnelInfoMap.isEmpty(), is(false)); assertThat(tunnelInfoMap.size(), is(2)); } "
    },
    {
        "test_src": "@Test public final void backup() { no(new CreateBackup(NAME)); ok(new CreateDB(NAME)); ok(new CreateDB(NAME2)); ok(new CreateBackup(NAME)); ok(new Close()); ok(new Restore(NAME)); ok(new CreateBackup(NAME)); ok(new DropBackup(NAME)); ok(new CreateBackup(NAME + \"*\")); ok(new Restore(NAME2)); ok(new DropBackup(NAME + \"*\")); no(new Restore(\":\")); } ",
        "focal_tgt": "private boolean backup(final String db, final Prop pr) { ZipOutputStream zos = null; try { final File in = pr.dbpath(db); final File file = pr.dbpath(db + \"-\" + DATE.format(new Date()) + IO.ZIPSUFFIX); final byte[]data = new byte[IO.BLOCKSIZE]; zos = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(file))); zos.putNextEntry(new ZipEntry(in.getName() + '/')); zos.closeEntry(); final File[]files = in.listFiles(); tf = files.length; for(final File f : files) { of ++ ; BufferedInputStream bis = null; try { bis = new BufferedInputStream(new FileInputStream(f), IO.BLOCKSIZE); zos.putNextEntry(new ZipEntry(in.getName() + '/' + f.getName())); int c; while((c = bis.read(data)) != - 1)zos.write(data, 0, c); zos.closeEntry(); } finally { if(bis != null)try { bis.close(); } catch(final IOException e) { } } } zos.close(); return true; } catch(final IOException ex) { return false; } finally { if(zos != null)try { zos.close(); } catch(final IOException e) { } } } ",
        "focal_src": "private boolean backup(final String db, final Prop pr) { ZipOutputStream zos = null; try { final File in = pr.dbpath(db); final File file = new File(pr.get(Prop.DBPATH) + '/' + db + \"-\" + DATE.format(new Date()) + IO.ZIPSUFFIX); final byte[]data = new byte[IO.BLOCKSIZE]; zos = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(file))); zos.putNextEntry(new ZipEntry(in.getName() + '/')); zos.closeEntry(); final File[]files = in.listFiles(); tf = files.length; for(final File f : files) { of ++ ; BufferedInputStream bis = null; try { bis = new BufferedInputStream(new FileInputStream(f), IO.BLOCKSIZE); zos.putNextEntry(new ZipEntry(in.getName() + '/' + f.getName())); int c; while((c = bis.read(data)) != - 1)zos.write(data, 0, c); zos.closeEntry(); } finally { if(bis != null)try { bis.close(); } catch(final IOException e) { } } } zos.close(); return true; } catch(final IOException ex) { return false; } finally { if(zos != null)try { zos.close(); } catch(final IOException e) { } } } ",
        "test_tgt": "@Test public final void createBackup() { no(new CreateBackup(NAME)); ok(new CreateDB(NAME)); ok(new CreateDB(NAME2)); ok(new CreateBackup(NAME)); ok(new Close()); ok(new Restore(NAME)); ok(new CreateBackup(NAME)); ok(new DropBackup(NAME)); ok(new CreateBackup(NAME + \"*\")); ok(new Restore(NAME2)); ok(new DropBackup(NAME + \"*\")); no(new Restore(\":\")); } "
    },
    {
        "test_src": "@Test public void sort() { query(SORT.args(\"(1, 4, 6, 5, 3)\"), \"1\\n3\\n4\\n5\\n6\"); query(SORT.args(\"(1,-2,5,10,-10,10,8)\", \" abs#1\"), \"1\\n-2\\n5\\n8\\n10\\n-10\\n10\"); query(SORT.args(\"((1,0), (1,1), (0,1), (0,0))\"), \"0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\"); query(COUNT.args(SORT.args(\"('9','8','29','310','75','85','36-37','68-69','93','72','185',\" + \"'188','86','87','83','79','82','71','67','63','58','57','53','31','26','22','21','20'\" + \",'15','10','03','05','1')\", \"function($s) { number($s) }\")), \"33\"); } ",
        "focal_tgt": "public static Integer[]sort(final ValueList vl, final StandardFunc sf, final Collation coll)throws QueryException { final int al = vl.size(); final Integer[]order = new Integer[al]; for(int o = 0; o < al; o ++ )order[o] = o; try { Arrays.sort(order, new Comparator < Integer > () { @Override public int compare(final Integer i1, final Integer i2) { try { final Value v1 = vl.get(i1), v2 = vl.get(i2); final long s1 = v1.size(), s2 = v2.size(), sl = Math.min(s1, s2); for(int v = 0; v < sl; v ++ ) { Item m = v1.itemAt(v), n = v2.itemAt(v); if(m == Dbl.NAN || m == Flt.NAN)m = null; if(n == Dbl.NAN || n == Flt.NAN)n = null; if(m != null && n != null && ! m.comparable(n)) { throw m instanceof FItem ? FIEQ_X.get(sf.info, m.type) : n instanceof FItem ? FIEQ_X.get(sf.info, n.type) : diffError(m, n, sf.info); } final int d = m == null ? n == null ? 0 : - 1 : n == null ? 1 : m.diff(n, coll, sf.info); if(d != 0 && d != Item.UNDEF)return d; } return(int)(s1 - s2); } catch(final QueryException ex) { throw new QueryRTException(ex); } } }); } catch(final QueryRTException ex) { throw ex.getCause(); } return order; } ",
        "focal_src": "public static Integer[]sort(final ValueList vl, final StandardFunc sf)throws QueryException { final int al = vl.size(); final Integer[]order = new Integer[al]; for(int o = 0; o < al; o ++ )order[o] = o; try { Arrays.sort(order, new Comparator < Integer > () { @Override public int compare(final Integer i1, final Integer i2) { try { final Value v1 = vl.get(i1), v2 = vl.get(i2); final long s1 = v1.size(), s2 = v2.size(), sl = Math.min(s1, s2); for(int v = 0; v < sl; v ++ ) { Item m = v1.itemAt(v), n = v2.itemAt(v); if(m == Dbl.NAN || m == Flt.NAN)m = null; if(n == Dbl.NAN || n == Flt.NAN)n = null; if(m != null && n != null && ! m.comparable(n)) { throw m instanceof FItem ? FIEQ_X.get(sf.info, m.type) : n instanceof FItem ? FIEQ_X.get(sf.info, n.type) : diffError(m, n, sf.info); } final int d = m == null ? n == null ? 0 : - 1 : n == null ? 1 : m.diff(n, sf.sc.collation, sf.info); if(d != 0 && d != Item.UNDEF)return d; } return(int)(s1 - s2); } catch(final QueryException ex) { throw new QueryRTException(ex); } } }); } catch(final QueryRTException ex) { throw ex.getCause(); } return order; } ",
        "test_tgt": "@Test public void sort() { query(SORT.args(\"(1, 4, 6, 5, 3)\"), \"1\\n3\\n4\\n5\\n6\"); query(SORT.args(\"(1,-2,5,10,-10,10,8)\", \"\", \" abs#1\"), \"1\\n-2\\n5\\n8\\n10\\n-10\\n10\"); query(SORT.args(\"((1,0), (1,1), (0,1), (0,0))\"), \"0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\"); query(COUNT.args(SORT.args(\"('9','8','29','310','75','85','36-37','68-69','93','72','185',\" + \"'188','86','87','83','79','82','71','67','63','58','57','53','31','26','22','21','20'\" + \",'15','10','03','05','1')\", \"\", \"function($s) { number($s) }\")), \"33\"); } "
    },
    {
        "test_src": "@Test(expectedExceptions = CalendricalFormatException.class)public void test_print_emptyCalendrical()throws Exception { ZoneOffsetPrinterParser pp = new ZoneOffsetPrinterParser(\"Z\", true, true); pp.print(emptyCalendrical, buf, symbols); } ",
        "focal_tgt": "public void print(Calendrical calendrical, Appendable appendable) { DateTimeFormatter.checkNotNull(calendrical, \"Calendrical must not be null\"); DateTimeFormatter.checkNotNull(appendable, \"Appendable must not be null\"); try { printerParser.print(calendrical, appendable, symbols); } catch(UnsupportedRuleException ex) { throw new CalendricalPrintFieldException(ex); } catch(IOException ex) { throw new CalendricalPrintException(ex.getMessage(), ex); } } ",
        "focal_src": "public void print(Calendrical calendrical, Appendable appendable) { DateTimeFormatter.checkNotNull(calendrical, \"Calendrical must not be null\"); DateTimeFormatter.checkNotNull(appendable, \"Appendable must not be null\"); try { printerParser.print(calendrical, appendable, symbols); } catch(UnsupportedRuleException ex) { throw new CalendricalFormatFieldException(ex); } catch(IOException ex) { throw new CalendricalFormatException(ex.getMessage(), ex); } } ",
        "test_tgt": "@Test(expectedExceptions = CalendricalPrintException.class)public void test_print_emptyCalendrical()throws Exception { ZoneOffsetPrinterParser pp = new ZoneOffsetPrinterParser(\"Z\", true, true); pp.print(emptyCalendrical, buf, symbols); } "
    },
    {
        "test_src": "@Test public void process() { Se2_F32 initial = new Se2_F32(1, 2, 3); Se2_F32 computed = new Se2_F32(4, 5, 6); Se2_F32 model = new Se2_F32(); DummyTracker tracker = new DummyTracker(); DummyModelMatcher < Se2_F32 > matcher = new DummyModelMatcher < Se2_F32 > (computed, 5); ImageUInt8 input = new ImageUInt8(20, 30); ImageMotionPointTrackerKey < ImageUInt8, Se2_F32 > alg = new ImageMotionPointTrackerKey < ImageUInt8, Se2_F32 > (tracker, matcher, null, model, 1000); alg.setInitialTransform(initial); assertFalse(alg.process(input)); assertEquals(0, tracker.numSpawn); alg.changeKeyFrame(); assertEquals(1, tracker.numSpawn); assertTrue(alg.process(input)); assertEquals(1, tracker.numSpawn); Se2_F32 keyToCurr = alg.getKeyToCurr(); assertEquals(computed.getX(), keyToCurr.getX(), 1e-8); Se2_F32 worldToCurr = initial.concat(keyToCurr, null); Se2_F32 found = alg.getWorldToCurr(); assertEquals(worldToCurr.getX(), found.getX(), 1e-8); } ",
        "focal_tgt": "public boolean process(I frame) { keyFrame = false; tracker.process(frame); totalFramesProcessed ++ ; List < PointTrack > tracks = tracker.getActiveTracks(null); if(tracks.size() == 0)return false; List < AssociatedPair > pairs = new ArrayList < AssociatedPair > (); for(PointTrack t : tracks) { pairs.add((AssociatedPair)t.getCookie()); } if( ! modelMatcher.process((List)pairs)) { return false; } if(modelRefiner != null) { if( ! modelRefiner.fitModel(modelMatcher.getMatchSet(), modelMatcher.getModel(), keyToCurr))return false; } else { keyToCurr.set(modelMatcher.getModel()); } for(AssociatedPair p : modelMatcher.getMatchSet()) { ((AssociatedPairTrack)p).lastUsed = totalFramesProcessed; } pruneUnusedTracks(); worldToKey.concat(keyToCurr, worldToCurr); return true; } ",
        "focal_src": "public boolean process(I frame) { keyFrame = false; pruneUnusedTracks(); tracker.process(frame); totalFramesProcessed ++ ; List < PointTrack > tracks = tracker.getActiveTracks(null); if(tracks.size() == 0)return false; List < AssociatedPair > pairs = new ArrayList < AssociatedPair > (); for(PointTrack t : tracks) { pairs.add((AssociatedPair)t.getCookie()); } if( ! modelMatcher.process((List)pairs)) { return false; } keyToCurr.set(modelMatcher.getModel()); for(AssociatedPair p : modelMatcher.getMatchSet()) { ((AssociatedPairTrack)p).lastUsed = totalFramesProcessed; } worldToKey.concat(keyToCurr, worldToCurr); return true; } ",
        "test_tgt": "@Test public void process() { Se2_F32 computed = new Se2_F32(4, 5, 6); Se2_F32 model = new Se2_F32(); DummyTracker tracker = new DummyTracker(); DummyModelMatcher < Se2_F32 > matcher = new DummyModelMatcher < Se2_F32 > (computed, 5); ImageUInt8 input = new ImageUInt8(20, 30); ImageMotionPointTrackerKey < ImageUInt8, Se2_F32 > alg = new ImageMotionPointTrackerKey < ImageUInt8, Se2_F32 > (tracker, matcher, null, model, 1000); assertFalse(alg.process(input)); assertFalse(alg.isKeyFrame()); assertEquals(0, tracker.numSpawn); alg.changeKeyFrame(); assertEquals(0, tracker.numDropAll); assertEquals(1, tracker.numSpawn); assertTrue(alg.isKeyFrame()); assertTrue(alg.process(input)); assertFalse(alg.isKeyFrame()); assertEquals(1, tracker.numSpawn); assertEquals(computed.getX(), alg.getKeyToCurr().getX(), 1e-8); assertEquals(computed.getX(), alg.getWorldToCurr().getX(), 1e-8); assertEquals(0, tracker.numDropAll); alg.reset(); assertEquals(1, tracker.numDropAll); assertEquals(0, alg.getTotalFramesProcessed()); assertEquals(0, alg.getKeyToCurr().getX(), 1e-8); assertEquals(0, alg.getWorldToCurr().getX(), 1e-8); } "
    },
    {
        "test_src": "@Test public void testAddCriticalityToVulnerability()throws AnalysisException, DatabaseException { try { analyzer.initialize(); final Dependency result = new Dependency(BaseTest.getResourceAsFile(this, \"ruby/vulnerable/gems/sinatra/Gemfile.lock\")); final Engine engine = new Engine(); analyzer.analyze(result, engine); Dependency dependency = engine.getDependencies().get(0); Vulnerability vulnerability = dependency.getVulnerabilities().first(); assertEquals(vulnerability.getCvssScore(), 5.0f, 0.0); } catch(InitializationException | DatabaseException | AnalysisException e) { LOGGER.warn(\"Exception setting up RubyBundleAuditAnalyzer. Make sure Ruby gem bundle-audit is installed. You may also need to set property \\\"analyzer.bundle.audit.path\\\".\"); Assume.assumeNoException(\"Exception setting up RubyBundleAuditAnalyzer; bundle audit may not be installed, or property \\\"analyzer.bundle.audit.path\\\" may not be set.\", e); } } ",
        "focal_tgt": "private void addCriticalityToVulnerability(String parentName, Vulnerability vulnerability, String nextLine) { if(null != vulnerability) { final String criticality = nextLine.substring(CRITICALITY.length()).trim(); float score = - 1.0f; Vulnerability v = null; if(cvedb != null) { try { v = cvedb.getVulnerability(vulnerability.getName()); } catch(DatabaseException ex) { LOGGER.debug(\"Unable to look up vulnerability {}\", vulnerability.getName()); } } if(v != null) { score = v.getCvssScore(); vulnerability.setCvssAccessComplexity(v.getCvssAccessComplexity()); vulnerability.setCvssAccessVector(v.getCvssAccessVector()); vulnerability.setCvssAuthentication(v.getCvssAuthentication()); vulnerability.setCvssAvailabilityImpact(v.getCvssAvailabilityImpact()); vulnerability.setCvssConfidentialityImpact(v.getCvssConfidentialityImpact()); vulnerability.setCvssIntegrityImpact(v.getCvssIntegrityImpact()); } else if(\"High\".equalsIgnoreCase(criticality)) { score = 8.5f; } else if(\"Medium\".equalsIgnoreCase(criticality)) { score = 5.5f; } else if(\"Low\".equalsIgnoreCase(criticality)) { score = 2.0f; } vulnerability.setCvssScore(score); } LOGGER.debug(\"bundle-audit ({}): {}\", parentName, nextLine); } ",
        "focal_src": "private void addCriticalityToVulnerability(String parentName, Vulnerability vulnerability, String nextLine) { if(null != vulnerability) { final String criticality = nextLine.substring(CRITICALITY.length()).trim(); float score = - 1.0f; Vulnerability v = null; try { v = cvedb.getVulnerability(vulnerability.getName()); } catch(DatabaseException ex) { LOGGER.debug(\"Unable to look up vulnerability {}\", vulnerability.getName()); } if(v != null) { score = v.getCvssScore(); } else if(\"High\".equalsIgnoreCase(criticality)) { score = 8.5f; } else if(\"Medium\".equalsIgnoreCase(criticality)) { score = 5.5f; } else if(\"Low\".equalsIgnoreCase(criticality)) { score = 2.0f; } vulnerability.setCvssScore(score); } LOGGER.debug(\"bundle-audit ({}): {}\", parentName, nextLine); } ",
        "test_tgt": "@Test public void testAddCriticalityToVulnerability()throws AnalysisException, DatabaseException { try { analyzer.initialize(null); final Dependency result = new Dependency(BaseTest.getResourceAsFile(this, \"ruby/vulnerable/gems/sinatra/Gemfile.lock\")); final Engine engine = new Engine(getSettings()); analyzer.analyze(result, engine); Dependency dependency = engine.getDependencies().get(0); Vulnerability vulnerability = dependency.getVulnerabilities().first(); assertEquals(vulnerability.getCvssScore(), 5.0f, 0.0); } catch(InitializationException | DatabaseException | AnalysisException e) { LOGGER.warn(\"Exception setting up RubyBundleAuditAnalyzer. Make sure Ruby gem bundle-audit is installed. You may also need to set property \\\"analyzer.bundle.audit.path\\\".\"); Assume.assumeNoException(\"Exception setting up RubyBundleAuditAnalyzer; bundle audit may not be installed, or property \\\"analyzer.bundle.audit.path\\\" may not be set.\", e); } } "
    },
    {
        "test_src": "@Test public void test_setInvoice() { final String esrImportLineText = \"00201059931000000010501536417000120686900000040000012 190013011813011813012100015000400000000000000\"; final I_AD_Org org = getAD_Org(); final I_ESR_Import esrImport = createImport(); final I_C_BP_BankAccount account = newInstance(I_C_BP_BankAccount.class); account.setIsEsrAccount(true); account.setAD_Org_ID(Env.getAD_Org_ID(getCtx())); account.setAD_User_ID(Env.getAD_User_ID(getCtx())); account.setESR_RenderedAccountNo(\"01-059931-0\"); save(account); esrImport.setC_BP_BankAccount(account); final I_C_ReferenceNo_Type refNoType = newInstance(I_C_ReferenceNo_Type.class); refNoType.setName(\"InvoiceReference\"); save(refNoType); final I_C_BPartner partner = newInstance(I_C_BPartner.class); partner.setValue(\"partner1\"); partner.setAD_Org_ID(org.getAD_Org_ID()); save(partner); esrImport.setAD_Org(org); save(esrImport); final I_C_DocType type = newInstance(I_C_DocType.class); type.setDocBaseType(X_C_DocType.DOCBASETYPE_ARInvoice); save(type); final I_C_Currency currencyEUR = newInstance(I_C_Currency.class); currencyEUR.setISO_Code(\"EUR\"); currencyEUR.setStdPrecision(2); currencyEUR.setIsEuro(true); save(currencyEUR); POJOWrapper.enableStrictValues(currencyEUR); final I_C_Invoice invoice = newInstance(I_C_Invoice.class); invoice.setC_BPartner_ID(partner.getC_BPartner_ID()); invoice.setAD_Org_ID(org.getAD_Org_ID()); invoice.setDocumentNo(\"000120686\"); invoice.setAD_Org_ID(org.getAD_Org_ID()); invoice.setGrandTotal(HUNDRET); invoice.setC_DocType_ID(type.getC_DocType_ID()); invoice.setC_Currency_ID(currencyEUR.getC_Currency_ID()); save(invoice); final I_C_ReferenceNo referenceNo = newInstance(I_C_ReferenceNo.class); referenceNo.setReferenceNo(\"0000000105015364170001206869\"); referenceNo.setC_ReferenceNo_Type(refNoType); referenceNo.setIsManual(true); referenceNo.setAD_Org_ID(org.getAD_Org_ID()); save(referenceNo); final I_C_ReferenceNo_Doc esrReferenceNumberDocument = newInstance(I_C_ReferenceNo_Doc.class); esrReferenceNumberDocument.setAD_Table_ID(Services.get(IADTableDAO.class).retrieveTableId(I_C_Invoice.Table_Name)); esrReferenceNumberDocument.setRecord_ID(invoice.getC_Invoice_ID()); esrReferenceNumberDocument.setC_ReferenceNo(referenceNo); save(esrReferenceNumberDocument); esrImportBL.loadAndEvaluateESRImportStream(esrImport, new ByteArrayInputStream(esrImportLineText.getBytes())); refresh(esrImport, true); final I_ESR_ImportLine esrImportLine = ESRTestUtil.retrieveSingleLine(esrImport); assertThat(esrImportLine.getAmount(), comparesEqualTo(FOURTY)); assertThat(esrImportLine.getC_Invoice_ID()).as(\"Invoice not set correctly\").isEqualTo(invoice.getC_Invoice_ID()); assertThat(esrImportLine.getESR_Invoice_Grandtotal()).as(\"Incorrect grandtotal\").isEqualByComparingTo(HUNDRET); assertThat(invoice.getGrandTotal()).as(\"Incorrect grandtotal\").isEqualByComparingTo(HUNDRET); assertThat(esrImportLine.getESR_Invoice_Openamt()).as(\"Incorrect invoice open amount\").isEqualByComparingTo(SIXTY); final BigDecimal invoice2GrandTotal = new BigDecimal(\"123.56\"); final I_C_Invoice invoice2 = newInstance(I_C_Invoice.class); invoice2.setGrandTotal(invoice2GrandTotal); invoice2.setC_BPartner_ID(partner.getC_BPartner_ID()); invoice2.setDocumentNo(\"000120688\"); invoice2.setAD_Org_ID(org.getAD_Org_ID()); invoice2.setC_DocType_ID(type.getC_DocType_ID()); save(invoice2); final I_C_AllocationLine allocAmt2 = newInstance(I_C_AllocationLine.class); allocAmt2.setWriteOffAmt(TWENTY); allocAmt2.setAmount(HUNDRET); allocAmt2.setC_Invoice_ID(invoice2.getC_Invoice_ID()); save(allocAmt2); esrImportBL.setInvoice(esrImportLine, invoice2); assertThat(esrImportLine.getC_Invoice_ID()).as(\"Invoice not set correctly\").isEqualTo(invoice2.getC_Invoice_ID()); assertThat(invoice2GrandTotal).as(\"Incorrect grandtotal\").isEqualByComparingTo(esrImportLine.getESR_Invoice_Grandtotal()); assertThat(esrImportLine.getESR_Invoice_Openamt()).isEqualByComparingTo(new BigDecimal(\"3.56\").subtract(esrImportLine.getAmount())); } ",
        "focal_tgt": "public void setInvoice(int C_Invoice_ID, int C_Currency_ID, BigDecimal GrandTotal, BigDecimal Open, BigDecimal FeeAmount, int DaysDue, boolean IsInDispute, int TimesDunned, int DaysAfterLast) { setC_Invoice_ID(C_Invoice_ID); m_C_CurrencyFrom_ID = C_Currency_ID; setAmt(GrandTotal); setOpenAmt(Open); setFeeAmt(FeeAmount); setConvertedAmt(Services.get(ICurrencyBL.class).convert(getOpenAmt(), CurrencyId.ofRepoId(C_Currency_ID), CurrencyId.ofRepoId(getC_CurrencyTo_ID()), ClientId.ofRepoId(getAD_Client_ID()), OrgId.ofRepoId(getAD_Org_ID()))); setIsInDispute(IsInDispute); setDaysDue(DaysDue); setTimesDunned(TimesDunned); } ",
        "focal_src": "public void setInvoice(int C_Invoice_ID, int C_Currency_ID, BigDecimal GrandTotal, BigDecimal Open, BigDecimal FeeAmount, int DaysDue, boolean IsInDispute, int TimesDunned, int DaysAfterLast) { setC_Invoice_ID(C_Invoice_ID); m_C_CurrencyFrom_ID = C_Currency_ID; setAmt(GrandTotal); setOpenAmt(Open); setFeeAmt(FeeAmount); setConvertedAmt(Services.get(ICurrencyBL.class).convert(getOpenAmt(), CurrencyId.ofRepoId(C_Currency_ID), CurrencyId.ofRepoId(getC_CurrencyTo_ID()), getAD_Client_ID(), getAD_Org_ID())); setIsInDispute(IsInDispute); setDaysDue(DaysDue); setTimesDunned(TimesDunned); } ",
        "test_tgt": "@Test public void test_setInvoice() { final String esrImportLineText = \"00201059931000000010501536417000120686900000040000012 190013011813011813012100015000400000000000000\"; final I_AD_Org org = getAD_Org(); final I_ESR_Import esrImport = createImport(); final I_C_BP_BankAccount account = newInstance(I_C_BP_BankAccount.class); account.setIsEsrAccount(true); account.setAD_Org_ID(Env.getAD_Org_ID(getCtx())); account.setAD_User_ID(Env.getAD_User_ID(getCtx())); account.setESR_RenderedAccountNo(\"01-059931-0\"); save(account); esrImport.setC_BP_BankAccount(account); final I_C_ReferenceNo_Type refNoType = newInstance(I_C_ReferenceNo_Type.class); refNoType.setName(\"InvoiceReference\"); save(refNoType); final I_C_BPartner partner = newInstance(I_C_BPartner.class); partner.setValue(\"partner1\"); partner.setAD_Org_ID(org.getAD_Org_ID()); save(partner); esrImport.setAD_Org(org); save(esrImport); final I_C_DocType type = newInstance(I_C_DocType.class); type.setDocBaseType(X_C_DocType.DOCBASETYPE_ARInvoice); save(type); final CurrencyId currencyEUR = PlainCurrencyDAO.createCurrencyId(CurrencyCode.EUR); final I_C_Invoice invoice = newInstance(I_C_Invoice.class); invoice.setC_BPartner_ID(partner.getC_BPartner_ID()); invoice.setAD_Org_ID(org.getAD_Org_ID()); invoice.setDocumentNo(\"000120686\"); invoice.setAD_Org_ID(org.getAD_Org_ID()); invoice.setGrandTotal(HUNDRET); invoice.setC_DocType_ID(type.getC_DocType_ID()); invoice.setC_Currency_ID(currencyEUR.getRepoId()); save(invoice); final I_C_ReferenceNo referenceNo = newInstance(I_C_ReferenceNo.class); referenceNo.setReferenceNo(\"0000000105015364170001206869\"); referenceNo.setC_ReferenceNo_Type(refNoType); referenceNo.setIsManual(true); referenceNo.setAD_Org_ID(org.getAD_Org_ID()); save(referenceNo); final I_C_ReferenceNo_Doc esrReferenceNumberDocument = newInstance(I_C_ReferenceNo_Doc.class); esrReferenceNumberDocument.setAD_Table_ID(Services.get(IADTableDAO.class).retrieveTableId(I_C_Invoice.Table_Name)); esrReferenceNumberDocument.setRecord_ID(invoice.getC_Invoice_ID()); esrReferenceNumberDocument.setC_ReferenceNo(referenceNo); save(esrReferenceNumberDocument); esrImportBL.loadAndEvaluateESRImportStream(esrImport, new ByteArrayInputStream(esrImportLineText.getBytes())); refresh(esrImport, true); final I_ESR_ImportLine esrImportLine = ESRTestUtil.retrieveSingleLine(esrImport); assertThat(esrImportLine.getAmount(), comparesEqualTo(FOURTY)); assertThat(esrImportLine.getC_Invoice_ID()).as(\"Invoice not set correctly\").isEqualTo(invoice.getC_Invoice_ID()); assertThat(esrImportLine.getESR_Invoice_Grandtotal()).as(\"Incorrect grandtotal\").isEqualByComparingTo(HUNDRET); assertThat(invoice.getGrandTotal()).as(\"Incorrect grandtotal\").isEqualByComparingTo(HUNDRET); assertThat(esrImportLine.getESR_Invoice_Openamt()).as(\"Incorrect invoice open amount\").isEqualByComparingTo(SIXTY); final BigDecimal invoice2GrandTotal = new BigDecimal(\"123.56\"); final I_C_Invoice invoice2 = newInstance(I_C_Invoice.class); invoice2.setGrandTotal(invoice2GrandTotal); invoice2.setC_BPartner_ID(partner.getC_BPartner_ID()); invoice2.setDocumentNo(\"000120688\"); invoice2.setAD_Org_ID(org.getAD_Org_ID()); invoice2.setC_DocType_ID(type.getC_DocType_ID()); save(invoice2); final I_C_AllocationLine allocAmt2 = newInstance(I_C_AllocationLine.class); allocAmt2.setWriteOffAmt(TWENTY); allocAmt2.setAmount(HUNDRET); allocAmt2.setC_Invoice_ID(invoice2.getC_Invoice_ID()); save(allocAmt2); esrImportBL.setInvoice(esrImportLine, invoice2); assertThat(esrImportLine.getC_Invoice_ID()).as(\"Invoice not set correctly\").isEqualTo(invoice2.getC_Invoice_ID()); assertThat(invoice2GrandTotal).as(\"Incorrect grandtotal\").isEqualByComparingTo(esrImportLine.getESR_Invoice_Grandtotal()); assertThat(esrImportLine.getESR_Invoice_Openamt()).isEqualByComparingTo(new BigDecimal(\"3.56\").subtract(esrImportLine.getAmount())); } "
    },
    {
        "test_src": "@Test public void testValidate() { System.out.println(\"validate\"); RandomValue.randomGenerator = new Random(42); Dataset trainingData = generateDataset(); Dataset validationData = new Dataset(); validationData.add(Record.newDataVector(new Object[] { 51, \"M\", \"3\", 100, 222, \"no\", \"0\", 143, \"yes\", 1.2, 2, 0, \"3\" }, \"healthy\")); validationData.add(Record.newDataVector(new Object[] { 67, \"M\", \"4\", 120, 229, \"no\", \"2\", 129, \"yes\", 2.6, 2, 2, \"7\" }, \"problem\")); String dbName = \"JUnitClusterer\"; DummyXYMinMaxNormalizer df = new DummyXYMinMaxNormalizer(dbName, TestConfiguration.getDBConfig()); df.fit_transform(trainingData, new DummyXYMinMaxNormalizer.TrainingParameters()); df.transform(validationData); Kmeans instance = new Kmeans(dbName, TestConfiguration.getDBConfig()); Kmeans.TrainingParameters param = new Kmeans.TrainingParameters(); param.setK(2); param.setMaxIterations(200); param.setInitMethod(Kmeans.TrainingParameters.Initialization.FORGY); param.setDistanceMethod(Kmeans.TrainingParameters.Distance.EUCLIDIAN); param.setWeighted(false); param.setCategoricalGamaMultiplier(1.0); param.setSubsetFurthestFirstcValue(2.0); instance.fit(trainingData, param); instance = null; instance = new Kmeans(dbName, TestConfiguration.getDBConfig()); instance.validate(validationData); df.denormalize(trainingData); df.denormalize(validationData); df.erase(); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); Map < Integer, Kmeans.Cluster > clusters = instance.getClusters(); for(Record r : validationData) { expResult.put(r.getId(), r.getY()); Integer clusterId = (Integer)r.getYPredicted(); Object label = clusters.get(clusterId).getLabelY(); if(label == null) { label = clusterId; } result.put(r.getId(), label); } assertEquals(expResult, result); instance.erase(); } ",
        "focal_tgt": "public VM validate(Dataset testingData) { logger.debug(\"test()\"); knowledgeBase.load(); VM validationMetrics = validateModel(testingData); return validationMetrics; } ",
        "focal_src": "public VM validate(Dataset testingData) { if(GeneralConfiguration.DEBUG) { System.out.println(\"test()\"); } knowledgeBase.load(); VM validationMetrics = validateModel(testingData); return validationMetrics; } ",
        "test_tgt": "@Test public void testValidate() { TestConfiguration.getLogger().debug(\"validate\"); RandomValue.randomGenerator = new Random(42); Dataset trainingData = generateDataset(); Dataset validationData = new Dataset(); validationData.add(Record.newDataVector(new Object[] { 51, \"M\", \"3\", 100, 222, \"no\", \"0\", 143, \"yes\", 1.2, 2, 0, \"3\" }, \"healthy\")); validationData.add(Record.newDataVector(new Object[] { 67, \"M\", \"4\", 120, 229, \"no\", \"2\", 129, \"yes\", 2.6, 2, 2, \"7\" }, \"problem\")); String dbName = \"JUnitClusterer\"; DummyXYMinMaxNormalizer df = new DummyXYMinMaxNormalizer(dbName, TestConfiguration.getDBConfig()); df.fit_transform(trainingData, new DummyXYMinMaxNormalizer.TrainingParameters()); df.transform(validationData); Kmeans instance = new Kmeans(dbName, TestConfiguration.getDBConfig()); Kmeans.TrainingParameters param = new Kmeans.TrainingParameters(); param.setK(2); param.setMaxIterations(200); param.setInitMethod(Kmeans.TrainingParameters.Initialization.FORGY); param.setDistanceMethod(Kmeans.TrainingParameters.Distance.EUCLIDIAN); param.setWeighted(false); param.setCategoricalGamaMultiplier(1.0); param.setSubsetFurthestFirstcValue(2.0); instance.fit(trainingData, param); instance = null; instance = new Kmeans(dbName, TestConfiguration.getDBConfig()); instance.validate(validationData); df.denormalize(trainingData); df.denormalize(validationData); df.erase(); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); Map < Integer, Kmeans.Cluster > clusters = instance.getClusters(); for(Record r : validationData) { expResult.put(r.getId(), r.getY()); Integer clusterId = (Integer)r.getYPredicted(); Object label = clusters.get(clusterId).getLabelY(); if(label == null) { label = clusterId; } result.put(r.getId(), label); } assertEquals(expResult, result); instance.erase(); } "
    },
    {
        "test_src": "@Test public void testResolveVariable() { final StrBuilder builder = new StrBuilder(\"Hi ${name}!\"); Map < String, String > map = new HashMap < String, String > (); map.put(\"name\", \"commons\"); StrSubstitutor sub = new StrSubstitutor(map) { @Override protected String resolveVariable(final String variableName, final StrBuilder buf, final int startPos, final int endPos) { assertEquals(\"name\", variableName); assertSame(builder, buf); assertEquals(3, startPos); assertEquals(10, endPos); return \"jakarta\"; } }; sub.replaceIn(builder); assertEquals(\"Hi jakarta!\", builder.toString()); } ",
        "focal_tgt": "protected String resolveVariable(final String variableName, final StrBuilder buf, final int startPos, final int endPos) { final StrLookup < ? > resolver = getVariableResolver(); if(resolver == null) { return null; } return resolver.lookup(variableName); } ",
        "focal_src": "protected String resolveVariable(final String variableName, final StrBuilder buf, final int startPos, final int endPos) { StrLookup < ? > resolver = getVariableResolver(); if(resolver == null) { return null; } return resolver.lookup(variableName); } ",
        "test_tgt": "@Test public void testResolveVariable() { final StrBuilder builder = new StrBuilder(\"Hi ${name}!\"); final Map < String, String > map = new HashMap < String, String > (); map.put(\"name\", \"commons\"); final StrSubstitutor sub = new StrSubstitutor(map) { @Override protected String resolveVariable(final String variableName, final StrBuilder buf, final int startPos, final int endPos) { assertEquals(\"name\", variableName); assertSame(builder, buf); assertEquals(3, startPos); assertEquals(10, endPos); return \"jakarta\"; } }; sub.replaceIn(builder); assertEquals(\"Hi jakarta!\", builder.toString()); } "
    },
    {
        "test_src": "@Test public void dtdInfo() { query(_VALIDATE_DTD_INFO.args(FILE, DTD), \"\"); query(_VALIDATE_DTD_INFO.args(DOC.args(FILE), DTD), \"\"); query(_VALIDATE_DTD_INFO.args(_FILE_READ_TEXT.args(FILE), _FILE_READ_TEXT.args(DTD)), \"\"); query(\"let $doc := <root/> \" + \"let $dtd := '<!ELEMENT root (#PCDATA)>' \" + \"return validate:dtd($doc, $dtd) \", \"\"); query(EXISTS.args(_VALIDATE_DTD_INFO.args(FILE)), \"true\"); query(EXISTS.args(\"let $doc := <root/> \" + \"let $dtd := '<!ELEMENT unknown (#PCDATA)>' \" + \"return validate:dtd($doc, $dtd) \"), \"true\"); error(_VALIDATE_DTD_INFO.args(\"unknown\"), Err.WHICHRES); error(_VALIDATE_DTD_INFO.args(FILE, \"unknown.dtd\"), Err.WHICHRES); } ",
        "focal_tgt": "private Value dtdInfo(final QueryContext qc)throws QueryException { return process(new Validate() { @Override void process(final ErrorHandler handler)throws IOException, ParserConfigurationException, SAXException, QueryException { final Item it = toItem(exprs[0], qc); SerializerOptions sp = null; if(exprs.length > 1) { sp = new SerializerOptions(); IO dtd = checkPath(exprs[1], qc); tmp = createTmp(dtd); if(tmp != null)dtd = tmp; sp.set(SerializerOptions.DOCTYPE_SYSTEM, dtd.url()); } final IO in = read(it, qc, sp); final SAXParserFactory sf = SAXParserFactory.newInstance(); sf.setValidating(true); sf.newSAXParser().parse(in.inputSource(), handler); } }); } ",
        "focal_src": "private Value dtdInfo(final QueryContext qc)throws QueryException { return process(new Validate() { @Override void process(final ErrorHandler handler)throws IOException, ParserConfigurationException, SAXException, QueryException { final Item it = checkItem(exprs[0], qc); SerializerOptions sp = null; if(exprs.length > 1) { sp = new SerializerOptions(); IO dtd = checkPath(exprs[1], qc); tmp = createTmp(dtd); if(tmp != null)dtd = tmp; sp.set(SerializerOptions.DOCTYPE_SYSTEM, dtd.url()); } final IO in = read(it, qc, sp); final SAXParserFactory sf = SAXParserFactory.newInstance(); sf.setValidating(true); sf.newSAXParser().parse(in.inputSource(), handler); } }); } ",
        "test_tgt": "@Test public void dtdInfo() { query(_VALIDATE_DTD_INFO.args(FILE, DTD), \"\"); query(_VALIDATE_DTD_INFO.args(DOC.args(FILE), DTD), \"\"); query(_VALIDATE_DTD_INFO.args(_FILE_READ_TEXT.args(FILE), _FILE_READ_TEXT.args(DTD)), \"\"); query(\"let $doc := <root/> \" + \"let $dtd := '<!ELEMENT root (#PCDATA)>' \" + \"return validate:dtd($doc, $dtd) \", \"\"); query(EXISTS.args(_VALIDATE_DTD_INFO.args(FILE)), \"true\"); query(EXISTS.args(\"let $doc := <root/> \" + \"let $dtd := '<!ELEMENT unknown (#PCDATA)>' \" + \"return validate:dtd($doc, $dtd) \"), \"true\"); error(_VALIDATE_DTD_INFO.args(\"unknown\"), Err.WHICHRES_X); error(_VALIDATE_DTD_INFO.args(FILE, \"unknown.dtd\"), Err.WHICHRES_X); } "
    },
    {
        "test_src": "@Test(description = \"PUT /vApp/{id}\", dependsOnMethods = { \"testGetVm\" })public void testEditVm() { Vm newVm = Vm.builder().name(name(\"new-name-\")).description(\"New Description\").build(); Task editVm = vmApi.edit(vm.getHref(), newVm); assertTrue(retryTaskSuccess.apply(editVm), String.format(TASK_COMPLETE_TIMELY, \"editVm\")); vm = vmApi.get(vm.getHref()); assertEquals(vm.getName(), newVm.getName(), String.format(OBJ_FIELD_EQ, VM, \"Name\", newVm.getName(), vm.getName())); assertEquals(vm.getDescription(), newVm.getDescription(), String.format(OBJ_FIELD_EQ, VM, \"Description\", newVm.getDescription(), vm.getDescription())); } ",
        "focal_tgt": "@PUT@Produces(VM)@Consumes(TASK)@JAXBResponseParser ListenableFuture < Task > edit(@EndpointParam(parser = VmURNToHref.class)String vmUrn, @BinderParam(BindToXMLPayload.class)Vm vApp); ",
        "focal_src": "@PUT@Produces(VM)@Consumes(TASK)@JAXBResponseParser ListenableFuture < Task > editVm(@EndpointParam URI vmURI, @BinderParam(BindToXMLPayload.class)Vm vApp); ",
        "test_tgt": "@Test(description = \"PUT /vApp/{id}\", dependsOnMethods = { \"testGetVm\" })public void testEditVm() { Vm newVm = Vm.builder().name(name(\"new-name-\")).description(\"New Description\").build(); Task editVm = vmApi.edit(vmUrn, newVm); assertTrue(retryTaskSuccess.apply(editVm), String.format(TASK_COMPLETE_TIMELY, \"editVm\")); vm = vmApi.get(vmUrn); assertEquals(vm.getName(), newVm.getName(), String.format(OBJ_FIELD_EQ, VM, \"Name\", newVm.getName(), vm.getName())); assertEquals(vm.getDescription(), newVm.getDescription(), String.format(OBJ_FIELD_EQ, VM, \"Description\", newVm.getDescription(), vm.getDescription())); } "
    },
    {
        "test_src": "@Test public final void replace()throws IOException { session.execute(\"create db \" + DB); check(\"0\", session.query(\"count(\" + _DB_OPEN.args(DB) + \")\").execute()); session.replace(DB, new ArrayInput(\"<X/>\")); check(\"1\", session.query(\"count(\" + _DB_OPEN.args(DB) + \")\").execute()); session.replace(DB + \"2\", new ArrayInput(\"<X/>\")); check(\"2\", session.query(\"count(\" + _DB_OPEN.args(DB) + \")\").execute()); session.replace(DB + \"2\", new ArrayInput(\"<X/>\")); check(\"2\", session.query(\"count(\" + _DB_OPEN.args(DB) + \")\").execute()); } ",
        "focal_tgt": "private static String replace(final String cls, final char incl) { final int[]v = cls.startsWith(\"Is\") ? MAP.get(cls.substring(2)) : null; if(v == null)return \"\\\\\" + incl + '{' + cls + '}'; final TokenBuilder tb = new TokenBuilder().add('['); if(incl == 'P')tb.add(\"!\"); for(int i = 0; i < v.length; ) { tb.add(v[i ++ ]); tb.add('-'); tb.add(v[i ++ ]); } return tb.add(']').toString(); } ",
        "focal_src": "private static String replace(final String cls, final char incl) { final int[]v = cls.startsWith(\"Is\") ? MAP.get(cls.substring(2)) : null; if(v == null)return \"\\\\\" + incl + \"{\" + cls + \"}\"; final TokenBuilder tb = new TokenBuilder().add('['); if(incl == 'P')tb.add(\"!\"); for(int i = 0; i < v.length; ) { tb.add(v[i ++ ]); tb.add('-'); tb.add(v[i ++ ]); } return tb.add(']').toString(); } ",
        "test_tgt": "@Test public final void replace()throws IOException { session.execute(\"create db \" + DB); check(\"0\", session.query(\"count(\" + _DB_OPEN.args(DB) + ')').execute()); session.replace(DB, new ArrayInput(\"<X/>\")); check(\"1\", session.query(\"count(\" + _DB_OPEN.args(DB) + ')').execute()); session.replace(DB + '2', new ArrayInput(\"<X/>\")); check(\"2\", session.query(\"count(\" + _DB_OPEN.args(DB) + ')').execute()); session.replace(DB + '2', new ArrayInput(\"<X/>\")); check(\"2\", session.query(\"count(\" + _DB_OPEN.args(DB) + ')').execute()); } "
    },
    {
        "test_src": "@Test public void setImage() { ImageFloat32 image = new ImageFloat32(640, 480); GImageMiscOps.fillUniform(image, rand, 0, 200); UnrollSiftScaleSpaceGradient alg = new UnrollSiftScaleSpaceGradient(new SiftScaleSpace( - 1, 3, 3, 2)); alg.setImage(image); SiftScaleSpace ss = new SiftScaleSpace( - 1, 3, 3, 2); ss.initialize(image); ImageFloat32 derivX = new ImageFloat32(640, 480); ImageFloat32 derivY = new ImageFloat32(640, 480); int total = 0; do { for(int i = 0; i < ss.getNumScales(); i ++ , total ++ ) { ImageFloat32 scaleImage = ss.getImageScale(i); derivX.reshape(scaleImage.width, scaleImage.height); derivY.reshape(scaleImage.width, scaleImage.height); GImageDerivativeOps.gradient(DerivativeType.THREE, scaleImage, derivX, derivY, BorderType.EXTENDED); UnrollSiftScaleSpaceGradient.ImageScale found = alg.usedScales.get(total); BoofTesting.assertEquals(derivX, found.derivX, 1e-4); BoofTesting.assertEquals(derivY, found.derivY, 1e-4); assertEquals(ss.computeSigmaScale(i), found.sigma, 1e-4); assertEquals(image.width / (double)scaleImage.width, found.imageToInput, 1e-4); } } while(ss.computeNextOctave()); } ",
        "focal_tgt": "public void setImage(GrayF32 image) { scaleSpace.initialize(image); usedScales.clear(); do { for(int i = 0; i < scaleSpace.getNumScales(); i ++ ) { GrayF32 scaleImage = scaleSpace.getImageScale(i); double sigma = scaleSpace.computeSigmaScale(i); double pixelCurrentToInput = scaleSpace.pixelScaleCurrentToInput(); ImageScale scale = allScales.get(usedScales.size()); scale.derivX.reshape(scaleImage.width, scaleImage.height); scale.derivY.reshape(scaleImage.width, scaleImage.height); gradient.process(scaleImage, scale.derivX, scale.derivY); scale.imageToInput = pixelCurrentToInput; scale.sigma = sigma; usedScales.add(scale); } } while(scaleSpace.computeNextOctave()); } ",
        "focal_src": "public void setImage(ImageFloat32 image) { scaleSpace.initialize(image); usedScales.clear(); do { for(int i = 0; i < scaleSpace.getNumScales(); i ++ ) { ImageFloat32 scaleImage = scaleSpace.getImageScale(i); double sigma = scaleSpace.computeSigmaScale(i); double pixelCurrentToInput = scaleSpace.pixelScaleCurrentToInput(); ImageScale scale = allScales.get(usedScales.size()); scale.derivX.reshape(scaleImage.width, scaleImage.height); scale.derivY.reshape(scaleImage.width, scaleImage.height); gradient.process(scaleImage, scale.derivX, scale.derivY); scale.imageToInput = pixelCurrentToInput; scale.sigma = sigma; usedScales.add(scale); } } while(scaleSpace.computeNextOctave()); } ",
        "test_tgt": "@Test public void setImage() { GrayF32 image = new GrayF32(640, 480); GImageMiscOps.fillUniform(image, rand, 0, 200); UnrollSiftScaleSpaceGradient alg = new UnrollSiftScaleSpaceGradient(new SiftScaleSpace( - 1, 3, 3, 2)); alg.setImage(image); SiftScaleSpace ss = new SiftScaleSpace( - 1, 3, 3, 2); ss.initialize(image); GrayF32 derivX = new GrayF32(640, 480); GrayF32 derivY = new GrayF32(640, 480); int total = 0; do { for(int i = 0; i < ss.getNumScales(); i ++ , total ++ ) { GrayF32 scaleImage = ss.getImageScale(i); derivX.reshape(scaleImage.width, scaleImage.height); derivY.reshape(scaleImage.width, scaleImage.height); GImageDerivativeOps.gradient(DerivativeType.THREE, scaleImage, derivX, derivY, BorderType.EXTENDED); UnrollSiftScaleSpaceGradient.ImageScale found = alg.usedScales.get(total); BoofTesting.assertEquals(derivX, found.derivX, 1e-4); BoofTesting.assertEquals(derivY, found.derivY, 1e-4); assertEquals(ss.computeSigmaScale(i), found.sigma, 1e-4); assertEquals(image.width / (double)scaleImage.width, found.imageToInput, 1e-4); } } while(ss.computeNextOctave()); } "
    },
    {
        "test_src": "@Test public void testGetLicenseCollection() { assertThat(\"testGetLicenseCollection 0\", c.getLicenseCollection(), notNullValue()); assertThat(\"testGetLicenseCollection 1\", c.getLicenseCollection(), equalTo(\"\")); } ",
        "focal_tgt": "public String getLicenseCollection() { return getCollectionService().getMetadata(this, \"license\"); } ",
        "focal_src": "public String getLicenseCollection() { return getMetadata(\"license\"); } ",
        "test_tgt": "@Test public void testGetLicenseCollection() { assertThat(\"testGetLicenseCollection 0\", collection.getLicenseCollection(), notNullValue()); assertThat(\"testGetLicenseCollection 1\", collection.getLicenseCollection(), equalTo(\"\")); } "
    },
    {
        "test_src": "@Test public void formatPermissionTest() { Assert.assertEquals(\"-rw-rw-rw-\", FormatUtils.formatPermission((short)0666, false)); Assert.assertEquals(\"drw-rw-rw-\", FormatUtils.formatPermission((short)0666, true)); Assert.assertEquals(\"-rwxrwxrwx\", FormatUtils.formatPermission((short)0777, false)); Assert.assertEquals(\"drwxrwxrwx\", FormatUtils.formatPermission((short)0777, true)); Assert.assertEquals(\"-r--r--r--\", FormatUtils.formatPermission((short)0444, false)); Assert.assertEquals(\"dr--r--r--\", FormatUtils.formatPermission((short)0444, true)); Assert.assertEquals(\"-r-xr-xr-x\", FormatUtils.formatPermission((short)0555, false)); Assert.assertEquals(\"dr-xr-xr-x\", FormatUtils.formatPermission((short)0555, true)); Assert.assertEquals(\"-rwxr-xr--\", FormatUtils.formatPermission((short)0754, false)); Assert.assertEquals(\"drwxr-xr--\", FormatUtils.formatPermission((short)0754, true)); } ",
        "focal_tgt": "public static String formatMode(short mode, boolean directory) { StringBuffer str = new StringBuffer(); if(directory) { str.append(\"d\"); } else { str.append(\"-\"); } str.append(new Mode(mode).toString()); return str.toString(); } ",
        "focal_src": "public static String formatPermission(short permission, boolean isDirectory) { StringBuffer permissionStr = new StringBuffer(); if(isDirectory) { permissionStr.append(\"d\"); } else { permissionStr.append(\"-\"); } permissionStr.append(new Mode(permission).toString()); return permissionStr.toString(); } ",
        "test_tgt": "@Test public void formatPermissionTest() { Assert.assertEquals(\"-rw-rw-rw-\", FormatUtils.formatMode((short)0666, false)); Assert.assertEquals(\"drw-rw-rw-\", FormatUtils.formatMode((short)0666, true)); Assert.assertEquals(\"-rwxrwxrwx\", FormatUtils.formatMode((short)0777, false)); Assert.assertEquals(\"drwxrwxrwx\", FormatUtils.formatMode((short)0777, true)); Assert.assertEquals(\"-r--r--r--\", FormatUtils.formatMode((short)0444, false)); Assert.assertEquals(\"dr--r--r--\", FormatUtils.formatMode((short)0444, true)); Assert.assertEquals(\"-r-xr-xr-x\", FormatUtils.formatMode((short)0555, false)); Assert.assertEquals(\"dr-xr-xr-x\", FormatUtils.formatMode((short)0555, true)); Assert.assertEquals(\"-rwxr-xr--\", FormatUtils.formatMode((short)0754, false)); Assert.assertEquals(\"drwxr-xr--\", FormatUtils.formatMode((short)0754, true)); } "
    },
    {
        "test_src": "@Test public void testInitializeUnchecked()throws ConcurrentException { @SuppressWarnings(\"unchecked\")ConcurrentInitializer < Object > init = EasyMock.createMock(ConcurrentInitializer.class); final Object result = new Object(); EasyMock.expect(init.get()).andReturn(result); EasyMock.replay(init); assertSame(\"Wrong result object\", result, ConcurrentUtils.initializeUnchecked(init)); EasyMock.verify(init); } ",
        "focal_tgt": "public static < T > T initializeUnchecked(final ConcurrentInitializer < T > initializer) { try { return initialize(initializer); } catch(final ConcurrentException cex) { throw new ConcurrentRuntimeException(cex.getCause()); } } ",
        "focal_src": "public static < T > T initializeUnchecked(final ConcurrentInitializer < T > initializer) { try { return initialize(initializer); } catch(ConcurrentException cex) { throw new ConcurrentRuntimeException(cex.getCause()); } } ",
        "test_tgt": "@Test public void testInitializeUnchecked()throws ConcurrentException { @SuppressWarnings(\"unchecked\")final ConcurrentInitializer < Object > init = EasyMock.createMock(ConcurrentInitializer.class); final Object result = new Object(); EasyMock.expect(init.get()).andReturn(result); EasyMock.replay(init); assertSame(\"Wrong result object\", result, ConcurrentUtils.initializeUnchecked(init)); EasyMock.verify(init); } "
    },
    {
        "test_src": "@Test public void testSynthesize() { File audio = new File(\"src/test/resources/sample1.wav\"); if(audio == null || ! audio.exists() || ! audio.isFile())throw new IllegalArgumentException(\"audio is not a valid audio file\"); InputStreamEntity reqEntity = null; try { reqEntity = new InputStreamEntity(new FileInputStream(audio), - 1); List < Parameter > parameters = new ArrayList < Parameter > (); parameters.add(new Parameter(\"text\", text)); parameters.add(new Parameter(\"voice\", Voice.EN_LISA.getName())); parameters.add(new Parameter(\"accept\", MediaType.AUDIO_WAV)); mockServer.when(request().withQueryStringParameters(parameters).withPath(SYNTHESIZE_PATH)).respond(response().withHeaders(new Header(HttpHeaders.Names.CONTENT_TYPE, MediaType.AUDIO_WAV)).withBody(IOUtils.toString(reqEntity.getContent()))); InputStream in = service.synthesize(text, Voice.EN_LISA, MediaType.AUDIO_WAV); Assert.assertNotNull(in); writeInputStreamToOutputStream(in, new FileOutputStream(\"target/output.wav\")); } catch(FileNotFoundException e) { Assert.fail(e.getMessage()); } catch(IOException e) { Assert.fail(e.getMessage()); } } ",
        "focal_tgt": "public InputStream synthesize(final String text, final Voice voice, final String format) { if(text == null)throw new IllegalArgumentException(\"text cannot be null\"); if(voice == null)throw new IllegalArgumentException(\"voice cannot be null\"); final RequestBuilder request = RequestBuilder.get(\"/v1/synthesize\"); request.withQuery(\"text\", text); request.withQuery(\"voice\", voice.getName()); if(format != null && ! format.startsWith(\"audio/\"))throw new IllegalArgumentException(\"format needs to be an audio mime type, for example: audio/wav or audio/ogg; codecs=opus\"); request.withQuery(\"accept\", format != null ? format : HttpMediaType.AUDIO_WAV); final Response response = execute(request.build()); return ResponseUtil.getInputStream(response); } ",
        "focal_src": "public InputStream synthesize(final String text, final Voice voice, final String format) { if(text == null)throw new IllegalArgumentException(\"text can not be null\"); if(voice == null)throw new IllegalArgumentException(\"voice can not be null\"); Request request = Request.Get(\"/v1/synthesize\"); request.withQuery(\"text\", text); request.withQuery(\"voice\", voice.getName()); if(format != null && ! format.startsWith(\"audio/\"))throw new IllegalArgumentException(\"format needs to be an audio mime type, for example: audio/wav or audio/ogg; codecs=opus\"); request.withQuery(\"accept\", format != null ? format : MediaType.AUDIO_WAV); try { HttpResponse response = execute(request.build()); InputStream is = ResponseUtil.getInputStream(response); return is; } catch(IOException e) { throw new RuntimeException(e); } } ",
        "test_tgt": "@Test public void testSynthesize() { final File audio = new File(\"src/test/resources/sample1.wav\"); if(audio == null || ! audio.exists() || ! audio.isFile())throw new IllegalArgumentException(\"audio is not a valid audio file\"); try { final List < Parameter > parameters = new ArrayList < Parameter > (); parameters.add(new Parameter(\"text\", text)); parameters.add(new Parameter(\"voice\", Voice.EN_LISA.getName())); parameters.add(new Parameter(\"accept\", HttpMediaType.AUDIO_WAV)); mockServer.when(request().withQueryStringParameters(parameters).withPath(SYNTHESIZE_PATH)).respond(response().withHeaders(new Header(HttpHeaders.Names.CONTENT_TYPE, HttpMediaType.AUDIO_WAV)).withBody(Files.toByteArray(audio))); final InputStream in = service.synthesize(text, Voice.EN_LISA, HttpMediaType.AUDIO_WAV); Assert.assertNotNull(in); writeInputStreamToOutputStream(in, new FileOutputStream(\"target/output.wav\")); } catch(final FileNotFoundException e) { Assert.fail(e.getMessage()); } catch(final IOException e) { Assert.fail(e.getMessage()); } } "
    },
    {
        "test_src": "@Test public void transform() { final Function func = _XSLT_TRANSFORM; final String doc = \" <a/>\"; String style = wrap(\"<xsl:template match='/'><X/></xsl:template>\"); query(func.args(doc, ' ' + style), \"<X/>\"); query(func.args(doc, style), \"<X/>\"); style = wrap(\"<xsl:param name='t'/><xsl:template match='/'>\" + \"<X><xsl:value-of select='$t'/></X></xsl:template>\"); query(func.args(doc, ' ' + style, \" map { 't': '1' }\"), \"<X>1</X>\"); query(func.args(doc, ' ' + style, \" map { 't' : text { '1' } }\"), \"<X>1</X>\"); } ",
        "focal_tgt": "final byte[]transform(final QueryContext qc)throws QueryException { checkCreate(qc); final IO in = read(0, qc), xsl = read(1, qc); final Options opts = toOptions(2, new Options(), qc); final XsltOptions xopts = toOptions(3, new XsltOptions(), qc); final PrintStream tmp = System.err; final ArrayOutput ao = new ArrayOutput(); try { System.setErr(new PrintStream(ao)); return transform(in, xsl, opts.free(), xopts, qc); } catch(final TransformerException ex) { Util.debug(ex); throw XSLT_ERROR_X.get(info, trim(utf8(ao.finish(), Prop.ENCODING))); } finally { System.setErr(tmp); } } ",
        "focal_src": "final byte[]transform(final QueryContext qc)throws QueryException { checkCreate(qc); final IO in = read(0, qc), xsl = read(1, qc); final Options opts = toOptions(2, new Options(), qc); final XsltOptions xopts = toOptions(3, new XsltOptions(), qc); final PrintStream tmp = System.err; final ArrayOutput ao = new ArrayOutput(); try { System.setErr(new PrintStream(ao)); return transform(in, xsl, opts.free(), xopts); } catch(final TransformerException ex) { Util.debug(ex); throw XSLT_ERROR_X.get(info, trim(utf8(ao.finish(), Prop.ENCODING))); } finally { System.setErr(tmp); } } ",
        "test_tgt": "@Test public void transform() { final Function func = _XSLT_TRANSFORM; final String doc = \" <a/>\"; String style = wrap(\"<xsl:template match='/'><X/></xsl:template>\"); query(func.args(doc, ' ' + style), \"<X/>\"); query(func.args(doc, style), \"<X/>\"); style = wrap(\"<xsl:param name='t'/><xsl:template match='/'>\" + \"<X><xsl:value-of select='$t'/></X></xsl:template>\"); query(func.args(doc, ' ' + style, \" map { 't': '1' }\"), \"<X>1</X>\"); query(func.args(doc, ' ' + style, \" map { 't' : text { '1' } }\"), \"<X>1</X>\"); final String dir = \"src/test/resources/catalog/\"; query(\"declare option db:catfile '\" + dir + \"catalog.xml';\" + func.args(\" <dummy/>\", dir + \"document.xsl\"), \"<x>X</x>\"); query(\"declare option db:catfile '\" + dir + \"catalog.xml';\" + func.args(\" <dummy/>\", \" doc('\" + dir + \"document.xsl')\"), \"<x>X</x>\"); query(\"(# db:catfile \" + dir + \"catalog.xml #) { \" + func.args(\" <dummy/>\", dir + \"document.xsl\") + \" }\", \"<x>X</x>\"); } "
    },
    {
        "test_src": "@Test public void testPromote_shouldPromoteKey()throws Exception { int primaryKeyId = 42; int newPrimaryKeyId = 43; KeysetHandle handle = KeysetHandle.fromKeyset(TestUtil.createKeyset(createEnabledKey(primaryKeyId), createEnabledKey(newPrimaryKeyId))); Keyset keyset = KeysetManager.withKeysetHandle(handle).promote(newPrimaryKeyId).getKeysetHandle().getKeyset(); assertThat(keyset.getKeyCount()).isEqualTo(2); assertThat(keyset.getPrimaryKeyId()).isEqualTo(newPrimaryKeyId); } ",
        "focal_tgt": "@GuardedBy(\"this\")@Deprecated public synchronized KeysetManager promote(int keyId)throws GeneralSecurityException { return setPrimary(keyId); } ",
        "focal_src": "@GuardedBy(\"this\")public synchronized KeysetManager promote(int keyId)throws GeneralSecurityException { for(int i = 0; i < keysetBuilder.getKeyCount(); i ++ ) { Keyset.Key key = keysetBuilder.getKey(i); if(key.getKeyId() == keyId) { if( ! key.getStatus().equals(KeyStatusType.ENABLED)) { throw new GeneralSecurityException(\"cannot promote key because it's not enabled: \" + keyId); } keysetBuilder.setPrimaryKeyId(keyId); return this; } } throw new GeneralSecurityException(\"key not found: \" + keyId); } ",
        "test_tgt": "@Test public void testPromote_shouldPromote()throws Exception { int primaryKeyId = 42; int newPrimaryKeyId = 43; KeysetHandle handle = KeysetHandle.fromKeyset(TestUtil.createKeyset(createEnabledKey(primaryKeyId), createEnabledKey(newPrimaryKeyId))); Keyset keyset = KeysetManager.withKeysetHandle(handle).promote(newPrimaryKeyId).getKeysetHandle().getKeyset(); assertThat(keyset.getKeyCount()).isEqualTo(2); assertThat(keyset.getPrimaryKeyId()).isEqualTo(newPrimaryKeyId); } "
    },
    {
        "test_src": "@Test public void testGetDocument() { String html = \"<html><body><p/></body></html>\"; try { Document doc = Helper.getDocument(html); assertNotNull(doc); } catch(SAXException e) { fail(e.getMessage()); } catch(IOException e) { fail(e.getMessage()); } } ",
        "focal_tgt": "public Document getDocument()throws SAXException, IOException { return DomUtils.getDocument(this.dom); } ",
        "focal_src": "public Document getDocument()throws SAXException, IOException { return Helper.getDocument(this.dom); } ",
        "test_tgt": "@Test public void testGetDocument() { String html = \"<html><body><p/></body></html>\"; try { Document doc = DomUtils.getDocument(html); assertNotNull(doc); } catch(SAXException e) { fail(e.getMessage()); } catch(IOException e) { fail(e.getMessage()); } } "
    },
    {
        "test_src": "@Test public void getConcreteMembers_isCorrect()throws Exception { Element genericElement = Utils.getElementFromClass(DummyGenericClass.class); assertNotNull(genericElement); Map < Element, TypeMirror > genericMembers = new HashMap < > (); for(Element element : genericElement.getEnclosedElements()) { if(element instanceof VariableElement) { genericMembers.put(element, element.asType()); } } TypeMirror concreteType = TypeUtils.getInheritedType(Utils.getElementFromClass(DummyInheritedClass.class)); assertNotNull(concreteType); TypeMirror genericType = Utils.getGenericVersionOfClass(DummyGenericClass.class); assertNotNull(genericType); LinkedHashMap < Element, TypeMirror > members = TypeUtils.getConcreteMembers(concreteType, types.asElement(genericType), genericMembers); TypeMirror stringType = Utils.getTypeMirrorFromClass(String.class); assertNotNull(stringType); for(Entry < Element, TypeMirror > entry : members.entrySet()) { if(entry.getKey().getSimpleName().contentEquals(\"testObject\")) { assertTrue(entry.getValue().toString().equals(stringType.toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testList\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType((TypeElement)Utils.getElementFromClass(ArrayList.class), stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testMap\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType((TypeElement)Utils.getElementFromClass(HashMap.class), stringType, stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testSet\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType((TypeElement)Utils.getElementFromClass(HashSet.class), stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testArrayMap\")) { TypeMirror listString = types.getDeclaredType((TypeElement)Utils.getElementFromClass(List.class), stringType); assertTrue(entry.getValue().toString().equals(types.getDeclaredType((TypeElement)Utils.getElementFromClass(HashMap.class), stringType, listString).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testListMap\")) { TypeMirror mapStringString = types.getDeclaredType((TypeElement)Utils.getElementFromClass(Map.class), stringType, stringType); assertTrue(entry.getValue().toString().equals(types.getDeclaredType((TypeElement)Utils.getElementFromClass(ArrayList.class), mapStringString).toString())); } } } ",
        "focal_tgt": "@NotNull public static LinkedHashMap < VariableElement, TypeMirror > getConcreteMembers(@NotNull TypeMirror concreteInherited, @NotNull TypeElement genericInherited, @NotNull Map < VariableElement, TypeMirror > members) { DebugLog.log(TAG, \"Inherited concrete type: \" + concreteInherited.toString()); DebugLog.log(TAG, \"Inherited generic type: \" + genericInherited.asType().toString()); List < ? extends TypeMirror > concreteTypes = getParameterizedTypes(concreteInherited); List < ? extends TypeMirror > inheritedTypes = getParameterizedTypes(genericInherited); LinkedHashMap < VariableElement, TypeMirror > map = new LinkedHashMap < > (); for(Entry < VariableElement, TypeMirror > member : members.entrySet()) { DebugLog.log(TAG, \"\\t\\tEvaluating member - \" + member.getValue().toString()); if(isConcreteType(member.getValue())) { DebugLog.log(TAG, \"\\t\\t\\tConcrete Type: \" + member.getValue().toString()); map.put(member.getKey(), member.getValue()); } else { if(isParameterizedType(member.getValue())) { TypeMirror resolvedType = resolveTypeVars(member.getValue(), inheritedTypes, concreteTypes); map.put(member.getKey(), resolvedType); DebugLog.log(TAG, \"\\t\\t\\tGeneric Parameterized Type - \" + member.getValue().toString() + \" resolved to - \" + resolvedType.toString()); } else { int index = inheritedTypes.indexOf(member.getKey().asType()); TypeMirror concreteType = concreteTypes.get(index); map.put(member.getKey(), concreteType); DebugLog.log(TAG, \"\\t\\t\\tGeneric Type - \" + member.getValue().toString() + \" resolved to - \" + concreteType.toString()); } } } return map; } ",
        "focal_src": "@NotNull public static LinkedHashMap < Element, TypeMirror > getConcreteMembers(@NotNull TypeMirror concreteInherited, @NotNull Element genericInherited, @NotNull Map < Element, TypeMirror > members) { DebugLog.log(TAG, \"Inherited concrete type: \" + concreteInherited.toString()); DebugLog.log(TAG, \"Inherited generic type: \" + genericInherited.asType().toString()); List < ? extends TypeMirror > concreteTypes = getParameterizedTypes(concreteInherited); List < ? extends TypeMirror > inheritedTypes = getParameterizedTypes(genericInherited); LinkedHashMap < Element, TypeMirror > map = new LinkedHashMap < > (); for(Entry < Element, TypeMirror > member : members.entrySet()) { DebugLog.log(TAG, \"\\t\\tEvaluating member - \" + member.getValue().toString()); if(isConcreteType(member.getValue())) { DebugLog.log(TAG, \"\\t\\t\\tConcrete Type: \" + member.getValue().toString()); map.put(member.getKey(), member.getValue()); } else { if(isParameterizedType(member.getValue())) { TypeMirror resolvedType = resolveTypeVars(member.getValue(), inheritedTypes, concreteTypes); map.put(member.getKey(), resolvedType); DebugLog.log(TAG, \"\\t\\t\\tGeneric Parameterized Type - \" + member.getValue().toString() + \" resolved to - \" + resolvedType.toString()); } else { int index = inheritedTypes.indexOf(member.getKey().asType()); TypeMirror concreteType = concreteTypes.get(index); map.put(member.getKey(), concreteType); DebugLog.log(TAG, \"\\t\\t\\tGeneric Type - \" + member.getValue().toString() + \" resolved to - \" + concreteType.toString()); } } } return map; } ",
        "test_tgt": "@Test public void getConcreteMembers_isCorrect()throws Exception { Element genericElement = Utils.getElementFromClass(DummyGenericClass.class); assertNotNull(genericElement); Map < Element, TypeMirror > genericMembers = new HashMap < > (); for(Element element : genericElement.getEnclosedElements()) { if(element instanceof VariableElement) { genericMembers.put(element, element.asType()); } } TypeMirror concreteType = TypeUtils.getInheritedType(Utils.getElementFromClass(DummyInheritedClass.class)); assertNotNull(concreteType); TypeMirror genericType = Utils.getGenericVersionOfClass(DummyGenericClass.class); assertNotNull(genericType); LinkedHashMap < Element, TypeMirror > members = TypeUtils.getConcreteMembers(concreteType, (TypeElement)types.asElement(genericType), genericMembers); TypeMirror stringType = Utils.getTypeMirrorFromClass(String.class); assertNotNull(stringType); for(Entry < Element, TypeMirror > entry : members.entrySet()) { if(entry.getKey().getSimpleName().contentEquals(\"testObject\")) { assertTrue(entry.getValue().toString().equals(stringType.toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testList\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType(Utils.getElementFromClass(ArrayList.class), stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testMap\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType(Utils.getElementFromClass(HashMap.class), stringType, stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testSet\")) { assertTrue(entry.getValue().toString().equals(types.getDeclaredType(Utils.getElementFromClass(HashSet.class), stringType).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testArrayMap\")) { TypeMirror listString = types.getDeclaredType(Utils.getElementFromClass(List.class), stringType); assertTrue(entry.getValue().toString().equals(types.getDeclaredType(Utils.getElementFromClass(HashMap.class), stringType, listString).toString())); } else if(entry.getKey().getSimpleName().contentEquals(\"testListMap\")) { TypeMirror mapStringString = types.getDeclaredType(Utils.getElementFromClass(Map.class), stringType, stringType); assertTrue(entry.getValue().toString().equals(types.getDeclaredType(Utils.getElementFromClass(ArrayList.class), mapStringString).toString())); } } } "
    },
    {
        "test_src": "@Test public void changeReplicationFactor_TransientErrorInVerify(TestContext context) { MockAdminClient adminClient = new MockAdminClient(); Vertx vertx = Vertx.vertx(); Topic topic = new Topic.Builder(\"changeReplicationFactor\", 2, (short)2, emptyMap()).build(); String[]partitions = new String[] { \"changeReplicationFactor-0\", \"changeReplicationFactor-1\" }; Subclass sub = new Subclass(adminClient, vertx, config, asList(Subclass.generate(\"{\\\"version\\\":1,\\\"partitions\\\":[{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":0,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]},{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":1,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]}]}\", \"{\\\"version\\\":1,\\\"partitions\\\":[{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":0,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]},{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":1,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]}]}\"), Subclass.executeStarted(), Subclass.verifyInProgress(partitions), Subclass.fail(\"Bang!\"), Subclass.verifySuccess(partitions))); Async async = context.async(); sub.changeReplicationFactor(topic, ar -> { context.assertTrue(ar.succeeded()); async.complete(); }); } ",
        "focal_tgt": "Future < Void > changeReplicationFactor(Topic topic); ",
        "focal_src": "void changeReplicationFactor(Topic topic, Handler < AsyncResult < Void > > handler); ",
        "test_tgt": "@Test public void changeReplicationFactor_TransientErrorInVerify(TestContext context) { MockAdminClient adminClient = new MockAdminClient(); Vertx vertx = Vertx.vertx(); Topic topic = new Topic.Builder(\"changeReplicationFactor\", 2, (short)2, emptyMap()).build(); String[]partitions = new String[] { \"changeReplicationFactor-0\", \"changeReplicationFactor-1\" }; Subclass sub = new Subclass(adminClient, vertx, config, asList(Subclass.generate(\"{\\\"version\\\":1,\\\"partitions\\\":[{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":0,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]},{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":1,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]}]}\", \"{\\\"version\\\":1,\\\"partitions\\\":[{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":0,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]},{\\\"topic\\\":\\\"test-topic\\\",\\\"partition\\\":1,\\\"replicas\\\":[0],\\\"log_dirs\\\":[\\\"any\\\"]}]}\"), Subclass.executeStarted(), Subclass.verifyInProgress(partitions), Subclass.fail(\"Bang!\"), Subclass.verifySuccess(partitions))); Async async = context.async(); sub.changeReplicationFactor(topic).setHandler(ar -> { context.assertTrue(ar.succeeded()); async.complete(); }); } "
    },
    {
        "test_src": "@Test public void testRepairSurvivors() { InitiatorMailbox mailbox = mock(InitiatorMailbox.class); ZooKeeper zk = mock(ZooKeeper.class); ArrayList < Long > masters = new ArrayList < Long > (); masters.add(1L); masters.add(2L); masters.add(3L); MpPromoteAlgo algo = new MpPromoteAlgo(masters, zk, - 1, mailbox, VoltZK.iv2masters, \"Test\"); long requestId = algo.getRequestId(); algo.prepareForFaultRecovery(); verify(mailbox, times(1)).send(any(long[].class), any(Iv2RepairLogRequestMessage.class)); algo.deliver(makeRealAckResponse(requestId, 1L, 0, 2, 1000L)); algo.deliver(makeRealFragResponse(requestId, 1L, 1, 2, 1000L)); algo.deliver(makeRealAckResponse(requestId, 2L, 0, 1, Long.MAX_VALUE)); algo.deliver(makeRealAckResponse(requestId, 3L, 0, 3, 1000L)); algo.deliver(makeRealFragResponse(requestId, 3L, 1, 3, 1000L)); algo.deliver(makeRealCompleteResponse(requestId, 3L, 2, 3, 1000L)); List < Long > needsRepair = new ArrayList < Long > (); needsRepair.add(1L); verify(mailbox, times(1)).repairReplicasWith(eq(needsRepair), any(Iv2RepairLogResponseMessage.class)); } ",
        "focal_tgt": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"skipping repair message creation for cancelled Term.\"); return; } int queued = 0; tmLog.info(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { List < Long > needsRepair = new ArrayList < Long > (5); for(Entry < Long, ReplicaRepairStruct > entry : m_replicaRepairStructs.entrySet()) { if(entry.getValue().needs(li.getHandle())) { ++ queued; tmLog.debug(m_whoami + \"repairing \" + entry.getKey() + \". Max seen \" + entry.getValue().m_maxHandleCompleted + \". Repairing with \" + li.getHandle()); needsRepair.add(entry.getKey()); } } if( ! needsRepair.isEmpty()) { m_mailbox.repairReplicasWith(needsRepair, createRepairMessage(li)); } } tmLog.info(m_whoami + \"finished queuing \" + queued + \" replica repair messages.\"); m_promotionResult.done(m_maxSeenTxnId); } ",
        "focal_src": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"skipping repair message creation for cancelled Term.\"); return; } int queued = 0; tmLog.info(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { List < Long > needsRepair = new ArrayList < Long > (5); for(Entry < Long, ReplicaRepairStruct > entry : m_replicaRepairStructs.entrySet()) { if(entry.getValue().needs(li.getHandle())) { ++ queued; tmLog.debug(m_whoami + \"repairing \" + entry.getKey() + \". Max seen \" + entry.getValue().m_maxHandleCompleted + \". Repairing with \" + li.getHandle()); needsRepair.add(entry.getKey()); } } if( ! needsRepair.isEmpty()) { m_mailbox.repairReplicasWith(needsRepair, createRepairMessage(li)); } } tmLog.info(m_whoami + \"finished queuing \" + queued + \" replica repair messages.\"); Thread declareLeaderThread = new Thread() { @Override public void run() { declareReadyAsLeader(); } }; declareLeaderThread.start(); } ",
        "test_tgt": "@Test public void testRepairSurvivors() { InitiatorMailbox mailbox = mock(InitiatorMailbox.class); ArrayList < Long > masters = new ArrayList < Long > (); masters.add(1L); masters.add(2L); masters.add(3L); MpPromoteAlgo algo = new MpPromoteAlgo(masters, mailbox, \"Test\"); long requestId = algo.getRequestId(); algo.prepareForFaultRecovery(); verify(mailbox, times(1)).send(any(long[].class), any(Iv2RepairLogRequestMessage.class)); algo.deliver(makeRealAckResponse(requestId, 1L, 0, 2, 1000L)); algo.deliver(makeRealFragResponse(requestId, 1L, 1, 2, 1000L)); algo.deliver(makeRealAckResponse(requestId, 2L, 0, 1, Long.MAX_VALUE)); algo.deliver(makeRealAckResponse(requestId, 3L, 0, 3, 1000L)); algo.deliver(makeRealFragResponse(requestId, 3L, 1, 3, 1000L)); algo.deliver(makeRealCompleteResponse(requestId, 3L, 2, 3, 1000L)); List < Long > needsRepair = new ArrayList < Long > (); needsRepair.add(1L); verify(mailbox, times(1)).repairReplicasWith(eq(needsRepair), any(Iv2RepairLogResponseMessage.class)); } "
    },
    {
        "test_src": "@Test public void testSerialize() { TCP tcp = new TCP(); tcp.setSourcePort((short)0x50); tcp.setDestinationPort((short)0x60); tcp.setSequence(0x10); tcp.setAcknowledge(0x20); tcp.setDataOffset((byte)0x5); tcp.setFlags((short)0x2); tcp.setWindowSize((short)0x1000); tcp.setUrgentPointer((short)0x1); tcp.setParent(ipv4); assertArrayEquals(bytePacketTCP4, tcp.serialize()); tcp.resetChecksum(); tcp.setParent(ipv6); assertArrayEquals(bytePacketTCP6, tcp.serialize()); } ",
        "focal_tgt": "@Override public byte[]serialize() { int length; if(this.dataOffset == 0) { this.dataOffset = 5; } length = this.dataOffset << 2; byte[]payloadData = null; if(this.payload != null) { this.payload.setParent(this); payloadData = this.payload.serialize(); length += payloadData.length; } final byte[]data = new byte[length]; final ByteBuffer bb = ByteBuffer.wrap(data); bb.putShort((short)(this.sourcePort & 0xffff)); bb.putShort((short)(this.destinationPort & 0xffff)); bb.putInt(this.sequence); bb.putInt(this.acknowledge); bb.putShort((short)(this.flags | this.dataOffset << 12)); bb.putShort(this.windowSize); bb.putShort(this.checksum); bb.putShort(this.urgentPointer); if(this.dataOffset > 5) { int padding; bb.put(this.options); padding = (this.dataOffset << 2) - 20 - this.options.length; for(int i = 0; i < padding; i ++ ) { bb.put((byte)0); } } if(payloadData != null) { bb.put(payloadData); } if(this.parent != null && this.parent instanceof IPv4) { ((IPv4)this.parent).setProtocol(IPv4.PROTOCOL_TCP); } if(this.checksum == 0) { bb.rewind(); int accumulation = 0; if(this.parent != null) { if(this.parent instanceof IPv4) { final IPv4 ipv4 = (IPv4)this.parent; accumulation += (ipv4.getSourceAddress() > > 16 & 0xffff) + (ipv4.getSourceAddress() & 0xffff); accumulation += (ipv4.getDestinationAddress() > > 16 & 0xffff) + (ipv4.getDestinationAddress() & 0xffff); accumulation += ipv4.getProtocol() & 0xff; accumulation += length & 0xffff; } else if(this.parent instanceof IPv6) { final IPv6 ipv6 = (IPv6)this.parent; final int bbLength = Ip6Address.BYTE_LENGTH * 2 + 2 + 4; final ByteBuffer bbChecksum = ByteBuffer.allocate(bbLength); bbChecksum.put(ipv6.getSourceAddress()); bbChecksum.put(ipv6.getDestinationAddress()); bbChecksum.put((byte)0); bbChecksum.put(ipv6.getNextHeader()); bbChecksum.putInt(length); bbChecksum.rewind(); for(int i = 0; i < bbLength / 2; ++ i) { accumulation += 0xffff & bbChecksum.getShort(); } } } for(int i = 0; i < length / 2; ++ i) { accumulation += 0xffff & bb.getShort(); } if(length % 2 > 0) { accumulation += (bb.get() & 0xff) << 8; } accumulation = (accumulation > > 16 & 0xffff) + (accumulation & 0xffff); this.checksum = (short)( ~ accumulation & 0xffff); bb.putShort(16, this.checksum); } return data; } ",
        "focal_src": "@Override public byte[]serialize() { int length; if(this.dataOffset == 0) { this.dataOffset = 5; } length = this.dataOffset << 2; byte[]payloadData = null; if(this.payload != null) { this.payload.setParent(this); payloadData = this.payload.serialize(); length += payloadData.length; } final byte[]data = new byte[length]; final ByteBuffer bb = ByteBuffer.wrap(data); bb.putShort(this.sourcePort); bb.putShort(this.destinationPort); bb.putInt(this.sequence); bb.putInt(this.acknowledge); bb.putShort((short)(this.flags | this.dataOffset << 12)); bb.putShort(this.windowSize); bb.putShort(this.checksum); bb.putShort(this.urgentPointer); if(this.dataOffset > 5) { int padding; bb.put(this.options); padding = (this.dataOffset << 2) - 20 - this.options.length; for(int i = 0; i < padding; i ++ ) { bb.put((byte)0); } } if(payloadData != null) { bb.put(payloadData); } if(this.parent != null && this.parent instanceof IPv4) { ((IPv4)this.parent).setProtocol(IPv4.PROTOCOL_TCP); } if(this.checksum == 0) { bb.rewind(); int accumulation = 0; if(this.parent != null) { if(this.parent instanceof IPv4) { final IPv4 ipv4 = (IPv4)this.parent; accumulation += (ipv4.getSourceAddress() > > 16 & 0xffff) + (ipv4.getSourceAddress() & 0xffff); accumulation += (ipv4.getDestinationAddress() > > 16 & 0xffff) + (ipv4.getDestinationAddress() & 0xffff); accumulation += ipv4.getProtocol() & 0xff; accumulation += length & 0xffff; } else if(this.parent instanceof IPv6) { final IPv6 ipv6 = (IPv6)this.parent; final int bbLength = Ip6Address.BYTE_LENGTH * 2 + 2 + 4; final ByteBuffer bbChecksum = ByteBuffer.allocate(bbLength); bbChecksum.put(ipv6.getSourceAddress()); bbChecksum.put(ipv6.getDestinationAddress()); bbChecksum.put((byte)0); bbChecksum.put(ipv6.getNextHeader()); bbChecksum.putInt(length); bbChecksum.rewind(); for(int i = 0; i < bbLength / 2; ++ i) { accumulation += 0xffff & bbChecksum.getShort(); } } } for(int i = 0; i < length / 2; ++ i) { accumulation += 0xffff & bb.getShort(); } if(length % 2 > 0) { accumulation += (bb.get() & 0xff) << 8; } accumulation = (accumulation > > 16 & 0xffff) + (accumulation & 0xffff); this.checksum = (short)( ~ accumulation & 0xffff); bb.putShort(16, this.checksum); } return data; } ",
        "test_tgt": "@Test public void testSerialize() { TCP tcp = new TCP(); tcp.setSourcePort(0x50); tcp.setDestinationPort(0x60); tcp.setSequence(0x10); tcp.setAcknowledge(0x20); tcp.setDataOffset((byte)0x5); tcp.setFlags((short)0x2); tcp.setWindowSize((short)0x1000); tcp.setUrgentPointer((short)0x1); tcp.setParent(ipv4); assertArrayEquals(bytePacketTCP4, tcp.serialize()); tcp.resetChecksum(); tcp.setParent(ipv6); assertArrayEquals(bytePacketTCP6, tcp.serialize()); } "
    },
    {
        "test_src": "@Test public void optimizeEbv() { query(\"not(<a/>[b])\", \"true\"); query(\"empty(<a/>[b])\", \"true\"); query(\"exists(<a/>[b])\", \"false\"); query(\"not(<a/>[b = 'c'])\", \"true\"); query(\"empty(<a/>[b = 'c'])\", \"true\"); query(\"exists(<a/>[b = 'c'])\", \"false\"); check(\"empty(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"exists(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"boolean(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"not(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"if(<a>X</a>[text()]) then 1 else 2\", null, \"//@axis = 'child'\"); check(\"<a>X</a>[text()] and <a/>\", null, \"//@axis = 'child'\"); check(\"<a>X</a>[text()] or <a/>\", null, \"//Bln/@value = 'true'\"); check(\"<a>X</a>[text()] or <a/>[text()]\", null, \"//@axis = 'child'\"); check(\"for $a in <a>X</a> where $a[text()] return $a\", null, \"//@axis = 'child'\"); check(\"empty(<a>X</a>/.[text()])\", null, \"//@axis = 'child'\"); } ",
        "focal_tgt": "@SuppressWarnings(\"unused\")public Expr optimizeEbv(final CompileContext cc)throws QueryException { final SeqType st = seqType(); return st.type instanceof NodeType && st.oneOrMore() && ! has(Flag.UPD) && ! has(Flag.NDT) ? cc.replaceEbv(this, Bln.TRUE) : this; } ",
        "focal_src": "@SuppressWarnings(\"unused\")public Expr optimizeEbv(final CompileContext cc)throws QueryException { final SeqType st = seqType(); return st.type instanceof NodeType && st.oneOrMore() && ! has(Flag.UPD) && ! has(Flag.NDT) ? cc.replaceWith(this, Bln.TRUE) : this; } ",
        "test_tgt": "@Test public void optimizeEbv() { query(\"not(<a/>[b])\", \"true\"); query(\"empty(<a/>[b])\", \"true\"); query(\"exists(<a/>[b])\", \"false\"); query(\"not(<a/>[b = 'c'])\", \"true\"); query(\"empty(<a/>[b = 'c'])\", \"true\"); query(\"exists(<a/>[b = 'c'])\", \"false\"); query(\"let $n := <n/> where $n[<a><b/><b/></a>/*] return $n\", \"<n/>\"); check(\"empty(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"exists(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"boolean(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"not(<a>X</a>[text()])\", null, \"//@axis = 'child'\"); check(\"if(<a>X</a>[text()]) then 1 else 2\", null, \"//@axis = 'child'\"); check(\"<a>X</a>[text()] and <a/>\", null, \"//@axis = 'child'\"); check(\"<a>X</a>[text()] or <a/>\", null, \"//Bln/@value = 'true'\"); check(\"<a>X</a>[text()] or <a/>[text()]\", null, \"//@axis = 'child'\"); check(\"for $a in <a>X</a> where $a[text()] return $a\", null, \"//@axis = 'child'\"); check(\"empty(<a>X</a>/.[text()])\", null, \"//@axis = 'child'\"); } "
    },
    {
        "test_src": "@Test public void testGetItemId() { assertTrue(\"testGetItemId 0\", mv.getItemId() >= 0); } ",
        "focal_tgt": "public int getResourceId() { return resourceId; } ",
        "focal_src": "public int getItemId() { return itemId; } ",
        "test_tgt": "@Test public void testGetItemId() { assertTrue(\"testGetItemId 0\", mv.getResourceId() >= 0); } "
    },
    {
        "test_src": "@SuppressWarnings(\"unchecked\")@Test(expected = GenieServerException.class)public void testSubmitJob()throws GenieException, IOException { final Set < CommandStatus > enumStatuses = EnumSet.noneOf(CommandStatus.class); enumStatuses.add(CommandStatus.ACTIVE); final String app1 = UUID.randomUUID().toString(); final String app2 = UUID.randomUUID().toString(); final String app3 = UUID.randomUUID().toString(); final List < String > applications = Lists.newArrayList(app3, app1, app2); final String placeholder = UUID.randomUUID().toString(); Mockito.when(this.applicationService.getApplication(app3)).thenReturn(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app3).build()); Mockito.when(this.applicationService.getApplication(app1)).thenReturn(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app1).build()); Mockito.when(this.applicationService.getApplication(app2)).thenReturn(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app2).build()); final JobRequest jobRequest = new JobRequest.Builder(JOB_1_NAME, USER, VERSION, null, null, null).withId(JOB_1_ID).withApplications(applications).build(); final Cluster cluster = new Cluster.Builder(CLUSTER_NAME, USER, VERSION, ClusterStatus.UP).withId(CLUSTER_ID).build(); final List < Cluster > clusterList = new ArrayList < > (); clusterList.add(cluster); final Command command = new Command.Builder(COMMAND_NAME, USER, VERSION, CommandStatus.ACTIVE, \"foo\", 5000L).withId(COMMAND_ID).build(); final List < Command > commandList = new ArrayList < > (); commandList.add(command); Mockito.when(this.clusterService.chooseClusterForJobRequest(jobRequest)).thenReturn(clusterList); Mockito.when(this.clusterLoadBalancer.selectCluster(clusterList)).thenReturn(cluster); Mockito.when(this.clusterService.getCommandsForCluster(CLUSTER_ID, enumStatuses)).thenReturn(commandList); Mockito.doThrow(new IOException(\"something bad\")).when(this.task2).executeTask(Mockito.anyMap()); final ArgumentCaptor < String > jobId1 = ArgumentCaptor.forClass(String.class); final ArgumentCaptor < String > clusterId = ArgumentCaptor.forClass(String.class); final ArgumentCaptor < String > commandId = ArgumentCaptor.forClass(String.class); final ArgumentCaptor < List < String > > applicationIds = ArgumentCaptor.forClass((Class)List.class); this.jobSubmitterService.submitJob(jobRequest); Mockito.verify(this.jobPersistenceService).updateJobWithRuntimeEnvironment(jobId1.capture(), clusterId.capture(), commandId.capture(), applicationIds.capture()); Assert.assertThat(jobId1.getValue(), Matchers.is(JOB_1_ID)); Assert.assertThat(clusterId.getValue(), Matchers.is(CLUSTER_ID)); Assert.assertThat(commandId.getValue(), Matchers.is(COMMAND_ID)); Assert.assertThat(applicationIds.getValue().get(0), Matchers.is(app3)); Assert.assertThat(applicationIds.getValue().get(1), Matchers.is(app1)); Assert.assertThat(applicationIds.getValue().get(2), Matchers.is(app2)); } ",
        "focal_tgt": "void submitJob(@Valid@NotNull(message = \"No job provided. Unable to submit job for execution.\")final JobRequest jobRequest, @Valid@NotNull(message = \"No cluster provided. Unable to submit job for execution\")final Cluster cluster, @Valid@NotNull(message = \"No command provided. Unable to submit job for execution\")final Command command, @NotNull(message = \"No applications provided. Unable to submit job for execution\")final List < Application > applications, @Min(value = 1, message = \"Memory can't be less than 1 MB\")final int memory)throws GenieException; ",
        "focal_src": "void submitJob(@NotNull(message = \"No job provided. Unable to submit job for execution.\")@Valid final JobRequest jobRequest)throws GenieException; ",
        "test_tgt": "@SuppressWarnings(\"unchecked\")@Test(expected = GenieServerException.class)public void testSubmitJob()throws GenieException, IOException { final Set < CommandStatus > enumStatuses = EnumSet.noneOf(CommandStatus.class); enumStatuses.add(CommandStatus.ACTIVE); final String placeholder = UUID.randomUUID().toString(); final String app1 = UUID.randomUUID().toString(); final String app2 = UUID.randomUUID().toString(); final String app3 = UUID.randomUUID().toString(); final List < Application > applications = Lists.newArrayList(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app3).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app1).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app2).build()); final JobRequest jobRequest = new JobRequest.Builder(JOB_1_NAME, USER, VERSION, null, null, null).withId(JOB_1_ID).withApplications(Lists.newArrayList(app3, app1, app2)).build(); final Cluster cluster = new Cluster.Builder(CLUSTER_NAME, USER, VERSION, ClusterStatus.UP).withId(CLUSTER_ID).build(); final Command command = new Command.Builder(COMMAND_NAME, USER, VERSION, CommandStatus.ACTIVE, \"foo\", 5000L).withId(COMMAND_ID).build(); final int memory = 2438; Mockito.doThrow(new IOException(\"something bad\")).when(this.task2).executeTask(Mockito.anyMap()); this.jobSubmitterService.submitJob(jobRequest, cluster, command, applications, memory); } "
    },
    {
        "test_src": "@Test(expected = APIException.class)@Verifies(value = \"should fail if the visit has encounters associated to it\", method = \"purgeVisit(Visit)\")public void purgeVisit_shouldFailIfTheVisitHasEncountersAssociatedToIt()throws Exception { Visit visit = Context.getVisitService().getVisit(1); Encounter e = Context.getEncounterService().getEncounter(3); e.setVisit(visit); Context.getEncounterService().saveEncounter(e); Assert.assertTrue(Context.getEncounterService().getEncountersByVisit(visit).size() > 0); Context.getVisitService().purgeVisit(visit); } ",
        "focal_tgt": "@Override public void purgeVisit(Visit visit)throws APIException { if(visit.getVisitId() == null)return; if(Context.getEncounterService().getEncountersByVisit(visit, true).size() > 0)throw new APIException(Context.getMessageSourceService().getMessage(\"Visit.purge.inUse\", null, \"Cannot purge a visit that has encounters associated to it\", Context.getLocale())); dao.deleteVisit(visit); } ",
        "focal_src": "@Override public void purgeVisit(Visit visit)throws APIException { if(visit.getVisitId() == null)return; if(Context.getEncounterService().getEncountersByVisit(visit).size() > 0)throw new APIException(Context.getMessageSourceService().getMessage(\"Visit.purge.inUse\", null, \"Cannot purge a visit that has encounters associated to it\", Context.getLocale())); dao.deleteVisit(visit); } ",
        "test_tgt": "@Test(expected = APIException.class)@Verifies(value = \"should fail if the visit has encounters associated to it\", method = \"purgeVisit(Visit)\")public void purgeVisit_shouldFailIfTheVisitHasEncountersAssociatedToIt()throws Exception { Visit visit = Context.getVisitService().getVisit(1); Encounter e = Context.getEncounterService().getEncounter(3); e.setVisit(visit); Context.getEncounterService().saveEncounter(e); Assert.assertTrue(Context.getEncounterService().getEncountersByVisit(visit, false).size() > 0); Context.getVisitService().purgeVisit(visit); } "
    },
    {
        "test_src": "@Test public void testDivideInternally()throws StructureException, IOException { Structure s = StructureIO.getStructure(\"4e3e\"); SubunitCluster sc1 = new SubunitCluster(new Subunit(StructureTools.getRepresentativeAtomArray(s.getChainByIndex(0)), \"chain 0\", null, s)); boolean divided = sc1.divideInternally(0.8, 3.0, 20); assertTrue(divided); assertEquals(sc1.size(), 2); assertTrue(sc1.length() < 178); assertEquals(sc1.getAlignedAtomsSubunit(0).length, sc1.getAlignedAtomsSubunit(1).length); } ",
        "focal_tgt": "public boolean divideInternally(SubunitClustererParameters clusterParams)throws StructureException { CESymmParameters cesym_params = new CESymmParameters(); cesym_params.setMinCoreLength(clusterParams.getMinimumSequenceLength()); cesym_params.setGaps(false); CeSymmResult result = CeSymm.analyze(subunits.get(representative).getRepresentativeAtoms(), cesym_params); if( ! result.isSignificant())return false; double rmsd = result.getMultipleAlignment().getScore(MultipleAlignmentScorer.RMSD); if(rmsd > clusterParams.getRMSDThreshold())return false; double coverage = result.getMultipleAlignment().getCoverages().get(0) * result.getNumRepeats(); if(coverage < clusterParams.getStructureCoverageThreshold())return false; logger.info(\"SubunitCluster is internally symmetric with {} repeats, \" + \"{} RMSD and {} coverage\", result.getNumRepeats(), rmsd, coverage); List < List < Integer > > alignedRes = result.getMultipleAlignment().getBlock(0).getAlignRes(); List < List < Integer > > columns = new ArrayList < List < Integer > > (); for(int s = 0; s < alignedRes.size(); s ++ )columns.add(new ArrayList < Integer > (alignedRes.get(s).size())); for(int col = 0; col < alignedRes.get(0).size(); col ++ ) { boolean missing = false; for(int s = 0; s < alignedRes.size(); s ++ ) { if( ! subunitEQR.get(representative).contains(alignedRes.get(s).get(col))) { missing = true; break; } } if(missing)continue; for(int s = 0; s < alignedRes.size(); s ++ ) { columns.get(s).add(subunitEQR.get(representative).indexOf(alignedRes.get(s).get(col))); } } List < Subunit > newSubunits = new ArrayList < Subunit > (subunits.size() * columns.size()); List < List < Integer > > newSubunitEQR = new ArrayList < List < Integer > > (subunits.size() * columns.size()); for(int s = 0; s < subunits.size(); s ++ ) { for(int r = 0; r < columns.size(); r ++ ) { int start = subunitEQR.get(s).get(columns.get(r).get(0)); int end = subunitEQR.get(s).get(columns.get(r).get(columns.get(r).size() - 1)); Atom[]reprAtoms = Arrays.copyOfRange(subunits.get(s).getRepresentativeAtoms(), start, end + 1); newSubunits.add(new Subunit(reprAtoms, subunits.get(s).getName(), subunits.get(s).getIdentifier(), subunits.get(s).getStructure())); List < Integer > eqr = new ArrayList < Integer > (); for(int p = 0; p < columns.get(r).size(); p ++ ) { eqr.add(subunitEQR.get(s).get(columns.get(r).get(p)) - start); } newSubunitEQR.add(eqr); } } subunits = newSubunits; subunitEQR = newSubunitEQR; for(int s = 0; s < subunits.size(); s ++ ) { if(subunits.get(s).size() > subunits.get(representative).size())representative = s; } method = SubunitClustererMethod.STRUCTURE; pseudoStoichiometric = true; return true; } ",
        "focal_src": "public boolean divideInternally(double coverageThreshold, double rmsdThreshold, int minSequenceLength)throws StructureException { CESymmParameters params = new CESymmParameters(); params.setMinCoreLength(minSequenceLength); params.setGaps(false); CeSymmResult result = CeSymm.analyze(subunits.get(representative).getRepresentativeAtoms(), params); if( ! result.isSignificant())return false; double rmsd = result.getMultipleAlignment().getScore(MultipleAlignmentScorer.RMSD); if(rmsd > rmsdThreshold)return false; double coverage = result.getMultipleAlignment().getCoverages().get(0) * result.getNumRepeats(); if(coverage < coverageThreshold)return false; logger.info(\"SubunitCluster is internally symmetric with {} repeats, \" + \"{} RMSD and {} coverage\", result.getNumRepeats(), rmsd, coverage); List < List < Integer > > alignedRes = result.getMultipleAlignment().getBlock(0).getAlignRes(); List < List < Integer > > columns = new ArrayList < List < Integer > > (); for(int s = 0; s < alignedRes.size(); s ++ )columns.add(new ArrayList < Integer > (alignedRes.get(s).size())); for(int col = 0; col < alignedRes.get(0).size(); col ++ ) { boolean missing = false; for(int s = 0; s < alignedRes.size(); s ++ ) { if( ! subunitEQR.get(representative).contains(alignedRes.get(s).get(col))) { missing = true; break; } } if(missing)continue; for(int s = 0; s < alignedRes.size(); s ++ ) { columns.get(s).add(subunitEQR.get(representative).indexOf(alignedRes.get(s).get(col))); } } List < Subunit > newSubunits = new ArrayList < Subunit > (subunits.size() * columns.size()); List < List < Integer > > newSubunitEQR = new ArrayList < List < Integer > > (subunits.size() * columns.size()); for(int s = 0; s < subunits.size(); s ++ ) { for(int r = 0; r < columns.size(); r ++ ) { int start = subunitEQR.get(s).get(columns.get(r).get(0)); int end = subunitEQR.get(s).get(columns.get(r).get(columns.get(r).size() - 1)); Atom[]reprAtoms = Arrays.copyOfRange(subunits.get(s).getRepresentativeAtoms(), start, end + 1); newSubunits.add(new Subunit(reprAtoms, subunits.get(s).getName(), subunits.get(s).getIdentifier(), subunits.get(s).getStructure())); List < Integer > eqr = new ArrayList < Integer > (); for(int p = 0; p < columns.get(r).size(); p ++ ) { eqr.add(subunitEQR.get(s).get(columns.get(r).get(p)) - start); } newSubunitEQR.add(eqr); } } subunits = newSubunits; subunitEQR = newSubunitEQR; for(int s = 0; s < subunits.size(); s ++ ) { if(subunits.get(s).size() > subunits.get(representative).size())representative = s; } method = SubunitClustererMethod.STRUCTURE; return true; } ",
        "test_tgt": "@Test public void testDivideInternally()throws StructureException, IOException { Structure s = StructureIO.getStructure(\"4e3e\"); SubunitCluster sc1 = new SubunitCluster(new Subunit(StructureTools.getRepresentativeAtomArray(s.getChainByIndex(0)), \"chain 0\", null, s)); SubunitClustererParameters clustererParameters = new SubunitClustererParameters(); clustererParameters.setStructureCoverageThreshold(0.8); clustererParameters.setRMSDThreshold(3.0); clustererParameters.setMinimumSequenceLength(20); boolean divided = sc1.divideInternally(clustererParameters); assertTrue(divided); assertEquals(sc1.size(), 2); assertTrue(sc1.length() < 178); assertEquals(sc1.getAlignedAtomsSubunit(0).length, sc1.getAlignedAtomsSubunit(1).length); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_parseToEngine_String()throws Exception { DateTimeFormatter test = new DateTimeFormatter(Locale.ENGLISH, DateTimeFormatSymbols.STANDARD, compPP); CalendricalEngine result = test.parseToEngine(\"ONE30\"); assertEquals(result.getInput().size(), 1); assertEquals(result.getInput().get(0), DAY_OF_MONTH.field(30L)); } ",
        "focal_tgt": "public DateTimeBuilder parseToBuilder(CharSequence text) { DateTimes.checkNotNull(text, \"Text must not be null\"); String str = text.toString(); ParsePosition pos = new ParsePosition(0); DateTimeParseContext result = parseToContext(str, pos); if(pos.getErrorIndex() >= 0 || pos.getIndex() < str.length()) { String abbr = str.toString(); if(abbr.length() > 64) { abbr = abbr.substring(0, 64) + \"...\"; } if(pos.getErrorIndex() >= 0) { throw new CalendricalParseException(\"Text '\" + abbr + \"' could not be parsed at index \" + pos.getErrorIndex(), str, pos.getErrorIndex()); } else { throw new CalendricalParseException(\"Text '\" + abbr + \"' could not be parsed, unparsed text found at index \" + pos.getIndex(), str, pos.getIndex()); } } return result.toBuilder(); } ",
        "focal_src": "public CalendricalEngine parseToEngine(CharSequence text) { DateTimes.checkNotNull(text, \"Text must not be null\"); String str = text.toString(); ParsePosition pos = new ParsePosition(0); DateTimeParseContext result = parseToContext(str, pos); if(pos.getErrorIndex() >= 0 || pos.getIndex() < str.length()) { String abbr = str.toString(); if(abbr.length() > 64) { abbr = abbr.substring(0, 64) + \"...\"; } if(pos.getErrorIndex() >= 0) { throw new CalendricalParseException(\"Text '\" + abbr + \"' could not be parsed at index \" + pos.getErrorIndex(), str, pos.getErrorIndex()); } else { throw new CalendricalParseException(\"Text '\" + abbr + \"' could not be parsed, unparsed text found at index \" + pos.getIndex(), str, pos.getIndex()); } } return result.toCalendricalEngine(); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_parseToEngine_String()throws Exception { DateTimeFormatter test = new DateTimeFormatter(Locale.ENGLISH, DateTimeFormatSymbols.STANDARD, compPP); CalendricalEngine result = test.parseToBuilder(\"ONE30\"); assertEquals(result.getInput().size(), 1); assertEquals(result.getInput().get(0), DAY_OF_MONTH.field(30L)); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_firstDayOfMonth_serialization()throws IOException, ClassNotFoundException { DateTimeAdjuster firstDayOfMonth = DateTimeAdjusters.firstDayOfMonth(); assertTrue(firstDayOfMonth instanceof Serializable); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(firstDayOfMonth); oos.close(); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(baos.toByteArray())); assertSame(ois.readObject(), firstDayOfMonth); } ",
        "focal_tgt": "public static WithAdjuster firstDayOfMonth() { return Impl.FIRST_DAY_OF_MONTH; } ",
        "focal_src": "public static DateTimeAdjuster firstDayOfMonth() { return Impl.FIRST_DAY_OF_MONTH; } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_firstDayOfMonth_serialization()throws IOException, ClassNotFoundException { WithAdjuster firstDayOfMonth = DateTimeAdjusters.firstDayOfMonth(); assertTrue(firstDayOfMonth instanceof Serializable); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(firstDayOfMonth); oos.close(); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(baos.toByteArray())); assertSame(ois.readObject(), firstDayOfMonth); } "
    },
    {
        "test_src": "@Test public void testUpdate()throws Exception { definition = JSONUtils.INSTANCE.load(testUpdateProfile, ProfileConfig.class); builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity(\"10.0.0.1\").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build(); int count = 10; for(int i = 0; i < count; i ++ ) { builder.apply(message); } Optional < ProfileMeasurement > m = builder.flush(); assertTrue(m.isPresent()); assertEquals(count * 1 + count * 2, (int)convert(m.get().getProfileValue(), Integer.class)); } ",
        "focal_tgt": "public void uploadConfig(String path)throws Exception { configUploadComponent.withGlobalConfiguration(path).withProfilerConfiguration(path).update(); } ",
        "focal_src": "public void update(String path)throws Exception { configUploadComponent.withGlobalConfiguration(path).withProfilerConfiguration(path); configUploadComponent.update(); } ",
        "test_tgt": "@Test public void testUpdate()throws Exception { long timestamp = 100; definition = JSONUtils.INSTANCE.load(testUpdateProfile, ProfileConfig.class); builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity(\"10.0.0.1\").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build(); int count = 10; for(int i = 0; i < count; i ++ ) { builder.apply(message, timestamp); timestamp += 5; } Optional < ProfileMeasurement > m = builder.flush(); assertTrue(m.isPresent()); assertEquals(count * 1 + count * 2, (int)convert(m.get().getProfileValue(), Integer.class)); } "
    },
    {
        "test_src": "@Test public void testSum() { List < User > list = toList(new User(2L), new User(5L), new User(5L)); assertEquals(new BigDecimal(12L), AggregateUtil.sum(list, \"id\")); assertEquals(null, AggregateUtil.sum(null, \"id\")); } ",
        "focal_tgt": "public static < O > BigDecimal sum(Collection < O > objectCollection, String propertyName) { Validate.notBlank(propertyName, \"propertyName can't be blank!\"); return sum(objectCollection, propertyName, null); } ",
        "focal_src": "public static < O > BigDecimal sum(Collection < O > objectCollection, String propertyName) { return sum(objectCollection, propertyName, null); } ",
        "test_tgt": "@Test public void testSum() { List < User > list = toList(new User(2L), new User(5L), new User(5L)); assertEquals(new BigDecimal(12L), AggregateUtil.sum(list, \"id\")); } "
    },
    {
        "test_src": "@Test public void z() { runQuery(\"geo:z(<gml:Point><gml:coordinates>2,1,3</gml:coordinates></gml:Point>)\", \"3\"); runQuery(\"geo:z(<gml:Point><gml:coordinates>2</gml:coordinates></gml:Point>)\", \"NaN\"); runError(\"geo:z(<gml:MultiPoint><gml:Point><gml:coordinates>1,1\" + \"</gml:coordinates></gml:Point><gml:Point><gml:coordinates>1,2\" + \"</gml:coordinates></gml:Point></gml:MultiPoint>)\", GeoErrors.qname(5)); runError(\"geo:z(\" + \"<gml:LinearRing><gml:coordinates>0,0 20,0 0,20 0,0\" + \"</gml:coordinates></gml:LinearRing>)\", GeoErrors.qname(5)); runError(\"geo:z(<gml:Point><gml:coordinates></gml:coordinates></gml:Point>)\", GeoErrors.qname(2)); runError(\"geo:z(<gml:geo><gml:coordinates>2,1</gml:coordinates></gml:geo>)\", GeoErrors.qname(1)); runError(\"geo:z(a)\", XPNOCTX.qname()); } ",
        "focal_tgt": "public Dbl z(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_POINT); if(geo == null && checkGeo(node) != null)throw GeoErrors.geoType(node.qname().local(), \"Line\"); return Dbl.get(geo.getCoordinate().z); } ",
        "focal_src": "public Dbl z(final ANode node)throws QueryException { final Geometry geo = geo(node, Q_GML_POINT); if(geo == null && checkGeo(node) != null)throw GeoErrors.pointNeeded(node.qname().local()); return Dbl.get(geo.getCoordinate().z); } ",
        "test_tgt": "@Test public void z() { runQuery(\"geo:z(<gml:Point><gml:coordinates>2,1,3</gml:coordinates></gml:Point>)\", \"3\"); runQuery(\"geo:z(<gml:Point><gml:coordinates>2</gml:coordinates></gml:Point>)\", \"NaN\"); runError(\"geo:z(<gml:MultiPoint><gml:Point><gml:coordinates>1,1\" + \"</gml:coordinates></gml:Point><gml:Point><gml:coordinates>1,2\" + \"</gml:coordinates></gml:Point></gml:MultiPoint>)\", GeoErrors.qname(3)); runError(\"geo:z(\" + \"<gml:LinearRing><gml:coordinates>0,0 20,0 0,20 0,0\" + \"</gml:coordinates></gml:LinearRing>)\", GeoErrors.qname(3)); runError(\"geo:z(<gml:Point><gml:coordinates></gml:coordinates></gml:Point>)\", GeoErrors.qname(2)); runError(\"geo:z(<gml:geo><gml:coordinates>2,1</gml:coordinates></gml:geo>)\", GeoErrors.qname(1)); runError(\"geo:z(a)\", XPNOCTX.qname()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); expectedException.expect(CannotEditOrderPropertyInUseException.class); expectedException.expectMessage(\"Order.frequency.cannot.edit\"); orderService.saveOrderFrequency(orderFrequency); } ",
        "focal_tgt": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw new CannotUpdateObjectInUseException(\"Order.frequency.cannot.edit\"); } } return dao.saveOrderFrequency(orderFrequency); } ",
        "focal_src": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw CannotEditOrderPropertyInUseException.withProperty(\"frequency\"); } } return dao.saveOrderFrequency(orderFrequency); } ",
        "test_tgt": "@Test@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); expectedException.expect(CannotUpdateObjectInUseException.class); expectedException.expectMessage(\"Order.frequency.cannot.edit\"); orderService.saveOrderFrequency(orderFrequency); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, method = \"getNextEntry\", args = { })public void test_getNextEntry()throws Exception { assertNotNull(\"getNextEntry failed\", zis.getNextEntry()); File resources = Support_Resources.createTempFolder(); Support_Resources.copyFile(resources, null, \"Broken_manifest.jar\"); FileInputStream fis = new FileInputStream(new File(resources, \"Broken_manifest.jar\")); ZipInputStream zis1 = new ZipInputStream(fis); try { for(int i = 0; i < 6; i ++ ) { zis1.getNextEntry(); } fail(\"ZipException expected\"); } catch(ZipException ee) { } try { zis1.close(); zis1.getNextEntry(); fail(\"IOException expected\"); } catch(IOException ee) { } } ",
        "focal_tgt": "public ZipEntry getNextEntry()throws IOException { closeEntry(); if(entriesEnd) { return null; } int x = 0, count = 0; while(count != 4) { count += x = in.read(hdrBuf, count, 4 - count); if(x == - 1) { return null; } } long hdr = getLong(hdrBuf, 0); if(hdr == CENSIG) { entriesEnd = true; return null; } if(hdr != LOCSIG) { return null; } count = 0; while(count != (LOCHDR - LOCVER)) { count += x = in.read(hdrBuf, count, (LOCHDR - LOCVER) - count); if(x == - 1) { throw new EOFException(); } } int version = getShort(hdrBuf, 0) & 0xff; if(version > ZIPLocalHeaderVersionNeeded) { throw new ZipException(Messages.getString(\"archive.22\")); } int flags = getShort(hdrBuf, LOCFLG - LOCVER); hasDD = ((flags & ZIPDataDescriptorFlag) == ZIPDataDescriptorFlag); int cetime = getShort(hdrBuf, LOCTIM - LOCVER); int cemodDate = getShort(hdrBuf, LOCTIM - LOCVER + 2); int cecompressionMethod = getShort(hdrBuf, LOCHOW - LOCVER); long cecrc = 0, cecompressedSize = 0, cesize = - 1; if( ! hasDD) { cecrc = getLong(hdrBuf, LOCCRC - LOCVER); cecompressedSize = getLong(hdrBuf, LOCSIZ - LOCVER); cesize = getLong(hdrBuf, LOCLEN - LOCVER); } int flen = getShort(hdrBuf, LOCNAM - LOCVER); if(flen == 0) { throw new ZipException(Messages.getString(\"archive.23\")); } int elen = getShort(hdrBuf, LOCEXT - LOCVER); count = 0; if(flen > nameBuf.length) { nameBuf = new byte[flen]; charBuf = new char[flen]; } while(count != flen) { count += x = in.read(nameBuf, count, flen - count); if(x == - 1) { throw new EOFException(); } } currentEntry = createZipEntry(Util.convertUTF8WithBuf(nameBuf, charBuf, 0, flen)); currentEntry.time = cetime; currentEntry.modDate = cemodDate; currentEntry.setMethod(cecompressionMethod); if(cesize != - 1) { currentEntry.setCrc(cecrc); currentEntry.setSize(cesize); currentEntry.setCompressedSize(cecompressedSize); } if(elen > 0) { count = 0; byte[]e = new byte[elen]; while(count != elen) { count += x = in.read(e, count, elen - count); if(x == - 1) { throw new EOFException(); } } currentEntry.setExtra(e); } eof = false; return currentEntry; } ",
        "focal_src": "public ZipEntry getNextEntry()throws IOException { if(currentEntry != null) { closeEntry(); } if(entriesEnd) { return null; } int x = 0, count = 0; while(count != 4) { count += x = in.read(hdrBuf, count, 4 - count); if(x == - 1) { return null; } } long hdr = getLong(hdrBuf, 0); if(hdr == CENSIG) { entriesEnd = true; return null; } if(hdr != LOCSIG) { return null; } count = 0; while(count != (LOCHDR - LOCVER)) { count += x = in.read(hdrBuf, count, (LOCHDR - LOCVER) - count); if(x == - 1) { throw new EOFException(); } } int version = getShort(hdrBuf, 0) & 0xff; if(version > ZIPLocalHeaderVersionNeeded) { throw new ZipException(Messages.getString(\"archive.22\")); } int flags = getShort(hdrBuf, LOCFLG - LOCVER); hasDD = ((flags & ZIPDataDescriptorFlag) == ZIPDataDescriptorFlag); int cetime = getShort(hdrBuf, LOCTIM - LOCVER); int cemodDate = getShort(hdrBuf, LOCTIM - LOCVER + 2); int cecompressionMethod = getShort(hdrBuf, LOCHOW - LOCVER); long cecrc = 0, cecompressedSize = 0, cesize = - 1; if( ! hasDD) { cecrc = getLong(hdrBuf, LOCCRC - LOCVER); cecompressedSize = getLong(hdrBuf, LOCSIZ - LOCVER); cesize = getLong(hdrBuf, LOCLEN - LOCVER); } int flen = getShort(hdrBuf, LOCNAM - LOCVER); if(flen == 0) { throw new ZipException(Messages.getString(\"archive.23\")); } int elen = getShort(hdrBuf, LOCEXT - LOCVER); count = 0; if(flen > nameBuf.length) { nameBuf = new byte[flen]; charBuf = new char[flen]; } while(count != flen) { count += x = in.read(nameBuf, count, flen - count); if(x == - 1) { throw new EOFException(); } } currentEntry = createZipEntry(Util.convertUTF8WithBuf(nameBuf, charBuf, 0, flen)); currentEntry.time = cetime; currentEntry.modDate = cemodDate; currentEntry.setMethod(cecompressionMethod); if(cesize != - 1) { currentEntry.setCrc(cecrc); currentEntry.setSize(cesize); currentEntry.setCompressedSize(cecompressedSize); } if(elen > 0) { count = 0; byte[]e = new byte[elen]; while(count != elen) { count += x = in.read(e, count, elen - count); if(x == - 1) { throw new EOFException(); } } currentEntry.setExtra(e); } eof = false; return currentEntry; } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, method = \"getNextEntry\", args = { })public void test_getNextEntry()throws Exception { assertNotNull(\"getNextEntry failed\", zis.getNextEntry()); File resources = Support_Resources.createTempFolder(); Support_Resources.copyFile(resources, null, \"Broken_manifest.jar\"); FileInputStream fis = new FileInputStream(new File(resources, \"Broken_manifest.jar\")); ZipInputStream zis1 = new ZipInputStream(fis); try { for(int i = 0; i < 6; i ++ ) { zis1.getNextEntry(); } fail(\"ZipException expected\"); } catch(ZipException ee) { } try { zis1.close(); zis1.getNextEntry(); fail(\"IOException expected\"); } catch(IOException ee) { } } "
    },
    {
        "test_src": "@Test public void testAggregate2() { String s = Linq4j.asEnumerable(emps).aggregate(new Function0 < String > () { public String apply() { return null; } }.apply(), new Function2 < String, Employee, String > () { public String apply(String v1, Employee e0) { return v1 == null ? e0.name : (v1 + \"+\" + e0.name); } }, new Function1 < String, String > () { public String apply(String v2) { return \"<no key>: \" + v2; } }); assertEquals(\"<no key>: Fred+Bill+Eric+Janet\", s); } ",
        "focal_tgt": "public RelBuilder aggregate(GroupKey groupKey, Iterable < AggCall > aggCalls) { final Registrar registrar = new Registrar(); registrar.extraNodes.addAll(fields()); registrar.names.addAll(peek().getRowType().getFieldNames()); final GroupKeyImpl groupKey_ = (GroupKeyImpl)groupKey; final ImmutableBitSet groupSet = ImmutableBitSet.of(registrar.registerExpressions(groupKey_.nodes)); label : if(Iterables.isEmpty(aggCalls) && ! groupKey_.indicator) { final RelMetadataQuery mq = peek().getCluster().getMetadataQuery(); if(groupSet.isEmpty()) { final Double minRowCount = mq.getMinRowCount(peek()); if(minRowCount == null || minRowCount < 1D) { break label; } } if(registrar.extraNodes.size() == fields().size()) { final Boolean unique = mq.areColumnsUnique(peek(), groupSet); if(unique != null && unique) { return project(fields(groupSet.asList())); } } final Double maxRowCount = mq.getMaxRowCount(peek()); if(maxRowCount != null && maxRowCount <= 1D) { return this; } } final ImmutableList < ImmutableBitSet > groupSets; if(groupKey_.nodeLists != null) { final int sizeBefore = registrar.extraNodes.size(); final SortedSet < ImmutableBitSet > groupSetSet = new TreeSet < > (ImmutableBitSet.ORDERING); for(ImmutableList < RexNode > nodeList : groupKey_.nodeLists) { final ImmutableBitSet groupSet2 = ImmutableBitSet.of(registrar.registerExpressions(nodeList)); if( ! groupSet.contains(groupSet2)) { throw new IllegalArgumentException(\"group set element \" + nodeList + \" must be a subset of group key\"); } groupSetSet.add(groupSet2); } groupSets = ImmutableList.copyOf(groupSetSet); if(registrar.extraNodes.size() > sizeBefore) { throw new IllegalArgumentException(\"group sets contained expressions not in group key: \" + registrar.extraNodes.subList(sizeBefore, registrar.extraNodes.size())); } } else { groupSets = ImmutableList.of(groupSet); } for(AggCall aggCall : aggCalls) { if(aggCall instanceof AggCallImpl) { final AggCallImpl aggCall1 = (AggCallImpl)aggCall; registrar.registerExpressions(aggCall1.operands); if(aggCall1.filter != null) { registrar.registerExpression(aggCall1.filter); } } } project(registrar.extraNodes); rename(registrar.names); final Frame frame = stack.pop(); final RelNode r = frame.rel; final List < AggregateCall > aggregateCalls = new ArrayList < > (); for(AggCall aggCall : aggCalls) { final AggregateCall aggregateCall; if(aggCall instanceof AggCallImpl) { final AggCallImpl aggCall1 = (AggCallImpl)aggCall; final List < Integer > args = registrar.registerExpressions(aggCall1.operands); final int filterArg = aggCall1.filter == null ? - 1 : registrar.registerExpression(aggCall1.filter); if(aggCall1.distinct && ! aggCall1.aggFunction.isQuantifierAllowed()) { throw new IllegalArgumentException(\"DISTINCT not allowed\"); } if(aggCall1.filter != null && ! aggCall1.aggFunction.allowsFilter()) { throw new IllegalArgumentException(\"FILTER not allowed\"); } aggregateCall = AggregateCall.create(aggCall1.aggFunction, aggCall1.distinct, aggCall1.approximate, args, filterArg, groupSet.cardinality(), r, null, aggCall1.alias); } else { aggregateCall = ((AggCallImpl2)aggCall).aggregateCall; } aggregateCalls.add(aggregateCall); } assert ImmutableBitSet.ORDERING.isStrictlyOrdered(groupSets) : groupSets; for(ImmutableBitSet set : groupSets) { assert groupSet.contains(set); } RelNode aggregate = aggregateFactory.createAggregate(r, groupKey_.indicator, groupSet, groupSets, aggregateCalls); final ImmutableList.Builder < Field > fields = ImmutableList.builder(); final List < RelDataTypeField > aggregateFields = aggregate.getRowType().getFieldList(); int i = 0; for(Integer groupField : groupSet.asList()) { RexNode node = registrar.extraNodes.get(groupField); final SqlKind kind = node.getKind(); switch(kind) { case INPUT_REF : fields.add(frame.fields.get(((RexInputRef)node).getIndex())); break; default : String name = aggregateFields.get(i).getName(); RelDataTypeField fieldType = new RelDataTypeFieldImpl(name, i, node.getType()); fields.add(new Field(ImmutableSet.of(), fieldType)); break; } i ++ ; } if(groupKey_.indicator) { for(int j = 0; j < groupSet.cardinality(); ++ j) { final RelDataTypeField field = aggregateFields.get(i); final RelDataTypeField fieldType = new RelDataTypeFieldImpl(field.getName(), i, field.getType()); fields.add(new Field(ImmutableSet.of(), fieldType)); i ++ ; } } for(int j = 0; j < aggregateCalls.size(); ++ j) { final AggregateCall call = aggregateCalls.get(j); final RelDataTypeField fieldType = new RelDataTypeFieldImpl(aggregateFields.get(i + j).getName(), i + j, call.getType()); fields.add(new Field(ImmutableSet.of(), fieldType)); } stack.push(new Frame(aggregate, fields.build())); return this; } ",
        "focal_src": "public RelBuilder aggregate(GroupKey groupKey, Iterable < AggCall > aggCalls) { final Registrar registrar = new Registrar(); registrar.extraNodes.addAll(fields()); registrar.names.addAll(peek().getRowType().getFieldNames()); final GroupKeyImpl groupKey_ = (GroupKeyImpl)groupKey; final ImmutableBitSet groupSet = ImmutableBitSet.of(registrar.registerExpressions(groupKey_.nodes)); label : if(Iterables.isEmpty(aggCalls) && ! groupKey_.indicator) { final RelMetadataQuery mq = peek().getCluster().getMetadataQuery(); if(groupSet.isEmpty()) { final Double minRowCount = mq.getMinRowCount(peek()); if(minRowCount == null || minRowCount < 1D) { break label; } } if(registrar.extraNodes.size() == fields().size()) { final Boolean unique = mq.areColumnsUnique(peek(), groupSet); if(unique != null && unique) { return project(fields(groupSet.asList())); } } final Double maxRowCount = mq.getMaxRowCount(peek()); if(maxRowCount != null && maxRowCount <= 1D) { return this; } } final ImmutableList < ImmutableBitSet > groupSets; if(groupKey_.nodeLists != null) { final int sizeBefore = registrar.extraNodes.size(); final SortedSet < ImmutableBitSet > groupSetSet = new TreeSet < > (ImmutableBitSet.ORDERING); for(ImmutableList < RexNode > nodeList : groupKey_.nodeLists) { final ImmutableBitSet groupSet2 = ImmutableBitSet.of(registrar.registerExpressions(nodeList)); if( ! groupSet.contains(groupSet2)) { throw new IllegalArgumentException(\"group set element \" + nodeList + \" must be a subset of group key\"); } groupSetSet.add(groupSet2); } groupSets = ImmutableList.copyOf(groupSetSet); if(registrar.extraNodes.size() > sizeBefore) { throw new IllegalArgumentException(\"group sets contained expressions not in group key: \" + registrar.extraNodes.subList(sizeBefore, registrar.extraNodes.size())); } } else { groupSets = ImmutableList.of(groupSet); } for(AggCall aggCall : aggCalls) { if(aggCall instanceof AggCallImpl) { final AggCallImpl aggCall1 = (AggCallImpl)aggCall; registrar.registerExpressions(aggCall1.operands); if(aggCall1.filter != null) { registrar.registerExpression(aggCall1.filter); } } } project(registrar.extraNodes); rename(registrar.names); final Frame frame = stack.pop(); final RelNode r = frame.rel; final List < AggregateCall > aggregateCalls = new ArrayList < > (); for(AggCall aggCall : aggCalls) { final AggregateCall aggregateCall; if(aggCall instanceof AggCallImpl) { final AggCallImpl aggCall1 = (AggCallImpl)aggCall; final List < Integer > args = registrar.registerExpressions(aggCall1.operands); final int filterArg = aggCall1.filter == null ? - 1 : registrar.registerExpression(aggCall1.filter); if(aggCall1.distinct && ! aggCall1.aggFunction.isQuantifierAllowed()) { throw new IllegalArgumentException(\"DISTINCT not allowed\"); } if(aggCall1.filter != null && ! aggCall1.aggFunction.allowsFilter()) { throw new IllegalArgumentException(\"FILTER not allowed\"); } aggregateCall = AggregateCall.create(aggCall1.aggFunction, aggCall1.distinct, aggCall1.approximate, args, filterArg, groupSet.cardinality(), r, null, aggCall1.alias); } else { aggregateCall = ((AggCallImpl2)aggCall).aggregateCall; } aggregateCalls.add(aggregateCall); } assert ImmutableBitSet.ORDERING.isStrictlyOrdered(groupSets) : groupSets; for(ImmutableBitSet set : groupSets) { assert groupSet.contains(set); } RelNode aggregate = aggregateFactory.createAggregate(r, groupKey_.indicator, groupSet, groupSets, aggregateCalls); final ImmutableList.Builder < Field > fields = ImmutableList.builder(); final List < RelDataTypeField > aggregateFields = aggregate.getRowType().getFieldList(); int i = 0; for(Integer groupField : groupSet.asList()) { RexNode node = registrar.extraNodes.get(groupField); final SqlKind kind = node.getKind(); switch(kind) { case INPUT_REF : fields.add(frame.fields.get(((RexInputRef)node).getIndex())); break; default : String name = aggregateFields.get(i).getName(); RelDataTypeField fieldType = new RelDataTypeFieldImpl(name, i, node.getType()); fields.add(new Field(ImmutableSet. < String > of(), fieldType)); break; } i ++ ; } if(groupKey_.indicator) { for(int j = 0; j < groupSet.cardinality(); ++ j) { final RelDataTypeField field = aggregateFields.get(i); final RelDataTypeField fieldType = new RelDataTypeFieldImpl(field.getName(), i, field.getType()); fields.add(new Field(ImmutableSet. < String > of(), fieldType)); i ++ ; } } for(int j = 0; j < aggregateCalls.size(); ++ j) { final AggregateCall call = aggregateCalls.get(j); final RelDataTypeField fieldType = new RelDataTypeFieldImpl(aggregateFields.get(i + j).getName(), i + j, call.getType()); fields.add(new Field(ImmutableSet. < String > of(), fieldType)); } stack.push(new Frame(aggregate, fields.build())); return this; } ",
        "test_tgt": "@Test public void testAggregate2() { String s = Linq4j.asEnumerable(emps).aggregate(((Function0 < String > )() -> null).apply(), (v1, e0) -> v1 == null ? e0.name : (v1 + \"+\" + e0.name), v2 -> \"<no key>: \" + v2); assertEquals(\"<no key>: Fred+Bill+Eric+Janet\", s); } "
    },
    {
        "test_src": "@Test public void testDepth_Component() { page.send(c1, Broadcast.DEPTH, new Payload()); assertPath(c12, c134, c135, c13, c1); } ",
        "focal_tgt": "private void depth(final ComponentEvent < ? > event) { IEventSink sink = event.getSink(); boolean targetsApplication = sink instanceof Application; boolean targetsSession = targetsApplication || sink instanceof Session; boolean targetsCycle = targetsSession || sink instanceof RequestCycle; boolean targetsComponnet = sink instanceof Component; if( ! targetsComponnet && ! targetsCycle) { dispatcher.dispatchEvent(sink, event); return; } Component cursor = (targetsCycle) ? source.getPage() : (Component)sink; if(cursor instanceof MarkupContainer) { Visits.visitPostOrder(cursor, new ComponentEventVisitor(event, dispatcher)); } else { dispatcher.dispatchEvent(cursor, event); } if(event.isStop()) { return; } if(targetsCycle) { dispatcher.dispatchEvent(source.getRequestCycle(), event); } if(event.isStop()) { return; } if(targetsSession) { dispatcher.dispatchEvent(source.getSession(), event); } if(event.isStop()) { return; } if(targetsApplication) { dispatcher.dispatchEvent(source.getApplication(), event); } } ",
        "focal_src": "private void depth(final ComponentEvent < ? > event) { IEventSink sink = event.getSink(); boolean targetsApplication = sink instanceof Application; boolean targetsSession = targetsApplication || sink instanceof Session; boolean targetsCycle = targetsSession || sink instanceof RequestCycle; boolean targetsComponnet = sink instanceof Component; if( ! targetsComponnet && ! targetsCycle) { dispatcher.dispatchEvent(sink, event); return; } Component cursor = (targetsCycle) ? source.getPage() : (Component)sink; if(cursor instanceof MarkupContainer) { Visits.visitPostOrder(cursor, new ComponentEventVisitor(event, dispatcher)); } if(event.isStop()) { return; } if(targetsCycle) { dispatcher.dispatchEvent(source.getRequestCycle(), event); } if(event.isStop()) { return; } if(targetsSession) { dispatcher.dispatchEvent(source.getSession(), event); } if(event.isStop()) { return; } if(targetsApplication) { dispatcher.dispatchEvent(source.getApplication(), event); } } ",
        "test_tgt": "@Test public void testDepth_Component() { page.send(c6, Broadcast.DEPTH, new Payload()); assertPath(c6); } "
    },
    {
        "test_src": "@Test public void applyUMaskTest() { FileSystemPermission umaskPermission = new FileSystemPermission((short)0022); PermissionStatus permissionStatus = new PermissionStatus(\"user1\", \"group1\", FileSystemPermission.getDefault()); Configuration conf = new Configuration(); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); conf.set(Constants.SECURITY_AUTHORIZATION_PERMISSION_ENABLED, \"true\"); permissionStatus = permissionStatus.applyUMask(umaskPermission, conf); Assert.assertEquals(FileSystemAction.ALL, permissionStatus.getPermission().getUserAction()); Assert.assertEquals(FileSystemAction.READ_EXECUTE, permissionStatus.getPermission().getGroupAction()); Assert.assertEquals(FileSystemAction.READ_EXECUTE, permissionStatus.getPermission().getOtherAction()); Assert.assertEquals(0755, permissionStatus.getPermission().toShort()); } ",
        "focal_tgt": "public PermissionStatus applyUMask(FileSystemPermission umask) { FileSystemPermission newFileSystemPermission = mPermission.applyUMask(umask); return new PermissionStatus(mUserName, mGroupName, newFileSystemPermission); } ",
        "focal_src": "public PermissionStatus applyUMask(FileSystemPermission umask, Configuration configuration) { if( ! SecurityUtils.isAuthorizationEnabled(configuration)) { return new PermissionStatus(mUserName, mGroupName, mPermission); } FileSystemPermission newFileSystemPermission = mPermission.applyUMask(umask); return new PermissionStatus(mUserName, mGroupName, newFileSystemPermission); } ",
        "test_tgt": "@Test public void applyUMaskTest() { FileSystemPermission umaskPermission = new FileSystemPermission((short)0022); PermissionStatus permissionStatus = new PermissionStatus(\"user1\", \"group1\", FileSystemPermission.getDefault()); permissionStatus = permissionStatus.applyUMask(umaskPermission); Assert.assertEquals(FileSystemAction.ALL, permissionStatus.getPermission().getUserAction()); Assert.assertEquals(FileSystemAction.READ_EXECUTE, permissionStatus.getPermission().getGroupAction()); Assert.assertEquals(FileSystemAction.READ_EXECUTE, permissionStatus.getPermission().getOtherAction()); Assert.assertEquals(0755, permissionStatus.getPermission().toShort()); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_plusHours() { LocalDateTime ldt = LocalDateTime.of(2008, 6, 30, 23, 30, 59, 0); ZonedDateTime base = ZonedDateTime.of(ldt, ZONE_0100); ZonedDateTime test = base.plusHours(13); assertEquals(test, ZonedDateTime.of(ldt.plusHours(13), ZONE_0100)); } ",
        "focal_tgt": "public ZonedDateTime plusHours(long hours) { return resolveInstant(dateTime.plusHours(hours)); } ",
        "focal_src": "public ZonedDateTime plusHours(long hours) { return resolveLocal(dateTime.plusHours(hours)); } ",
        "test_tgt": "@Test(groups = { \"tck\" }, dataProvider = \"plusTime\")public void test_plusHours(ZonedDateTime base, long amount, ZonedDateTime expected) { assertEquals(base.plusHours(amount), expected); } "
    },
    {
        "test_src": "@Test public void fit_obvious() { List < Point2D_I32 > contours = createSquare(10, 12, 20, 30); GrowQueue_I32 corners = createSquareCorners(10, 12, 20, 30); corners.add(corners.get(3) + 4); MinimizeEnergyPrune alg = new MinimizeEnergyPrune(1); GrowQueue_I32 output = new GrowQueue_I32(); alg.fit(contours, corners, output); assertEquals(4, output.size()); for(int i = 0; i < 4; i ++ ) { assertEquals(corners.get(i), output.get(i)); } } ",
        "focal_tgt": "public boolean prune(List < Point2D_I32 > contour, GrowQueue_I32 input, GrowQueue_I32 output) { this.contour = contour; output.setTo(input); removeDuplicates(output); if(output.size() <= 3)return false; computeSegmentEnergy(output); double total = 0; for(int i = 0; i < output.size(); i ++ ) { total += energySegment[i]; } FitLinesToContour fit = new FitLinesToContour(); fit.setContour(contour); boolean modified = false; while(output.size() > 3) { double bestEnergy = total; boolean betterFound = false; bestCorners.reset(); for(int i = 0; i < output.size(); i ++ ) { workCorners1.reset(); for(int j = 0; j < output.size(); j ++ ) { if(i != j) { workCorners1.add(output.get(j)); } } removeDuplicates(workCorners1); if(workCorners1.size() > 3) { int anchor0 = CircularIndex.addOffset(i, - 2, workCorners1.size()); int anchor1 = CircularIndex.addOffset(i, 1, workCorners1.size()); if(fit.fitAnchored(anchor0, anchor1, workCorners1, workCorners2)) { double score = 0; for(int j = 0, k = workCorners2.size() - 1; j < workCorners2.size(); k = j, j ++ ) { score += computeSegmentEnergy(workCorners2, k, j); } if(score < bestEnergy) { betterFound = true; bestEnergy = score; bestCorners.reset(); bestCorners.addAll(workCorners2); } } } } if(betterFound) { modified = true; total = bestEnergy; output.setTo(bestCorners); } else { break; } } return modified; } ",
        "focal_src": "public boolean fit(List < Point2D_I32 > contour, GrowQueue_I32 input, GrowQueue_I32 output) { this.contour = contour; output.setTo(input); removeDuplicates(output); if(output.size() <= 3)return false; computeSegmentEnergy(output); double total = 0; for(int i = 0; i < output.size(); i ++ ) { total += energySegment[i]; } FitLinesToContour fit = new FitLinesToContour(); fit.setContour(contour); boolean modified = false; while(output.size() > 3) { double bestEnergy = total; boolean betterFound = false; bestCorners.reset(); for(int i = 0; i < output.size(); i ++ ) { workCorners1.reset(); for(int j = 0; j < output.size(); j ++ ) { if(i != j) { workCorners1.add(output.get(j)); } } removeDuplicates(workCorners1); if(workCorners1.size() > 3) { int anchor0 = CircularIndex.addOffset(i, - 2, workCorners1.size()); int anchor1 = CircularIndex.addOffset(i, 1, workCorners1.size()); if(fit.fitAnchored(anchor0, anchor1, workCorners1, workCorners2)) { double score = 0; for(int j = 0, k = workCorners2.size() - 1; j < workCorners2.size(); k = j, j ++ ) { score += computeSegmentEnergy(workCorners2, k, j); } if(score < bestEnergy) { betterFound = true; bestEnergy = score; bestCorners.reset(); bestCorners.addAll(workCorners2); } } } } if(betterFound) { modified = true; total = bestEnergy; output.setTo(bestCorners); } else { break; } } return modified; } ",
        "test_tgt": "@Test public void prune_obvious() { List < Point2D_I32 > contours = createSquare(10, 12, 20, 30); GrowQueue_I32 corners = createSquareCorners(10, 12, 20, 30); corners.add(corners.get(3) + 4); MinimizeEnergyPrune alg = new MinimizeEnergyPrune(1); GrowQueue_I32 output = new GrowQueue_I32(); alg.prune(contours, corners, output); assertEquals(4, output.size()); checkMatched(corners, output); } "
    },
    {
        "test_src": "@Test public void modify() { query(\"let $c := <x/> return $c !! ()\", \"<x/>\"); query(\"let $c := <x/> return $c !! insert node <y/> into .\", \"<x><y/></x>\"); } ",
        "focal_tgt": "private Expr modify()throws QueryException { final Expr e = comparison(); if(e != null) { if(wsConsumeWs(UPDATE)) { final int s = scope.open(); final boolean u = ctx.updating; ctx.updating(false); final Expr m = check(single(), COPYEXPR); scope.close(s); ctx.updating = u; return new Modify(info(), e, m); } } return e; } ",
        "focal_src": "private Expr modify()throws QueryException { final Expr e = comparison(); if(e != null) { if(wsConsumeWs(\"!!\")) { final int s = scope.open(); final boolean u = ctx.updating; ctx.updating(false); final Expr m = check(single(), COPYEXPR); scope.close(s); ctx.updating = u; return new Modify(info(), e, m); } } return e; } ",
        "test_tgt": "@Test public void modify() { query(\"let $c := <x/> return $c update ()\", \"<x/>\"); query(\"let $c := <x/> return $c update insert node <y/> into .\", \"<x><y/></x>\"); } "
    },
    {
        "test_src": "@Test public void testBuildNdpSolicit()throws Exception { Ethernet ethPacket = NeighborSolicitation.buildNdpSolicit(TARGET_IP.toOctets(), SRC_IP.toOctets(), DST_IP.toOctets(), SRC_MAC.toBytes(), DST_MAC.toBytes(), VLAN_ID); IPv6 ipPacket = (IPv6)ethPacket.getPayload(); ICMP6 icmp6Packet = (ICMP6)ipPacket.getPayload(); NeighborSolicitation nsPacket = (NeighborSolicitation)icmp6Packet.getPayload(); assertEquals(\"Non-DAD NS should have 1 option\", 1, nsPacket.getOptions().size()); assertEquals(\"The option should be SRC_LL_ADDR type\", TYPE_SOURCE_LL_ADDRESS, nsPacket.getOptions().stream().findFirst().get().type()); } ",
        "focal_tgt": "@Deprecated public static Ethernet buildNdpSolicit(byte[]targetIp, byte[]sourceIp, byte[]destinationIp, byte[]sourceMac, byte[]destinationMac, VlanId vlan) { if(targetIp.length != Ip6Address.BYTE_LENGTH || sourceIp.length != Ip6Address.BYTE_LENGTH || destinationIp.length != Ip6Address.BYTE_LENGTH || sourceMac.length != MacAddress.MAC_ADDRESS_LENGTH || destinationMac.length != MacAddress.MAC_ADDRESS_LENGTH) { return null; } Ethernet ethernet = new Ethernet(); ethernet.setEtherType(Ethernet.TYPE_IPV6).setDestinationMACAddress(destinationMac).setSourceMACAddress(sourceMac); ethernet.setVlanID(vlan.id()); IPv6 ipv6 = new IPv6(); ipv6.setSourceAddress(sourceIp); ipv6.setDestinationAddress(destinationIp); ipv6.setHopLimit((byte)255); ICMP6 icmp6 = new ICMP6(); icmp6.setIcmpType(ICMP6.NEIGHBOR_SOLICITATION); icmp6.setIcmpCode((byte)0); NeighborSolicitation ns = new NeighborSolicitation(); ns.setTargetAddress(targetIp); if( ! Arrays.equals(sourceIp, Ip6Address.ZERO.toOctets())) { ns.addOption(NeighborDiscoveryOptions.TYPE_SOURCE_LL_ADDRESS, sourceMac); } icmp6.setPayload(ns); ipv6.setPayload(icmp6); ethernet.setPayload(ipv6); return ethernet; } ",
        "focal_src": "public static Ethernet buildNdpSolicit(byte[]targetIp, byte[]sourceIp, byte[]destinationIp, byte[]sourceMac, byte[]destinationMac, VlanId vlan) { if(targetIp.length != Ip6Address.BYTE_LENGTH || sourceIp.length != Ip6Address.BYTE_LENGTH || destinationIp.length != Ip6Address.BYTE_LENGTH || sourceMac.length != MacAddress.MAC_ADDRESS_LENGTH || destinationMac.length != MacAddress.MAC_ADDRESS_LENGTH) { return null; } Ethernet ethernet = new Ethernet(); ethernet.setEtherType(Ethernet.TYPE_IPV6).setDestinationMACAddress(destinationMac).setSourceMACAddress(sourceMac); ethernet.setVlanID(vlan.id()); IPv6 ipv6 = new IPv6(); ipv6.setSourceAddress(sourceIp); ipv6.setDestinationAddress(destinationIp); ipv6.setHopLimit((byte)255); ICMP6 icmp6 = new ICMP6(); icmp6.setIcmpType(ICMP6.NEIGHBOR_SOLICITATION); icmp6.setIcmpCode((byte)0); NeighborSolicitation ns = new NeighborSolicitation(); ns.setTargetAddress(targetIp); if( ! Arrays.equals(sourceIp, Ip6Address.ZERO.toOctets())) { ns.addOption(NeighborDiscoveryOptions.TYPE_SOURCE_LL_ADDRESS, sourceMac); } icmp6.setPayload(ns); ipv6.setPayload(icmp6); ethernet.setPayload(ipv6); return ethernet; } ",
        "test_tgt": "@Test public void testBuildNdpSolicit()throws Exception { final Ethernet ethPacket = NeighborSolicitation.buildNdpSolicit(TARGET_IP, SRC_IP, DST_IP, SRC_MAC, DST_MAC, VLAN_ID); assertTrue(ethPacket.getDestinationMAC().equals(DST_MAC)); assertTrue(ethPacket.getSourceMAC().equals(SRC_MAC)); assertTrue(ethPacket.getEtherType() == Ethernet.TYPE_IPV6); assertTrue(ethPacket.getVlanID() == VLAN_ID.id()); final IPv6 ipPacket = (IPv6)ethPacket.getPayload(); assertArrayEquals(ipPacket.getSourceAddress(), SRC_IP.toOctets()); assertArrayEquals(ipPacket.getDestinationAddress(), DST_IP.toOctets()); final ICMP6 icmp6Packet = (ICMP6)ipPacket.getPayload(); final NeighborSolicitation nsPacket = (NeighborSolicitation)icmp6Packet.getPayload(); assertArrayEquals(nsPacket.getTargetAddress(), TARGET_IP.toOctets()); assertEquals(\"Non-DAD NS should have 1 option\", 1, nsPacket.getOptions().size()); assertEquals(\"The option should be SRC_LL_ADDR type\", TYPE_SOURCE_LL_ADDRESS, nsPacket.getOptions().stream().findFirst().get().type()); } "
    },
    {
        "test_src": "@Test public void create() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname)); query(_DB_EXISTS.args(dbname), true); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(dbname) + \",\" + _DB_CREATE.args(dbname), Err.BXDB_CREATE); query(_DB_CREATE.args(dbname, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(dbname + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(dbname, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(dbname + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(dbname, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(dbname, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + dbname + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + dbname + \"' || $i\")); error(_DB_CREATE.args(dbname, \"\"), Err.WHICHRES); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(dbname)); error(_DB_CREATE.args(dbname) + \",\" + _DB_DROP.args(dbname), Err.BXDB_OPEN); query(_DB_CREATE.args(dbname, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(dbname)); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(dbname) + \",\" + _DB_DROP.args(dbname)); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(dbname)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(dbname) + \"//updindex/text()\", b ? \"ON\" : \"OFF\"); } assertEquals(context.options.is(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':'' }\")); } error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'xyz':'abc' }\"), Err.BASX_OPTIONS); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'maxlen':-1 }\"), Err.BASX_VALUE); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'maxlen':'a' }\"), Err.BASX_VALUE); } ",
        "focal_tgt": "public static synchronized Data create(final IO source, final boolean single, final Context ctx)throws IOException { if( ! source.exists() || single && source.isDir())throw new BaseXException(RES_NOT_FOUND_X, source); if( ! ctx.options.bool(MainOptions.FORCECREATE))return CreateDB.mainMem(source, ctx); final String nm = source.dbname(); final DirParser dp = new DirParser(source, ctx.options, ctx.globalopts.dbpath(nm)); return CreateDB.create(nm, dp, ctx); } ",
        "focal_src": "public static synchronized Data create(final IO source, final boolean single, final Context ctx)throws IOException { if( ! source.exists() || single && source.isDir())throw new BaseXException(RES_NOT_FOUND_X, source); if( ! ctx.options.is(MainOptions.FORCECREATE))return CreateDB.mainMem(source, ctx); final String nm = source.dbname(); final DirParser dp = new DirParser(source, ctx.options, ctx.globalopts.dbpath(nm)); return CreateDB.create(nm, dp, ctx); } ",
        "test_tgt": "@Test public void create() { final String dbname = NAME + \"DBCreate\"; query(_DB_CREATE.args(dbname)); query(_DB_EXISTS.args(dbname), true); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(dbname) + \",\" + _DB_CREATE.args(dbname), Err.BXDB_CREATE); query(_DB_CREATE.args(dbname, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(dbname + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(dbname, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(dbname + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(dbname, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(dbname, \"()\", \"1.xml\"), Err.BXDB_CREATEARGS); error(_DB_CREATE.args(dbname, \"(<a/>,<b/>)\", \"1.xml\"), Err.BXDB_CREATEARGS); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + dbname + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + dbname + \"' || $i\")); error(_DB_CREATE.args(dbname, \"\"), Err.WHICHRES); error(_DB_CREATE.args(\"\"), Err.BXDB_NAME); query(_DB_DROP.args(dbname)); error(_DB_CREATE.args(dbname) + \",\" + _DB_DROP.args(dbname), Err.BXDB_OPEN); query(_DB_CREATE.args(dbname, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(dbname)); query(_DB_CREATE.args(dbname, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(dbname) + \",\" + _DB_DROP.args(dbname)); query(_DB_OPEN.args(dbname) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(dbname)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(dbname) + \"//updindex/text()\", b ? \"ON\" : \"OFF\"); } assertEquals(context.options.bool(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(dbname, \"()\", \"()\", \" { '\" + k + \"':'' }\")); } error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'xyz':'abc' }\"), Err.BASX_OPTIONS); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'maxlen':-1 }\"), Err.BASX_VALUE); error(_DB_CREATE.args(dbname, \"()\", \"()\", \" { 'maxlen':'a' }\"), Err.BASX_VALUE); } "
    },
    {
        "test_src": "@Test public void decode() { result = URIUtil.decode(\"%E9%87%91%E6%80%BB%EF%BC%8C%E4%BD%A0%E6%83%B3%E6%80%8E%E4%B9%88%E4%B9%88%EF%BC%8C%E5%B0%B1%E6%80%8E%E4%B9%88%E4%B9%88\", CharsetType.UTF8); LOGGER.info(result); } ",
        "focal_tgt": "public static String decode(String value, String charsetType) { if(Validator.isNullOrEmpty(value)) { return StringUtils.EMPTY; } if(Validator.isNullOrEmpty(charsetType)) { return value; } try { return URLDecoder.decode(value, charsetType); } catch(UnsupportedEncodingException e) { LOGGER.error(\"UnsupportedEncodingException:\", e); throw new URIParseException(e); } } ",
        "focal_src": "public static String decode(String value, String charsetType) { if(Validator.isNullOrEmpty(charsetType)) { return value; } try { return URLDecoder.decode(value, charsetType); } catch(UnsupportedEncodingException e) { LOGGER.error(\"UnsupportedEncodingException:\", e); throw new URIParseException(e); } } ",
        "test_tgt": "@Test public void decode() { LOGGER.info(URIUtil.decode(\"%E9%87%91%E6%80%BB%EF%BC%8C%E4%BD%A0%E6%83%B3%E6%80%8E%E4%B9%88%E4%B9%88%EF%BC%8C%E5%B0%B1%E6%80%8E%E4%B9%88%E4%B9%88\", CharsetType.UTF8)); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should not return concepts with matching names that are voided\", method = \"getConcepts(String,Locale,null,List<QConceptClass;>,List<QConceptDatatype;>)\")public void getConcepts_shouldNotReturnConceptsWithMatchingNamesThatAreVoided()throws Exception { Concept concept = dao.getConcept(7); Context.getConceptService().updateConceptIndex(concept); Assert.assertEquals(0, dao.getConcepts(\"VOIDED\", null, false, new ArrayList < ConceptClass > (), new ArrayList < ConceptDatatype > ()).size()); } ",
        "focal_tgt": "public List < Concept > getConcepts(final String name, final Locale loc, final boolean searchOnPhrase, final List < ConceptClass > classes, final List < ConceptDatatype > datatypes)throws DAOException { final List < Concept > concepts = new LuceneQueryBuilder < Concept > (sessionFactory.getCurrentSession()) { @Override protected org.apache.lucene.search.Query prepareQuery()throws ParseException { StringBuilder query = new StringBuilder(); final Locale locale; if(loc == null) { locale = Context.getLocale(); } else { locale = loc; } if( ! StringUtils.isBlank(name)) { if(searchOnPhrase) { String searchPhrase = newRequirePartialWordsSearchPhrase(name); String search = newNamesQuery(locale, searchPhrase, true); query.append(search); } else { String search = newNamesQuery(locale, QueryParser.escape(name), false); query.append(search); } } query.append(\" +retired:false\"); if(classes != null && ! classes.isEmpty()) { String ids = transformToIds(classes); query.append(\" +conceptClass.conceptClassId:(\").append(ids).append(\")\"); } if(datatypes != null && ! datatypes.isEmpty()) { String ids = transformToIds(datatypes); query.append(\" +datatype.conceptDatatypeId:(\").append(ids).append(\")\"); } return newQueryParser().parse(query.toString()); } }.list(); return concepts; } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public List < Concept > getConcepts(String name, Locale loc, boolean searchOnPhrase, List < ConceptClass > classes, List < ConceptDatatype > datatypes)throws DAOException { Criteria criteria = sessionFactory.getCurrentSession().createCriteria(Concept.class); criteria.add(Restrictions.eq(\"retired\", false)); if( ! StringUtils.isBlank(name)) { if(loc == null)loc = Context.getLocale(); String caseSensitiveNamesInConceptNameTable = Context.getAdministrationService().getGlobalProperty(OpenmrsConstants.GP_CASE_SENSITIVE_NAMES_IN_CONCEPT_NAME_TABLE, \"true\"); criteria.createAlias(\"names\", \"names\"); MatchMode matchmode = MatchMode.EXACT; if(searchOnPhrase)matchmode = MatchMode.ANYWHERE; if(Boolean.valueOf(caseSensitiveNamesInConceptNameTable)) { criteria.add(Restrictions.ilike(\"names.name\", name, matchmode)); } else { if(searchOnPhrase) { criteria.add(Restrictions.like(\"names.name\", name, matchmode)); } else { criteria.add(Restrictions.eq(\"names.name\", name)); } } criteria.add(Restrictions.eq(\"names.voided\", false)); String language = loc.getLanguage(); if(language.length() > 2) { criteria.add(Restrictions.or(Restrictions.eq(\"names.locale\", loc), Restrictions.eq(\"names.locale\", new Locale(loc.getLanguage().substring(0, 2))))); } else { } } if(classes.size() > 0)criteria.add(Restrictions.in(\"conceptClass\", classes)); if(datatypes.size() > 0)criteria.add(Restrictions.in(\"datatype\", datatypes)); return criteria.list(); } ",
        "test_tgt": "@Test@Verifies(value = \"should not return concepts with matching names that are voided\", method = \"getConcepts(String,Locale,null,List<QConceptClass;>,List<QConceptDatatype;>)\")public void getConcepts_shouldNotReturnConceptsWithMatchingNamesThatAreVoided()throws Exception { Concept concept = dao.getConcept(7); Context.getConceptService().updateConceptIndex(concept); List < Concept > concepts = dao.getConcepts(\"VOIDED\", null, false, new ArrayList < ConceptClass > (), new ArrayList < ConceptDatatype > ()); Assert.assertEquals(0, concepts.size()); } "
    },
    {
        "test_src": "@Test public void testApply() { IPWhitelistPolicy policy = new IPWhitelistPolicy(); String json = \"{\" + \" \\\"ipList\\\" : [\" + \" \\\"1.2.3.4\\\",\" + \" \\\"3.4.5.6\\\",\" + \" \\\"10.0.0.11\\\"\" + \" ]\" + \"}\"; Object config = policy.parseConfiguration(json); ServiceRequest request = new ServiceRequest(); request.setType(\"GET\"); request.setApiKey(\"12345\"); request.setRemoteAddr(\"1.2.3.4\"); request.setDestination(\"/\"); IPolicyContext context = Mockito.mock(IPolicyContext.class); IPolicyChain chain = Mockito.mock(IPolicyChain.class); policy.apply(request, context, config, chain); Mockito.verify(chain).doApply(request); final PolicyFailure failure = new PolicyFailure(); Mockito.when(context.getComponent(IPolicyFailureFactoryComponent.class)).thenReturn(new IPolicyFailureFactoryComponent() { @Override public PolicyFailure createFailure(PolicyFailureType type, int failureCode, String message) { return failure; } }); chain = Mockito.mock(IPolicyChain.class); request.setRemoteAddr(\"9.8.7.6\"); policy.apply(request, context, config, chain); Mockito.verify(chain).doFailure(failure); } ",
        "focal_tgt": "@Override public void apply(ServiceRequest request, IPolicyContext context, IPolicyChain < ServiceRequest > chain) { context.setAttribute(\"X-Conversation-Success\", \"true\"); chain.doApply(request); } ",
        "focal_src": "@Override public void apply(ServiceRequest request, IPolicyContext context, Object config, IPolicyChain chain) { context.setAttribute(\"X-Conversation-Success\", \"true\"); chain.doApply(request); } ",
        "test_tgt": "@Test public void testApply() { IPWhitelistPolicy policy = new IPWhitelistPolicy(); String json = \"{\" + \" \\\"ipList\\\" : [\" + \" \\\"1.2.3.4\\\",\" + \" \\\"3.4.5.6\\\",\" + \" \\\"10.0.0.11\\\"\" + \" ]\" + \"}\"; Object config = policy.parseConfiguration(json); policy.setConfiguration(config); ServiceRequest request = new ServiceRequest(); request.setType(\"GET\"); request.setApiKey(\"12345\"); request.setRemoteAddr(\"1.2.3.4\"); request.setDestination(\"/\"); IPolicyContext context = Mockito.mock(IPolicyContext.class); IPolicyChain < ServiceRequest > chain = Mockito.mock(IPolicyChain.class); policy.apply(request, context, chain); Mockito.verify(chain).doApply(request); final PolicyFailure failure = new PolicyFailure(); Mockito.when(context.getComponent(IPolicyFailureFactoryComponent.class)).thenReturn(new IPolicyFailureFactoryComponent() { @Override public PolicyFailure createFailure(PolicyFailureType type, int failureCode, String message) { return failure; } }); chain = Mockito.mock(IPolicyChain.class); request.setRemoteAddr(\"9.8.7.6\"); policy.apply(request, context, chain); Mockito.verify(chain).doFailure(failure); } "
    },
    {
        "test_src": "@Test public void testRollback()throws SQLException { sqlSessionTemplate.rollback(); assertNoRollback(); sqlSessionTemplate.rollback(true); assertNoRollback(); sqlSessionTemplate.rollback(false); assertNoRollback(); connection.close(); } ",
        "focal_tgt": "public void rollback(boolean force) { throw new UnsupportedOperationException(\"Manual rollback is not allowed over a Spring managed SqlSessio\"); } ",
        "focal_src": "public void rollback(boolean force) { } ",
        "test_tgt": "@Test(expected = UnsupportedOperationException.class)public void testRollback()throws SQLException { try { sqlSessionTemplate.rollback(); } finally { connection.close(); } } "
    },
    {
        "test_src": "@Test public void run()throws Exception { context.prop.set(Prop.TEXTINDEX, false); context.prop.set(Prop.ATTRINDEX, false); context.prop.set(Prop.AUTOFLUSH, false); new CreateDB(NAME).execute(context); for(int i = 0; i < NQUERIES; i ++ ) { new Add(i + IO.XMLSUFFIX, \"<a/>\").execute(context); } for(int i = 0; i < NQUERIES; i ++ ) { new Replace(i + IO.XMLSUFFIX, \"<a/>\").execute(context); } new DropDB(NAME).execute(context); } ",
        "focal_tgt": "public boolean run(final Context ctx, final OutputStream os) { perf = new Performance(); context = ctx; options = ctx.options; globalopts = ctx.globalopts; out = PrintOutput.get(os); try { return run(); } catch(final ProcException ex) { abort(); return error(INTERRUPTED); } catch(final Throwable ex) { Performance.gc(2); abort(); if(ex instanceof OutOfMemoryError) { Util.debug(ex); return error(OUT_OF_MEM + (createWrite() ? H_OUT_OF_MEM : \"\")); } return error(Util.bug(ex) + NL + info.toString()); } finally { try { if(out != null)out.flush(); } catch(final IOException ignored) { } } } ",
        "focal_src": "public boolean run(final Context ctx, final OutputStream os) { perf = new Performance(); context = ctx; prop = ctx.prop; mprop = ctx.mprop; out = PrintOutput.get(os); try { return run(); } catch(final ProcException ex) { abort(); return error(INTERRUPTED); } catch(final Throwable ex) { Performance.gc(2); abort(); if(ex instanceof OutOfMemoryError) { Util.debug(ex); return error(OUT_OF_MEM + (createWrite() ? H_OUT_OF_MEM : \"\")); } return error(Util.bug(ex) + NL + info.toString()); } finally { try { if(out != null)out.flush(); } catch(final IOException ignored) { } } } ",
        "test_tgt": "@Test public void run()throws Exception { context.options.set(Options.TEXTINDEX, false); context.options.set(Options.ATTRINDEX, false); context.options.set(Options.AUTOFLUSH, false); new CreateDB(NAME).execute(context); for(int i = 0; i < NQUERIES; i ++ ) { new Add(i + IO.XMLSUFFIX, \"<a/>\").execute(context); } for(int i = 0; i < NQUERIES; i ++ ) { new Replace(i + IO.XMLSUFFIX, \"<a/>\").execute(context); } new DropDB(NAME).execute(context); } "
    },
    {
        "test_src": "@Test public void testSleep() { ThreadUtil.sleep(1000); } ",
        "focal_tgt": "public static void sleep(long millis) { try { Thread.sleep(millis); } catch(InterruptedException e) { throw new UncheckedInterruptedException(e); } } ",
        "focal_src": "public static void sleep(long millisecond) { try { Thread.sleep(millisecond); } catch(InterruptedException e) { noOp(); } } ",
        "test_tgt": "@Test public void testSleep() { StopWatch watch = new StopWatch(); watch.start(); ThreadUtils.sleep(1000); watch.stop(); assertThat(watch.getTime()).isGreaterThanOrEqualTo(1000); assertThat(watch.getTime()).isLessThan(3000); } "
    },
    {
        "test_src": "@Test public void testCreateJob()throws GenieException { final String name = UUID.randomUUID().toString(); final String user = UUID.randomUUID().toString(); final String version = UUID.randomUUID().toString(); final String commandArgs = UUID.randomUUID().toString(); final List < ClusterCriteria > clusterCriterias = new ArrayList < > (); final ClusterCriteria criteria1 = new ClusterCriteria(); final Set < String > tags1 = new HashSet < > (); tags1.add(UUID.randomUUID().toString()); tags1.add(UUID.randomUUID().toString()); criteria1.setTags(tags1); clusterCriterias.add(criteria1); final ClusterCriteria criteria2 = new ClusterCriteria(); final Set < String > tags2 = new HashSet < > (); tags2.add(UUID.randomUUID().toString()); tags2.add(UUID.randomUUID().toString()); criteria2.setTags(tags2); clusterCriterias.add(criteria2); final Set < String > commandCriteria = new HashSet < > (); commandCriteria.add(UUID.randomUUID().toString()); commandCriteria.add(UUID.randomUUID().toString()); final Job created = this.service.createJob(new Job(user, name, commandArgs, commandCriteria, clusterCriterias, version)); final Job job = this.service.getJob(created.getId()); Assert.assertNotNull(job.getId()); Assert.assertEquals(name, job.getName()); Assert.assertEquals(user, job.getUser()); Assert.assertEquals(version, job.getVersion()); Assert.assertEquals(commandArgs, job.getCommandArgs()); Assert.assertEquals(clusterCriterias.size(), job.getClusterCriterias().size()); Assert.assertEquals(commandCriteria.size(), job.getCommandCriteria().size()); Assert.assertEquals(commandCriteria.size(), job.getCommandCriteriaString().split(\",\").length); Assert.assertEquals(JobStatus.INIT, job.getStatus()); Assert.assertNotNull(job.getHostName()); Assert.assertNotNull(job.getOutputURI()); Assert.assertNotNull(job.getKillURI()); } ",
        "focal_tgt": "@Override@Transactional public Job createJob(@NotNull(message = \"No job entered. Unable to create.\")@Valid final Job job)throws GenieException { if(StringUtils.isNotEmpty(job.getId()) && this.jobRepo.exists(job.getId())) { throw new GenieConflictException(\"A job with id \" + job.getId() + \" already exists. Unable to save.\"); } job.setJobStatus(JobStatus.INIT, \"Initializing job\"); try { final Job persistedJob = this.jobRepo.save(job); final String hostName = NetUtil.getHostName(); persistedJob.setHostName(hostName); persistedJob.setOutputURI(getEndPoint(hostName) + \"/\" + JOB_DIR_PREFIX + \"/\" + persistedJob.getId()); persistedJob.setKillURI(getEndPoint(hostName) + \"/\" + JOB_RESOURCE_PREFIX + \"/\" + persistedJob.getId()); this.stats.incrGenieJobSubmissions(); return persistedJob; } catch(final RuntimeException e) { LOG.error(\"Can't create entity in the database\", e); throw new GenieServerException(e); } } ",
        "focal_src": "@Override@Transactional public Job createJob(final Job job)throws GenieException { if(StringUtils.isNotEmpty(job.getId()) && this.jobRepo.exists(job.getId())) { throw new GenieConflictException(\"A job with id \" + job.getId() + \" already exists. Unable to save.\"); } job.validate(); job.setJobStatus(JobStatus.INIT, \"Initializing job\"); try { final Job persistedJob = this.jobRepo.save(job); final String hostName = NetUtil.getHostName(); persistedJob.setHostName(hostName); persistedJob.setOutputURI(getEndPoint(hostName) + \"/\" + JOB_DIR_PREFIX + \"/\" + persistedJob.getId()); persistedJob.setKillURI(getEndPoint(hostName) + \"/\" + JOB_RESOURCE_PREFIX + \"/\" + persistedJob.getId()); this.stats.incrGenieJobSubmissions(); return persistedJob; } catch(final RuntimeException e) { LOG.error(\"Can't create entity in the database\", e); throw new GenieServerException(e); } } ",
        "test_tgt": "@Test public void testCreateJob()throws GenieException { final String name = UUID.randomUUID().toString(); final String user = UUID.randomUUID().toString(); final String version = UUID.randomUUID().toString(); final String commandArgs = UUID.randomUUID().toString(); final List < ClusterCriteria > clusterCriterias = new ArrayList < > (); final ClusterCriteria criteria1 = new ClusterCriteria(); final Set < String > tags1 = new HashSet < > (); tags1.add(UUID.randomUUID().toString()); tags1.add(UUID.randomUUID().toString()); criteria1.setTags(tags1); clusterCriterias.add(criteria1); final ClusterCriteria criteria2 = new ClusterCriteria(); final Set < String > tags2 = new HashSet < > (); tags2.add(UUID.randomUUID().toString()); tags2.add(UUID.randomUUID().toString()); criteria2.setTags(tags2); clusterCriterias.add(criteria2); final Set < String > commandCriteria = new HashSet < > (); commandCriteria.add(UUID.randomUUID().toString()); commandCriteria.add(UUID.randomUUID().toString()); final Job created = this.service.createJob(new Job(user, name, version, commandArgs, commandCriteria, clusterCriterias)); final Job job = this.service.getJob(created.getId()); Assert.assertNotNull(job.getId()); Assert.assertEquals(name, job.getName()); Assert.assertEquals(user, job.getUser()); Assert.assertEquals(version, job.getVersion()); Assert.assertEquals(commandArgs, job.getCommandArgs()); Assert.assertEquals(clusterCriterias.size(), job.getClusterCriterias().size()); Assert.assertEquals(commandCriteria.size(), job.getCommandCriteria().size()); Assert.assertEquals(commandCriteria.size(), job.getCommandCriteriaString().split(\",\").length); Assert.assertEquals(JobStatus.INIT, job.getStatus()); Assert.assertNotNull(job.getHostName()); Assert.assertNotNull(job.getOutputURI()); Assert.assertNotNull(job.getKillURI()); } "
    },
    {
        "test_src": "@Test public void allocateBlockTest()throws Exception { TachyonConf conf = new TachyonConf(); conf.set(Constants.WORKER_ALLOCATOR_CLASS, GreedyAllocator.class.getName()); mAllocator = Allocator.Factory.create(conf, mManagerView); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"MEM\", 0); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc2, 1000, true, \"SSD\", 0); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc2, 1500, true, \"SSD\", 1); assertTempBlockMeta(mAllocator, mAnyTierLoc, 1000, true, \"SSD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 1000, true, \"HDD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 2000, true, \"HDD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"MEM\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"SSD\", 1); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc3, 1000, true, \"HDD\", 1); assertTempBlockMeta(mAllocator, mAnyTierLoc, 700, true, \"HDD\", 1); } ",
        "focal_tgt": "private StorageDirView allocateBlock(long sessionId, long blockSize, BlockStoreLocation location) { Preconditions.checkNotNull(location); if(location.equals(BlockStoreLocation.anyTier())) { int tierIndex = 0; for(int i = 0; i < mManagerView.getTierViews().size(); i ++ ) { StorageTierView tierView = mManagerView.getTierViews().get(tierIndex); int dirViewIndex = getNextAvailDirInTier(tierView, blockSize); if(dirViewIndex >= 0) { mTierAliasToLastDirMap.put(tierView.getTierViewAlias(), dirViewIndex); return tierView.getDirView(dirViewIndex); } else { tierIndex ++ ; } } } else if(location.equals(BlockStoreLocation.anyDirInTier(location.tierAlias()))) { StorageTierView tierView = mManagerView.getTierView(location.tierAlias()); int dirViewIndex = getNextAvailDirInTier(tierView, blockSize); if(dirViewIndex >= 0) { mTierAliasToLastDirMap.put(tierView.getTierViewAlias(), dirViewIndex); return tierView.getDirView(dirViewIndex); } } else { StorageTierView tierView = mManagerView.getTierView(location.tierAlias()); StorageDirView dirView = tierView.getDirView(location.dir()); if(dirView.getAvailableBytes() >= blockSize) { return dirView; } } return null; } ",
        "focal_src": "private StorageDirView allocateBlock(long sessionId, long blockSize, BlockStoreLocation location) { Preconditions.checkNotNull(location); if(location.equals(BlockStoreLocation.anyTier())) { int tierIndex = 0; for(int i = 0; i < mManagerView.getTierViews().size(); i ++ ) { StorageTierView tierView = mManagerView.getTierViews().get(tierIndex); int dirViewIndex = getNextAvailDirInTier(tierView, blockSize); if(dirViewIndex >= 0) { mTierToLastDirMap.put(tierView, dirViewIndex); return tierView.getDirView(dirViewIndex); } else { tierIndex ++ ; } } } else if(location.equals(BlockStoreLocation.anyDirInTier(location.tierAlias()))) { StorageTierView tierView = mManagerView.getTierView(location.tierAlias()); int dirViewIndex = getNextAvailDirInTier(tierView, blockSize); if(dirViewIndex >= 0) { mTierToLastDirMap.put(tierView, dirViewIndex); return tierView.getDirView(dirViewIndex); } } else { StorageTierView tierView = mManagerView.getTierView(location.tierAlias()); StorageDirView dirView = tierView.getDirView(location.dir()); if(dirView.getAvailableBytes() >= blockSize) { return dirView; } } return null; } ",
        "test_tgt": "@Test public void allocateBlockTest()throws Exception { TachyonConf conf = new TachyonConf(); conf.set(Constants.WORKER_ALLOCATOR_CLASS, GreedyAllocator.class.getName()); mAllocator = Allocator.Factory.create(conf, getManagerView()); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"MEM\", 0); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc2, 1000, true, \"SSD\", 0); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc2, 1500, true, \"SSD\", 1); assertTempBlockMeta(mAllocator, mAnyTierLoc, 1000, true, \"SSD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 1000, true, \"HDD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 2000, true, \"HDD\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"MEM\", 0); assertTempBlockMeta(mAllocator, mAnyTierLoc, 500, true, \"SSD\", 1); assertTempBlockMeta(mAllocator, mAnyDirInTierLoc3, 1000, true, \"HDD\", 1); assertTempBlockMeta(mAllocator, mAnyTierLoc, 700, true, \"HDD\", 1); } "
    },
    {
        "test_src": "@Override@Test@Ignore public void clearStorageTest()throws Exception { } ",
        "focal_tgt": "public void clearStorage()throws BackendException { openStores.clear(); final String lp = \"ClearStorage: \"; CTConnection conn = null; try { conn = pool.borrowObject(SYSTEM_KS); Cassandra.Client client = conn.getClient(); KsDef ksDef; try { client.set_keyspace(keySpaceName); ksDef = client.describe_keyspace(keySpaceName); } catch(NotFoundException e) { log.debug(lp + \"Keyspace {} does not exist, not attempting to truncate.\", keySpaceName); return; } catch(InvalidRequestException e) { log.debug(lp + \"InvalidRequestException when attempting to describe keyspace {}, not attempting to truncate.\", keySpaceName); return; } if(null == ksDef) { log.debug(lp + \"Received null KsDef for keyspace {}; not truncating its CFs\", keySpaceName); return; } if(this.storageConfig.get(GraphDatabaseConfiguration.DROP_ON_CLEAR)) { client.system_drop_keyspace(keySpaceName); pool.clear(); } else { final List < CfDef > columnFamilyDefinitions = ksDef.getCf_defs(); if(null == columnFamilyDefinitions) { log.debug(lp + \"Received empty CfDef list for keyspace {}; not truncating CFs\", keySpaceName); return; } for(final CfDef cfDef : ksDef.getCf_defs()) { client.truncate(cfDef.name); log.info(lp + \"Truncated CF {} in keyspace {}\", cfDef.name, keySpaceName); } } } catch(Exception e) { throw new TemporaryBackendException(e); } finally { if(conn != null && conn.getClient() != null) { try { conn.getClient().set_keyspace(SYSTEM_KS); } catch(TException e) { log.warn(\"Failed to reset keyspace\", e); } } pool.returnObjectUnsafe(SYSTEM_KS, conn); } } ",
        "focal_src": "public void clearStorage()throws BackendException { openStores.clear(); final String lp = \"ClearStorage: \"; CTConnection conn = null; try { conn = pool.borrowObject(SYSTEM_KS); Cassandra.Client client = conn.getClient(); KsDef ksDef; try { client.set_keyspace(keySpaceName); ksDef = client.describe_keyspace(keySpaceName); } catch(NotFoundException e) { log.debug(lp + \"Keyspace {} does not exist, not attempting to truncate.\", keySpaceName); return; } catch(InvalidRequestException e) { log.debug(lp + \"InvalidRequestException when attempting to describe keyspace {}, not attempting to truncate.\", keySpaceName); return; } if(null == ksDef) { log.debug(lp + \"Received null KsDef for keyspace {}; not truncating its CFs\", keySpaceName); return; } if(this.storageConfig.get(GraphDatabaseConfiguration.DROP_ON_CLEAR)) { client.system_drop_keyspace(keySpaceName); pool.clear(); } else { final List < CfDef > columnFamilyDefinitions = ksDef.getCf_defs(); if(null == columnFamilyDefinitions) { log.debug(lp + \"Received empty CfDef list for keyspace {}; not truncating CFs\", keySpaceName); return; } for(final CfDef cfDef : ksDef.getCf_defs()) { client.truncate(cfDef.name); log.info(lp + \"Truncated CF {} in keyspace {}\", cfDef.name, keySpaceName); } } } catch(Exception e) { throw new TemporaryBackendException(e); } finally { if(conn != null && conn.getClient() != null) { try { conn.getClient().set_keyspace(SYSTEM_KS); } catch(InvalidRequestException e) { log.warn(\"Failed to reset keyspace\", e); } catch(TException e) { log.warn(\"Failed to reset keyspace\", e); } } pool.returnObjectUnsafe(SYSTEM_KS, conn); } } ",
        "test_tgt": "@Override@Test@Ignore public void clearStorageTest()throws Exception { super.clearStorageTest(); } "
    },
    {
        "test_src": "@Test public void parse()throws Exception { context.options.set(MainOptions.STRIPNS, true); context.options.set(MainOptions.SERIALIZER, \"indent=no\"); final String doc = \"<e xmlns='A'><b:f xmlns:b='B'/></e>\"; for(final boolean b : new boolean[] { false, true }) { context.options.set(MainOptions.INTPARSE, b); new CreateDB(NAME, doc).execute(context); String result = new XQuery(\".\").execute(context); assertEquals(\"<e><f/></e>\", result); result = new XQuery(\"e/f\").execute(context); assertEquals(\"<f/>\", result); } } ",
        "focal_tgt": "public void parse(final Item item, final Options options, final boolean ignore)throws QueryException { if(item == null)return; if(item instanceof Map) { final Map map = (Map)item; final ValueIter vi = map.keys().iter(); for(Item it; (it = vi.next()) != null; ) { if( ! (it instanceof AStr))FUNCMP.thrw(info, map.description(), AtomType.STR, it.type); final Value v = map.get(it, info); if( ! v.isItem())FUNCMP.thrw(info, map.description(), AtomType.ITEM, v); final String key = string(it.string(null)); final String val = string(((Item)v).string(info)); if( ! options.set(key, val) && options.predefined())ELMOPTION.thrw(info, key); } } else { if( ! test.eq(item))ELMMAPTYPE.thrw(info, root, item.type); final AxisIter ai = ((ANode)item).children(); for(ANode n; (n = ai.next()) != null; ) { if(n.type != NodeType.ELM)continue; final QNm qn = n.qname(); if( ! eq(qn.uri(), root.uri())) { if(ignore)continue; ELMOPTION.thrw(info, n); } final String key = string(qn.local()); byte[]val = n.attribute(VALUE); if(val == null)val = n.string(); if( ! options.set(key, string(val)) && options.predefined())ELMOPTION.thrw(info, key); } } } ",
        "focal_src": "public void parse(final Item item, final Options options, final boolean ignore)throws QueryException { if(item == null)return; if(item instanceof Map) { final Map map = (Map)item; final ValueIter vi = map.keys().iter(); for(Item it; (it = vi.next()) != null; ) { if( ! (it instanceof AStr))FUNCMP.thrw(info, map.description(), AtomType.STR, it.type); final Value v = map.get(it, info); if( ! v.isItem())FUNCMP.thrw(info, map.description(), AtomType.ITEM, v); final String key = Token.string(it.string(null)); final String val = Token.string(((Item)v).string(info)); if( ! options.set(key, val, true) && options.predefined())ELMOPTION.thrw(info, key); } } else { if( ! test.eq(item))ELMMAPTYPE.thrw(info, root, item.type); final AxisIter ai = ((ANode)item).children(); for(ANode n; (n = ai.next()) != null; ) { if(n.type != NodeType.ELM)continue; final QNm qn = n.qname(); if( ! eq(qn.uri(), root.uri())) { if(ignore)continue; ELMOPTION.thrw(info, n); } final String key = string(qn.local()); byte[]val = n.attribute(VALUE); if(val == null)val = n.string(); if( ! options.set(key, string(val), true) && options.predefined())ELMOPTION.thrw(info, key); } } } ",
        "test_tgt": "@Test public void parse()throws Exception { context.options.bool(MainOptions.STRIPNS, true); context.options.string(MainOptions.SERIALIZER, \"indent=no\"); final String doc = \"<e xmlns='A'><b:f xmlns:b='B'/></e>\"; for(final boolean b : new boolean[] { false, true }) { context.options.bool(MainOptions.INTPARSE, b); new CreateDB(NAME, doc).execute(context); String result = new XQuery(\".\").execute(context); assertEquals(\"<e><f/></e>\", result); result = new XQuery(\"e/f\").execute(context); assertEquals(\"<f/>\", result); } } "
    },
    {
        "test_src": "@Test public void testLogCurrentState()throws Exception { long lockTimeoutMs = LockRequest.DEFAULT_LOCK_TIMEOUT.toMillis(); long logCurrentStateCallTimeoutMs = 2 * 5000L; LockRequest request1 = LockRequest.builder(ImmutableSortedMap.of(lock1, LockMode.READ)).doNotBlock().build(); long currentTimeMs = System.currentTimeMillis(); LockResponse response1 = server.lockWithFullLockResponse(LockClient.ANONYMOUS, request1); Assert.assertTrue(response1.success()); Assert.assertTrue(response1.getLockHolders().isEmpty()); HeldLocksToken token1 = response1.getToken(); Assert.assertNotNull(token1); Assert.assertEquals(LockClient.ANONYMOUS, token1.getClient()); Assert.assertEquals(request1.getLockDescriptors(), token1.getLockDescriptors()); Assert.assertTrue(currentTimeMs + lockTimeoutMs <= token1.getExpirationDateMs()); Assert.assertTrue(token1.getExpirationDateMs() <= System.currentTimeMillis() + lockTimeoutMs); executor.submit(new Callable < Void > () { @Override public Void call()throws Exception { barrier.await(); LockRequest request2 = LockRequest.builder(ImmutableSortedMap.of(lock1, LockMode.WRITE)).build(); LockResponse response2 = server.lockWithFullLockResponse(LockClient.ANONYMOUS, request2); HeldLocksToken validToken = response2.getToken(); Assert.assertNotNull(validToken); server.unlock(validToken); return null; } }); barrier.await(); Thread.sleep(500); Future < ? > logCallFuture = executor.submit(new Callable < Void > () { @Override public Void call() { server.logCurrentState(); return null; } }); try { logCallFuture.get(logCurrentStateCallTimeoutMs, TimeUnit.MILLISECONDS); } catch(TimeoutException e) { Assert.fail(); } } ",
        "focal_tgt": "@Override public void logCurrentState() { StringBuilder logString = getGeneralLockStats(); log.info(\"Current State: {}\", logString.toString()); try { logAllHeldAndOutstandingLocks(); } catch(IOException e) { log.error(\"Can't dump state to Yaml: [{}]\", e); throw new IllegalStateException(e); } } ",
        "focal_src": "@Override public void logCurrentState() { StringBuilder logString = new StringBuilder(); logString.append(\"Logging current state. Time = \").append(currentTimeMillis()).append(\"\\n\"); logString.append(\"isStandaloneServer = \").append(isStandaloneServer).append(\"\\n\"); logString.append(\"maxAllowedLockTimeout = \").append(maxAllowedLockTimeout).append(\"\\n\"); logString.append(\"maxAllowedClockDrift = \").append(maxAllowedClockDrift).append(\"\\n\"); logString.append(\"maxAllowedBlockingDuration = \").append(maxAllowedBlockingDuration).append(\"\\n\"); logString.append(\"randomBitCount = \").append(randomBitCount).append(\"\\n\"); for(Pair < String, ? extends Collection < ? > > nameValuePair : ImmutableList.of(Pair.create(\"descriptorToLockMap\", descriptorToLockMap.asMap().entrySet()), Pair.create(\"outstandingLockRequestMultimap\", outstandingLockRequestMultimap.asMap().entrySet()), Pair.create(\"heldLocksTokenMap\", heldLocksTokenMap.entrySet()), Pair.create(\"heldLocksGrantMap\", heldLocksGrantMap.entrySet()), Pair.create(\"lockTokenReaperQueue\", queueToOrderedList(lockTokenReaperQueue)), Pair.create(\"lockGrantReaperQueue\", queueToOrderedList(lockGrantReaperQueue)), Pair.create(\"lockClientMultimap\", lockClientMultimap.asMap().entrySet()), Pair.create(\"versionIdMap\", versionIdMap.asMap().entrySet()))) { Collection < ? > elements = nameValuePair.getRhSide(); logString.append(nameValuePair.getLhSide()).append(\".size() = \").append(elements.size()).append(\"\\n\"); if(elements.size() > MAX_LOCKS_TO_LOG) { logString.append(\"WARNING: Only logging the first \").append(MAX_LOCKS_TO_LOG).append(\" locks, \"); logString.append(\"logging more is likely to OOM or slow down lock server to the point of failure\"); } for(Object element : Iterables.limit(elements, MAX_LOCKS_TO_LOG)) { logString.append(element).append(\"\\n\"); } } logString.append(\"Finished logging current state. Time = \").append(currentTimeMillis()); log.error(logString.toString()); } ",
        "test_tgt": "@Test public void testLogCurrentState()throws Exception { long lockTimeoutMs = LockRequest.DEFAULT_LOCK_TIMEOUT.toMillis(); long logCurrentStateCallTimeoutMs = 2 * 5000L; LockRequest request1 = LockRequest.builder(ImmutableSortedMap.of(lock1, LockMode.READ)).doNotBlock().build(); long currentTimeMs = System.currentTimeMillis(); LockResponse response1 = server.lockWithFullLockResponse(LockClient.ANONYMOUS, request1); Assert.assertTrue(response1.success()); Assert.assertTrue(response1.getLockHolders().isEmpty()); HeldLocksToken token1 = response1.getToken(); Assert.assertNotNull(token1); Assert.assertEquals(LockClient.ANONYMOUS, token1.getClient()); Assert.assertEquals(request1.getLockDescriptors(), token1.getLockDescriptors()); Assert.assertTrue(currentTimeMs + lockTimeoutMs <= token1.getExpirationDateMs()); Assert.assertTrue(token1.getExpirationDateMs() <= System.currentTimeMillis() + lockTimeoutMs); executor.submit(new Callable < Void > () { @Override public Void call()throws Exception { barrier.await(); LockRequest request2 = LockRequest.builder(ImmutableSortedMap.of(lock1, LockMode.WRITE)).build(); LockResponse response2 = server.lockWithFullLockResponse(LockClient.ANONYMOUS, request2); HeldLocksToken validToken = response2.getToken(); Assert.assertNotNull(validToken); server.unlock(validToken); return null; } }); barrier.await(); Thread.sleep(500); Future < ? > logCallFuture = executor.submit(new Callable < Void > () { @Override public Void call() { server.logCurrentState(); return null; } }); try { logCallFuture.get(logCurrentStateCallTimeoutMs, TimeUnit.MILLISECONDS); } catch(TimeoutException e) { Assert.fail(); } finally { LockServiceLoggerTestUtils.cleanUpLogStateDir(); } } "
    },
    {
        "test_src": "@Test public void cacheBlockTest()throws IOException { int fileLen = USER_QUOTA_UNIT_BYTES + 4; int fid = TestUtils.createByteFile(mTfs, \"/cacheBlockTest\", WriteType.THROUGH, fileLen); long usedBytes = mLocalTachyonCluster.getMasterInfo().getWorkersInfo().get(0).getUsedBytes(); Assert.assertEquals(0, usedBytes); byte[]content = new byte[fileLen]; TachyonFS tfs1 = mLocalTachyonCluster.getClient(); tfs1.getFile(fid).getInStream(ReadType.CACHE).read(content); usedBytes = mLocalTachyonCluster.getMasterInfo().getWorkersInfo().get(0).getUsedBytes(); Assert.assertEquals(fileLen, usedBytes); TachyonFS tfs2 = mLocalTachyonCluster.getClient(); tfs2.getFile(fid).getInStream(ReadType.CACHE).read(content); usedBytes = mLocalTachyonCluster.getMasterInfo().getWorkersInfo().get(0).getUsedBytes(); Assert.assertEquals(fileLen, usedBytes); } ",
        "focal_tgt": "public void cacheBlock(long userId, long blockId)throws FileDoesNotExistException, SuspectedFileSizeException, BlockInfoException, IOException { File srcFile = new File(CommonUtils.concat(getUserLocalTempFolder(userId), blockId)); File dstFile = new File(CommonUtils.concat(mLocalDataFolder, blockId)); long fileSizeBytes = srcFile.length(); if( ! srcFile.exists()) { throw new FileDoesNotExistException(\"File \" + srcFile + \" does not exist.\"); } synchronized(LATEST_BLOCK_ACCESS_TIME_MS) { if( ! srcFile.renameTo(dstFile)) { throw new FileDoesNotExistException(\"Failed to rename file from \" + srcFile.getPath() + \" to \" + dstFile.getPath()); } if(mBlockSizes.containsKey(blockId)) { mWorkerSpaceCounter.returnUsedBytes(mBlockSizes.get(blockId)); } addBlockId(blockId, fileSizeBytes); mUsers.addOwnBytes(userId, - fileSizeBytes); mMasterClient.worker_cacheBlock(mWorkerId, mWorkerSpaceCounter.getUsedBytes(), blockId, fileSizeBytes); } LOG.info(userId + \" \" + dstFile); } ",
        "focal_src": "public void cacheBlock(long userId, long blockId)throws FileDoesNotExistException, SuspectedFileSizeException, BlockInfoException, IOException { File srcFile = new File(CommonUtils.concat(getUserLocalTempFolder(userId), blockId)); File dstFile = new File(CommonUtils.concat(mLocalDataFolder, blockId)); long fileSizeBytes = srcFile.length(); if( ! srcFile.exists()) { throw new FileDoesNotExistException(\"File \" + srcFile + \" does not exist.\"); } synchronized(mLatestBlockAccessTimeMs) { if( ! srcFile.renameTo(dstFile)) { throw new FileDoesNotExistException(\"Failed to rename file from \" + srcFile.getPath() + \" to \" + dstFile.getPath()); } if(mBlockSizes.containsKey(blockId)) { mWorkerSpaceCounter.returnUsedBytes(mBlockSizes.get(blockId)); } addBlockId(blockId, fileSizeBytes); mUsers.addOwnBytes(userId, - fileSizeBytes); mMasterClient.worker_cacheBlock(mWorkerId, mWorkerSpaceCounter.getUsedBytes(), blockId, fileSizeBytes); } LOG.info(userId + \" \" + dstFile); } ",
        "test_tgt": "@Test public void cacheBlockTest()throws Exception { int fileLen = USER_QUOTA_UNIT_BYTES + 1000; for(int round = 0; round < 10; round ++ ) { int fid = TestUtils.createByteFile(mTfs, \"/cacheBlockTest\", WriteType.THROUGH, fileLen); long usedBytes = mLocalTachyonCluster.getMasterInfo().getWorkersInfo().get(0).getUsedBytes(); Assert.assertEquals(0, usedBytes); ExecutorService executor = Executors.newCachedThreadPool(); ArrayList < Future < Void > > futures = new ArrayList < Future < Void > > (5); for(int i = 0; i < 5; i ++ ) { Callable < Void > call = new ConcurrentCacheBlock(fid, fileLen); futures.add(executor.submit(call)); } for(Future < Void > f : futures) { f.get(); } executor.shutdown(); usedBytes = mLocalTachyonCluster.getMasterInfo().getWorkersInfo().get(0).getUsedBytes(); Assert.assertEquals(fileLen, usedBytes); mTfs.delete(fid, false); } } "
    },
    {
        "test_src": "@Test public void findAllByExample() { flushTestUsers(); User prototype = new User(); prototype.setAge(28); prototype.setCreatedAt(null); List < User > users = repository.findAllByExample(exampleOf(prototype)); assertThat(users, hasSize(1)); assertThat(users.get(0), is(firstUser)); } ",
        "focal_tgt": "@Override public < S extends T > List < S > findAll(Example < S > example) { return getQuery(new ExampleSpecification < S > (example), getResultType(example), (Sort)null).getResultList(); } ",
        "focal_src": "@Override public List < T > findAllByExample(Example < T > example) { return findAll(new ExampleSpecification < T > (example)); } ",
        "test_tgt": "@Test public void findAllByExample() { flushTestUsers(); User prototype = new User(); prototype.setAge(28); prototype.setCreatedAt(null); List < User > users = repository.findAll(of(prototype)); assertThat(users, hasSize(1)); assertThat(users.get(0), is(firstUser)); } "
    },
    {
        "test_src": "@Test public void mount()throws Exception { AlluxioURI alluxioPath = new AlluxioURI(\"/t\"); AlluxioURI ufsPath = new AlluxioURI(\"/u\"); MountPOptions mountOptions = MountPOptions.getDefaultInstance(); doNothing().when(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); mFileSystem.mount(alluxioPath, ufsPath, mountOptions); verify(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); verifyFilesystemContextAcquiredAndReleased(); } ",
        "focal_tgt": "@POST@Path(PATH_PARAM + MOUNT)@ReturnType(\"java.lang.Void\")public Response mount(@PathParam(\"path\")final String path, @QueryParam(\"src\")final String src, final MountPOptions options) { return RestUtils.call(new RestUtils.RestCallable < Void > () { @Override public Void call()throws Exception { Preconditions.checkNotNull(src, \"required 'src' parameter is missing\"); if(options == null) { mFileSystem.mount(new AlluxioURI(path), new AlluxioURI(src)); } else { mFileSystem.mount(new AlluxioURI(path), new AlluxioURI(src), options); } return null; } }, ServerConfiguration.global()); } ",
        "focal_src": "@POST@Path(PATH_PARAM + MOUNT)@ReturnType(\"java.lang.Void\")public Response mount(@PathParam(\"path\")final String path, @QueryParam(\"src\")final String src, final MountPOptions options) { return RestUtils.call(new RestUtils.RestCallable < Void > () { @Override public Void call()throws Exception { Preconditions.checkNotNull(src, \"required 'src' parameter is missing\"); if(options == null) { mFileSystem.mount(new AlluxioURI(path), new AlluxioURI(src), MountPOptions.getDefaultInstance()); } else { mFileSystem.mount(new AlluxioURI(path), new AlluxioURI(src), options); } return null; } }, ServerConfiguration.global()); } ",
        "test_tgt": "@Test public void mount()throws Exception { AlluxioURI alluxioPath = new AlluxioURI(\"/t\"); AlluxioURI ufsPath = new AlluxioURI(\"/u\"); MountPOptions mountOptions = MountPOptions.getDefaultInstance(); doNothing().when(mFileSystemMasterClient).mount(alluxioPath, ufsPath, FileSystemOptions.mountDefaults(mConf).toBuilder().mergeFrom(mountOptions).build()); mFileSystem.mount(alluxioPath, ufsPath, mountOptions); verify(mFileSystemMasterClient).mount(alluxioPath, ufsPath, FileSystemOptions.mountDefaults(mConf).toBuilder().mergeFrom(mountOptions).build()); verifyFilesystemContextAcquiredAndReleased(); } "
    },
    {
        "test_src": "@Test public void module() { error(_INSPECT_MODULE.args(\"src/test/resources/non-existent.xqm\"), Err.WHICHRES); final String module = \"src/test/resources/hello.xqm\"; final String result = query(_INSPECT_MODULE.args(module)); final String var = query(result + \"/variable[@name = 'hello:lazy']\"); query(var + \"/@uri/data()\", \"world\"); query(var + \"/annotation/@name/data()\", \"basex:lazy\"); query(var + \"/annotation/@uri/data()\", \"http://basex.org\"); final String func = query(result + \"/function[@name = 'hello:world']\"); query(func + \"/@uri/data()\", \"world\"); query(func + \"/annotation/@name/data()\", \"public\"); query(func + \"/annotation/@uri/data()\", \"http://www.w3.org/2012/xquery\"); query(func + \"/return/@type/data()\", \"xs:string\"); query(func + \"/return/@occurrence/data()\", \"\"); } ",
        "focal_tgt": "public void module(final byte[]path, final byte[]uri)throws QueryException { final IO io = sc.io(string(path)); final byte[]p = token(io.path()); final byte[]u = qc.modParsed.get(p); if(u != null) { if( ! eq(uri, u))throw error(WRONGMODULE_X_X, uri, qc.context.user.has(Perm.ADMIN) ? io.path() : io.name()); if( ! sc.xquery3() && qc.modStack.contains(p))throw error(CIRCMODULE); return; } qc.modParsed.put(p, uri); final String qu; try { qu = string(io.read()); } catch(final IOException ex) { throw error(WHICHMODFILE_X, qc.context.user.has(Perm.ADMIN) ? io.path() : io.name()); } qc.modStack.push(p); final StaticContext sub = new StaticContext(qc.context); final LibraryModule lib = new QueryParser(qu, io.path(), qc, sub).parseLibrary(false); final byte[]muri = lib.name.uri(); if( ! eq(uri, muri))throw error(WRONGMODULE_X_X, muri, file); if(sub.contextType != null) { if(sc.contextType == null) { sc.contextType = sub.contextType; } else if( ! sub.contextType.eq(sc.contextType)) { throw error(CITYPES_X_X, sub.contextType, sc.contextType); } } qc.modStack.pop(); } ",
        "focal_src": "public void module(final byte[]path, final byte[]uri)throws QueryException { final IO io = sc.io(string(path)); final byte[]p = token(io.path()); final byte[]u = qc.modParsed.get(p); if(u != null) { if( ! eq(uri, u))throw error(WRONGMODULE, uri, qc.context.user.has(Perm.ADMIN) ? io.path() : io.name()); if( ! sc.xquery3() && qc.modStack.contains(p))throw error(CIRCMODULE); return; } qc.modParsed.put(p, uri); final String qu; try { qu = string(io.read()); } catch(final IOException ex) { throw error(WHICHMODFILE, qc.context.user.has(Perm.ADMIN) ? io.path() : io.name()); } qc.modStack.push(p); final StaticContext sub = new StaticContext(qc.context); final LibraryModule lib = new QueryParser(qu, io.path(), qc, sub).parseLibrary(false); final byte[]muri = lib.name.uri(); if( ! eq(uri, muri))throw error(WRONGMODULE, muri, file); if(sub.contextType != null) { if(sc.contextType == null) { sc.contextType = sub.contextType; } else if( ! sub.contextType.eq(sc.contextType)) { throw error(CITYPES, sub.contextType, sc.contextType); } } qc.modStack.pop(); } ",
        "test_tgt": "@Test public void module() { error(_INSPECT_MODULE.args(\"src/test/resources/non-existent.xqm\"), Err.WHICHRES_X); final String module = \"src/test/resources/hello.xqm\"; final String result = query(_INSPECT_MODULE.args(module)); final String var = query(result + \"/variable[@name = 'hello:lazy']\"); query(var + \"/@uri/data()\", \"world\"); query(var + \"/annotation/@name/data()\", \"basex:lazy\"); query(var + \"/annotation/@uri/data()\", \"http://basex.org\"); final String func = query(result + \"/function[@name = 'hello:world']\"); query(func + \"/@uri/data()\", \"world\"); query(func + \"/annotation/@name/data()\", \"public\"); query(func + \"/annotation/@uri/data()\", \"http://www.w3.org/2012/xquery\"); query(func + \"/return/@type/data()\", \"xs:string\"); query(func + \"/return/@occurrence/data()\", \"\"); } "
    },
    {
        "test_src": "@Test public void testMm() { System.out.println(\"mm\"); double[][]A = { { 0.7220180, 0.07121225, 0.6881997 }, { - 0.2648886, - 0.89044952, 0.3700456 }, { - 0.6391588, 0.44947578, 0.6240573 } }; double[][]B = { { 0.6881997, - 0.07121225, 0.7220180 }, { 0.3700456, 0.89044952, - 0.2648886 }, { 0.6240573, - 0.44947578, - 0.6391588 } }; double[][]C = { { 0.9527204, - 0.2973347, 0.06257778 }, { - 0.2808735, - 0.9403636, - 0.19190231 }, { 0.1159052, 0.1652528, - 0.97941688 } }; ColumnMajorMatrix a = new ColumnMajorMatrix(A); ColumnMajorMatrix b = new ColumnMajorMatrix(B); ColumnMajorMatrix c = new ColumnMajorMatrix(C); assertTrue(smile.math.Math.equals(a.mm(b).array(), c.array(), 1E-7)); } ",
        "focal_tgt": "public A abmm(B b); ",
        "focal_src": "public A mm(B b); ",
        "test_tgt": "@Test public void testMm() { System.out.println(\"mm\"); double[][]A = { { 0.7220180, 0.07121225, 0.6881997 }, { - 0.2648886, - 0.89044952, 0.3700456 }, { - 0.6391588, 0.44947578, 0.6240573 } }; double[][]B = { { 0.6881997, - 0.07121225, 0.7220180 }, { 0.3700456, 0.89044952, - 0.2648886 }, { 0.6240573, - 0.44947578, - 0.6391588 } }; double[][]C = { { 0.9527204, - 0.2973347, 0.06257778 }, { - 0.2808735, - 0.9403636, - 0.19190231 }, { 0.1159052, 0.1652528, - 0.97941688 } }; ColumnMajorMatrix a = new ColumnMajorMatrix(A); ColumnMajorMatrix b = new ColumnMajorMatrix(B); assertTrue(Math.equals(a.abmm(b).array(), C, 1E-7)); Math.abtmm(A, B, C); assertTrue(Math.equals(a.abtmm(b).array(), C, 1E-7)); Math.atbmm(A, B, C); assertTrue(Math.equals(a.atbmm(b).array(), C, 1E-7)); } "
    },
    {
        "test_src": "@Test public void testNormalize() { System.out.println(\"normalize\"); double[]data = { 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0 }; Math.normalize(data); assertEquals(0, Math.mean(data), 1E-7); assertEquals(1, Math.sd(data), 1E-7); } ",
        "focal_tgt": "public static void normalize(double[][]x) { int n = x.length; int p = x[0].length; double[]min = colMin(x); double[]max = colMax(x); for(int j = 0; j < p; j ++ ) { double scale = max[j] - min[j]; if( ! Math.isZero(scale)) { for(int i = 0; i < n; i ++ ) { x[i][j] = (x[i][j] - min[j]) / scale; } } } } ",
        "focal_src": "public static void normalize(double[][]x) { int n = x.length; int p = x[0].length; for(int j = 0; j < p; j ++ ) { double mu = 0.0; double sd = 0.0; for(int i = 0; i < n; i ++ ) { mu += x[i][j]; sd += x[i][j] * x[i][j]; } sd = Math.sqrt(sd / (n - 1) - (mu / n) * (mu / (n - 1))); mu /= n; if(sd <= 0) { throw new IllegalArgumentException(String.format(\"Column %d has variance of 0.\", j)); } for(int i = 0; i < n; i ++ ) { x[i][j] = (x[i][j] - mu) / sd; } } } ",
        "test_tgt": "@Test public void testStandardize() { System.out.println(\"normalize\"); double[]data = { 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0 }; Math.standardize(data); assertEquals(0, Math.mean(data), 1E-7); assertEquals(1, Math.sd(data), 1E-7); } "
    },
    {
        "test_src": "@Test public void testNotEqProp() { assertEquals(new NotEqPropCriterion(\"id\", \"name\"), instance.notEqProp(\"id\", \"name\").getQueryCriterion()); } ",
        "focal_tgt": "public CriteriaQuery notEqProp(String propName, String otherProp) { criterion = criterion.and(Criteria.notEqProp(propName, otherProp)); return this; } ",
        "focal_src": "public CriteriaQuery notEqProp(String propName, String otherProp) { criterion = criterion.and(criterionBuilder.notEqProp(propName, otherProp)); return this; } ",
        "test_tgt": "@Test public void testNotEqProp() { assertEquals(Criteria.notEqProp(\"id\", \"name\"), instance.notEqProp(\"id\", \"name\").getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void testOpen() { CveDB instance = null; try { instance = CveDB.getInstance(); instance.commit(); } catch(DatabaseException | SQLException ex) { fail(ex.getMessage()); } finally { int start = instance.getUsageCount(); instance.close(); int end = instance.getUsageCount(); assertTrue(end < start); } } ",
        "focal_tgt": "public void open(CveDB cve)throws IOException, DatabaseException { if( ! isOpen()) { this.cve = cve; this.cpe = CpeMemoryIndex.getInstance(); try { final long creationStart = System.currentTimeMillis(); cpe.open(cve); final long creationSeconds = TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - creationStart); LOGGER.info(\"Created CPE Index ({} seconds)\", creationSeconds); } catch(IndexException ex) { LOGGER.debug(\"IndexException\", ex); throw new DatabaseException(ex); } } } ",
        "focal_src": "public void open()throws IOException, DatabaseException { if( ! isOpen()) { cve = CveDB.getInstance(); cpe = CpeMemoryIndex.getInstance(); try { final long creationStart = System.currentTimeMillis(); cpe.open(cve); final long creationSeconds = TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - creationStart); LOGGER.info(\"Created CPE Index ({} seconds)\", creationSeconds); } catch(IndexException ex) { LOGGER.debug(\"IndexException\", ex); throw new DatabaseException(ex); } } } ",
        "test_tgt": "@Test public void testOpen() { try { instance.commit(); } catch(DatabaseException | SQLException ex) { fail(ex.getMessage()); } } "
    },
    {
        "test_src": "@Test public void testGet()throws IOException, InterruptedException { byte[]key = new byte[] { 123, 124, 122 }; byte[]distributedKey = keyDistributor.getDistributedKey(key); byte[]value = Bytes.toBytes(\"some\"); hTable.put(new Put(distributedKey).add(CF, QUAL, value)); Result result = hTable.get(new Get(distributedKey)); Assert.assertArrayEquals(key, keyDistributor.getOriginalKey(result.getRow())); Assert.assertArrayEquals(value, result.getValue(CF, QUAL)); } ",
        "focal_tgt": "Table get()throws IOException; ",
        "focal_src": "HTableInterface get()throws IOException; ",
        "test_tgt": "@Test public void testGet()throws IOException, InterruptedException { byte[]key = new byte[] { 123, 124, 122 }; byte[]distributedKey = keyDistributor.getDistributedKey(key); byte[]value = Bytes.toBytes(\"some\"); table.put(new Put(distributedKey).addColumn(CF, QUAL, value)); Result result = table.get(new Get(distributedKey)); Assert.assertArrayEquals(key, keyDistributor.getOriginalKey(result.getRow())); Assert.assertArrayEquals(value, result.getValue(CF, QUAL)); } "
    },
    {
        "test_src": "@Test public void testRemove() { map.put(key1, value1); assertEquals2(value1, map.remove(key1)); assertEquals2(Intrinsics.defaultVTypeValue(), map.remove(key1)); assertEquals(0, map.size()); assertEquals(0, map.assigned); } ",
        "focal_tgt": "@Override public KType remove(int index) { assert(index >= 0 && index < size()) : \"Index \" + index + \" out of bounds [\" + 0 + \", \" + size() + \").\"; final KType v = Intrinsics. < KType > cast(buffer[index]); if(index + 1 < elementsCount) { System.arraycopy(buffer, index + 1, buffer, index, elementsCount - index - 1); } elementsCount -- ; buffer[elementsCount] = Intrinsics.empty(); return v; } ",
        "focal_src": "@Override public KType remove(int index) { assert(index >= 0 && index < size()) : \"Index \" + index + \" out of bounds [\" + 0 + \", \" + size() + \").\"; final KType v = Intrinsics. < KType > cast(buffer[index]); if(index + 1 < elementsCount) { System.arraycopy(buffer, index + 1, buffer, index, elementsCount - index - 1); } elementsCount -- ; buffer[elementsCount] = Intrinsics. < KType > defaultKTypeValue(); return v; } ",
        "test_tgt": "@Test public void testRemove() { map.put(key1, value1); assertEquals2(value1, map.remove(key1)); assertEquals2(Intrinsics. < VType > empty(), map.remove(key1)); assertEquals(0, map.size()); assertEquals(0, map.assigned); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should compare when patient and identifier and type is null\", method = \"equals(Object)\")public void equals_shouldCompareWhenPatientAndIdentifierAndTypeIsNull()throws Exception { Patient patient = new Patient(); PatientIdentifier second = new PatientIdentifier(); second.setIdentifier(\"EXAMPLE IDENTIFIER\"); second.setPatient(patient); second.setIdentifierType(new PatientIdentifierType(1)); PatientIdentifier first = new PatientIdentifier(); Assert.assertNull(first.getPatient()); Assert.assertNull(first.getIdentifier()); Assert.assertNull(first.getIdentifierType()); Assert.assertFalse(first + \" and \" + second + \" should not equal.\", second.equals(first)); first.setIdentifier(\"EXAMPLE IDENTIFIER\"); first.setPatient(patient); first.setIdentifierType(new PatientIdentifierType(1)); Assert.assertTrue(first + \" and \" + second + \" should be equal.\", second.equals(first)); } ",
        "focal_tgt": "@Override public boolean equals(Object obj) { return super.equals(obj); } ",
        "focal_src": "public boolean equals(Object obj) { return super.equals(obj); } ",
        "test_tgt": "@Test@Verifies(value = \"should compare when patient and identifier and type is null\", method = \"equals(Object)\")public void equals_shouldCompareWhenPatientAndIdentifierAndTypeIsNull()throws Exception { Patient patient = new Patient(); PatientIdentifier second = new PatientIdentifier(); second.setIdentifier(\"EXAMPLE IDENTIFIER\"); second.setPatient(patient); second.setIdentifierType(new PatientIdentifierType(1)); PatientIdentifier first = new PatientIdentifier(); Assert.assertNull(first.getPatient()); Assert.assertNull(first.getIdentifier()); Assert.assertNull(first.getIdentifierType()); Assert.assertFalse(first + \" and \" + second + \" should not equal.\", second.equals(first)); } "
    },
    {
        "test_src": "@Test public void addYear() { logDate(DateUtil.addYear(NOW, 5)); logDate(DateUtil.addYear(NOW, - 5)); } ",
        "focal_tgt": "public static Date addYear(Date date, int year) { return DateUtils.addYears(date, year); } ",
        "focal_src": "public static Date addYear(Date date, int year) { return operateDate(date, Calendar.YEAR, year); } ",
        "test_tgt": "@Test public void addYear() { logDate(DateUtil.addYear(NOW, 5)); logDate(NOW); logDate(DateUtils.addYears(NOW, 5)); logDate(NOW); logDate(DateUtil.addYear(NOW, - 5)); logDate(NOW); } "
    },
    {
        "test_src": "@Test public void testGetBuffer() { System.out.println(\"getBuffer\"); RunTable instance = createVerticalInstance(); String expResult = \"ip[width=10, height=5, bits=8, min=0.0, max=255.0]\"; ByteProcessor result = instance.getBuffer(); System.out.println(\"result: \" + result); assertEquals(expResult, result.toString()); } ",
        "focal_tgt": "public ByteProcessor getBuffer() { ByteProcessor buffer = new ByteProcessor(width, height); buffer.invert(); switch(orientation) { case HORIZONTAL : for(int row = 0, size = getSize(); row < size; row ++ ) { for(Itr it = new Itr(row); it.hasNext(); ) { Run run = it.next(); for(int c = run.getStart(); c <= run.getStop(); c ++ ) { buffer.set(c, row, 0); } } } break; case VERTICAL : for(int row = 0, size = getSize(); row < size; row ++ ) { for(Itr it = new Itr(row); it.hasNext(); ) { Run run = it.next(); for(int col = run.getStart(); col <= run.getStop(); col ++ ) { buffer.set(row, col, 0); } } } break; } return buffer; } ",
        "focal_src": "public ByteProcessor getBuffer() { ByteProcessor buffer = new ByteProcessor(width, height); buffer.invert(); switch(orientation) { case HORIZONTAL : for(int row = 0; row < getSize(); row ++ ) { RunSequence seq = getSequence(row); for(Run run : seq) { for(int c = run.getStart(); c <= run.getStop(); c ++ ) { buffer.set(c, row, 0); } } } break; case VERTICAL : for(int row = 0; row < getSize(); row ++ ) { RunSequence seq = getSequence(row); for(Run run : seq) { for(int col = run.getStart(); col <= run.getStop(); col ++ ) { buffer.set(row, col, 0); } } } break; } return buffer; } ",
        "test_tgt": "@Test public void testGetBuffer() { System.out.println(\"\\n+++ getBuffer\"); RunTable instance = createVerticalInstance(); String expResult = \"ip[width=10, height=5, bits=8, min=0.0, max=255.0]\"; ByteProcessor result = instance.getBuffer(); System.out.println(\"result: \" + result); assertEquals(expResult, result.toString()); } "
    },
    {
        "test_src": "@Test public void testGetMetadata_String() { String mdString = \"dc.contributor.author\"; DCValue[]dc = it.getMetadata(mdString); assertThat(\"testGetMetadata_String 0\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 1\", dc.length == 0); mdString = \"dc.contributor.*\"; dc = it.getMetadata(mdString); assertThat(\"testGetMetadata_String 2\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 3\", dc.length == 0); mdString = \"dc.contributor\"; dc = it.getMetadata(mdString); assertThat(\"testGetMetadata_String 4\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 5\", dc.length == 0); } ",
        "focal_tgt": "public DCValue[]getMetadata(String schema, String element, String qualifier, String lang) { try { BrowseItemDAO dao = BrowseDAOFactory.getItemInstance(ourContext); if(Item.ANY.equals(qualifier)) { try { return dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } } if( ! metadata.isEmpty()) { List < DCValue > values = new ArrayList < DCValue > (); Iterator < DCValue > i = metadata.iterator(); while(i.hasNext()) { DCValue dcv = i.next(); if(match(schema, element, qualifier, lang, dcv)) { values.add(dcv); } } if(values.isEmpty()) { DCValue[]dcvs = new DCValue[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } DCValue[]valueArray = new DCValue[values.size()]; valueArray = (DCValue[])values.toArray(valueArray); return valueArray; } else { DCValue[]dcvs = new DCValue[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } } catch(BrowseException be) { log.error(\"caught exception: \", be); return null; } } ",
        "focal_src": "public DCValue[]getMetadata(String schema, String element, String qualifier, String lang)throws SQLException { try { BrowseItemDAO dao = BrowseDAOFactory.getItemInstance(context); if(Item.ANY.equals(qualifier)) { return dao.queryMetadata(id, schema, element, qualifier, lang); } if( ! metadata.isEmpty()) { List < DCValue > values = new ArrayList < DCValue > (); Iterator < DCValue > i = metadata.iterator(); while(i.hasNext()) { DCValue dcv = i.next(); if(match(schema, element, qualifier, lang, dcv)) { values.add(dcv); } } if(values.isEmpty()) { DCValue[]dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } DCValue[]valueArray = new DCValue[values.size()]; valueArray = (DCValue[])values.toArray(valueArray); return valueArray; } else { DCValue[]dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } } catch(BrowseException be) { log.error(\"caught exception: \", be); return null; } } ",
        "test_tgt": "@Test public void testGetMetadata_String() { String mdString = \"dc.contributor.author\"; DCValue[]dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 0\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 1\", dc.length == 0); mdString = \"dc.contributor.*\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 2\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 3\", dc.length == 0); mdString = \"dc.contributor\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 4\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 5\", dc.length == 0); } "
    },
    {
        "test_src": "@Test public void addCheckpointTest()throws Exception { FileOutStream os = mTfs.getOutStream(new TachyonURI(\"/testFile\")); TachyonFile file = mTfs.open(new TachyonURI(\"/testFile\")); final int blockSize = (int)WORKER_CAPACITY_BYTES / 10; FileInfo fileInfo = mLocalTachyonCluster.getClient().getInfo(file); String ufsPath = fileInfo.getUfsPath(); UnderFileSystem ufs = UnderFileSystem.get(ufsPath, mMasterTachyonConf); OutputStream out = ufs.create(ufsPath); out.write(BufferUtils.getIncreasingByteArray(blockSize)); out.close(); mWorkerServiceHandler.addCheckpoint(file.getFileId(), os.getNonce()); Assert.assertEquals(0, mBlockMasterClient.getUsedBytes()); Assert.assertTrue(mTfs.getInfo(file).isCompleted); } ",
        "focal_tgt": "public synchronized void persistFile(long fileId, long nonce, String path)throws IOException { mustConnect(); try { mClient.persistFile(fileId, nonce, path); } catch(FileDoesNotExistException e) { throw new IOException(e); } catch(SuspectedFileSizeException e) { throw new IOException(e); } catch(FailedToCheckpointException e) { throw new IOException(e); } catch(BlockInfoException e) { throw new IOException(e); } catch(TException e) { mConnected = false; throw new IOException(e); } } ",
        "focal_src": "public synchronized void addCheckpoint(long fileId, long nonce)throws IOException { mustConnect(); try { mClient.addCheckpoint(fileId, nonce); } catch(FileDoesNotExistException e) { throw new IOException(e); } catch(SuspectedFileSizeException e) { throw new IOException(e); } catch(FailedToCheckpointException e) { throw new IOException(e); } catch(BlockInfoException e) { throw new IOException(e); } catch(TException e) { mConnected = false; throw new IOException(e); } } ",
        "test_tgt": "@Test public void addCheckpointTest()throws Exception { FileOutStream os = mTfs.getOutStream(new TachyonURI(\"/testFile\")); TachyonFile file = mTfs.open(new TachyonURI(\"/testFile\")); final int blockSize = (int)WORKER_CAPACITY_BYTES / 10; FileInfo fileInfo = mLocalTachyonCluster.getClient().getInfo(file); String ufsPath = fileInfo.getUfsPath(); UnderFileSystem ufs = UnderFileSystem.get(ufsPath, mMasterTachyonConf); OutputStream out = ufs.create(ufsPath); out.write(BufferUtils.getIncreasingByteArray(blockSize)); out.close(); mWorkerServiceHandler.persistFile(file.getFileId(), os.getNonce(), ufsPath); Assert.assertEquals(0, mBlockMasterClient.getUsedBytes()); Assert.assertTrue(mTfs.getInfo(file).isCompleted); } "
    },
    {
        "test_src": "@Test public void testUploadDocument()throws URISyntaxException, IOException { String docId = UUID.randomUUID().toString(); String pdfDocId = UUID.randomUUID().toString(); Document response = createMockDocument(docId, \"html-with-extra-content-input.htm\", MediaType.TEXT_HTML); Document pdfResponse = createMockDocument(pdfDocId, \"pdf-with-sections-input.pdf\", MediaType.APPLICATION_PDF); File html = new File(\"src/test/resources/document_conversion/html-with-extra-content-input.htm\"); File pdf = new File(\"src/test/resources/document_conversion/pdf-with-sections-input.pdf\"); mockServer.when(request().withMethod(\"POST\").withPath(DocumentConversion.DOCUMENTS_PATH)).respond((response().withBody(GsonSingleton.getGson().toJson(response)))); Document document = service.uploadDocument(html); Assert.assertNotNull(document); Assert.assertEquals(document.toString(), response.toString()); mockServer.reset().when(request().withMethod(\"POST\").withPath(DocumentConversion.DOCUMENTS_PATH)).respond((response().withBody(GsonSingleton.getGson().toJson(pdfResponse)))); Document pdfDocument = service.uploadDocument(pdf, MediaType.APPLICATION_PDF); Assert.assertNotNull(pdfDocument); Assert.assertEquals(pdfDocument.toString(), pdfResponse.toString()); } ",
        "focal_tgt": "public Document uploadDocument(final File document, final String mediaType) { if(mediaType == null || mediaType.isEmpty())throw new IllegalArgumentException(\"media type cannot be null or empty\"); if( ! ConversionUtils.isValidMediaType(mediaType))throw new IllegalArgumentException(\"file with the given media type is not supported\"); if(document == null || ! document.exists())throw new IllegalArgumentException(\"document cannot be null and must exist\"); try { MultipartEntity reqEntity = new MultipartEntity(); reqEntity.addPart(\"file\", new FileBody(document, mediaType)); HttpRequestBase request = Request.Post(ConfigConstants.DOCUMENTS_PATH).withEntity(reqEntity).build(); HttpResponse response = docConversionService.execute(request); String documentAsJson = ResponseUtil.getString(response); Document doc = GsonSingleton.getGson().fromJson(documentAsJson, Document.class); return doc; } catch(IOException e) { throw new RuntimeException(e); } } ",
        "focal_src": "public Document uploadDocument(final File document, final String mediaType) { if(mediaType == null || mediaType.isEmpty())throw new IllegalArgumentException(\"media type cannot be null or empty\"); if( ! ConversionUtils.isValidMediaType(mediaType))throw new IllegalArgumentException(\"file with the given media type is not supported\"); if(document == null || ! document.exists())throw new IllegalArgumentException(\"document cannot be null and must exist\"); try { MultipartEntity reqEntity = new MultipartEntity(); reqEntity.addPart(\"file\", new FileBody(document, mediaType)); HttpRequestBase request = Request.Post(DocumentConversion.DOCUMENTS_PATH).withEntity(reqEntity).build(); HttpResponse response = docConversionService.execute(request); String documentAsJson = ResponseUtil.getString(response); Document doc = GsonSingleton.getGson().fromJson(documentAsJson, Document.class); return doc; } catch(IOException e) { throw new RuntimeException(e); } } ",
        "test_tgt": "@Test public void testUploadDocument()throws URISyntaxException, IOException { String docId = UUID.randomUUID().toString(); String pdfDocId = UUID.randomUUID().toString(); Document response = createMockDocument(docId, \"html-with-extra-content-input.htm\", MediaType.TEXT_HTML); Document pdfResponse = createMockDocument(pdfDocId, \"pdf-with-sections-input.pdf\", MediaType.APPLICATION_PDF); File html = new File(\"src/test/resources/document_conversion/html-with-extra-content-input.htm\"); File pdf = new File(\"src/test/resources/document_conversion/pdf-with-sections-input.pdf\"); mockServer.when(request().withMethod(\"POST\").withPath(DOCUMENTS_PATH)).respond((response().withBody(GsonSingleton.getGson().toJson(response)))); Document document = service.uploadDocument(html); Assert.assertNotNull(document); Assert.assertEquals(document.toString(), response.toString()); mockServer.reset().when(request().withMethod(\"POST\").withPath(DOCUMENTS_PATH)).respond((response().withBody(GsonSingleton.getGson().toJson(pdfResponse)))); Document pdfDocument = service.uploadDocument(pdf, MediaType.APPLICATION_PDF); Assert.assertNotNull(pdfDocument); Assert.assertEquals(pdfDocument.toString(), pdfResponse.toString()); } "
    },
    {
        "test_src": "@Test public void testAddBlockout() { BlockoutTrigger trigger = new BlockoutTrigger(\"blockout\", DefaultBlockoutManager.BLOCK_GROUP, \"job_name\", DefaultBlockoutManager.BLOCK_GROUP, new Date(), null, - 1, 1000000, 50000); try { blockoutManager.addBlockout(trigger); } catch(SchedulerException e) { e.printStackTrace(); } try { assertEquals(blockoutManager.getBlockout(\"blockout\"), trigger); } catch(SchedulerException e) { e.printStackTrace(); } } ",
        "focal_tgt": "void addBlockout(IBlockoutTrigger blockout)throws SchedulerException; ",
        "focal_src": "void addBlockout(BlockoutTrigger blockout)throws SchedulerException; ",
        "test_tgt": "@Test public void testAddBlockout() { SimpleBlockoutTrigger trigger = new SimpleBlockoutTrigger(\"blockout\", new Date(), null, - 1, 1000000, 50000); try { blockoutManager.addBlockout(trigger); } catch(SchedulerException e) { e.printStackTrace(); } try { assertEquals(blockoutManager.getBlockout(\"blockout\"), trigger); } catch(SchedulerException e) { e.printStackTrace(); } } "
    },
    {
        "test_src": "@Test public void testEstablishSSHTunnelIfNeeded()throws Exception { String mockHost = \"host0\"; int mockPort = 9049; String mockEndpoint = String.format(\"%s:%d\", mockHost, mockPort); InetSocketAddress mockAddr = NetworkUtils.getInetSocketAddress(mockEndpoint); int mockFreePort = 9519; String tunnelHost = \"tunnelHost\"; int timeout = - 1; int retryCount = - 1; int retryIntervalMs = - 1; int verifyCount = - 1; boolean isVerbose = true; NetworkUtils.TunnelConfig tunnelConfig = new NetworkUtils.TunnelConfig(true, tunnelHost, timeout, retryCount, retryIntervalMs, verifyCount); PowerMockito.spy(NetworkUtils.class); PowerMockito.doReturn(true).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(mockAddr), Mockito.anyInt(), Mockito.anyInt(), Mockito.anyInt()); Pair < InetSocketAddress, Process > ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertEquals(mockHost, ret.first.getHostName()); Assert.assertEquals(mockPort, ret.first.getPort()); Assert.assertEquals(mockEndpoint, ret.first.toString()); Assert.assertNull(ret.second); PowerMockito.doReturn(false).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(mockAddr), Mockito.anyInt(), Mockito.anyInt(), Mockito.anyInt()); PowerMockito.spy(SysUtils.class); PowerMockito.doReturn(mockFreePort).when(SysUtils.class, \"getFreePort\"); Process process = Mockito.mock(Process.class); Mockito.doReturn(true).when(process).isAlive(); PowerMockito.spy(ShellUtils.class); PowerMockito.doReturn(process).when(ShellUtils.class, \"establishSSHTunnelProcess\", Mockito.anyString(), Mockito.anyInt(), Mockito.anyString(), Mockito.anyInt()); InetSocketAddress newAddress = NetworkUtils.getInetSocketAddress(String.format(\"%s:%d\", NetworkUtils.LOCAL_HOST, mockFreePort)); PowerMockito.doReturn(false).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(newAddress), Mockito.anyInt(), Mockito.anyInt(), Mockito.anyInt()); ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertNull(ret.first); Assert.assertNull(ret.second); PowerMockito.doReturn(true).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(newAddress), Mockito.anyInt(), Mockito.anyInt(), Mockito.anyInt()); ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertEquals(NetworkUtils.LOCAL_HOST, ret.first.getHostName()); Assert.assertEquals(mockFreePort, ret.first.getPort()); Assert.assertEquals(process, ret.second); } ",
        "focal_tgt": "private static Pair < InetSocketAddress, Process > establishSSHTunnelIfNeeded(InetSocketAddress endpoint, String tunnelHost, TunnelType tunnelType, Duration timeout, int retryCount, Duration retryInterval, int verifyCount) { if(NetworkUtils.isLocationReachable(endpoint, timeout, retryCount, retryInterval)) { return new Pair < InetSocketAddress, Process > (endpoint, null); } else { int localFreePort = SysUtils.getFreePort(); InetSocketAddress newEndpoint = new InetSocketAddress(LOCAL_HOST, localFreePort); LOG.log(Level.FINE, \"Trying to opening up tunnel to {0} from {1}\", new Object[] { endpoint.toString(), newEndpoint.toString() }); final Process tunnelProcess; switch(tunnelType) { case PORT_FORWARD : tunnelProcess = ShellUtils.establishSSHTunnelProcess(tunnelHost, localFreePort, endpoint.getHostString(), endpoint.getPort()); break; case SOCKS_PROXY : tunnelProcess = ShellUtils.establishSocksProxyProcess(tunnelHost, localFreePort); break; default : throw new IllegalArgumentException(\"Unrecognized TunnelType passed: \" + tunnelType); } if(tunnelProcess != null && tunnelProcess.isAlive() && NetworkUtils.isLocationReachable(newEndpoint, timeout, verifyCount, retryInterval)) { java.lang.Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { tunnelProcess.destroy(); } }); return new Pair < InetSocketAddress, Process > (newEndpoint, tunnelProcess); } LOG.log(Level.FINE, \"Failed to opening up tunnel to {0} from {1}. Releasing process..\", new Object[] { endpoint, newEndpoint }); tunnelProcess.destroy(); } return new Pair < InetSocketAddress, Process > (null, null); } ",
        "focal_src": "private static Pair < InetSocketAddress, Process > establishSSHTunnelIfNeeded(InetSocketAddress endpoint, String tunnelHost, TunnelType tunnelType, int timeoutMs, int retryCount, int retryIntervalMs, int verifyCount) { if(NetworkUtils.isLocationReachable(endpoint, timeoutMs, retryCount, retryIntervalMs)) { return new Pair < InetSocketAddress, Process > (endpoint, null); } else { int localFreePort = SysUtils.getFreePort(); InetSocketAddress newEndpoint = new InetSocketAddress(LOCAL_HOST, localFreePort); LOG.log(Level.FINE, \"Trying to opening up tunnel to {0} from {1}\", new Object[] { endpoint.toString(), newEndpoint.toString() }); final Process tunnelProcess; switch(tunnelType) { case PORT_FORWARD : tunnelProcess = ShellUtils.establishSSHTunnelProcess(tunnelHost, localFreePort, endpoint.getHostString(), endpoint.getPort()); break; case SOCKS_PROXY : tunnelProcess = ShellUtils.establishSocksProxyProcess(tunnelHost, localFreePort); break; default : throw new IllegalArgumentException(\"Unrecognized TunnelType passed: \" + tunnelType); } if(tunnelProcess != null && tunnelProcess.isAlive() && NetworkUtils.isLocationReachable(newEndpoint, timeoutMs, verifyCount, retryIntervalMs)) { java.lang.Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { tunnelProcess.destroy(); } }); return new Pair < InetSocketAddress, Process > (newEndpoint, tunnelProcess); } LOG.log(Level.FINE, \"Failed to opening up tunnel to {0} from {1}. Releasing process..\", new Object[] { endpoint, newEndpoint }); tunnelProcess.destroy(); } return new Pair < InetSocketAddress, Process > (null, null); } ",
        "test_tgt": "@Test public void testEstablishSSHTunnelIfNeeded()throws Exception { String mockHost = \"host0\"; int mockPort = 9049; String mockEndpoint = String.format(\"%s:%d\", mockHost, mockPort); InetSocketAddress mockAddr = NetworkUtils.getInetSocketAddress(mockEndpoint); int mockFreePort = 9519; String tunnelHost = \"tunnelHost\"; Duration timeout = Duration.ofMillis( - 1); int retryCount = - 1; Duration retryInterval = Duration.ofMillis( - 1); int verifyCount = - 1; NetworkUtils.TunnelConfig tunnelConfig = new NetworkUtils.TunnelConfig(true, tunnelHost, timeout, retryCount, retryInterval, verifyCount); PowerMockito.spy(NetworkUtils.class); PowerMockito.doReturn(true).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(mockAddr), Mockito.eq(timeout), Mockito.anyInt(), Mockito.eq(retryInterval)); Pair < InetSocketAddress, Process > ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertEquals(mockHost, ret.first.getHostName()); Assert.assertEquals(mockPort, ret.first.getPort()); Assert.assertEquals(mockEndpoint, ret.first.toString()); Assert.assertNull(ret.second); PowerMockito.doReturn(false).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(mockAddr), Mockito.eq(timeout), Mockito.anyInt(), Mockito.eq(retryInterval)); PowerMockito.spy(SysUtils.class); PowerMockito.doReturn(mockFreePort).when(SysUtils.class, \"getFreePort\"); Process process = Mockito.mock(Process.class); Mockito.doReturn(true).when(process).isAlive(); PowerMockito.spy(ShellUtils.class); PowerMockito.doReturn(process).when(ShellUtils.class, \"establishSSHTunnelProcess\", Mockito.anyString(), Mockito.anyInt(), Mockito.anyString(), Mockito.anyInt()); InetSocketAddress newAddress = NetworkUtils.getInetSocketAddress(String.format(\"%s:%d\", NetworkUtils.LOCAL_HOST, mockFreePort)); PowerMockito.doReturn(false).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(newAddress), Mockito.eq(timeout), Mockito.anyInt(), Mockito.eq(retryInterval)); ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertNull(ret.first); Assert.assertNull(ret.second); PowerMockito.doReturn(true).when(NetworkUtils.class, \"isLocationReachable\", Mockito.eq(newAddress), Mockito.eq(timeout), Mockito.anyInt(), Mockito.eq(retryInterval)); ret = NetworkUtils.establishSSHTunnelIfNeeded(NetworkUtils.getInetSocketAddress(mockEndpoint), tunnelConfig, NetworkUtils.TunnelType.PORT_FORWARD); Assert.assertEquals(NetworkUtils.LOCAL_HOST, ret.first.getHostName()); Assert.assertEquals(mockFreePort, ret.first.getPort()); Assert.assertEquals(process, ret.second); } "
    },
    {
        "test_src": "@Test public void testGetSession()throws MessagingException { System.out.println(\"getSession\"); Session session; EmailService instance = getService(EmailService.class); session = instance.getSession(); assertNotNull(\" getSession returned null\", session); } ",
        "focal_tgt": "@Override public Session getSession() { return session; } ",
        "focal_src": "@Override public Session getSession() { init(); return session; } ",
        "test_tgt": "@Test public void testGetSession()throws MessagingException { System.out.println(\"getSession\"); Session session; EmailService instance = getService(EmailServiceImpl.class); session = instance.getSession(); assertNotNull(\" getSession returned null\", session); } "
    },
    {
        "test_src": "@Test public void validate_shouldFailValidationIfDoseUnitsIsNullForSIMPLEDosingType()throws Exception { DrugOrder order = new DrugOrder(); order.setDosingType(DrugOrder.DosingType.SIMPLE); order.setDoseUnits(null); Errors errors = new BindException(order, \"order\"); new DrugOrderValidator().validate(order, errors); Assert.assertTrue(errors.hasFieldErrors(\"doseUnits\")); } ",
        "focal_tgt": "public void validate(Object obj, Errors errors) { super.validate(obj, errors); DrugOrder order = (DrugOrder)obj; if(order == null) { errors.reject(\"error.general\"); } else { ValidationUtils.rejectIfEmpty(errors, \"asNeeded\", \"error.null\"); if(order.getAction() != Order.Action.DISCONTINUE) { ValidationUtils.rejectIfEmpty(errors, \"dosingType\", \"error.null\"); } if(order.getDrug() == null || order.getDrug().getConcept() == null) { ValidationUtils.rejectIfEmpty(errors, \"concept\", \"error.null\"); } if(order.getConcept() != null && order.getDrug() != null && order.getDrug().getConcept() != null) { if( ! order.getDrug().getConcept().equals(order.getConcept())) { errors.rejectValue(\"drug\", \"error.general\"); errors.rejectValue(\"concept\", \"error.concept\"); } } if(order.getAction() != Order.Action.DISCONTINUE && order.getDosingType() != null) { DosingInstructions dosingInstructions = order.getDosingInstructionsInstance(); dosingInstructions.validate(order, errors); } validateFieldsForOutpatientCareSettingType(order, errors); validatePairedFields(order, errors); validateUnitsAreAmongAllowedConcepts(errors, order); } } ",
        "focal_src": "public void validate(Object obj, Errors errors) { super.validate(obj, errors); DrugOrder order = (DrugOrder)obj; if(order == null) { errors.reject(\"error.general\"); } else { ValidationUtils.rejectIfEmpty(errors, \"asNeeded\", \"error.null\"); if(order.getAction() != Order.Action.DISCONTINUE) { ValidationUtils.rejectIfEmpty(errors, \"dosingType\", \"error.null\"); } if(order.getDrug() == null || order.getDrug().getConcept() == null) { ValidationUtils.rejectIfEmpty(errors, \"concept\", \"error.null\"); } if(order.getConcept() != null && order.getDrug() != null && order.getDrug().getConcept() != null) { if( ! order.getDrug().getConcept().equals(order.getConcept())) { errors.rejectValue(\"drug\", \"error.general\"); errors.rejectValue(\"concept\", \"error.concept\"); } } if(order.getAction() != Order.Action.DISCONTINUE && order.getDosingType() != null) { if(order.getDosingType().equals(DrugOrder.DosingType.SIMPLE)) { ValidationUtils.rejectIfEmpty(errors, \"dose\", \"DrugOrder.error.doseIsNullForDosingTypeSimple\"); ValidationUtils.rejectIfEmpty(errors, \"doseUnits\", \"DrugOrder.error.doseUnitsIsNullForDosingTypeSimple\"); ValidationUtils.rejectIfEmpty(errors, \"route\", \"DrugOrder.error.routeIsNullForDosingTypeSimple\"); ValidationUtils.rejectIfEmpty(errors, \"frequency\", \"DrugOrder.error.frequencyIsNullForDosingTypeSimple\"); } else { ValidationUtils.rejectIfEmpty(errors, \"dosingInstructions\", \"DrugOrder.error.dosingInstructionsIsNullForDosingTypeOther\"); } } validateFieldsForOutpatientCareSettingType(order, errors); validatePairedFields(order, errors); validateUnitsAreAmongAllowedConcepts(errors, order); } } ",
        "test_tgt": "@Test public void validate_shouldFailValidationIfDoseUnitsIsNullForSimpleDosingInstructionsDosingType()throws Exception { DrugOrder order = new DrugOrder(); order.setDosingType(SimpleDosingInstructions.class); order.setDoseUnits(null); Errors errors = new BindException(order, \"order\"); new DrugOrderValidator().validate(order, errors); Assert.assertTrue(errors.hasFieldErrors(\"doseUnits\")); } "
    },
    {
        "test_src": "@Test public void startNewSpan() { brave.serverTracer().setStateCurrentTrace(PARENT_CONTEXT, \"name\"); SpanId newContext = brave.localTracer().startNewSpan(COMPONENT_NAME, OPERATION_NAME); assertThat(newContext).isEqualTo(PARENT_CONTEXT.toBuilder().parentId(PARENT_CONTEXT.spanId).spanId(newContext.spanId).build()); assertThat(spans).isEmpty(); recorder.flush(brave.localSpanThreadBinder().get()); zipkin2.Span started = spans.get(0); assertThat(started.timestamp()).isEqualTo(START_TIME_MICROSECONDS); assertThat(started.name()).isEqualTo(OPERATION_NAME); assertThat(started.tags()).containsOnly(entry(\"lc\", COMPONENT_NAME)); } ",
        "focal_tgt": "public SpanId startNewSpan(String component, String operation, long timestamp) { Span span = newSpan(); if(span == null)return null; return startSpan(component, operation, timestamp, span); } ",
        "focal_src": "public SpanId startNewSpan(String component, String operation, long timestamp) { Boolean sample = currentServerSpan().sampled(); if(Boolean.FALSE.equals(sample)) { currentSpan().setCurrentSpan(null); return null; } Span span = spanFactory().nextSpan(maybeParent()); SpanId context = Brave.context(span); if(Boolean.FALSE.equals(context.sampled())) { currentSpan().setCurrentSpan(null); return null; } recorder().start(span, timestamp); recorder().name(span, operation); recorder().tag(span, LOCAL_COMPONENT, component); currentSpan().setCurrentSpan(span); return context; } ",
        "test_tgt": "@Test public void startNewSpan() { brave.serverTracer().setStateCurrentTrace(PARENT_CONTEXT, \"name\"); SpanId newContext = brave.localTracer().startNewSpan(COMPONENT_NAME, OPERATION_NAME); assertThat(newContext).isEqualTo(PARENT_CONTEXT.toBuilder().parentId(PARENT_CONTEXT.spanId).spanId(newContext.spanId).build()); assertThat(spans).isEmpty(); recorder.flush(brave.localSpanThreadBinder().get()); zipkin2.Span started = spans.get(0); assertThat(started.timestamp()).isGreaterThanOrEqualTo(START_TIME_MICROSECONDS); assertThat(started.name()).isEqualTo(OPERATION_NAME); assertThat(started.tags()).containsOnly(entry(\"lc\", COMPONENT_NAME)); } "
    },
    {
        "test_src": "@Test public void testContextual_3args_2() { System.out.println(\"contextual\"); double target = 0.2; double[]ratios = new double[] { 5.0, 2.0 }; double[]sources = new double[] { 0.5, 0.8 }; double expResult = 0.49; double result = Grades.contextual(target, ratios, sources); assertEquals(expResult, result, 0.01); } ",
        "focal_tgt": "public static double contextual(double target, double source, double ratio) { return(source * support(target, ratio)) + ((1 - source) * target); } ",
        "focal_src": "public static double contextual(double target, double ratio, double source) { return(source * support(target, ratio)) + ((1 - source) * target); } ",
        "test_tgt": "@Test public void testContextual_3args_2() { System.out.println(\"contextual\"); double target = 0.2; double[]ratios = new double[] { 5.0, 2.0 }; double[]sources = new double[] { 0.5, 0.8 }; double expResult = 0.49; double result = Grades.contextual(target, sources, ratios); assertEquals(expResult, result, 0.01); } "
    },
    {
        "test_src": "@Test public void liftM2() { Streamable < String > stream1 = Streamable.of(\"ALL UPPER\", \"MiXed Case\"); Streamable < String > stream2 = Streamable.of(\"MixedCase\", \"all lower\"); AnyM < String > responses = LiftMFunctions.liftM2(this :: response).apply(anyM(stream1), anyM(stream2)); assertThat(responses.toList(), equalTo(Arrays.asList(\"all upper::MIXEDCASE\", \"all upper::ALL LOWER\", \"mixed case::MIXEDCASE\", \"mixed case::ALL LOWER\"))); } ",
        "focal_tgt": "public static < U1, U2, R > BiFunction < AnyM < U1 > , AnyM < U2 > , AnyM < R > > liftM2(BiFunction < U1, U2, R > fn) { return(u1, u2) -> u1.bind(input1 -> (R)u2.map(input2 -> fn.apply(input1, input2)).unwrap()); } ",
        "focal_src": "public static < U1, U2, R > BiFunction < AnyM < U1 > , AnyM < U2 > , AnyM < R > > liftM2(BiFunction < U1, U2, R > fn) { return(u1, u2) -> u1.bind(input1 -> u2.map(input2 -> fn.apply(input1, input2)).unwrap()); } ",
        "test_tgt": "@Test public void liftM2() { Streamable < String > stream1 = Streamable.of(\"ALL UPPER\", \"MiXed Case\"); Streamable < String > stream2 = Streamable.of(\"MixedCase\", \"all lower\"); AnyM < String > responses = LiftMFunctions.liftM2(this :: response).apply(anyM(stream1), anyM(stream2)); assertThat(responses.traversable().toList(), equalTo(Arrays.asList(\"all upper::MIXEDCASE\", \"all upper::ALL LOWER\", \"mixed case::MIXEDCASE\", \"mixed case::ALL LOWER\"))); } "
    },
    {
        "test_src": "@Test@RunTestInLooperThread public void removeAllChangeListeners() { final Realm realm = looperThread.getRealm(); realm.beginTransaction(); Dog dog = realm.createObject(Dog.class); dog.setAge(13); realm.commitTransaction(); dog.addChangeListener(new RealmChangeListener < Dog > () { @Override public void onChange(Dog object) { fail(); } }); dog.addChangeListener(new RealmObjectChangeListener < Dog > () { @Override public void onChange(Dog object, ObjectChangeSet changeSet) { fail(); } }); dog.removeAllChangeListeners(); realm.beginTransaction(); Dog sameDog = realm.where(Dog.class).equalTo(Dog.FIELD_AGE, 13).findFirst(); sameDog.setName(\"Jesper\"); realm.commitTransaction(); realm.sharedRealm.refresh(); looperThread.testComplete(); } ",
        "focal_tgt": "public static < E extends RealmModel > void removeAllChangeListeners(E object) { if(object instanceof RealmObjectProxy) { RealmObjectProxy proxy = (RealmObjectProxy)object; BaseRealm realm = proxy.realmGet$proxyState().getRealm$realm(); realm.checkIfValid(); realm.osSharedRealm.capabilities.checkCanDeliverNotification(BaseRealm.LISTENER_NOT_ALLOWED_MESSAGE); proxy.realmGet$proxyState().removeAllChangeListeners(); } else { throw new IllegalArgumentException(\"Cannot remove listeners from this unmanaged RealmObject (created outside of Realm)\"); } } ",
        "focal_src": "public static < E extends RealmModel > void removeAllChangeListeners(E object) { if(object instanceof RealmObjectProxy) { RealmObjectProxy proxy = (RealmObjectProxy)object; BaseRealm realm = proxy.realmGet$proxyState().getRealm$realm(); realm.checkIfValid(); realm.sharedRealm.capabilities.checkCanDeliverNotification(BaseRealm.LISTENER_NOT_ALLOWED_MESSAGE); proxy.realmGet$proxyState().removeAllChangeListeners(); } else { throw new IllegalArgumentException(\"Cannot remove listeners from this unmanaged RealmObject (created outside of Realm)\"); } } ",
        "test_tgt": "@Test@RunTestInLooperThread public void removeAllChangeListeners() { final Realm realm = looperThread.getRealm(); realm.beginTransaction(); Dog dog = realm.createObject(Dog.class); dog.setAge(13); realm.commitTransaction(); dog.addChangeListener(new RealmChangeListener < Dog > () { @Override public void onChange(Dog object) { fail(); } }); dog.addChangeListener(new RealmObjectChangeListener < Dog > () { @Override public void onChange(Dog object, ObjectChangeSet changeSet) { fail(); } }); dog.removeAllChangeListeners(); realm.beginTransaction(); Dog sameDog = realm.where(Dog.class).equalTo(Dog.FIELD_AGE, 13).findFirst(); sameDog.setName(\"Jesper\"); realm.commitTransaction(); realm.osSharedRealm.refresh(); looperThread.testComplete(); } "
    },
    {
        "test_src": "@Test public void testToString() { StrBuilder sb = new StrBuilder(\"abc\"); assertEquals(\"abc\", sb.toString()); } ",
        "focal_tgt": "public static String toString(final Annotation a) { final ToStringBuilder builder = new ToStringBuilder(a, TO_STRING_STYLE); for(final Method m : a.annotationType().getDeclaredMethods()) { if(m.getParameterTypes().length > 0) { continue; } try { builder.append(m.getName(), m.invoke(a)); } catch(final RuntimeException ex) { throw ex; } catch(final Exception ex) { throw new RuntimeException(ex); } } return builder.build(); } ",
        "focal_src": "public static String toString(final Annotation a) { ToStringBuilder builder = new ToStringBuilder(a, TO_STRING_STYLE); for(Method m : a.annotationType().getDeclaredMethods()) { if(m.getParameterTypes().length > 0) { continue; } try { builder.append(m.getName(), m.invoke(a)); } catch(RuntimeException ex) { throw ex; } catch(Exception ex) { throw new RuntimeException(ex); } } return builder.build(); } ",
        "test_tgt": "@Test public void testToString() { final StrBuilder sb = new StrBuilder(\"abc\"); assertEquals(\"abc\", sb.toString()); } "
    },
    {
        "test_src": "@Test public void testLeProp() { assertTrue(instance.leProp(\"id\", \"name\").getQueryCriterions().contains(new LePropCriterion(\"id\", \"name\"))); } ",
        "focal_tgt": "public CriteriaQuery leProp(String propName, String otherProp) { criterion = criterion.and(criterionBuilder.leProp(propName, otherProp)); return this; } ",
        "focal_src": "public CriteriaQuery leProp(String propName, String otherProp) { addCriterion(criterionBuilder.leProp(propName, otherProp)); return this; } ",
        "test_tgt": "@Test public void testLeProp() { assertEquals(new LePropCriterion(\"id\", \"name\"), instance.leProp(\"id\", \"name\").getQueryCriterion()); } "
    },
    {
        "test_src": "@Test void computeCostInnerD() { Planar < GrayU16 > costYXD = new Planar < > (GrayU16.class, rangeD, width, height); GImageMiscOps.fillUniform(costYXD, rand, 0, SgmDisparityCost.MAX_COST); SgmCostAggregation alg = new SgmCostAggregation(); alg.init(costYXD); for(int i = 0; i < alg.workCostLr.length; i ++ ) { alg.workCostLr[i] = (short)rand.nextInt(SgmDisparityCost.MAX_COST); } GrayU16 costXD = costYXD.getBand(2); int x = rangeD + 2; int pathI = 3; int idxCost = costXD.getIndex(0, x); int idxWork = alg.lengthD * pathI; alg.computeCostInnerD(costXD, idxCost, idxWork, rangeD); for(int d = 1; d < rangeD - 1; d ++ ) { int cost_p_d = costXD.get(d, x); int l0 = workArray(alg, pathI, d); int l1 = workArray(alg, pathI, d - 1) + alg.penalty1; int l2 = workArray(alg, pathI, d + 1) + alg.penalty1; int l3 = alg.penalty2; int v = min(min(min(l0, l1), l2), l3); int expected = cost_p_d + v; int found = workArray(alg, pathI + 1, d); assertEquals(expected, found); } } ",
        "focal_tgt": "void computeCostInnerD(GrayU16 costXD, int idxCost, int idxLrPrev, int lengthLocalD, short[]workCostLr) { idxLrPrev += 1; for(int d = 1; d < lengthLocalD - 1; d ++ , idxLrPrev ++ ) { int cost = costXD.data[idxCost + d] & 0xFFFF; int b = workCostLr[idxLrPrev - 1] & 0xFFFF; int a = workCostLr[idxLrPrev] & 0xFFFF; int c = workCostLr[idxLrPrev + 1] & 0xFFFF; b += penalty1; c += penalty1; if(b < a)a = b; if(c < a)a = c; if(penalty2 < a)a = penalty2; if(cost + a > Short.MAX_VALUE)throw new RuntimeException(\"Egads\"); workCostLr[idxLrPrev + this.lengthD] = (short)(cost + a); } } ",
        "focal_src": "void computeCostInnerD(GrayU16 costXD, int idxCost, int idxLrPrev, int lengthLocalD) { idxLrPrev += 1; for(int d = 1; d < lengthLocalD - 1; d ++ , idxLrPrev ++ ) { int cost = costXD.data[idxCost + d] & 0xFFFF; int b = workCostLr[idxLrPrev - 1] & 0xFFFF; int a = workCostLr[idxLrPrev] & 0xFFFF; int c = workCostLr[idxLrPrev + 1] & 0xFFFF; b += penalty1; c += penalty1; if(b < a)a = b; if(c < a)a = c; if(penalty2 < a)a = penalty2; if(cost + a > Short.MAX_VALUE)throw new RuntimeException(\"Egads\"); workCostLr[idxLrPrev + this.lengthD] = (short)(cost + a); } } ",
        "test_tgt": "@Test void computeCostInnerD() { Planar < GrayU16 > costYXD = new Planar < > (GrayU16.class, rangeD, width, height); GImageMiscOps.fillUniform(costYXD, rand, 0, SgmDisparityCost.MAX_COST); SgmCostAggregation alg = new SgmCostAggregation(); alg.init(costYXD); short[]workCostLr = alg.workspace.get(0).workCostLr; for(int i = 0; i < workCostLr.length; i ++ ) { workCostLr[i] = (short)rand.nextInt(SgmDisparityCost.MAX_COST); } GrayU16 costXD = costYXD.getBand(2); int x = rangeD + 2; int pathI = 3; int idxCost = costXD.getIndex(0, x); int idxWork = alg.lengthD * pathI; alg.computeCostInnerD(costXD, idxCost, idxWork, rangeD, workCostLr); for(int d = 1; d < rangeD - 1; d ++ ) { int cost_p_d = costXD.get(d, x); int l0 = workArray(alg, pathI, d); int l1 = workArray(alg, pathI, d - 1) + alg.penalty1; int l2 = workArray(alg, pathI, d + 1) + alg.penalty1; int l3 = alg.penalty2; int v = min(min(min(l0, l1), l2), l3); int expected = cost_p_d + v; int found = workArray(alg, pathI + 1, d); assertEquals(expected, found); } } "
    },
    {
        "test_src": "@Test public void xsd() { query(_VALIDATE_XSD.args(FILE, XSD), \"\"); query(_VALIDATE_XSD.args(DOC.args(FILE), DOC.args(XSD)), \"\"); query(_VALIDATE_XSD.args(_FILE_READ_TEXT.args(FILE), _FILE_READ_TEXT.args(XSD)), \"\"); query(\"let $doc := <root/> \" + \"let $schema := <xs:schema xmlns:xs='http://www.w3.org/2001/XMLSchema'> \" + \"<xs:element name='root'/> \" + \"</xs:schema> \" + \"return validate:xsd($doc, $schema)\", \"\"); error(_VALIDATE_XSD.args(\"unknown\"), Err.WHICHRES); error(_VALIDATE_XSD.args(FILE, \"unknown.xsd\"), Err.WHICHRES); error(_VALIDATE_XSD.args(FILE), Err.BXVA_FAIL); error(\"let $doc := <root/> \" + \"let $schema := <xs:schema xmlns:xs='http://www.w3.org/2001/XMLSchema'> \" + \"<xs:element name='unknown'/> \" + \"</xs:schema> \" + \"return validate:xsd($doc, $schema)\", Err.BXVA_FAIL); } ",
        "focal_tgt": "private Item xsd(final QueryContext qc)throws QueryException { final Value seq = xsdInfo(qc); if(seq == Empty.SEQ)return null; throw BXVA_FAIL_X.get(info, seq.iter().next()); } ",
        "focal_src": "private Item xsd(final QueryContext qc)throws QueryException { final Value seq = xsdInfo(qc); if(seq == Empty.SEQ)return null; throw BXVA_FAIL.get(info, seq.iter().next()); } ",
        "test_tgt": "@Test public void xsd() { query(_VALIDATE_XSD.args(FILE, XSD), \"\"); query(_VALIDATE_XSD.args(DOC.args(FILE), DOC.args(XSD)), \"\"); query(_VALIDATE_XSD.args(_FILE_READ_TEXT.args(FILE), _FILE_READ_TEXT.args(XSD)), \"\"); query(\"let $doc := <root/> \" + \"let $schema := <xs:schema xmlns:xs='http://www.w3.org/2001/XMLSchema'> \" + \"<xs:element name='root'/> \" + \"</xs:schema> \" + \"return validate:xsd($doc, $schema)\", \"\"); error(_VALIDATE_XSD.args(\"unknown\"), Err.WHICHRES_X); error(_VALIDATE_XSD.args(FILE, \"unknown.xsd\"), Err.WHICHRES_X); error(_VALIDATE_XSD.args(FILE), Err.BXVA_FAIL_X); error(\"let $doc := <root/> \" + \"let $schema := <xs:schema xmlns:xs='http://www.w3.org/2001/XMLSchema'> \" + \"<xs:element name='unknown'/> \" + \"</xs:schema> \" + \"return validate:xsd($doc, $schema)\", Err.BXVA_FAIL_X); } "
    },
    {
        "test_src": "@Test public void testGetXpathExpression()throws SAXException, IOException { final String html = \"<body><div id='firstdiv'></div><div><span id='thespan'>\" + \"<a id='thea'>test</a></span></div></body>\"; Document dom = DomUtils.asDocument(html); assertNotNull(dom); String expectedXpath = \"/HTML[1]/BODY[1]/DIV[1]\"; String xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"firstdiv\")); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"/HTML[1]/BODY[1]/DIV[2]/SPAN[1]\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"thespan\")); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"/HTML[1]/BODY[1]/DIV[2]/SPAN[1]/A[1]\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"thea\")); assertEquals(expectedXpath, xpathExpr); } ",
        "focal_tgt": "public static String getXPathExpression(Node node) { Object xpathCache = node.getUserData(FULL_XPATH_CACHE); if(xpathCache != null) { return xpathCache.toString(); } Node parent = node.getParentNode(); if((parent == null) || parent.getNodeName().contains(\"#document\")) { String xPath = \"/\" + node.getNodeName() + \"[1]\"; node.setUserData(FULL_XPATH_CACHE, xPath, null); return xPath; } if(node.hasAttributes() && node.getAttributes().getNamedItem(\"id\") != null) { String xPath = \"//\" + node.getNodeName() + \"[@id = '\" + node.getAttributes().getNamedItem(\"id\").getNodeValue() + \"']\"; node.setUserData(FULL_XPATH_CACHE, xPath, null); return xPath; } StringBuffer buffer = new StringBuffer(); if(parent != node) { buffer.append(getXPathExpression(parent)); buffer.append(\"/\"); } buffer.append(node.getNodeName()); List < Node > mySiblings = getSiblings(parent, node); for(int i = 0; i < mySiblings.size(); i ++ ) { Node el = mySiblings.get(i); if(el.equals(node)) { buffer.append('[').append(Integer.toString(i + 1)).append(']'); break; } } String xPath = buffer.toString(); node.setUserData(FULL_XPATH_CACHE, xPath, null); return xPath; } ",
        "focal_src": "public static String getXPathExpression(Node node) { Object xpathCache = node.getUserData(FULL_XPATH_CACHE); if(xpathCache != null) { return xpathCache.toString(); } Node parent = node.getParentNode(); if((parent == null) || parent.getNodeName().contains(\"#document\")) { String xPath = \"/\" + node.getNodeName() + \"[1]\"; node.setUserData(FULL_XPATH_CACHE, xPath, null); return xPath; } StringBuffer buffer = new StringBuffer(); if(parent != node) { buffer.append(getXPathExpression(parent)); buffer.append(\"/\"); } buffer.append(node.getNodeName()); List < Node > mySiblings = getSiblings(parent, node); for(int i = 0; i < mySiblings.size(); i ++ ) { Node el = mySiblings.get(i); if(el.equals(node)) { buffer.append('[').append(Integer.toString(i + 1)).append(']'); break; } } String xPath = buffer.toString(); node.setUserData(FULL_XPATH_CACHE, xPath, null); return xPath; } ",
        "test_tgt": "@Test public void testGetXpathExpression()throws IOException { String html = \"<body><div id='firstdiv'></div><div><span id='thespan'>\" + \"<a id='thea'>test</a></span></div></body>\"; Document dom = DomUtils.asDocument(html); assertNotNull(dom); String expectedXpath = \"//DIV[@id = 'firstdiv']\"; String xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"firstdiv\")); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"//SPAN[@id = 'thespan']\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"thespan\")); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"//A[@id = 'thea']\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"thea\")); assertEquals(expectedXpath, xpathExpr); html = \"<body><div id='firstdiv'><span><div></div></span></div>\" + \"<div><span id='thespan'><div></div></span><span></span></div></body>\"; dom = DomUtils.asDocument(html); expectedXpath = \"//DIV[@id = 'firstdiv']/SPAN[1]/DIV[1]\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"firstdiv\").getFirstChild().getFirstChild()); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"//SPAN[@id = 'thespan']/DIV[1]\"; xpathExpr = XPathHelper.getXPathExpression(dom.getElementById(\"thespan\").getFirstChild()); assertEquals(expectedXpath, xpathExpr); expectedXpath = \"/HTML[1]/BODY[1]/DIV[2]/SPAN[2]\"; xpathExpr = XPathHelper.getXPathExpression(dom.getFirstChild().getLastChild().getLastChild().getLastChild()); assertEquals(expectedXpath, xpathExpr); } "
    },
    {
        "test_src": "@Test public void testGetProjectDescriptions() { Project foo = new Project(\"foo\", \"/foo\"); Project bar = new Project(\"bar\", \"/bar\"); HashMap < String, Project > projects = new HashMap < > (); projects.put(\"foo\", foo); projects.put(\"bar\", bar); RuntimeEnvironment env = RuntimeEnvironment.getInstance(); env.setProjects(projects); List < String > descs = env.getProjectDescriptions(); assertTrue(descs.contains(\"foo\")); assertTrue(descs.contains(\"bar\")); assertFalse(descs.contains(\"foobar\")); assertEquals(2, descs.size()); } ",
        "focal_tgt": "public List < String > getProjectNames() { return getProjectList().stream().map(Project :: getName).collect(Collectors.toList()); } ",
        "focal_src": "public List < String > getProjectDescriptions() { return getProjectList().stream().map(Project :: getName).collect(Collectors.toList()); } ",
        "test_tgt": "@Test public void testGetProjectDescriptions() { Project foo = new Project(\"foo\", \"/foo\"); Project bar = new Project(\"bar\", \"/bar\"); HashMap < String, Project > projects = new HashMap < > (); projects.put(\"foo\", foo); projects.put(\"bar\", bar); RuntimeEnvironment env = RuntimeEnvironment.getInstance(); env.setProjects(projects); List < String > descs = env.getProjectNames(); assertTrue(descs.contains(\"foo\")); assertTrue(descs.contains(\"bar\")); assertFalse(descs.contains(\"foobar\")); assertEquals(2, descs.size()); } "
    },
    {
        "test_src": "@Test public void testFindByProperties() { List list = Collections.singletonList(instance); Map props = Collections.singletonMap(\"name\", \"abc\"); when(repository.findByProperties(MyEntity.class, MapParameters.create(props))).thenReturn(list); assertEquals(list, AbstractEntity.findByProperties(MyEntity.class, props)); } ",
        "focal_tgt": "public static < T extends Entity > List < T > findByProperties(Class < T > clazz, Map < String, Object > propValues) { return getRepository().findByProperties(clazz, NamedParameters.create(propValues)); } ",
        "focal_src": "public static < T extends Entity > List < T > findByProperties(Class < T > clazz, Map < String, Object > propValues) { return getRepository().findByProperties(clazz, MapParameters.create(propValues)); } ",
        "test_tgt": "@Test public void testFindByProperties() { List list = Collections.singletonList(instance); Map props = Collections.singletonMap(\"name\", \"abc\"); when(repository.findByProperties(MyEntity.class, NamedParameters.create(props))).thenReturn(list); assertEquals(list, AbstractEntity.findByProperties(MyEntity.class, props)); } "
    },
    {
        "test_src": "@Test public void testDownloadFileFromServer()throws Exception { final RestfulMgr restfulMgr = new RestfulMgrMock().getMockInstance(); FetcherMgr fetcherMgr = new FetcherMgrImpl(restfulMgr, 3, 5, true, \"\", new ArrayList < String > ()); try { String valueString = fetcherMgr.downloadFileFromServer(requestUrl, RestfulMgrMock.defaultFileName); Assert.assertEquals(RestfulMgrMock.defaultFileName, valueString); } catch(Exception e) { e.printStackTrace(); Assert.assertTrue(false); } } ",
        "focal_tgt": "String downloadFileFromServer(String url, String fileName, String copy2TargetDirPath)throws Exception; ",
        "focal_src": "String downloadFileFromServer(String url, String fileName)throws Exception; ",
        "test_tgt": "@Test public void testDownloadFileFromServer()throws Exception { final RestfulMgr restfulMgr = new RestfulMgrMock().getMockInstance(); FetcherMgr fetcherMgr = new FetcherMgrImpl(restfulMgr, 3, 5, true, \"\", new ArrayList < String > ()); try { String valueString = fetcherMgr.downloadFileFromServer(requestUrl, RestfulMgrMock.defaultFileName, \"./disconf\"); Assert.assertEquals(RestfulMgrMock.defaultFileName, valueString); } catch(Exception e) { e.printStackTrace(); Assert.assertTrue(false); } } "
    },
    {
        "test_src": "@Test public void listCertificates()throws Exception { String certificateName = \"listCertificate\"; String certificateContent = \"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\"; String certificatePassword = \"123\"; SecretProperties secretProperties = new SecretProperties(); secretProperties.withContentType(MIME_PKCS12); CertificatePolicy certificatePolicy = new CertificatePolicy(); certificatePolicy.withSecretProperties(secretProperties); HashSet < String > certificates = new HashSet < String > (); for(int i = 0; i < MAX_CERTS; ++ i) { int failureCount = 0; for(; ; ) { try { CertificateBundle certificateBundle = keyVaultClient.importCertificate(new ImportCertificateRequest.Builder(getVaultUri(), certificateName + i, certificateContent).withPassword(certificatePassword).withPolicy(certificatePolicy).build()).getBody(); CertificateIdentifier id = certificateBundle.certificateIdentifier(); certificates.add(id.baseIdentifier()); break; } catch(KeyVaultErrorException e) { ++ failureCount; if(e.getBody().error().code().equals(\"Throttled\")) { System.out.println(\"Waiting to avoid throttling\"); Thread.sleep(failureCount * 1500); continue; } throw e; } } } PagedList < CertificateItem > listResult = keyVaultClient.listCertificates(getVaultUri(), PAGELIST_MAX_CERTS).getBody(); Assert.assertTrue(PAGELIST_MAX_CERTS >= listResult.currentPage().getItems().size()); HashSet < String > toDelete = new HashSet < String > (); for(CertificateItem item : listResult) { if(item != null) { CertificateIdentifier id = new CertificateIdentifier(item.id()); toDelete.add(id.name()); certificates.remove(item.id()); } } Assert.assertEquals(0, certificates.size()); for(String toDeleteCertificateName : toDelete) { keyVaultClient.deleteCertificate(getVaultUri(), toDeleteCertificateName); } } ",
        "focal_tgt": "public PagedList < CertificateItem > listCertificates(final String vaultBaseUrl, final Integer maxresults)throws KeyVaultErrorException, IOException, IllegalArgumentException { return innerKeyVaultClient.getCertificates(vaultBaseUrl, maxresults); } ",
        "focal_src": "public ServiceResponse < PagedList < CertificateItem > > listCertificates(final String vaultBaseUrl, final Integer maxresults)throws KeyVaultErrorException, IOException, IllegalArgumentException { return innerKeyVaultClient.getCertificates(vaultBaseUrl, maxresults); } ",
        "test_tgt": "@Test public void listCertificates()throws Exception { String certificateName = \"listCertificate\"; String certificateContent = \"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\"; String certificatePassword = \"123\"; SecretProperties secretProperties = new SecretProperties(); secretProperties.withContentType(MIME_PKCS12); CertificatePolicy certificatePolicy = new CertificatePolicy(); certificatePolicy.withSecretProperties(secretProperties); HashSet < String > certificates = new HashSet < String > (); for(int i = 0; i < MAX_CERTS; ++ i) { int failureCount = 0; for(; ; ) { try { CertificateBundle certificateBundle = keyVaultClient.importCertificate(new ImportCertificateRequest.Builder(getVaultUri(), certificateName + i, certificateContent).withPassword(certificatePassword).withPolicy(certificatePolicy).build()); CertificateIdentifier id = certificateBundle.certificateIdentifier(); certificates.add(id.baseIdentifier()); break; } catch(KeyVaultErrorException e) { ++ failureCount; if(e.getBody().error().code().equals(\"Throttled\")) { System.out.println(\"Waiting to avoid throttling\"); Thread.sleep(failureCount * 1500); continue; } throw e; } } } PagedList < CertificateItem > listResult = keyVaultClient.listCertificates(getVaultUri(), PAGELIST_MAX_CERTS); Assert.assertTrue(PAGELIST_MAX_CERTS >= listResult.currentPage().getItems().size()); HashSet < String > toDelete = new HashSet < String > (); for(CertificateItem item : listResult) { if(item != null) { CertificateIdentifier id = new CertificateIdentifier(item.id()); toDelete.add(id.name()); certificates.remove(item.id()); } } Assert.assertEquals(0, certificates.size()); for(String toDeleteCertificateName : toDelete) { keyVaultClient.deleteCertificate(getVaultUri(), toDeleteCertificateName); } } "
    },
    {
        "test_src": "@Test public void testIsSPNegoMessage() { final SimpleHttpRequest request = new SimpleHttpRequest(); final AuthorizationHeader header = new AuthorizationHeader(request); Assert.assertFalse(header.isSPNegoMessage()); request.addHeader(\"Authorization\", \"\"); Assert.assertFalse(header.isSPNegoMessage()); request.addHeader(\"Authorization\", \"Negotiate YHYGBisGAQUFAqBsMGqgMDAuBgorBgEEAYI3AgIKBgkqhkiC9xIBAgIGCSqGSIb3EgECAgYKKwYBBAGCNwICHqI2BDROVExNU1NQAAEAAACXsgjiAwADADEAAAAJAAkAKAAAAAYBsR0AAAAPR0xZQ0VSSU5FU0FE\"); Assert.assertTrue(header.isSPNegoMessage()); } ",
        "focal_tgt": "public boolean isSPNegTokenInitMessage() { if(this.isNull()) { return false; } final byte[]tokenBytes = this.getTokenBytes(); return SPNegoMessage.isNegTokenInit(tokenBytes); } ",
        "focal_src": "public boolean isSPNegoMessage() { if(this.isNull()) { return false; } final byte[]tokenBytes = this.getTokenBytes(); return SPNegoMessage.isSPNegoMessage(tokenBytes); } ",
        "test_tgt": "@Test public void testIsSPNegTokenInitMessage() { final SimpleHttpRequest request = new SimpleHttpRequest(); final AuthorizationHeader header = new AuthorizationHeader(request); Assert.assertFalse(header.isSPNegTokenInitMessage()); request.addHeader(\"Authorization\", \"\"); Assert.assertFalse(header.isSPNegTokenInitMessage()); request.addHeader(\"Authorization\", \"Negotiate YHYGBisGAQUFAqBsMGqgMDAuBgorBgEEAYI3AgIKBgkqhkiC9xIBAgIGCSqGSIb3EgECAgYKKwYBBAGCNwICHqI2BDROVExNU1NQAAEAAACXsgjiAwADADEAAAAJAAkAKAAAAAYBsR0AAAAPR0xZQ0VSSU5FU0FE\"); Assert.assertTrue(header.isSPNegTokenInitMessage()); } "
    },
    {
        "test_src": "@Test public final void testToArray() { ItemList il = new ItemList(Itr.ZERO); for(int i = 0; i < CAP - 1; i ++ ) { il.add(Itr.ZERO); } assertEquals(CAP, il.toArray().length); assertEquals(il.size(), il.toArray().length); } ",
        "focal_tgt": "public Item[]finish() { assert size > 0 : \"List is empty.\"; Item[]its = new Item[size]; System.arraycopy(values, 0, its, 0, size); values = new Item[CAP]; size = 0; return its; } ",
        "focal_src": "public Item[]toArray() { return Arrays.copyOf(values, size()); } ",
        "test_tgt": "@Test public final void testToArray() { ItemList il = new ItemList(Itr.ZERO); for(int i = 0; i < CAP - 1; i ++ ) { il.add(Itr.ZERO); } assertEquals(CAP, il.finish().length); } "
    },
    {
        "test_src": "@Test public void testAllStoredEventsSince() { System.out.println(\"allStoredEventsSince\"); Date occurredFrom = null; HibernateEventStore instance = new HibernateEventStore(); List < StoredEvent > expResult = null; List < StoredEvent > result = instance.allStoredEventsSince(occurredFrom); assertEquals(expResult, result); fail(\"The test case is a prototype.\"); } ",
        "focal_tgt": "public List < StoredEvent > findStoredEventsSince(Date occurredFrom); ",
        "focal_src": "public List < StoredEvent > allStoredEventsSince(Date occurredFrom); ",
        "test_tgt": "@Test public void testFindStoredEventsSince() { System.out.println(\"findStoredEventsSince\"); Date occurredFrom = null; HibernateEventStore instance = new HibernateEventStore(); List < StoredEvent > expResult = null; List < StoredEvent > result = instance.findStoredEventsSince(occurredFrom); assertEquals(expResult, result); fail(\"The test case is a prototype.\"); } "
    },
    {
        "test_src": "@Test public void testQueueStringForComm()throws Exception { System.out.println(\"queueStringForComm\"); String input = \"someCommand\"; MockConnection mc = new MockConnection(mg.in, mg.out); GrblCommunicator instance = new GrblCommunicator(cb, asl, mc); try { instance.queueStringForComm(input); assertEquals(1, cb.size()); assertEquals(input + \"\\n\", cb.peek()); instance.queueStringForComm(input); instance.queueStringForComm(input); assertEquals(3, cb.size()); input = \"someCommand\\n\"; cb = new LinkedBlockingDeque < > (); mc = new MockConnection(mg.in, mg.out); instance = new GrblCommunicator(cb, asl, mc); instance.queueStringForComm(input); assertEquals(input, cb.peek()); } catch(Exception e) { fail(\"queueStringForComm threw an exception: \" + e.getMessage()); } } ",
        "focal_tgt": "@Override public void queueStringForComm(final String input) { String commandString = input; this.commandBuffer.add(commandString); } ",
        "focal_src": "@Override public void queueStringForComm(final String input) { String commandString = input; if( ! commandString.endsWith(\"\\n\")) { commandString += \"\\n\"; } this.commandBuffer.add(commandString); } ",
        "test_tgt": "@Test public void testQueueStringForComm()throws Exception { System.out.println(\"queueStringForComm\"); String input = \"someCommand\"; MockConnection mc = new MockConnection(mg.in, mg.out); GrblCommunicator instance = new GrblCommunicator(cb, asl, mc); try { instance.queueStringForComm(input); assertEquals(1, cb.size()); String next = cb.peek(); assertEquals(input, cb.peek()); instance.queueStringForComm(input); instance.queueStringForComm(input); assertEquals(3, cb.size()); input = \"someCommand\"; cb = new LinkedBlockingDeque < > (); mc = new MockConnection(mg.in, mg.out); instance = new GrblCommunicator(cb, asl, mc); instance.queueStringForComm(input); assertEquals(input, cb.peek()); } catch(Exception e) { fail(\"queueStringForComm threw an exception: \" + e.getMessage()); } } "
    },
    {
        "test_src": "@Test public void testFindByClusterStackAndVersion() { Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", \"HDP-2.2\", \"2.2.0.0-995\").size()); Assert.assertEquals(3, hostVersionDAO.findAll().size()); addMoreVersions(); Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", \"HDP-2.2\", \"2.2.0.1-996\").size()); Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", \"HDP-2.2\", \"2.2.1.0-500\").size()); Assert.assertEquals(9, hostVersionDAO.findAll().size()); } ",
        "focal_tgt": "@RequiresSession public List < HostVersionEntity > findByClusterStackAndVersion(String clusterName, StackId stackId, String version) { final TypedQuery < HostVersionEntity > query = entityManagerProvider.get().createNamedQuery(\"hostVersionByClusterAndStackAndVersion\", HostVersionEntity.class); query.setParameter(\"clusterName\", clusterName); query.setParameter(\"stackName\", stackId.getStackName()); query.setParameter(\"stackVersion\", stackId.getStackVersion()); query.setParameter(\"version\", version); return daoUtils.selectList(query); } ",
        "focal_src": "@RequiresSession public List < HostVersionEntity > findByClusterStackAndVersion(String clusterName, String stack, String version) { final TypedQuery < HostVersionEntity > query = entityManagerProvider.get().createNamedQuery(\"hostVersionByClusterAndStackAndVersion\", HostVersionEntity.class); query.setParameter(\"clusterName\", clusterName); query.setParameter(\"stack\", stack); query.setParameter(\"version\", version); return daoUtils.selectList(query); } ",
        "test_tgt": "@Test public void testFindByClusterStackAndVersion() { Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", HDP_22_STACK, \"2.2.0.0-995\").size()); Assert.assertEquals(3, hostVersionDAO.findAll().size()); addMoreVersions(); Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", HDP_22_STACK, \"2.2.0.1-996\").size()); Assert.assertEquals(3, hostVersionDAO.findByClusterStackAndVersion(\"test_cluster1\", HDP_22_STACK, \"2.2.1.0-500\").size()); Assert.assertEquals(9, hostVersionDAO.findAll().size()); } "
    },
    {
        "test_src": "@Test public void saveVisitAttributeType_shouldCreateANewVisitAttributeType()throws Exception { executeDataSet(VISITS_ATTRIBUTES_XML); Assert.assertEquals(3, service.getAllVisitAttributeTypes().size()); VisitAttributeType vat = new VisitAttributeType(); vat.setName(\"Another one\"); vat.setDatatypeClassname(FreeText.class.getName()); service.saveVisitAttributeType(vat); Assert.assertNotNull(vat.getId()); Assert.assertEquals(4, service.getAllVisitAttributeTypes().size()); } ",
        "focal_tgt": "@Override@Transactional public VisitAttributeType saveVisitAttributeType(VisitAttributeType visitAttributeType) { getCurrentSession().saveOrUpdate(visitAttributeType); return visitAttributeType; } ",
        "focal_src": "@Override public VisitAttributeType saveVisitAttributeType(VisitAttributeType visitAttributeType) { getCurrentSession().saveOrUpdate(visitAttributeType); return visitAttributeType; } ",
        "test_tgt": "@Test public void saveVisitAttributeType_shouldCreateANewVisitAttributeType()throws Exception { executeDataSet(VISITS_ATTRIBUTES_XML); Assert.assertEquals(3, service.getAllVisitAttributeTypes().size()); VisitAttributeType vat = new VisitAttributeType(); vat.setName(\"Another one\"); vat.setDatatypeClassname(FreeTextDatatype.class.getName()); service.saveVisitAttributeType(vat); Assert.assertNotNull(vat.getId()); Assert.assertEquals(4, service.getAllVisitAttributeTypes().size()); } "
    },
    {
        "test_src": "@Test public void testMedian() { TestUtils.log(this.getClass(), \"median\"); DataTable2D classifierClassProbabilityMatrix = getClassifierClassProbabilityMatrix(); AssociativeArray expResult = new AssociativeArray(); expResult.put(\"class1\", 0.2665); expResult.put(\"class2\", 0.45); expResult.put(\"class3\", 0.3165); AssociativeArray result = FixedCombinationRules.median(classifierClassProbabilityMatrix); for(Object k : expResult.keySet()) { assertEquals(TypeConversions.toDouble(expResult.get(k)), TypeConversions.toDouble(result.get(k)), TestConfiguration.DOUBLE_ACCURACY_HIGH); } } ",
        "focal_tgt": "public static double median(AssociativeArray2D survivalFunction)throws IllegalArgumentException { Double ApointTi = null; Double BpointTi = null; int n = survivalFunction.size(); if(n == 0) { throw new IllegalArgumentException(); } for(Map.Entry < Object, AssociativeArray > entry : survivalFunction.entrySet()) { Object ti = entry.getKey(); AssociativeArray row = entry.getValue(); Double Sti = row.getDouble(\"Sti\"); if(Sti == null) { continue; } Double point = Double.valueOf(ti.toString()); if(Sti == 0.5) { return point; } else if(Sti > 0.5) { ApointTi = point; } else { BpointTi = point; break; } } if(n == 1) { return(ApointTi != null) ? ApointTi : BpointTi; } double ApointTiValue = TypeInference.toDouble(survivalFunction.get2d(ApointTi.toString(), \"Sti\")); double BpointTiValue = TypeInference.toDouble(survivalFunction.get2d(BpointTi.toString(), \"Sti\")); double median = BpointTi - (BpointTiValue - 0.5) * (BpointTi - ApointTi) / (BpointTiValue - ApointTiValue); return median; } ",
        "focal_src": "public static double median(AssociativeArray2D survivalFunction)throws IllegalArgumentException { Double ApointTi = null; Double BpointTi = null; int n = survivalFunction.size(); if(n == 0) { throw new IllegalArgumentException(); } for(Map.Entry < Object, AssociativeArray > entry : survivalFunction.entrySet()) { Object ti = entry.getKey(); AssociativeArray row = entry.getValue(); Double Sti = row.getDouble(\"Sti\"); if(Sti == null) { continue; } Double point = Double.valueOf(ti.toString()); if(Sti == 0.5) { return point; } else if(Sti > 0.5) { ApointTi = point; } else { BpointTi = point; break; } } if(n == 1) { return(ApointTi != null) ? ApointTi : BpointTi; } double ApointTiValue = TypeConversions.toDouble(survivalFunction.get2d(ApointTi.toString(), \"Sti\")); double BpointTiValue = TypeConversions.toDouble(survivalFunction.get2d(BpointTi.toString(), \"Sti\")); double median = BpointTi - (BpointTiValue - 0.5) * (BpointTi - ApointTi) / (BpointTiValue - ApointTiValue); return median; } ",
        "test_tgt": "@Test public void testMedian() { TestUtils.log(this.getClass(), \"median\"); DataTable2D classifierClassProbabilityMatrix = getClassifierClassProbabilityMatrix(); AssociativeArray expResult = new AssociativeArray(); expResult.put(\"class1\", 0.2665); expResult.put(\"class2\", 0.45); expResult.put(\"class3\", 0.3165); AssociativeArray result = FixedCombinationRules.median(classifierClassProbabilityMatrix); for(Object k : expResult.keySet()) { assertEquals(TypeInference.toDouble(expResult.get(k)), TypeInference.toDouble(result.get(k)), TestConfiguration.DOUBLE_ACCURACY_HIGH); } } "
    },
    {
        "test_src": "@Test public void matchIPProtocolTest() { Criterion criterion = Criteria.matchIPProtocol((byte)7); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result.get(\"type\").textValue(), is(criterion.type().toString())); assertThat(result.get(\"protocol\").asInt(), is(7)); } ",
        "focal_tgt": "public static Criterion matchIPProtocol(short proto) { return new IPProtocolCriterion(proto); } ",
        "focal_src": "public static Criterion matchIPProtocol(Byte proto) { return new IPProtocolCriterion(proto); } ",
        "test_tgt": "@Test public void matchIPProtocolTest() { Criterion criterion = Criteria.matchIPProtocol((byte)250); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result.get(\"type\").textValue(), is(criterion.type().toString())); assertThat(result.get(\"protocol\").asInt(), is(250)); } "
    },
    {
        "test_src": "@Test public void testScanArtifacts()throws DatabaseException, InvalidSettingException { new MockUp < MavenProject > () { @Mock public Set < Artifact > getArtifacts() { Set < Artifact > artifacts = new HashSet < > (); Artifact a = new ArtifactStub(); try { File file = new File(Test.class.getProtectionDomain().getCodeSource().getLocation().toURI()); a.setFile(file); artifacts.add(a); } catch(URISyntaxException ex) { Logger.getLogger(BaseDependencyCheckMojoTest.class.getName()).log(Level.SEVERE, null, ex); } return artifacts; }@Mock public String getName() { return \"test-project\"; } }; if(canRun()) { boolean autoUpdate = getSettings().getBoolean(Settings.KEYS.AUTO_UPDATE); getSettings().setBoolean(Settings.KEYS.AUTO_UPDATE, false); try(Engine engine = new Engine(getSettings())) { getSettings().setBoolean(Settings.KEYS.AUTO_UPDATE, autoUpdate); assertTrue(engine.getDependencies().length == 0); BaseDependencyCheckMojoImpl instance = new BaseDependencyCheckMojoImpl(); try { instance.scanArtifacts(project, engine); } catch(NullPointerException ex) { Assume.assumeNoException(ex); } assertFalse(engine.getDependencies().length == 0); } } } ",
        "focal_tgt": "protected ExceptionCollection scanArtifacts(MavenProject project, Engine engine, boolean aggregate) { try { final List < String > filterItems = Collections.singletonList(String.format(\"%s:%s\", project.getGroupId(), project.getArtifactId())); final ProjectBuildingRequest buildingRequest = newResolveArtifactProjectBuildingRequest(); buildingRequest.setProject(project); final ArtifactFilter filter = new ExcludesArtifactFilter(filterItems); final DependencyNode dn = dependencyGraphBuilder.buildDependencyGraph(buildingRequest, null, reactorProjects); final CollectingDependencyNodeVisitor visitor = new CollectingDependencyNodeVisitor(); dn.accept(visitor); final List < DependencyNode > nodes = new ArrayList < > (); for(DependencyNode node : visitor.getNodes()) { if(filter.include(node.getArtifact())) { nodes.add(node); } } return collectDependencies(engine, project, nodes, buildingRequest, aggregate); } catch(DependencyGraphBuilderException ex) { final String msg = String.format(\"Unable to build dependency graph on project %s\", project.getName()); getLog().debug(msg, ex); return new ExceptionCollection(ex); } } ",
        "focal_src": "protected ExceptionCollection scanArtifacts(MavenProject project, Engine engine, boolean aggregate) { try { final List < String > filterItems = Collections.singletonList(String.format(\"%s:%s\", project.getGroupId(), project.getArtifactId())); final ProjectBuildingRequest buildingRequest = newResolveArtifactProjectBuildingRequest(); buildingRequest.setProject(project); final ArtifactFilter filter = new ExcludesArtifactFilter(filterItems); final DependencyNode dn = dependencyGraphBuilder.buildDependencyGraph(buildingRequest, null, reactorProjects); final CollectingDependencyNodeVisitor visitor = new CollectingDependencyNodeVisitor(); dn.accept(visitor); final List < DependencyNode > nodes = new ArrayList < > (); for(DependencyNode node : visitor.getNodes()) { if(filter.include(node.getArtifact())) { nodes.add(node); } } return collectDependencies(engine, project, nodes, buildingRequest, aggregate); } catch(DependencyGraphBuilderException ex) { final String msg = String.format(\"Unable to build dependency graph on project %s\", project.getName()); getLog().debug(msg, ex); return new ExceptionCollection(msg, ex); } } ",
        "test_tgt": "@Test public void testScanArtifacts()throws DatabaseException, InvalidSettingException { new MockUp < MavenProject > () { @Mock public Set < Artifact > getArtifacts() { Set < Artifact > artifacts = new HashSet < > (); Artifact a = new ArtifactStub(); try { File file = new File(Test.class.getProtectionDomain().getCodeSource().getLocation().toURI()); a.setFile(file); artifacts.add(a); } catch(URISyntaxException ex) { Logger.getLogger(BaseDependencyCheckMojoTest.class.getName()).log(Level.SEVERE, null, ex); } return artifacts; }@Mock public String getName() { return \"test-project\"; } }; if(canRun()) { boolean autoUpdate = getSettings().getBoolean(Settings.KEYS.AUTO_UPDATE); getSettings().setBoolean(Settings.KEYS.AUTO_UPDATE, false); try(Engine engine = new Engine(getSettings())) { getSettings().setBoolean(Settings.KEYS.AUTO_UPDATE, autoUpdate); assertTrue(engine.getDependencies().length == 0); BaseDependencyCheckMojoImpl instance = new BaseDependencyCheckMojoImpl(); ExceptionCollection exCol = null; try { exCol = instance.scanArtifacts(project, engine); } catch(NullPointerException ex) { Assume.assumeNoException(ex); } assertNull(exCol); assertFalse(engine.getDependencies().length == 0); } } } "
    },
    {
        "test_src": "@Test public void testGetInputs() { Operator input1 = new OpImpl(0); Operator input2 = new OpImpl(1); Operator fixture = new OpImpl(0, input1, input2); List < Operator.Output > result = fixture.getInputs(); assertNotNull(result); assertEquals(2, result.size()); assertEquals(Arrays.asList(input1.getOutput(0), input2.getOutput(0)), result); } ",
        "focal_tgt": "public static Contract[]getInputs(final Contract contract) { if(contract instanceof DataSinkContract < ? , ? > )return new Contract[] { ((DataSinkContract < ? , ? > )contract).getInput() }; if(contract instanceof SingleInputContract < ? , ? , ? , ? > )return new Contract[] { ((SingleInputContract < ? , ? , ? , ? > )contract).getInput() }; if(contract instanceof DualInputContract < ? , ? , ? , ? , ? , ? > )return new Contract[] { ((DualInputContract < ? , ? , ? , ? , ? , ? > )contract).getFirstInput(), ((DualInputContract < ? , ? , ? , ? , ? , ? > )contract).getSecondInput() }; return new Contract[0]; } ",
        "focal_src": "public static Contract[]getInputs(Contract contract) { if(contract instanceof DataSinkContract < ? , ? > )return new Contract[] { ((DataSinkContract < ? , ? > )contract).getInput() }; if(contract instanceof SingleInputContract < ? , ? , ? , ? > )return new Contract[] { ((SingleInputContract < ? , ? , ? , ? > )contract).getInput() }; if(contract instanceof DualInputContract < ? , ? , ? , ? , ? , ? > )return new Contract[] { ((DualInputContract < ? , ? , ? , ? , ? , ? > )contract).getFirstInput(), ((DualInputContract < ? , ? , ? , ? , ? , ? > )contract).getSecondInput() }; return new Contract[0]; } ",
        "test_tgt": "@Test public void testGetInputs() { final Operator input1 = new OpImpl(0); final Operator input2 = new OpImpl(1); final Operator fixture = new OpImpl(0, input1, input2); final List < Operator.Output > result = fixture.getInputs(); assertNotNull(result); assertEquals(2, result.size()); assertEquals(Arrays.asList(input1.getOutput(0), input2.getOutput(0)), result); } "
    },
    {
        "test_src": "@Test public void authenticate_WithCookie()throws Exception { final Cookie[]cookieArray = { cookie }; final Subject authSubject = new Subject(); mock.checking(new Expectations() { { allowing(req).getCookies(); will(returnValue(cookieArray)); allowing(webAppSecConfig).getLogoutOnHttpSessionExpire(); will(returnValue(false)); allowing(webAppSecConfig).isTrackLoggedOutSSOCookiesEnabled(); will(returnValue(false)); allowing(ssoCookieHelper).getSSOCookiename(); will(returnValue(\"LTPAToken2\")); one(webAppSecConfig).isUseOnlyCustomCookieName(); will(returnValue(false)); one(authService).authenticate(with(equal(JaasLoginConfigConstants.SYSTEM_WEB_INBOUND)), with(any(AuthenticationData.class)), with(equal((Subject)null))); will(returnValue(authSubject)); } }); AuthenticationResult authResult = ssoAuth.authenticate(webRequest, webAppSecConfig); assertEquals(\"AuthenticationResult should be SUCCESS\", AuthResult.SUCCESS, authResult.getStatus()); } ",
        "focal_tgt": "public AuthenticationResult authenticate(WebRequest webRequest, WebAppSecurityConfig webAppSecConfig) { HttpServletRequest req = webRequest.getHttpServletRequest(); HttpServletResponse res = webRequest.getHttpServletResponse(); AuthenticationResult authResult = handleSSO(req, res); if(authResult != null && authResult.getStatus() == AuthResult.SUCCESS) { ssoCookieHelper.addJwtSsoCookiesToResponse(authResult.getSubject(), req, res); } return authResult; } ",
        "focal_src": "public AuthenticationResult authenticate(WebRequest webRequest, WebAppSecurityConfig webAppSecConfig) { HttpServletRequest req = webRequest.getHttpServletRequest(); HttpServletResponse res = webRequest.getHttpServletResponse(); AuthenticationResult authResult = handleSSO(req, res); if(authResult.getStatus() == AuthResult.SUCCESS) { ssoCookieHelper.addJwtSsoCookiesToResponse(authResult.getSubject(), req, res); } return authResult; } ",
        "test_tgt": "@Test public void authenticate_WithCookie()throws Exception { final Cookie[]cookieArray = { cookie }; final Subject authSubject = new Subject(); mock.checking(new Expectations() { { allowing(req).getCookies(); will(returnValue(cookieArray)); allowing(webAppSecConfig).getLogoutOnHttpSessionExpire(); will(returnValue(false)); allowing(webAppSecConfig).isTrackLoggedOutSSOCookiesEnabled(); will(returnValue(false)); allowing(ssoCookieHelper).getSSOCookiename(); will(returnValue(\"LTPAToken2\")); one(webAppSecConfig).isUseOnlyCustomCookieName(); will(returnValue(false)); allowing(ssoCookieHelper).addJwtSsoCookiesToResponse(authSubject, req, resp); one(authService).authenticate(with(equal(JaasLoginConfigConstants.SYSTEM_WEB_INBOUND)), with(any(AuthenticationData.class)), with(equal((Subject)null))); will(returnValue(authSubject)); } }); AuthenticationResult authResult = ssoAuth.authenticate(webRequest, webAppSecConfig); assertEquals(\"AuthenticationResult should be SUCCESS\", AuthResult.SUCCESS, authResult.getStatus()); } "
    },
    {
        "test_src": "@Test public void onFlushDirty_shouldFailIfAnEntityHasAChangedProperty()throws Exception { String[]propertyNames = new String[] { SomeImmutableEntityInterceptor.IMMUTABLE_FIELD_NAME }; String[]previousState = new String[] { \"old\" }; String[]currentState = new String[] { \"new\" }; ImmutableEntityInterceptor interceptor = new SomeImmutableEntityInterceptor(); expectedException.expect(APIException.class); expectedException.expectMessage(is(Context.getMessageSourceService().getMessage(\"editing.fields.not.allowed\", new Object[] { Order.class.getSimpleName() }, null))); interceptor.onFlushDirty(new Order(), null, currentState, previousState, propertyNames, null); } ",
        "focal_tgt": "@Override public boolean onFlushDirty(Object entity, Serializable id, Object[]currentState, Object[]previousState, String[]propertyNames, Type[]types) { if(getSupportedType().isAssignableFrom(entity.getClass())) { List < String > changedProperties = null; for(int i = 0; i < propertyNames.length; i ++ ) { String property = propertyNames[i]; if(ArrayUtils.contains(getMutablePropertyNames(), property)) { continue; } boolean isVoidedOrRetired = false; if(Voidable.class.isAssignableFrom(entity.getClass())) { isVoidedOrRetired = ((Voidable)entity).getVoided(); } else if(Retireable.class.isAssignableFrom(entity.getClass())) { isVoidedOrRetired = ((Retireable)entity).getRetired(); } if(isVoidedOrRetired && ignoreVoidedOrRetiredObjects()) { continue; } Object previousValue = (previousState != null) ? previousState[i] : null; Object currentValue = (currentState != null) ? currentState[i] : null; if( ! OpenmrsUtil.nullSafeEquals(currentValue, previousValue)) { if(changedProperties == null) { changedProperties = new ArrayList < String > (); } changedProperties.add(property); } } if(CollectionUtils.isNotEmpty(changedProperties)) { if(log.isDebugEnabled()) { log.debug(\"The following fields cannot be changed for \" + getSupportedType() + \":\" + changedProperties); } throw new APIException(\"Editing some fields \" + changedProperties + \" on \" + getSupportedType().getSimpleName() + \" is not allowed\"); } } return false; } ",
        "focal_src": "@Override public boolean onFlushDirty(Object entity, Serializable id, Object[]currentState, Object[]previousState, String[]propertyNames, Type[]types) { if(getSupportedType().isAssignableFrom(entity.getClass())) { List < String > changedProperties = null; for(int i = 0; i < propertyNames.length; i ++ ) { String property = propertyNames[i]; if(ArrayUtils.contains(getMutablePropertyNames(), property)) { continue; } boolean isVoidedOrRetired = false; if(Voidable.class.isAssignableFrom(entity.getClass())) { isVoidedOrRetired = ((Voidable)entity).getVoided(); } else if(Retireable.class.isAssignableFrom(entity.getClass())) { isVoidedOrRetired = ((Retireable)entity).getRetired(); } if(isVoidedOrRetired && ignoreVoidedOrRetiredObjects()) { continue; } Object previousValue = (previousState != null) ? previousState[i] : null; Object currentValue = (currentState != null) ? currentState[i] : null; if( ! OpenmrsUtil.nullSafeEquals(currentValue, previousValue)) { if(changedProperties == null) { changedProperties = new ArrayList < String > (); } changedProperties.add(property); } } if(CollectionUtils.isNotEmpty(changedProperties)) { if(log.isDebugEnabled()) { log.debug(\"The following fields cannot be changed for \" + getSupportedType() + \":\" + changedProperties); } throw new APIException(\"Editing some fields: \" + changedProperties + \" on \" + getSupportedType().getSimpleName() + \" is not allowed\"); } } return false; } ",
        "test_tgt": "@Test public void onFlushDirty_shouldFailIfAnEntityHasAChangedProperty()throws Exception { String[]propertyNames = new String[] { SomeImmutableEntityInterceptor.IMMUTABLE_FIELD_NAME }; String[]previousState = new String[] { \"old\" }; String[]currentState = new String[] { \"new\" }; ImmutableEntityInterceptor interceptor = new SomeImmutableEntityInterceptor(); expectedException.expect(APIException.class); expectedException.expectMessage(is(Context.getMessageSourceService().getMessage(\"editing.fields.not.allowed\", new Object[] { \"[immutable]\", Order.class.getSimpleName() }, null))); interceptor.onFlushDirty(new Order(), null, currentState, previousState, propertyNames, null); } "
    },
    {
        "test_src": "@Test public void testNoNeighborInLsaExchangeProcess()throws Exception { ospfInterfaces = new ArrayList(); ospfInterface1 = new OspfInterfaceImpl(); ospfInterface1.setIpAddress(Ip4Address.valueOf(\"1.1.1.1\")); ospfNbr = new OspfNbrImpl(new OspfAreaImpl(), new OspfInterfaceImpl(), Ip4Address.valueOf(\"1.1.1.1\"), Ip4Address.valueOf(\"2.2.2.2\"), 2, new OspfInterfaceChannelHandler(new Controller(), new OspfAreaImpl(), new OspfInterfaceImpl()), topologyForDeviceAndLink); ospfNbr.setState(OspfNeighborState.EXCHANGE.EXCHANGE); ospfInterface1.addNeighbouringRouter(ospfNbr); ospfInterfaces.add(ospfInterface1); ospfArea.setInterfacesLst(ospfInterfaces); assertThat(ospfArea.noNeighborInLsaExchangeProcess(), is(false)); } ",
        "focal_tgt": "public boolean noNeighborInLsaExchangeProcess() { OspfInterfaceImpl nextInterface; OspfNeighborState nextNeighborState; Iterator interfaces = ospfInterfaceList.iterator(); while(interfaces.hasNext()) { nextInterface = (OspfInterfaceImpl)interfaces.next(); Iterator neighbors = nextInterface.listOfNeighbors().values().iterator(); while(neighbors.hasNext()) { nextNeighborState = ((OspfNbrImpl)neighbors.next()).getState(); if(nextNeighborState == OspfNeighborState.EXCHANGE || nextNeighborState == OspfNeighborState.LOADING) { return false; } } } return true; } ",
        "focal_src": "public boolean noNeighborInLsaExchangeProcess() { OspfInterfaceImpl nextInterface; OspfNeighborState nextNeighborState; Iterator interfaces = interfacesLst.iterator(); while(interfaces.hasNext()) { nextInterface = (OspfInterfaceImpl)interfaces.next(); Iterator neighbors = nextInterface.listOfNeighbors().values().iterator(); while(neighbors.hasNext()) { nextNeighborState = ((OspfNbrImpl)neighbors.next()).getState(); if(nextNeighborState == OspfNeighborState.EXCHANGE || nextNeighborState == OspfNeighborState.LOADING) { return false; } } } return true; } ",
        "test_tgt": "@Test public void testNoNeighborInLsaExchangeProcess()throws Exception { ospfArea.setOspfInterfaceList(ospfInterfaces); ospfArea.noNeighborInLsaExchangeProcess(); assertThat(ospfArea, is(notNullValue())); } "
    },
    {
        "test_src": "@Test public void write_startsWithSpanKeyAndLengthPrefix() { byte[]buff = writer.write(CLIENT_SPAN); assertThat(buff).hasSize(writer.sizeInBytes(CLIENT_SPAN)).startsWith((byte)10, SPAN.sizeOfValue(CLIENT_SPAN)); } ",
        "focal_tgt": "public static < T > byte[]write(WriteBuffer.Writer < T > writer, T value) { byte[]result = new byte[writer.sizeInBytes(value)]; WriteBuffer b = WriteBuffer.wrap(result, 0); try { writer.write(value, b); } catch(RuntimeException e) { int lengthWritten = result.length; for(int i = 0; i < result.length; i ++ ) { if(result[i] == 0) { lengthWritten = i; break; } } String message = format(\"Bug found using %s to write %s as json. Wrote %s/%s bytes: %s\", writer.getClass().getSimpleName(), value.getClass().getSimpleName(), lengthWritten, result.length, new String(result, 0, lengthWritten, UTF_8)); throw Platform.get().assertionError(message, e); } return result; } ",
        "focal_src": "public static < T > byte[]write(UnsafeBuffer.Writer < T > writer, T value) { UnsafeBuffer b = UnsafeBuffer.allocate(writer.sizeInBytes(value)); try { writer.write(value, b); } catch(RuntimeException e) { byte[]bytes = b.unwrap(); int lengthWritten = bytes.length; for(int i = 0; i < bytes.length; i ++ ) { if(bytes[i] == 0) { lengthWritten = i; break; } } String message = format(\"Bug found using %s to write %s as json. Wrote %s/%s bytes: %s\", writer.getClass().getSimpleName(), value.getClass().getSimpleName(), lengthWritten, bytes.length, new String(bytes, 0, lengthWritten, UTF_8)); throw Platform.get().assertionError(message, e); } return b.unwrap(); } ",
        "test_tgt": "@Test public void write_startsWithSpanKeyAndLengthPrefix() { byte[]bytes = writer.write(CLIENT_SPAN); assertThat(bytes).hasSize(writer.sizeInBytes(CLIENT_SPAN)).startsWith((byte)10, SPAN.sizeOfValue(CLIENT_SPAN)); } "
    },
    {
        "test_src": "@Test public void isAbsolute() { assertUriIsAbsolute(\"x:\", true); assertUriIsAbsolute(\"x\", false); assertUriIsAbsolute(\"\", false); } ",
        "focal_tgt": "public boolean isAbsolute() { return parsed.valid && parsed.scheme != null; } ",
        "focal_src": "public boolean isAbsolute() { return Token.contains(value, ':'); } ",
        "test_tgt": "@Test public void isAbsolute() { assertEquals(\"Uri absolute check failed\", absolute, Uri.uri(uri).isAbsolute()); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.SUFFICIENT, notes = \"IOException is not checked.\", method = \"start\", args = { })@SuppressWarnings(\"nls\")public void testStart()throws IOException { String cmd = \"Dalvik\".equals(System.getProperty(\"java.vm.name\")) ? \"dalvikvm\" : \"java\"; ProcessBuilder pb = new ProcessBuilder(cmd, \"-version\"); Process process = pb.start(); InputStream in = process.getInputStream(); InputStream err = process.getErrorStream(); byte[]buf = new byte[1024]; if(in.available() > 0) { assertTrue(in.read(buf) > 0); } else { assertTrue(err.read(buf) > 0); } List < String > list = Arrays.asList(null, null, null); ProcessBuilder pbn = new ProcessBuilder(list); try { pbn.start(); fail(\"NullPointerException is not thrown.\"); } catch(NullPointerException npe) { } List < String > emptyList = Arrays.asList(); ProcessBuilder pbe = new ProcessBuilder(emptyList); try { pbe.start(); fail(\"IndexOutOfBoundsException is not thrown.\"); } catch(IndexOutOfBoundsException npe) { } SecurityManager sm = new SecurityManager() { public void checkPermission(Permission perm) { } public void checkExec(String cmd) { throw new SecurityException(); } }; SecurityManager oldSm = System.getSecurityManager(); System.setSecurityManager(sm); try { pb.start(); fail(\"SecurityException should be thrown.\"); } catch(SecurityException e) { } finally { System.setSecurityManager(oldSm); } pb.directory(new File(System.getProperty(\"java.class.path\"))); } ",
        "focal_tgt": "@Override public void start() { if(session == null) { session = findSessionToResume(); } else { if(clientHello != null && this.status != FINISHED) { return; } if( ! session.isValid()) { session = null; } } if(session != null) { isResuming = true; } else if(parameters.getEnableSessionCreation()) { isResuming = false; session = new SSLSessionImpl(parameters.getSecureRandom()); session.protocol = ProtocolVersion.getLatestVersion(parameters.getEnabledProtocols()); recordProtocol.setVersion(session.protocol.version); } else { fatalAlert(AlertProtocol.HANDSHAKE_FAILURE, \"SSL Session may not be created \"); } startSession(); } ",
        "focal_src": "public void start() { if(session == null) { session = findSessionToResume(); } else { if(clientHello != null && this.status != FINISHED) { return; } if( ! session.isValid()) { session = null; } } if(session != null) { isResuming = true; } else if(parameters.getEnableSessionCreation()) { isResuming = false; session = new SSLSessionImpl(parameters.getSecureRandom()); session.protocol = ProtocolVersion.getLatestVersion(parameters.getEnabledProtocols()); recordProtocol.setVersion(session.protocol.version); } else { fatalAlert(AlertProtocol.HANDSHAKE_FAILURE, \"SSL Session may not be created \"); } startSession(); } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.SUFFICIENT, notes = \"IOException is not checked.\", method = \"start\", args = { })@SuppressWarnings(\"nls\")public void testStart()throws IOException { String cmd = \"Dalvik\".equals(System.getProperty(\"java.vm.name\")) ? \"dalvikvm\" : \"java\"; ProcessBuilder pb = new ProcessBuilder(cmd, \"-version\"); Process process = pb.start(); InputStream in = process.getInputStream(); InputStream err = process.getErrorStream(); while(true) { try { process.waitFor(); break; } catch(InterruptedException e) { } } byte[]buf = new byte[1024]; if(in.available() > 0) { assertTrue(in.read(buf) > 0); } else { assertTrue(err.read(buf) > 0); } List < String > list = Arrays.asList(null, null, null); ProcessBuilder pbn = new ProcessBuilder(list); try { pbn.start(); fail(\"NullPointerException is not thrown.\"); } catch(NullPointerException npe) { } List < String > emptyList = Arrays.asList(); ProcessBuilder pbe = new ProcessBuilder(emptyList); try { pbe.start(); fail(\"IndexOutOfBoundsException is not thrown.\"); } catch(IndexOutOfBoundsException npe) { } SecurityManager sm = new SecurityManager() { public void checkPermission(Permission perm) { } public void checkExec(String cmd) { throw new SecurityException(); } }; SecurityManager oldSm = System.getSecurityManager(); System.setSecurityManager(sm); try { pb.start(); fail(\"SecurityException should be thrown.\"); } catch(SecurityException e) { } finally { System.setSecurityManager(oldSm); } pb.directory(new File(System.getProperty(\"java.class.path\"))); } "
    },
    {
        "test_src": "@Test public void trilinearInterpolation() { fail(\"Implement\"); } ",
        "focal_tgt": "void trilinearInterpolation(float weight, float sampleX, float sampleY, double angle) { for(int i = 0; i < widthGrid; i ++ ) { double weightGridY = 1.0 - Math.abs(sampleY - i); if(weightGridY <= 0)continue; for(int j = 0; j < widthGrid; j ++ ) { double weightGridX = 1.0 - Math.abs(sampleX - j); if(weightGridX <= 0)continue; for(int k = 0; k < numHistogramBins; k ++ ) { double angleBin = k * histogramBinWidth; double weightHistogram = 1.0 - UtilAngle.dist(angle, angleBin) / histogramBinWidth; if(weightHistogram <= 0)continue; int descriptorIndex = (i * widthGrid + j) * numHistogramBins + k; descriptor.value[descriptorIndex] += weight * weightGridX * weightGridY * weightHistogram; } } } } ",
        "focal_src": "private void trilinearInterpolation(float weight, float sampleX, float sampleY, double angle) { for(int i = 0; i < widthGrid; i ++ ) { double weightGridY = 1.0 - Math.abs(sampleY - i); if(weightGridY <= 0)continue; for(int j = 0; j < widthGrid; j ++ ) { double weightGridX = 1.0 - Math.abs(sampleX - j); if(weightGridX <= 0)continue; for(int k = 0; k < numHistogramBins; k ++ ) { double angleBin = k * histogramBinWidth; double weightHistogram = 1.0 - UtilAngle.dist(angle, angleBin) / histogramBinWidth; if(weightHistogram <= 0)continue; int descriptorIndex = (i * widthGrid + j) * numHistogramBins + k; descriptor.value[descriptorIndex] += weight * weightGridX * weightGridY * weightHistogram; } } } } ",
        "test_tgt": "@Test public void trilinearInterpolation() { DescribePointSiftLowe alg = new DescribePointSiftLowe(4, 4, 8, 1.5, 0.5, 0.2); alg.descriptor = new TupleDesc_F64(128); alg.trilinearInterpolation(2.0f, 1.25f, 2.0f, 0.5); double sum = 0; int count = 0; for(int i = 0; i < alg.descriptor.size(); i ++ ) { sum += alg.descriptor.value[i]; if(alg.descriptor.value[i] != 0)count ++ ; } assertEquals(2.0, sum, 1e-6); assertTrue(count > 1); sum = 0; alg.descriptor.fill(0); alg.trilinearInterpolation(2.0f, 3.25f, 3.25f, 0.5); for(int i = 0; i < alg.descriptor.size(); i ++ ) { sum += alg.descriptor.value[i]; } assertEquals(2.0 * 0.75 * 0.75 * 1.0, sum, 1e-8); alg.descriptor.fill(0); alg.trilinearInterpolation(2.0f, 3f, 3f, 2 * Math.PI / 8); count = 0; for(int i = 0; i < alg.descriptor.size(); i ++ ) { double weight = alg.descriptor.value[i]; if(weight > 0) { assertEquals(2.0, weight, 1e-8); count ++ ; } } assertEquals(1, count); } "
    },
    {
        "test_src": "@Test public void testSolve_doubleArrArr_doubleArrArr() { System.out.println(\"solve\"); double[][]A = { { 0.9000, 0.4000, 0.7000 }, { 0.4000, 0.5000, 0.3000 }, { 0.7000, 0.3000, 0.8000 } }; double[][]B2 = { { 0.5, 0.2 }, { 0.5, 0.8 }, { 0.5, 0.3 } }; double[][]X2 = { { - 0.2027027, - 1.2837838 }, { 0.8783784, 2.2297297 }, { 0.4729730, 0.6621622 } }; double[][]x = Math.solve(A, B2); assertEquals(X2.length, x.length); assertEquals(X2[0].length, x[0].length); for(int i = 0; i < X2.length; i ++ ) { for(int j = 0; j < X2[i].length; j ++ ) { assertEquals(X2[i][j], x[i][j], 1E-7); } } } ",
        "focal_tgt": "public static DenseMatrix solve(double[][]A, double[][]B) { DenseMatrix b = new ColumnMajorMatrix(B); DenseMatrix X = new ColumnMajorMatrix(A[0].length, B[0].length); if(A.length == A[0].length) { LUDecomposition lu = new LUDecomposition(A); lu.solve(b, X); } else { QRDecomposition qr = new QRDecomposition(A); qr.solve(b, X); } return X; } ",
        "focal_src": "public static double[][]solve(double[][]A, double[][]B) { if(A.length == A[0].length) { LUDecomposition lu = new LUDecomposition(A); lu.solve(B); return B; } else { double[][]X = new double[A[0].length][B[0].length]; QRDecomposition qr = new QRDecomposition(A); qr.solve(B, X); return X; } } ",
        "test_tgt": "@Test public void testSolve_doubleArrArr_doubleArrArr() { System.out.println(\"solve\"); double[][]A = { { 0.9000, 0.4000, 0.7000 }, { 0.4000, 0.5000, 0.3000 }, { 0.7000, 0.3000, 0.8000 } }; double[][]B2 = { { 0.5, 0.2 }, { 0.5, 0.8 }, { 0.5, 0.3 } }; double[][]X2 = { { - 0.2027027, - 1.2837838 }, { 0.8783784, 2.2297297 }, { 0.4729730, 0.6621622 } }; DenseMatrix x = Math.solve(A, B2); assertEquals(X2.length, x.nrows()); assertEquals(X2[0].length, x.ncols()); for(int i = 0; i < X2.length; i ++ ) { for(int j = 0; j < X2[i].length; j ++ ) { assertEquals(X2[i][j], x.get(i, j), 1E-7); } } } "
    },
    {
        "test_src": "@Test public void testConfigure()throws SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, NoSuchMethodException, ClassNotFoundException { expect(mockProperties.getProperty(CONFIG_TEST_STATEMENT)).andReturn(null).anyTimes(); expect(mockProperties.getProperty(CONFIG_PREPARED_STATEMENT_CACHE_SIZE)).andReturn(\"40\").anyTimes(); expect(mockProperties.getProperty(CONFIG_STATEMENTS_CACHED_PER_CONNECTION)).andReturn(\"30\").anyTimes(); expect(mockProperties.getProperty(CONFIG_MIN_CONNECTIONS_PER_PARTITION)).andReturn(\"20\").anyTimes(); expect(mockProperties.getProperty(CONFIG_MAX_CONNECTIONS_PER_PARTITION)).andReturn(\"50\").anyTimes(); expect(mockProperties.getProperty(CONFIG_ACQUIRE_INCREMENT)).andReturn(\"5\").anyTimes(); expect(mockProperties.getProperty(CONFIG_PARTITION_COUNT)).andReturn(\"5\").anyTimes(); expect(mockProperties.getProperty(CONFIG_RELEASE_HELPER_THREADS)).andReturn(\"3\").anyTimes(); expect(mockProperties.getProperty(CONFIG_IDLE_CONNECTION_TEST_PERIOD)).andReturn(\"60\").anyTimes(); expect(mockProperties.getProperty(CONFIG_IDLE_MAX_AGE)).andReturn(\"240\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(URL).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(DRIVER).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_HOOK_CLASS)).andReturn(\"com.jolbox.bonecp.provider.CustomHook\").anyTimes(); expect(mockProperties.getProperty(CONFIG_INIT_SQL)).andReturn(TEST_QUERY).anyTimes(); expect(mockProperties.getProperty(CONFIG_LOG_STATEMENTS_ENABLED)).andReturn(\"true\").anyTimes(); BoneCPConnectionProvider partialTestClass = createNiceMock(BoneCPConnectionProvider.class, BoneCPConnectionProvider.class.getDeclaredMethod(\"createPool\", BoneCPConfig.class)); expect(partialTestClass.createPool((BoneCPConfig)anyObject())).andReturn(mockPool).once(); replay(mockProperties, partialTestClass); partialTestClass.configure(mockProperties); BoneCPConfig config = partialTestClass.getConfig(); assertEquals(40, config.getStatementsCacheSize()); assertEquals(30, config.getStatementsCachedPerConnection()); assertEquals(20, config.getMinConnectionsPerPartition()); assertEquals(50, config.getMaxConnectionsPerPartition()); assertEquals(5, config.getAcquireIncrement()); assertEquals(5, config.getPartitionCount()); assertEquals(3, config.getReleaseHelperThreads()); assertEquals(60, config.getIdleConnectionTestPeriod()); assertEquals(240, config.getIdleMaxAge()); assertEquals(URL, config.getJdbcUrl()); assertEquals(USERNAME, config.getUsername()); assertEquals(PASSWORD, config.getPassword()); assertEquals(TEST_QUERY, config.getInitSQL()); assertEquals(true, config.isLogStatementsEnabled()); verify(mockProperties, partialTestClass); reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(null).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(DRIVER).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(\"somethinginvalid\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } verify(mockProperties); reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(\"somethingbad\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(\"somethinginvalid\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } testClass.setClassLoader(getClass().getClassLoader()); testClass.loadClass(\"java.lang.String\"); testClass.setClassLoader(this.getClass().getClassLoader()); assertEquals(this.getClass().getClassLoader(), testClass.getClassLoader()); } ",
        "focal_tgt": "public void configure(Properties props)throws HibernateException { String connectionTestStatement = props.getProperty(CONFIG_TEST_STATEMENT); int preparedStatementCacheSize = configParseNumber(props, CONFIG_PREPARED_STATEMENT_CACHE_SIZE, 50); int statementsCachedPerConnection = configParseNumber(props, CONFIG_STATEMENTS_CACHED_PER_CONNECTION, 30); int minsize = configParseNumber(props, CONFIG_MIN_CONNECTIONS_PER_PARTITION, 20); int maxsize = configParseNumber(props, CONFIG_MAX_CONNECTIONS_PER_PARTITION, 50); int acquireIncrement = configParseNumber(props, CONFIG_ACQUIRE_INCREMENT, 10); int partcount = configParseNumber(props, CONFIG_PARTITION_COUNT, 3); int releaseHelperThreads = configParseNumber(props, CONFIG_RELEASE_HELPER_THREADS, 3); long idleMaxAge = configParseNumber(props, CONFIG_IDLE_MAX_AGE, 240); long idleConnectionTestPeriod = configParseNumber(props, CONFIG_IDLE_CONNECTION_TEST_PERIOD, 60); int acquireRetryDelay = configParseNumber(props, CONFIG_ACQUIRE_RETRY_DELAY, 100); String url = props.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\"); String username = props.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\"); String password = props.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\"); String connectionHookClass = props.getProperty(CONFIG_CONNECTION_HOOK_CLASS); String initSQL = props.getProperty(CONFIG_INIT_SQL); boolean closeConnectionWatch = configParseBoolean(props, CONFIG_CLOSE_CONNECTION_WATCH, false); boolean logStatementsEnabled = configParseBoolean(props, CONFIG_LOG_STATEMENTS_ENABLED, false); this.isolation = PropertiesHelper.getInteger(Environment.ISOLATION, props); this.autocommit = PropertiesHelper.getBoolean(Environment.AUTOCOMMIT, props); try { String driver = props.getProperty(CONFIG_CONNECTION_DRIVER_CLASS); if(driver != null && ! driver.trim().equals(\"\")) { loadClass(driver); } logger.debug(String.format(CONFIG_STATUS, url, username, minsize, maxsize, acquireIncrement, partcount, idleConnectionTestPeriod, idleMaxAge)); this.config = new BoneCPConfig(); this.config.setMinConnectionsPerPartition(minsize); this.config.setMaxConnectionsPerPartition(maxsize); this.config.setAcquireIncrement(acquireIncrement); this.config.setPartitionCount(partcount); this.config.setJdbcUrl(url); this.config.setUsername(username); this.config.setPassword(password); this.config.setReleaseHelperThreads(releaseHelperThreads); this.config.setIdleConnectionTestPeriod(idleConnectionTestPeriod); this.config.setIdleMaxAge(idleMaxAge); this.config.setConnectionTestStatement(connectionTestStatement); this.config.setStatementsCacheSize(preparedStatementCacheSize); this.config.setStatementsCachedPerConnection(statementsCachedPerConnection); this.config.setInitSQL(initSQL); this.config.setCloseConnectionWatch(closeConnectionWatch); this.config.setLogStatementsEnabled(logStatementsEnabled); this.config.setAcquireRetryDelay(acquireRetryDelay); if(connectionHookClass != null) { Object hookClass = loadClass(connectionHookClass).newInstance(); this.config.setConnectionHook((ConnectionHook)hookClass); } this.pool = createPool(this.config); } catch(NullPointerException e) { throw new HibernateException(e); } catch(Exception e) { throw new HibernateException(e); } } ",
        "focal_src": "public void configure(Properties props)throws HibernateException { String connectionTestStatement = props.getProperty(CONFIG_TEST_STATEMENT); int preparedStatementCacheSize = configParseNumber(props, CONFIG_PREPARED_STATEMENT_CACHE_SIZE, 50); int statementsCachedPerConnection = configParseNumber(props, CONFIG_STATEMENTS_CACHED_PER_CONNECTION, 30); int minsize = configParseNumber(props, CONFIG_MIN_CONNECTIONS_PER_PARTITION, 20); int maxsize = configParseNumber(props, CONFIG_MAX_CONNECTIONS_PER_PARTITION, 50); int acquireIncrement = configParseNumber(props, CONFIG_ACQUIRE_INCREMENT, 10); int partcount = configParseNumber(props, CONFIG_PARTITION_COUNT, 3); int releaseHelperThreads = configParseNumber(props, CONFIG_RELEASE_HELPER_THREADS, 3); long idleMaxAge = configParseNumber(props, CONFIG_IDLE_MAX_AGE, 240); long idleConnectionTestPeriod = configParseNumber(props, CONFIG_IDLE_CONNECTION_TEST_PERIOD, 60); int acquireRetryDelay = configParseNumber(props, CONFIG_ACQUIRE_RETRY_DELAY, 100); String url = props.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\"); String username = props.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\"); String password = props.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\"); String connectionHookClass = props.getProperty(CONFIG_CONNECTION_HOOK_CLASS); String initSQL = props.getProperty(CONFIG_INIT_SQL); boolean closeConnectionWatch = configParseBoolean(props, CONFIG_CLOSE_CONNECTION_WATCH, false); boolean logStatementsEnabled = configParseBoolean(props, CONFIG_LOG_STATEMENTS_ENABLED, false); this.isolation = PropertiesHelper.getInteger(Environment.ISOLATION, props); this.autocommit = PropertiesHelper.getBoolean(Environment.AUTOCOMMIT, props); try { String driver = props.getProperty(CONFIG_CONNECTION_DRIVER_CLASS); if(driver != null && ! driver.trim().equals(\"\")) { loadClass(driver); } logger.debug(String.format(CONFIG_STATUS, url, username, minsize, maxsize, acquireIncrement, partcount, idleConnectionTestPeriod / 1000, idleMaxAge / (60 * 1000))); this.config = new BoneCPConfig(); this.config.setMinConnectionsPerPartition(minsize); this.config.setMaxConnectionsPerPartition(maxsize); this.config.setAcquireIncrement(acquireIncrement); this.config.setPartitionCount(partcount); this.config.setJdbcUrl(url); this.config.setUsername(username); this.config.setPassword(password); this.config.setReleaseHelperThreads(releaseHelperThreads); this.config.setIdleConnectionTestPeriod(idleConnectionTestPeriod); this.config.setIdleMaxAge(idleMaxAge); this.config.setConnectionTestStatement(connectionTestStatement); this.config.setStatementsCacheSize(preparedStatementCacheSize); this.config.setStatementsCachedPerConnection(statementsCachedPerConnection); this.config.setInitSQL(initSQL); this.config.setCloseConnectionWatch(closeConnectionWatch); this.config.setLogStatementsEnabled(logStatementsEnabled); this.config.setAcquireRetryDelay(acquireRetryDelay); if(connectionHookClass != null) { Object hookClass = loadClass(connectionHookClass).newInstance(); this.config.setConnectionHook((ConnectionHook)hookClass); } this.pool = createPool(this.config); } catch(NullPointerException e) { throw new HibernateException(e); } catch(Exception e) { throw new HibernateException(e); } } ",
        "test_tgt": "@Test public void testConfigure()throws SecurityException, NoSuchFieldException, IllegalArgumentException, IllegalAccessException, NoSuchMethodException, ClassNotFoundException { expect(mockProperties.getProperty(CONFIG_TEST_STATEMENT)).andReturn(null).anyTimes(); expect(mockProperties.getProperty(CONFIG_PREPARED_STATEMENT_CACHE_SIZE)).andReturn(\"40\").anyTimes(); expect(mockProperties.getProperty(CONFIG_STATEMENTS_CACHED_PER_CONNECTION)).andReturn(\"30\").anyTimes(); expect(mockProperties.getProperty(CONFIG_MIN_CONNECTIONS_PER_PARTITION)).andReturn(\"20\").anyTimes(); expect(mockProperties.getProperty(CONFIG_MAX_CONNECTIONS_PER_PARTITION)).andReturn(\"50\").anyTimes(); expect(mockProperties.getProperty(CONFIG_ACQUIRE_INCREMENT)).andReturn(\"5\").anyTimes(); expect(mockProperties.getProperty(CONFIG_PARTITION_COUNT)).andReturn(\"5\").anyTimes(); expect(mockProperties.getProperty(CONFIG_RELEASE_HELPER_THREADS)).andReturn(\"3\").anyTimes(); expect(mockProperties.getProperty(CONFIG_IDLE_CONNECTION_TEST_PERIOD)).andReturn(\"60\").anyTimes(); expect(mockProperties.getProperty(CONFIG_IDLE_MAX_AGE)).andReturn(\"240\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(URL).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(DRIVER).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_HOOK_CLASS)).andReturn(\"com.jolbox.bonecp.provider.CustomHook\").anyTimes(); expect(mockProperties.getProperty(CONFIG_INIT_SQL)).andReturn(TEST_QUERY).anyTimes(); expect(mockProperties.getProperty(CONFIG_LOG_STATEMENTS_ENABLED)).andReturn(\"true\").anyTimes(); BoneCPConnectionProvider partialTestClass = createNiceMock(BoneCPConnectionProvider.class, BoneCPConnectionProvider.class.getDeclaredMethod(\"createPool\", BoneCPConfig.class)); expect(partialTestClass.createPool((BoneCPConfig)anyObject())).andReturn(mockPool).once(); replay(mockProperties, partialTestClass); partialTestClass.configure(mockProperties); BoneCPConfig config = partialTestClass.getConfig(); assertEquals(40, config.getStatementsCacheSize()); assertEquals(30, config.getStatementsCachedPerConnection()); assertEquals(20, config.getMinConnectionsPerPartition()); assertEquals(50, config.getMaxConnectionsPerPartition()); assertEquals(5, config.getAcquireIncrement()); assertEquals(5, config.getPartitionCount()); assertEquals(3, config.getReleaseHelperThreads()); assertEquals(60 * 60 * 1000, config.getIdleConnectionTestPeriod()); assertEquals(240 * 60 * 1000, config.getIdleMaxAge()); assertEquals(URL, config.getJdbcUrl()); assertEquals(USERNAME, config.getUsername()); assertEquals(PASSWORD, config.getPassword()); assertEquals(TEST_QUERY, config.getInitSQL()); assertEquals(true, config.isLogStatementsEnabled()); verify(mockProperties, partialTestClass); reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(null).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(DRIVER).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(\"somethinginvalid\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } verify(mockProperties); reset(mockProperties); expect(mockProperties.getProperty(CONFIG_CONNECTION_DRIVER_CLASS)).andReturn(\"somethingbad\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_URL, \"JDBC URL NOT SET IN CONFIG\")).andReturn(\"somethinginvalid\").anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_USERNAME, \"username not set\")).andReturn(USERNAME).anyTimes(); expect(mockProperties.getProperty(CONFIG_CONNECTION_PASSWORD, \"password not set\")).andReturn(PASSWORD).anyTimes(); replay(mockProperties); try { testClass.configure(mockProperties); fail(\"Should have failed with exception\"); } catch(HibernateException e) { } testClass.setClassLoader(getClass().getClassLoader()); testClass.loadClass(\"java.lang.String\"); testClass.setClassLoader(this.getClass().getClassLoader()); assertEquals(this.getClass().getClassLoader(), testClass.getClassLoader()); } "
    },
    {
        "test_src": "@Test public void readText() { error(_FILE_READ_TEXT.args(PATH1), Err.FILE_NF); error(_FILE_READ_TEXT.args(PATH), Err.FILE_ID); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_TEXT.args(PATH1), \"a\"); error(_FILE_READ_TEXT.args(PATH1, \"UNKNOWN\"), Err.FILE_UE); assertEquals(3, query(_FILE_READ_TEXT.args(PATH1, \"CP1252\")).length()); query(_FILE_WRITE_BINARY.args(PATH1, \"xs:hexBinary('00')\")); error(_FILE_READ_TEXT.args(PATH1), Err.FILE_IE); query(\"declare option db:checkstrings 'off';\" + _FILE_READ_TEXT.args(PATH1), \"&#x0;\"); query(_FILE_DELETE.args(PATH1)); } ",
        "focal_tgt": "private StrStream readText(final QueryContext ctx)throws QueryException { final Path path = checkPath(0, ctx); final String enc = encoding(1, FILE_UNKNOWN_ENCODING, ctx); if( ! Files.exists(path))throw FILE_NOT_FOUND.get(info, path); if(Files.isDirectory(path))throw FILE_IS_DIR.get(info, path); return new StrStream(new IOFile(path.toFile()), enc, FILE_IO_ERROR, ctx); } ",
        "focal_src": "private StrStream readText(final QueryContext ctx)throws QueryException { final File path = checkFile(0, ctx); final String enc = encoding(1, FILE_UE, ctx); if( ! path.exists())throw FILE_NF.get(info, path.getAbsolutePath()); if(path.isDirectory())throw FILE_ID.get(info, path.getAbsolutePath()); return new StrStream(new IOFile(path), enc, FILE_IE, ctx); } ",
        "test_tgt": "@Test public void readText() { error(_FILE_READ_TEXT.args(PATH1), Err.FILE_NOT_FOUND); error(_FILE_READ_TEXT.args(PATH), Err.FILE_IS_DIR); query(_FILE_WRITE.args(PATH1, \"a\")); query(_FILE_READ_TEXT.args(PATH1), \"a\"); error(_FILE_READ_TEXT.args(PATH1, \"UNKNOWN\"), Err.FILE_UNKNOWN_ENCODING); assertEquals(3, query(_FILE_READ_TEXT.args(PATH1, \"CP1252\")).length()); query(_FILE_WRITE_BINARY.args(PATH1, \"xs:hexBinary('00')\")); error(_FILE_READ_TEXT.args(PATH1), Err.FILE_IO_ERROR); query(\"declare option db:checkstrings 'off';\" + _FILE_READ_TEXT.args(PATH1), \"&#x0;\"); query(_FILE_DELETE.args(PATH1)); } "
    },
    {
        "test_src": "@Test public void testPutVar32()throws Exception { checkVarInt(Integer.MAX_VALUE, 5); checkVarInt(25, 1); checkVarInt(100, 1); checkVarInt(Integer.MIN_VALUE, - 1); checkVarInt(Integer.MAX_VALUE / 2, - 1); checkVarInt(Integer.MAX_VALUE / 10, - 1); checkVarInt(Integer.MAX_VALUE / 10000, - 1); checkVarInt(Integer.MIN_VALUE / 2, - 1); checkVarInt(Integer.MIN_VALUE / 10, - 1); checkVarInt(Integer.MIN_VALUE / 10000, - 1); checkVarInt(0, - 1); checkVarInt(127, - 1); checkVarInt(128, - 1); checkVarInt(16383, - 1); checkVarInt(16384, - 1); checkVarInt(268435455, - 1); checkVarInt(268435456, - 1); } ",
        "focal_tgt": "@Deprecated void putVar(int v); ",
        "focal_src": "void putVar(int v); ",
        "test_tgt": "@Test public void testPutVInt()throws Exception { checkVInt(Integer.MAX_VALUE, 5); checkVInt(25, 1); checkVInt(100, 1); checkVInt(Integer.MIN_VALUE, - 1); checkVInt(Integer.MAX_VALUE / 2, - 1); checkVInt(Integer.MAX_VALUE / 10, - 1); checkVInt(Integer.MAX_VALUE / 10000, - 1); checkVInt(Integer.MIN_VALUE / 2, - 1); checkVInt(Integer.MIN_VALUE / 10, - 1); checkVInt(Integer.MIN_VALUE / 10000, - 1); checkVInt(0, - 1); checkVInt(127, - 1); checkVInt(128, - 1); checkVInt(16383, - 1); checkVInt(16384, - 1); checkVInt(268435455, - 1); checkVInt(268435456, - 1); } "
    },
    {
        "test_src": "@Test(description = \"GET /v${apiVersion}/{tenantId}/flavors/detail\")public void testListFlavorsInDetail()throws Exception { for(String zoneId : zones) { FlavorApi api = novaContext.getApi().getFlavorApiForZone(zoneId); Set < ? extends Flavor > response = api.listFlavorsInDetail(); assertNotNull(response); assertFalse(response.isEmpty()); for(Flavor flavor : response) { assertNotNull(flavor.getId()); assertNotNull(flavor.getName()); assertNotNull(flavor.getLinks()); assertTrue(flavor.getRam() > 0); assertTrue(flavor.getDisk() > 0); assertTrue(flavor.getVcpus() > 0); } } } ",
        "focal_tgt": "PagedIterable < ? extends Flavor > listInDetail(); ",
        "focal_src": "Set < ? extends Flavor > listFlavorsInDetail(); ",
        "test_tgt": "@Test(description = \"GET /v${apiVersion}/{tenantId}/flavors/detail\")public void testListFlavorsInDetail()throws Exception { for(String zoneId : zones) { FlavorApi api = novaContext.getApi().getFlavorApiForZone(zoneId); Set < ? extends Flavor > response = api.listInDetail().concat().toImmutableSet(); assertNotNull(response); assertFalse(response.isEmpty()); for(Flavor flavor : response) { assertNotNull(flavor.getId()); assertNotNull(flavor.getName()); assertNotNull(flavor.getLinks()); assertTrue(flavor.getRam() > 0); assertTrue(flavor.getDisk() > 0); assertTrue(flavor.getVcpus() > 0); } } } "
    },
    {
        "test_src": "@Test public void testApply() { IPWhitelistPolicy policy = new IPWhitelistPolicy(); String json = \"{\" + \" \\\"ipList\\\" : [\" + \" \\\"1.2.3.4\\\",\" + \" \\\"3.4.5.6\\\",\" + \" \\\"10.0.0.11\\\"\" + \" ]\" + \"}\"; Object config = policy.parseConfiguration(json); ServiceRequest request = new ServiceRequest(); request.setType(\"GET\"); request.setApiKey(\"12345\"); request.setRemoteAddr(\"1.2.3.4\"); request.setDestination(\"/\"); IPolicyContext context = Mockito.mock(IPolicyContext.class); IPolicyChain chain = Mockito.mock(IPolicyChain.class); policy.apply(request, context, config, chain); Mockito.verify(chain).doApply(request); chain = Mockito.mock(IPolicyChain.class); request.setRemoteAddr(\"9.8.7.6\"); policy.apply(request, context, config, chain); ArgumentCaptor < PolicyFailure > argument = ArgumentCaptor.forClass(PolicyFailure.class); Mockito.verify(chain).doFailure(argument.capture()); } ",
        "focal_tgt": "@Override public void apply(ServiceRequest request, IPolicyContext context, Object config, IPolicyChain chain) { IPWhitelistConfig wc = (IPWhitelistConfig)config; if(wc.getIpList().contains(request.getRemoteAddr())) { chain.doApply(request); } else { IPolicyFailureFactoryComponent ffactory = context.getComponent(IPolicyFailureFactoryComponent.class); String msg = Messages.i18n.format(\"IPWhitelistPolicy.NotWhitelisted\", request.getRemoteAddr()); chain.doFailure(ffactory.createFailure(PolicyFailureType.Other, FailureCodes.IP_NOT_WHITELISTED, msg)); } } ",
        "focal_src": "@Override public void apply(ServiceRequest request, IPolicyContext context, Object config, IPolicyChain chain) { IPWhitelistConfig wc = (IPWhitelistConfig)config; if(wc.getIpList().contains(request.getRemoteAddr())) { chain.doApply(request); } else { String msg = Messages.i18n.format(\"IPWhitelistPolicy.NotWhitelisted\", request.getRemoteAddr()); chain.doFailure(PolicyFailureFactory.createFailure(PolicyFailureType.Other, FailureCodes.IP_NOT_WHITELISTED, msg)); } } ",
        "test_tgt": "@Test public void testApply() { IPWhitelistPolicy policy = new IPWhitelistPolicy(); String json = \"{\" + \" \\\"ipList\\\" : [\" + \" \\\"1.2.3.4\\\",\" + \" \\\"3.4.5.6\\\",\" + \" \\\"10.0.0.11\\\"\" + \" ]\" + \"}\"; Object config = policy.parseConfiguration(json); ServiceRequest request = new ServiceRequest(); request.setType(\"GET\"); request.setApiKey(\"12345\"); request.setRemoteAddr(\"1.2.3.4\"); request.setDestination(\"/\"); IPolicyContext context = Mockito.mock(IPolicyContext.class); IPolicyChain chain = Mockito.mock(IPolicyChain.class); policy.apply(request, context, config, chain); Mockito.verify(chain).doApply(request); final PolicyFailure failure = new PolicyFailure(); Mockito.when(context.getComponent(IPolicyFailureFactoryComponent.class)).thenReturn(new IPolicyFailureFactoryComponent() { @Override public PolicyFailure createFailure(PolicyFailureType type, int failureCode, String message) { return failure; } }); chain = Mockito.mock(IPolicyChain.class); request.setRemoteAddr(\"9.8.7.6\"); policy.apply(request, context, config, chain); Mockito.verify(chain).doFailure(failure); } "
    },
    {
        "test_src": "@Test public void testGetContainers()throws ResourceExceededException { int paddingPercentage = 10; Map < Integer, List < InstanceId > > packing = new HashMap < > (); packing.put(7, Arrays.asList(new InstanceId(\"spout\", 1, 0), new InstanceId(\"bolt\", 2, 0))); packing.put(3, Arrays.asList(new InstanceId(\"spout\", 3, 0), new InstanceId(\"bolt\", 4, 0))); PackingPlan packingPlan = generatePacking(packing); Map < Integer, Container > containers = PackingPlanBuilder.getContainers(packingPlan, paddingPercentage, new HashMap < String, TreeSet < Integer > > (), new TreeSet < Integer > ()); assertEquals(packing.size(), containers.size()); for(Integer containerId : packing.keySet()) { Container foundContainer = containers.get(containerId); assertEquals(paddingPercentage, foundContainer.getPaddingPercentage()); assertEquals(packingPlan.getMaxContainerResources(), foundContainer.getCapacity()); assertEquals(2, foundContainer.getInstances().size()); } } ",
        "focal_tgt": "@VisibleForTesting static Map < Integer, Container > getContainers(PackingPlan currentPackingPlan, Resource maxContainerResource, Resource padding, Map < String, TreeSet < Integer > > componentIndexes, TreeSet < Integer > taskIds) { Map < Integer, Container > containers = new HashMap < > (); Resource capacity = maxContainerResource; for(PackingPlan.ContainerPlan currentContainerPlan : currentPackingPlan.getContainers()) { Container container = new Container(currentContainerPlan.getId(), capacity, padding); for(PackingPlan.InstancePlan instancePlan : currentContainerPlan.getInstances()) { addToContainer(container, instancePlan, componentIndexes, taskIds); } containers.put(currentContainerPlan.getId(), container); } return containers; } ",
        "focal_src": "@VisibleForTesting static Map < Integer, Container > getContainers(PackingPlan currentPackingPlan, int paddingPercentage, Map < String, TreeSet < Integer > > componentIndexes, TreeSet < Integer > taskIds)throws ResourceExceededException { Map < Integer, Container > containers = new HashMap < > (); Resource capacity = currentPackingPlan.getMaxContainerResources(); for(PackingPlan.ContainerPlan currentContainerPlan : currentPackingPlan.getContainers()) { Container container = new Container(currentContainerPlan.getId(), capacity, paddingPercentage); for(PackingPlan.InstancePlan instancePlan : currentContainerPlan.getInstances()) { try { addToContainer(container, instancePlan, componentIndexes, taskIds); } catch(ResourceExceededException e) { throw new ResourceExceededException(String.format(\"Insufficient container resources to add instancePlan %s to container %s\", instancePlan, container), e); } } containers.put(currentContainerPlan.getId(), container); } return containers; } ",
        "test_tgt": "@Test public void testGetContainers() { Resource padding = new Resource(1.0, ByteAmount.fromGigabytes(1), ByteAmount.fromGigabytes(1)); Map < Integer, List < InstanceId > > packing = new HashMap < > (); packing.put(7, Arrays.asList(new InstanceId(\"spout\", 1, 0), new InstanceId(\"bolt\", 2, 0))); packing.put(3, Arrays.asList(new InstanceId(\"spout\", 3, 0), new InstanceId(\"bolt\", 4, 0))); PackingPlan packingPlan = generatePacking(packing); Map < Integer, Container > containers = PackingPlanBuilder.getContainers(packingPlan, packingPlan.getMaxContainerResources(), padding, new HashMap < String, TreeSet < Integer > > (), new TreeSet < Integer > ()); assertEquals(packing.size(), containers.size()); for(Integer containerId : packing.keySet()) { Container foundContainer = containers.get(containerId); assertEquals(padding, foundContainer.getPadding()); assertEquals(packingPlan.getMaxContainerResources(), foundContainer.getCapacity()); assertEquals(2, foundContainer.getInstances().size()); } } "
    },
    {
        "test_src": "@Test public void getLastModified()throws Exception { URL url = new URL(\"http://wicket.apache.org/learn/books/wia.png\"); Instant lastModified = Connections.getLastModified(url); assertNotNull(lastModified); assertNotEquals(lastModified.toEpochMilli(), 0L); } ",
        "focal_tgt": "public Time getLastModified() { return lastModified; } ",
        "focal_src": "public Instant getLastModified() { return lastModified; } ",
        "test_tgt": "@Test public void getLastModified()throws Exception { URL url = new URL(\"http://wicket.apache.org/learn/books/wia.png\"); Time lastModified = Connections.getLastModified(url); assertNotNull(lastModified); assertNotEquals(lastModified.getMilliseconds(), 0L); } "
    },
    {
        "test_src": "@Test public void saveConcept_shouldLeavePreferredNamePreferredIfSet()throws Exception { Locale loc = new Locale(\"fr\", \"CA\"); ConceptName fullySpecifiedName = new ConceptName(\"fully specified\", loc); fullySpecifiedName.setConceptNameType(ConceptNameType.FULLY_SPECIFIED); ConceptName shortName = new ConceptName(\"short name\", loc); shortName.setConceptNameType(ConceptNameType.SHORT); ConceptName synonym = new ConceptName(\"synonym\", loc); synonym.setConceptNameType(null); ConceptName indexTerm = new ConceptName(\"indexTerm\", loc); indexTerm.setConceptNameType(ConceptNameType.INDEX_TERM); indexTerm.setLocalePreferred(true); Concept c = new Concept(); c.addName(fullySpecifiedName); c.addName(synonym); c.addName(indexTerm); c.addName(shortName); try { Context.getConceptService().saveConcept(c); } catch(org.openmrs.api.APIException e) { } assertNotNull(\"there's a preferred name\", c.getPreferredName(loc)); assertTrue(\"name was explicitly marked preferred\", c.getPreferredName(loc).isPreferred()); assertEquals(\"name matches\", c.getPreferredName(loc).getName(), indexTerm.getName()); } ",
        "focal_tgt": "public Concept saveConcept(Concept concept)throws APIException { ConceptMapType defaultConceptMapType = null; for(ConceptMap map : concept.getConceptMappings()) { if(map.getConceptMapType() == null) { if(defaultConceptMapType == null) { defaultConceptMapType = Context.getConceptService().getDefaultConceptMapType(); } map.setConceptMapType(defaultConceptMapType); } } checkIfLocked(); checkIfDatatypeCanBeChanged(concept); List < ConceptName > changedConceptNames = null; Map < String, ConceptName > uuidClonedConceptNameMap = null; if(concept.getConceptId() != null) { uuidClonedConceptNameMap = new HashMap < String, ConceptName > (); for(ConceptName conceptName : concept.getNames()) { if(conceptName.getConceptNameId() != null) { ConceptName clone = cloneConceptName(conceptName); clone.setConceptNameId(null); uuidClonedConceptNameMap.put(conceptName.getUuid(), clone); if(hasNameChanged(conceptName)) { if(changedConceptNames == null) { changedConceptNames = new ArrayList < ConceptName > (); } changedConceptNames.add(conceptName); } else { clone.setConceptNameId(conceptName.getConceptNameId()); try { BeanUtils.copyProperties(conceptName, clone); } catch(IllegalAccessException e) { log.error(\"Error generated\", e); } catch(InvocationTargetException e) { log.error(\"Error generated\", e); } } } } } if(CollectionUtils.isNotEmpty(changedConceptNames)) { for(ConceptName changedName : changedConceptNames) { ConceptName nameInDB = changedName; nameInDB.setVoided(true); nameInDB.setDateVoided(new Date()); nameInDB.setVoidedBy(Context.getAuthenticatedUser()); nameInDB.setVoidReason(Context.getMessageSourceService().getMessage(\"Concept.name.voidReason.nameChanged\")); if( ! nameInDB.isSynonym()) { nameInDB.setConceptNameType(null); } if(nameInDB.isLocalePreferred()) { nameInDB.setLocalePreferred(false); } ConceptName clone = uuidClonedConceptNameMap.get(nameInDB.getUuid()); clone.setUuid(UUID.randomUUID().toString()); clone.setDateCreated(null); clone.setCreator(null); concept.addName(clone); } } Set < Locale > checkedLocales = new HashSet < Locale > (); for(ConceptName n : concept.getNames()) { Locale locale = n.getLocale(); if(checkedLocales.contains(locale)) { continue; } ConceptName possiblePreferredName = concept.getPreferredName(locale); if(possiblePreferredName != null) { } else if(concept.getFullySpecifiedName(locale) != null) { possiblePreferredName = concept.getFullySpecifiedName(locale); } else if( ! CollectionUtils.isEmpty(concept.getSynonyms(locale))) { concept.getSynonyms(locale).iterator().next().setLocalePreferred(true); } if(possiblePreferredName != null) { possiblePreferredName.setLocalePreferred(true); } checkedLocales.add(locale); } concept.setDateChanged(new Date()); concept.setChangedBy(Context.getAuthenticatedUser()); if( ! concept.isSet() && (concept.getSetMembers().size() > 0)) { concept.setSet(true); } Concept conceptToReturn = dao.saveConcept(concept); return conceptToReturn; } ",
        "focal_src": "public Concept saveConcept(Concept concept)throws APIException { ConceptMapType defaultConceptMapType = null; for(ConceptMap map : concept.getConceptMappings()) { if(map.getConceptMapType() == null) { if(defaultConceptMapType == null) { defaultConceptMapType = Context.getConceptService().getDefaultConceptMapType(); } map.setConceptMapType(defaultConceptMapType); } } checkIfLocked(); checkIfDatatypeCanBeChanged(concept); List < ConceptName > changedConceptNames = null; Map < String, ConceptName > uuidClonedConceptNameMap = null; if(concept.getConceptId() != null) { uuidClonedConceptNameMap = new HashMap < String, ConceptName > (); for(ConceptName conceptName : concept.getNames()) { if(conceptName.getConceptNameId() != null) { ConceptName clone = cloneConceptName(conceptName); clone.setConceptNameId(null); uuidClonedConceptNameMap.put(conceptName.getUuid(), clone); if(hasNameChanged(conceptName)) { if(changedConceptNames == null) { changedConceptNames = new ArrayList < ConceptName > (); } changedConceptNames.add(conceptName); } else { clone.setConceptNameId(conceptName.getConceptNameId()); try { BeanUtils.copyProperties(conceptName, clone); } catch(IllegalAccessException e) { log.error(\"Error generated\", e); } catch(InvocationTargetException e) { log.error(\"Error generated\", e); } } } } } if(CollectionUtils.isNotEmpty(changedConceptNames)) { for(ConceptName changedName : changedConceptNames) { ConceptName nameInDB = changedName; nameInDB.setVoided(true); nameInDB.setDateVoided(new Date()); nameInDB.setVoidedBy(Context.getAuthenticatedUser()); nameInDB.setVoidReason(Context.getMessageSourceService().getMessage(\"Concept.name.voidReason.nameChanged\")); if( ! nameInDB.isSynonym()) { nameInDB.setConceptNameType(null); } if(nameInDB.isLocalePreferred()) { nameInDB.setLocalePreferred(false); } ConceptName clone = uuidClonedConceptNameMap.get(nameInDB.getUuid()); clone.setUuid(UUID.randomUUID().toString()); clone.setDateCreated(null); clone.setCreator(null); concept.addName(clone); } } Set < Locale > checkedLocales = new HashSet < Locale > (); for(ConceptName n : concept.getNames()) { Locale locale = n.getLocale(); if(checkedLocales.contains(locale)) { continue; } ConceptName possiblePreferredName = concept.getPreferredName(locale); if(possiblePreferredName != null) { } else if(concept.getFullySpecifiedName(locale) != null) { possiblePreferredName = concept.getFullySpecifiedName(locale); } else if( ! CollectionUtils.isEmpty(concept.getSynonyms(locale))) { concept.getSynonyms(locale).iterator().next().setLocalePreferred(true); } if(possiblePreferredName != null) { possiblePreferredName.setLocalePreferred(true); } checkedLocales.add(locale); } concept.setDateChanged(new Date()); concept.setChangedBy(Context.getAuthenticatedUser()); Concept conceptToReturn = dao.saveConcept(concept); return conceptToReturn; } ",
        "test_tgt": "@Test public void saveConcept_shouldLeavePreferredNamePreferredIfSet()throws Exception { Locale loc = new Locale(\"fr\", \"CA\"); ConceptName fullySpecifiedName = new ConceptName(\"fully specified\", loc); fullySpecifiedName.setConceptNameType(ConceptNameType.FULLY_SPECIFIED); ConceptName shortName = new ConceptName(\"short name\", loc); shortName.setConceptNameType(ConceptNameType.SHORT); ConceptName synonym = new ConceptName(\"synonym\", loc); synonym.setConceptNameType(null); ConceptName indexTerm = new ConceptName(\"indexTerm\", loc); indexTerm.setConceptNameType(ConceptNameType.INDEX_TERM); indexTerm.setLocalePreferred(true); Concept c = new Concept(); c.addName(fullySpecifiedName); c.addName(synonym); c.addName(indexTerm); c.addName(shortName); try { Context.getConceptService().saveConcept(c); } catch(org.openmrs.api.APIException e) { } assertNotNull(\"there's a preferred name\", c.getPreferredName(loc)); assertTrue(\"name was explicitly marked preferred\", c.getPreferredName(loc).isPreferred()); assertEquals(\"name matches\", c.getPreferredName(loc).getName(), indexTerm.getName()); } "
    },
    {
        "test_src": "@Test public void sessionHeartbeat() { long sessionId = mRandom.nextLong(); long metricIncrease = 3; List < Long > metrics = Arrays.asList(new Long[Constants.CLIENT_METRICS_SIZE]); Collections.fill(metrics, metricIncrease); metrics.set(0, Constants.CLIENT_METRICS_VERSION); mBlockWorker.sessionHeartbeat(sessionId, metrics); verify(mSessions).sessionHeartbeat(sessionId); Counter counter = WorkerContext.getWorkerSource().getMetricRegistry().getCounters().get(WorkerSource.BLOCKS_READ_LOCAL); assertEquals(metricIncrease, counter.getCount()); } ",
        "focal_tgt": "public synchronized void sessionHeartbeat()throws ConnectionFailedException, IOException { retryRPC(new RpcCallable < Void > () { @Override public Void call()throws TException { mClient.sessionHeartbeat(mSessionId, null); return null; } }); } ",
        "focal_src": "public synchronized void sessionHeartbeat()throws ConnectionFailedException, IOException { retryRPC(new RpcCallable < Void > () { @Override public Void call()throws TException { mClient.sessionHeartbeat(mSessionId, mClientMetrics.getHeartbeatData()); return null; } }); } ",
        "test_tgt": "@Test public void sessionHeartbeat() { long sessionId = mRandom.nextLong(); long metricIncrease = 3; mBlockWorker.sessionHeartbeat(sessionId, null); verify(mSessions).sessionHeartbeat(sessionId); Counter counter = WorkerContext.getWorkerSource().getMetricRegistry().getCounters().get(WorkerSource.BLOCKS_READ_LOCAL); assertEquals(metricIncrease, counter.getCount()); } "
    },
    {
        "test_src": "@Test public void module() { final QueryContext qc = new QueryContext(context); try { qc.parseLibrary(\"module namespace m='foo'; declare function m:foo() { m:bar() }; \", \"\"); fail(\"Unknown function 'm:bar()' was not detected.\"); } catch(final QueryException e) { assertSame(Err.FUNCUNKNOWN, e.err()); } finally { qc.close(); } } ",
        "focal_tgt": "private void module(final byte[]path, final byte[]uri, final boolean imprt)throws QueryException { final IO io = sc.io(string(path)); final byte[]p = token(io.path()); final byte[]u = ctx.modParsed.get(p); if(u != null) { if( ! eq(uri, u))error(WRONGMODULE, uri, ctx.context.user.has(Perm.ADMIN) ? io.path() : io.name()); if( ! sc.xquery3() && ctx.modStack.contains(p))error(CIRCMODULE); return; } ctx.modParsed.put(p, uri); String qu = null; try { qu = string(io.read()); } catch(final IOException ex) { error(WHICHMODFILE, ctx.context.user.has(Perm.ADMIN) ? io.path() : io.name()); } ctx.modStack.push(p); final StaticContext sub = new StaticContext(sc.xquery3()); final LibraryModule lib = new QueryParser(qu, io.path(), ctx, sub).parseLibrary( ! imprt); final byte[]muri = lib.name.uri(); if( ! eq(uri, muri))error(WRONGMODULE, muri, file); if(sub.initType != null) { if(sc.initType == null) { sc.initType = sub.initType; } else if( ! sub.initType.eq(sc.initType)) { error(CITYPES, sub.initType, sc.initType); } } ctx.modStack.pop(); } ",
        "focal_src": "private void module(final byte[]path, final byte[]uri, final boolean imprt)throws QueryException { final IO io = ctx.sc.io(string(path)); final byte[]p = token(io.path()); final byte[]u = ctx.modParsed.get(p); if(u != null) { if( ! eq(uri, u))error(WRONGMODULE, uri, ctx.context.user.has(Perm.ADMIN) ? io.path() : io.name()); if( ! ctx.sc.xquery3() && ctx.modStack.contains(p))error(CIRCMODULE); return; } ctx.modParsed.put(p, uri); String qu = null; try { qu = string(io.read()); } catch(final IOException ex) { error(WHICHMODFILE, ctx.context.user.has(Perm.ADMIN) ? io.path() : io.name()); } ctx.modStack.push(p); final StaticContext sc = ctx.sc; ctx.sc = new StaticContext(sc.xquery3()); final LibraryModule lib = new QueryParser(qu, io.path(), ctx).parseLibrary( ! imprt); final byte[]muri = lib.name.uri(); if( ! eq(uri, muri))error(WRONGMODULE, muri, file); if(ctx.sc.initType != null) { if(sc.initType == null) { sc.initType = ctx.sc.initType; } else if( ! ctx.sc.initType.eq(sc.initType)) { error(CITYPES, ctx.sc.initType, sc.initType); } } ctx.sc = sc; ctx.modStack.pop(); } ",
        "test_tgt": "@Test public void module() { final QueryContext qc = new QueryContext(context); try { qc.parseLibrary(\"module namespace m='foo'; declare function m:foo() { m:bar() }; \", \"\", null); fail(\"Unknown function 'm:bar()' was not detected.\"); } catch(final QueryException e) { assertSame(Err.FUNCUNKNOWN, e.err()); } finally { qc.close(); } } "
    },
    {
        "test_src": "@Test public void discontinueOrder_shouldSetCorrectAttributesOnTheDiscontinueAndDiscontinuedOrders()throws Exception { executeDataSet(\"org/openmrs/api/include/OrderServiceTest-discontinueReason.xml\"); Order order = orderService.getOrderByOrderNumber(\"111\"); Encounter encounter = encounterService.getEncounter(3); Provider orderer = providerService.getProvider(1); Date discontinueDate = new Date(); Concept concept = Context.getConceptService().getConcept(1); Order discontinueOrder = orderService.discontinueOrder(order, concept, discontinueDate, orderer, encounter); Assert.assertEquals(order.getDateStopped(), discontinueDate); Assert.assertNotNull(discontinueOrder); Assert.assertNotNull(discontinueOrder.getId()); Assert.assertEquals(discontinueOrder.getStartDate(), discontinueOrder.getAutoExpireDate()); Assert.assertEquals(discontinueOrder.getAction(), Action.DISCONTINUE); Assert.assertEquals(discontinueOrder.getOrderReason(), concept); Assert.assertEquals(discontinueOrder.getPreviousOrder(), order); } ",
        "focal_tgt": "@Override public Order discontinueOrder(Order orderToDiscontinue, Concept reasonCoded, Date discontinueDate, Provider orderer, Encounter encounter)throws Exception { stopOrder(orderToDiscontinue, discontinueDate); Order newOrder = orderToDiscontinue.cloneForDiscontinuing(); newOrder.setOrderReason(reasonCoded); newOrder.setOrderer(orderer); newOrder.setEncounter(encounter); if(discontinueDate == null) { discontinueDate = new Date(); } newOrder.setDateActivated(discontinueDate); return saveOrderInternal(newOrder, null); } ",
        "focal_src": "@Override public Order discontinueOrder(Order orderToDiscontinue, Concept reasonCoded, Date discontinueDate, Provider orderer, Encounter encounter)throws Exception { stopOrder(orderToDiscontinue, discontinueDate); Order newOrder = orderToDiscontinue.cloneForDiscontinuing(); newOrder.setOrderReason(reasonCoded); newOrder.setOrderer(orderer); newOrder.setEncounter(encounter); if(discontinueDate == null) { discontinueDate = new Date(); } newOrder.setStartDate(discontinueDate); return saveOrderInternal(newOrder, null); } ",
        "test_tgt": "@Test public void discontinueOrder_shouldSetCorrectAttributesOnTheDiscontinueAndDiscontinuedOrders()throws Exception { executeDataSet(\"org/openmrs/api/include/OrderServiceTest-discontinueReason.xml\"); Order order = orderService.getOrderByOrderNumber(\"111\"); Encounter encounter = encounterService.getEncounter(3); Provider orderer = providerService.getProvider(1); Date discontinueDate = new Date(); Concept concept = Context.getConceptService().getConcept(1); Order discontinueOrder = orderService.discontinueOrder(order, concept, discontinueDate, orderer, encounter); Assert.assertEquals(order.getDateStopped(), discontinueDate); Assert.assertNotNull(discontinueOrder); Assert.assertNotNull(discontinueOrder.getId()); Assert.assertEquals(discontinueOrder.getDateActivated(), discontinueOrder.getAutoExpireDate()); Assert.assertEquals(discontinueOrder.getAction(), Action.DISCONTINUE); Assert.assertEquals(discontinueOrder.getOrderReason(), concept); Assert.assertEquals(discontinueOrder.getPreviousOrder(), order); } "
    },
    {
        "test_src": "@SuppressWarnings(\"unchecked\")@Test(expected = GenieServerException.class)public void testSubmitJob()throws GenieException, IOException { final Set < CommandStatus > enumStatuses = EnumSet.noneOf(CommandStatus.class); enumStatuses.add(CommandStatus.ACTIVE); final String placeholder = UUID.randomUUID().toString(); final String app1 = UUID.randomUUID().toString(); final String app2 = UUID.randomUUID().toString(); final String app3 = UUID.randomUUID().toString(); final List < Application > applications = Lists.newArrayList(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app3).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app1).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app2).build()); final JobRequest jobRequest = new JobRequest.Builder(JOB_1_NAME, USER, VERSION, null, null, null).withId(JOB_1_ID).withApplications(Lists.newArrayList(app3, app1, app2)).build(); final Cluster cluster = new Cluster.Builder(CLUSTER_NAME, USER, VERSION, ClusterStatus.UP).withId(CLUSTER_ID).build(); final Command command = new Command.Builder(COMMAND_NAME, USER, VERSION, CommandStatus.ACTIVE, \"foo\", 5000L).withId(COMMAND_ID).build(); final int memory = 2438; Mockito.doThrow(new IOException(\"something bad\")).when(this.task2).executeTask(Mockito.anyMap()); this.jobSubmitterService.submitJob(jobRequest, cluster, command, applications, memory); } ",
        "focal_tgt": "@SuppressFBWarnings(value = \"REC_CATCH_EXCEPTION\", justification = \"We catch exception to make sure we always mark job failed.\")@Override public void submitJob(@Valid@NotNull(message = \"No job provided. Unable to submit job for execution.\")final JobRequest jobRequest, @Valid@NotNull(message = \"No cluster provided. Unable to submit job for execution\")final Cluster cluster, @Valid@NotNull(message = \"No command provided. Unable to submit job for execution\")final Command command, @NotNull(message = \"No applications provided. Unable to submit job for execution\")final List < Application > applications, @Min(value = 1, message = \"Memory can't be less than 1 MB\")final int memory)throws GenieException { final long start = System.nanoTime(); try { log.info(\"Beginning local job submission for {}\", jobRequest); final String id = jobRequest.getId().orElseThrow(() -> new GenieServerException(\"No job id found.\")); try { final File jobWorkingDir = this.createJobWorkingDirectory(id); final File runScript = this.createRunScript(jobWorkingDir); final Map < String, Object > context = this.createJobContext(jobRequest, cluster, command, applications, memory, jobWorkingDir); final JobExecution jobExecution = this.executeJob(context, runScript); if(jobExecution != null) { final long createJobExecutionStart = System.nanoTime(); try { log.info(\"Saving job execution for job {}\", jobRequest.getId()); this.jobPersistenceService.setJobRunningInformation(id, jobExecution.getProcessId().orElseThrow(() -> new GenieServerException(\"No process id returned. Unable to persist\")), jobExecution.getCheckDelay().orElse(Command.DEFAULT_CHECK_DELAY), jobExecution.getTimeout().orElseThrow(() -> new GenieServerException(\"No timeout date returned. Unable to persist\"))); } finally { this.saveJobExecutionTimer.record(System.nanoTime() - createJobExecutionStart, TimeUnit.NANOSECONDS); } final long publishEventStart = System.nanoTime(); try { log.info(\"Publishing job started event for job {}\", id); this.eventPublisher.publishEvent(new JobStartedEvent(jobExecution, this)); } finally { this.publishJobStartedEventTimer.record(System.nanoTime() - publishEventStart, TimeUnit.NANOSECONDS); } } } catch(final GeniePreconditionException gpe) { log.error(gpe.getMessage(), gpe); this.createInitFailureDetailsFile(id, gpe); this.eventMulticaster.multicastEvent(new JobFinishedEvent(id, JobFinishedReason.INVALID, JobStatusMessages.SUBMIT_PRECONDITION_FAILURE, this)); throw gpe; } catch(final Exception e) { log.error(e.getMessage(), e); this.createInitFailureDetailsFile(id, e); this.eventMulticaster.multicastEvent(new JobFinishedEvent(id, JobFinishedReason.FAILED_TO_INIT, JobStatusMessages.SUBMIT_INIT_FAILURE, this)); throw e; } } finally { this.overallSubmitTimer.record(System.nanoTime() - start, TimeUnit.NANOSECONDS); } } ",
        "focal_src": "@SuppressFBWarnings(value = \"REC_CATCH_EXCEPTION\", justification = \"We catch exception to make sure we always mark job failed.\")@Override public void submitJob(@Valid@NotNull(message = \"No job provided. Unable to submit job for execution.\")final JobRequest jobRequest, @Valid@NotNull(message = \"No cluster provided. Unable to submit job for execution\")final Cluster cluster, @Valid@NotNull(message = \"No command provided. Unable to submit job for execution\")final Command command, @NotNull(message = \"No applications provided. Unable to submit job for execution\")final List < Application > applications, @Min(value = 1, message = \"Memory can't be less than 1 MB\")final int memory)throws GenieException { final long start = System.nanoTime(); try { log.info(\"Beginning local job submission for {}\", jobRequest); final String id = jobRequest.getId().orElseThrow(() -> new GenieServerException(\"No job id found.\")); try { final File jobWorkingDir = this.createJobWorkingDirectory(id); final File runScript = this.createRunScript(jobWorkingDir); final Map < String, Object > context = this.createJobContext(jobRequest, cluster, command, applications, memory, jobWorkingDir); final JobExecution jobExecution = this.executeJob(context, runScript); if(jobExecution != null) { final long createJobExecutionStart = System.nanoTime(); try { log.info(\"Saving job execution for job {}\", jobRequest.getId()); this.jobPersistenceService.setJobRunningInformation(id, jobExecution.getProcessId().orElseThrow(() -> new GenieServerException(\"No process id returned. Unable to persist\")), jobExecution.getCheckDelay().orElse(Command.DEFAULT_CHECK_DELAY), jobExecution.getTimeout().orElseThrow(() -> new GenieServerException(\"No timeout date returned. Unable to persist\"))); } finally { this.saveJobExecutionTimer.record(System.nanoTime() - createJobExecutionStart, TimeUnit.NANOSECONDS); } final long publishEventStart = System.nanoTime(); try { log.info(\"Publishing job started event for job {}\", id); this.eventPublisher.publishEvent(new JobStartedEvent(jobExecution, this)); } finally { this.publishJobStartedEventTimer.record(System.nanoTime() - publishEventStart, TimeUnit.NANOSECONDS); } } } catch(final GeniePreconditionException gpe) { log.error(gpe.getMessage(), gpe); this.eventMulticaster.multicastEvent(new JobFinishedEvent(id, JobFinishedReason.INVALID, gpe.getMessage(), this)); throw gpe; } catch(final Exception e) { log.error(e.getMessage(), e); this.eventMulticaster.multicastEvent(new JobFinishedEvent(id, JobFinishedReason.FAILED_TO_INIT, e.getMessage(), this)); throw e; } } finally { this.overallSubmitTimer.record(System.nanoTime() - start, TimeUnit.NANOSECONDS); } } ",
        "test_tgt": "@SuppressWarnings(\"unchecked\")@Test(expected = GenieServerException.class)public void testSubmitJob()throws GenieException, IOException { final Set < CommandStatus > enumStatuses = EnumSet.noneOf(CommandStatus.class); enumStatuses.add(CommandStatus.ACTIVE); final String placeholder = UUID.randomUUID().toString(); final String app1 = UUID.randomUUID().toString(); final String app2 = UUID.randomUUID().toString(); final String app3 = UUID.randomUUID().toString(); final List < Application > applications = Lists.newArrayList(new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app3).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app1).build(), new Application.Builder(placeholder, placeholder, placeholder, ApplicationStatus.ACTIVE).withId(app2).build()); final JobRequest jobRequest = new JobRequest.Builder(JOB_1_NAME, USER, VERSION, null, null, null).withId(JOB_1_ID).withApplications(Lists.newArrayList(app3, app1, app2)).build(); final Cluster cluster = new Cluster.Builder(CLUSTER_NAME, USER, VERSION, ClusterStatus.UP).withId(CLUSTER_ID).build(); final Command command = new Command.Builder(COMMAND_NAME, USER, VERSION, CommandStatus.ACTIVE, \"foo\", 5000L).withId(COMMAND_ID).build(); final int memory = 2438; Mockito.doThrow(new IOException(\"something bad\")).when(this.task2).executeTask(Mockito.anyMap()); try { this.jobSubmitterService.submitJob(jobRequest, cluster, command, applications, memory); } catch(Throwable t) { final File jobDirectory = new File(tmpFolder, JOB_1_ID); Assert.assertTrue(jobDirectory.exists()); final File initFailureFile = new File(jobDirectory, JobConstants.GENIE_INIT_FAILURE_MESSAGE_FILE_NAME); Assert.assertTrue(initFailureFile.exists()); Assert.assertTrue(initFailureFile.length() > 0); throw t; } } "
    },
    {
        "test_src": "@Test public void testLe() { assertEquals(new LeCriterion(\"id\", 5), instance.le(\"id\", 5).getQueryCriterion()); } ",
        "focal_tgt": "public CriteriaQuery le(String propName, Comparable < ? > value) { criterion = criterion.and(Criteria.le(propName, value)); return this; } ",
        "focal_src": "public CriteriaQuery le(String propName, Comparable < ? > value) { criterion = criterion.and(criterionBuilder.le(propName, value)); return this; } ",
        "test_tgt": "@Test public void testLe() { assertEquals(Criteria.le(\"id\", 5), instance.le(\"id\", 5).getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void testSetParameters()throws StageException { List < JdbcFieldColumnParamMapping > columnMapping = ImmutableList.of(new JdbcFieldColumnParamMapping(\"/field1\", \"P_ID\", \"?\"), new JdbcFieldColumnParamMapping(\"/field2\", \"MSG\", \"?\")); boolean caseSensitive = false; JdbcGenericRecordWriter writer = new JdbcGenericRecordWriter(connectionString, dataSource, \"TEST\", \"TEST_TABLE\", false, columnMapping, JDBCOperationType.INSERT.getCode(), UnsupportedOperationAction.DISCARD, null, new JdbcRecordReader(), caseSensitive, Collections.emptyList()); Record record = RecordCreator.create(); Map < String, Field > fields = new HashMap < > (); fields.put(\"field1\", Field.create(100)); fields.put(\"field2\", Field.create(\"StreamSets\")); record.set(Field.create(fields)); SortedMap < String, String > columnsToParameters = new TreeMap < > (); columnsToParameters.put(\"P_ID\", \"?\"); columnsToParameters.put(\"MSG\", \"?\"); String query = \"INSERT INTO TEST.TEST_TABLE (MSG, P_ID) VALUES (?, ?)\"; executeSetParameters(OperationType.INSERT_CODE, query, writer, columnsToParameters, record); query = \"DELETE FROM TEST.TEST_TABLE WHERE P_ID = ?\"; executeSetParameters(OperationType.DELETE_CODE, query, writer, columnsToParameters, record); query = \"UPDATE TEST.TEST_TABLE SET MSG = ? WHERE P_ID = ?\"; fields.put(\"field2\", Field.create(\"This is an updated message\")); columnsToParameters.remove(\"P_ID\"); executeSetParameters(OperationType.UPDATE_CODE, query, writer, columnsToParameters, record); } ",
        "focal_tgt": "@VisibleForTesting@SuppressWarnings(\"unchecked\")int setParameters(int opCode, Map < String, String > columnsToParameters, final Record record, final Connection connection, PreparedStatement statement)throws OnRecordErrorException { int paramIdx = 1; if(opCode != OperationType.DELETE_CODE) { paramIdx = setParamsToStatement(paramIdx, statement, columnsToParameters, record, connection, opCode); } if(opCode != OperationType.INSERT_CODE) { paramIdx = setPrimaryKeys(paramIdx, record, statement, opCode); } return paramIdx; } ",
        "focal_src": "@VisibleForTesting@SuppressWarnings(\"unchecked\")int setParameters(int opCode, SortedMap < String, String > columnsToParameters, final Record record, final Connection connection, PreparedStatement statement)throws OnRecordErrorException { int paramIdx = 1; if(opCode != OperationType.DELETE_CODE) { paramIdx = setParamsToStatement(paramIdx, statement, columnsToParameters, record, connection, opCode); } if(opCode != OperationType.INSERT_CODE) { paramIdx = setPrimaryKeys(paramIdx, record, statement, opCode); } return paramIdx; } ",
        "test_tgt": "@Test public void testSetParameters()throws StageException { List < JdbcFieldColumnParamMapping > columnMapping = ImmutableList.of(new JdbcFieldColumnParamMapping(\"/field1\", \"P_ID\", \"?\"), new JdbcFieldColumnParamMapping(\"/field2\", \"MSG\", \"?\")); boolean caseSensitive = false; JdbcGenericRecordWriter writer = new JdbcGenericRecordWriter(connectionString, dataSource, \"TEST\", \"TEST_TABLE\", false, columnMapping, JDBCOperationType.INSERT.getCode(), UnsupportedOperationAction.DISCARD, null, new JdbcRecordReader(), caseSensitive, Collections.emptyList(), true); Record record = RecordCreator.create(); Map < String, Field > fields = new HashMap < > (); fields.put(\"field1\", Field.create(100)); fields.put(\"field2\", Field.create(\"StreamSets\")); record.set(Field.create(fields)); SortedMap < String, String > columnsToParameters = new TreeMap < > (); columnsToParameters.put(\"P_ID\", \"?\"); columnsToParameters.put(\"MSG\", \"?\"); String query = \"INSERT INTO TEST.TEST_TABLE (MSG, P_ID) VALUES (?, ?)\"; executeSetParameters(OperationType.INSERT_CODE, query, writer, columnsToParameters, record); query = \"DELETE FROM TEST.TEST_TABLE WHERE P_ID = ?\"; executeSetParameters(OperationType.DELETE_CODE, query, writer, columnsToParameters, record); query = \"UPDATE TEST.TEST_TABLE SET MSG = ? WHERE P_ID = ?\"; fields.put(\"field2\", Field.create(\"This is an updated message\")); columnsToParameters.remove(\"P_ID\"); executeSetParameters(OperationType.UPDATE_CODE, query, writer, columnsToParameters, record); } "
    },
    {
        "test_src": "@Test public void testRemovePartition()throws MetadataServiceException, URISyntaxException { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/mydb/clicks/?datastamp=12&region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServer() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency, false); assertFalse(missingPartitions.getPartitionsMap().containsKey(hcatUri.getPartitionMap())); pdms.addMissingPartition(newHCatDependency, actionId); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency); assertFalse(pdms.getHCatMap().containsKey(hcatUri.getTable())); } ",
        "focal_tgt": "public boolean removePartition(PartitionWrapper partition, boolean cascade) { log.debug(\"Removing partition \" + partition + \" with cascade :\" + cascade); String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); if(hcatInstanceMap.containsKey(prefix)) { Map < String, PartitionsGroup > tableMap = hcatInstanceMap.get(prefix); String tableName = partition.getTableName(); if(tableMap.containsKey(tableName)) { PartitionsGroup missingPartitions = tableMap.get(tableName); if(missingPartitions != null) { missingPartitions.getPartitionsMap().remove(partition); if(cascade) { if(missingPartitions.getPartitionsMap().size() == 0) { tableMap.remove(tableName); if(tableMap.size() == 0) { hcatInstanceMap.remove(prefix); } } } return true; } else { log.warn(\"No partition entries for table [{0}]\", tableName); } } else { log.warn(\"HCat table [{0}] not found\", tableName); } } else { log.warn(\"HCat instance entry [{0}] not found\", prefix); } return false; } ",
        "focal_src": "public boolean removePartition(PartitionWrapper partition, boolean cascade) { String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); if(hcatInstanceMap.containsKey(prefix)) { Map < String, PartitionsGroup > tableMap = hcatInstanceMap.get(prefix); String tableName = partition.getTableName(); if(tableMap.containsKey(tableName)) { PartitionsGroup missingPartitions = tableMap.get(tableName); if(missingPartitions != null) { missingPartitions.getPartitionsMap().remove(partition); if(cascade) { if(missingPartitions.getPartitionsMap().size() == 0) { tableMap.remove(tableName); if(tableMap.size() == 0) { hcatInstanceMap.remove(prefix); } } } return true; } else { log.warn(\"No partition entries for table [{0}]\", tableName); } } else { log.warn(\"HCat table [{0}] not found\", tableName); } } else { log.warn(\"HCat instance entry [{0}] not found\", prefix); } return false; } ",
        "test_tgt": "@Test public void testRemovePartition()throws MetadataServiceException, URISyntaxException { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/mydb/clicks/?datastamp=12&region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServerEndPoint() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency, false); assertFalse(missingPartitions.getPartitionsMap().containsKey(hcatUri.getPartitionMap())); pdms.addMissingPartition(newHCatDependency, actionId); assertNotNull(missingPartitions); pdms.removePartition(newHCatDependency); assertFalse(pdms.getHCatMap().containsKey(hcatUri.getTable())); } "
    },
    {
        "test_src": "@Test public void testGeoAdd() { doReturn(Arrays.asList(new Object[] { Arrays.asList(new Object[] { 1l }) })).when(nativeConnection).closePipeline(); super.testGeoAddBytes(); } ",
        "focal_tgt": "@Override public Long geoAdd(String key, Map < String, Point > memberCoordinateMap) { Assert.notNull(memberCoordinateMap, \"MemberCoordinateMap must not be null!\"); Map < byte[], Point > byteMap = new HashMap < byte[], Point > (); for(Entry < String, Point > entry : memberCoordinateMap.entrySet()) { byteMap.put(serialize(entry.getKey()), memberCoordinateMap.get(entry.getValue())); } return geoAdd(serialize(key), byteMap); } ",
        "focal_src": "@Override public Long geoAdd(String key, Map < String, GeoCoordinate > memberCoordinateMap) { Map < byte[], GeoCoordinate > byteMap = new HashMap < byte[], GeoCoordinate > (); for(String k : memberCoordinateMap.keySet()) { byteMap.put(serialize(k), memberCoordinateMap.get(k)); } Long result = delegate.geoAdd(serialize(key), byteMap); if(isFutureConversion()) { addResultConverter(identityConverter); } return result; } ",
        "test_tgt": "@Test public void testGeoAdd() { doReturn(Arrays.asList(Collections.singletonList(1L))).when(nativeConnection).closePipeline(); super.testGeoAddBytes(); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should return all cohorts and voided\", method = \"getAllCohorts(null)\")public void getAllCohorts_shouldReturnAllCohortsAndVoided()throws Exception { executeDataSet(COHORT_XML); List < Cohort > allCohorts = service.getAllCohorts(true); assertNotNull(allCohorts); assertEquals(2, allCohorts.size()); assertTrue(allCohorts.get(0).isVoided()); assertFalse(allCohorts.get(1).isVoided()); allCohorts = service.getAllCohorts(false); assertNotNull(allCohorts); assertEquals(1, allCohorts.size()); assertFalse(allCohorts.get(0).isVoided()); } ",
        "focal_tgt": "@Override@Transactional(readOnly = true)public List < Cohort > getAllCohorts(boolean includeVoided)throws APIException { return dao.getAllCohorts(includeVoided); } ",
        "focal_src": "@Transactional(readOnly = true)public List < Cohort > getAllCohorts(boolean includeVoided)throws APIException { return dao.getAllCohorts(includeVoided); } ",
        "test_tgt": "@Test public void getAllCohorts_shouldReturnAllCohortsAndVoided()throws Exception { executeDataSet(COHORT_XML); List < Cohort > allCohorts = service.getAllCohorts(true); assertNotNull(allCohorts); assertEquals(2, allCohorts.size()); assertTrue(allCohorts.get(0).getVoided()); assertFalse(allCohorts.get(1).getVoided()); allCohorts = service.getAllCohorts(false); assertNotNull(allCohorts); assertEquals(1, allCohorts.size()); assertFalse(allCohorts.get(0).getVoided()); } "
    },
    {
        "test_src": "@Test public void receive() { final int numberOfEvents = 15; final String messageId = UUID.randomUUID().toString(); final EventHubAsyncClient asyncClient = new EventHubClientBuilder().connectionString(getConnectionString()).buildAsyncClient(); final EventHubProducerAsyncClient producer = asyncClient.createProducer(); final EventHubConsumerClient receiver = client.createConsumer(EventHubClientBuilder.DEFAULT_CONSUMER_GROUP_NAME, EventPosition.earliest()); producer.send(TestUtils.getEvents(numberOfEvents, messageId), sendOptions).block(); final IterableStream < PartitionEvent > receive = receiver.receive(PARTITION_ID, 15, Duration.ofSeconds(30)); Assert.assertNotNull(receive); final List < PartitionEvent > results = receive.stream().collect(Collectors.toList()); Assert.assertEquals(numberOfEvents, results.size()); } ",
        "focal_tgt": "public void initialization() { EventHubConsumerAsyncClient consumer = new EventHubClientBuilder().connectionString(\"fake-string\").startingPosition(EventPosition.latest()).consumerGroup(EventHubClientBuilder.DEFAULT_CONSUMER_GROUP_NAME).buildAsyncConsumer(); } ",
        "focal_src": "public void receive() { String partitionId = \"0\"; EventHubConsumerAsyncClient consumer = new EventHubClientBuilder().connectionString(\"fake-string\").startingPosition(EventPosition.latest()).consumerGroup(EventHubClientBuilder.DEFAULT_CONSUMER_GROUP_NAME).buildAsyncConsumer(); Disposable subscription = consumer.receive(partitionId).subscribe(event -> { }, error -> System.err.print(error.toString())); subscription.dispose(); } ",
        "test_tgt": "@Test public void receive() { final int numberOfEvents = 15; final String messageId = UUID.randomUUID().toString(); final EventHubProducerAsyncClient producer = new EventHubClientBuilder().connectionString(getConnectionString()).buildAsyncProducer(); final EventHubConsumerClient receiver = new EventHubClientBuilder().connectionString(getConnectionString()).consumerGroup(EventHubClientBuilder.DEFAULT_CONSUMER_GROUP_NAME).startingPosition(EventPosition.earliest()).buildConsumer(); producer.send(TestUtils.getEvents(numberOfEvents, messageId), sendOptions).block(); final IterableStream < PartitionEvent > receive = receiver.receive(PARTITION_ID, 15, Duration.ofSeconds(30)); Assert.assertNotNull(receive); final List < PartitionEvent > results = receive.stream().collect(Collectors.toList()); Assert.assertEquals(numberOfEvents, results.size()); } "
    },
    {
        "test_src": "@Test public void testCreateStudent() { StudentData s = new StudentData(); s.name = \"herp derp\"; s.course = \"Winzor101\"; s.email = \"ching@chang.com\"; try { accountsDb.createStudent(s); } catch(EntityAlreadyExistsException e) { fail(); } try { accountsDb.createStudent(s); fail(); } catch(EntityAlreadyExistsException e) { } s.course = \"pwned 101\"; try { accountsDb.createStudent(s); fail(); } catch(AssertionError a) { } catch(EntityAlreadyExistsException e) { fail(); } } ",
        "focal_tgt": "public void createStudent(StudentData studentData)throws EntityAlreadyExistsException, InvalidParametersException { Assumption.assertNotNull(ERROR_NULL_PARAMETER, studentData); verifyCourseOwnerOrAbove(studentData.course); if( ! studentData.isValid()) { throw new InvalidParametersException(studentData.getInvalidStateInfo()); } AccountsStorage.inst().getDb().createStudent(studentData); EvaluationsStorage.inst().adjustSubmissionsForNewStudent(studentData.course, studentData.email, studentData.team); } ",
        "focal_src": "public void createStudent(StudentData studentData)throws EntityAlreadyExistsException, InvalidParametersException { verifyCourseOwnerOrAbove(studentData.course); if( ! studentData.isValid()) { throw new InvalidParametersException(studentData.getInvalidStateInfo()); } AccountsStorage.inst().getDb().createStudent(studentData); EvaluationsStorage.inst().adjustSubmissionsForNewStudent(studentData.course, studentData.email, studentData.team); } ",
        "test_tgt": "@Test public void testCreateStudent()throws EntityAlreadyExistsException { StudentData s = new StudentData(); s.name = \"valid student\"; s.course = \"valid-course\"; s.email = \"valid@email.com\"; accountsDb.createStudent(s); try { accountsDb.createStudent(s); fail(); } catch(EntityAlreadyExistsException e) { assertContains(AccountsDb.ERROR_CREATE_STUDENT_ALREADY_EXISTS, e.getMessage()); } s.course = \"invalid id space\"; try { accountsDb.createStudent(s); fail(); } catch(AssertionError a) { assertEquals(a.getMessage(), StudentData.ERROR_FIELD_COURSE); } catch(EntityAlreadyExistsException e) { fail(); } try { accountsDb.createStudent(null); fail(); } catch(AssertionError a) { assertEquals(Common.ERROR_DBLEVEL_NULL_INPUT, a.getMessage()); } } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_with_adjustment() { final OffsetTime sample = OffsetTime.of(23, 5, OFFSET_PONE); WithAdjuster adjuster = new WithAdjuster() { @Override public DateTime doWithAdjustment(DateTime dateTime) { return sample; } }; assertEquals(TEST_11_30_59_500_PONE.with(adjuster), sample); } ",
        "focal_tgt": "@Override public LocalDate with(TemporalField field, long newValue) { if(field instanceof ChronoField) { ChronoField f = (ChronoField)field; f.checkValidValue(newValue); switch(f) { case DAY_OF_WEEK : return plusDays(newValue - getDayOfWeek().getValue()); case ALIGNED_DAY_OF_WEEK_IN_MONTH : return plusDays(newValue - getLong(ALIGNED_DAY_OF_WEEK_IN_MONTH)); case ALIGNED_DAY_OF_WEEK_IN_YEAR : return plusDays(newValue - getLong(ALIGNED_DAY_OF_WEEK_IN_YEAR)); case DAY_OF_MONTH : return withDayOfMonth((int)newValue); case DAY_OF_YEAR : return withDayOfYear((int)newValue); case EPOCH_DAY : return LocalDate.ofEpochDay(newValue); case ALIGNED_WEEK_OF_MONTH : return plusWeeks(newValue - getLong(ALIGNED_WEEK_OF_MONTH)); case ALIGNED_WEEK_OF_YEAR : return plusWeeks(newValue - getLong(ALIGNED_WEEK_OF_YEAR)); case MONTH_OF_YEAR : return withMonth((int)newValue); case EPOCH_MONTH : return plusMonths(newValue - getLong(EPOCH_MONTH)); case YEAR_OF_ERA : return withYear((int)(year >= 1 ? newValue : 1 - newValue)); case YEAR : return withYear((int)newValue); case ERA : return(getLong(ERA) == newValue ? this : withYear(1 - year)); } throw new DateTimeException(\"Unsupported field: \" + field.getName()); } return field.doWith(this, newValue); } ",
        "focal_src": "@Override public LocalDate with(DateTimeField field, long newValue) { if(field instanceof ChronoField) { ChronoField f = (ChronoField)field; f.checkValidValue(newValue); switch(f) { case DAY_OF_WEEK : return plusDays(newValue - getDayOfWeek().getValue()); case ALIGNED_DAY_OF_WEEK_IN_MONTH : return plusDays(newValue - getLong(ALIGNED_DAY_OF_WEEK_IN_MONTH)); case ALIGNED_DAY_OF_WEEK_IN_YEAR : return plusDays(newValue - getLong(ALIGNED_DAY_OF_WEEK_IN_YEAR)); case DAY_OF_MONTH : return withDayOfMonth((int)newValue); case DAY_OF_YEAR : return withDayOfYear((int)newValue); case EPOCH_DAY : return LocalDate.ofEpochDay(newValue); case ALIGNED_WEEK_OF_MONTH : return plusWeeks(newValue - getLong(ALIGNED_WEEK_OF_MONTH)); case ALIGNED_WEEK_OF_YEAR : return plusWeeks(newValue - getLong(ALIGNED_WEEK_OF_YEAR)); case MONTH_OF_YEAR : return withMonth((int)newValue); case EPOCH_MONTH : return plusMonths(newValue - getLong(EPOCH_MONTH)); case YEAR_OF_ERA : return withYear((int)(year >= 1 ? newValue : 1 - newValue)); case YEAR : return withYear((int)newValue); case ERA : return(getLong(ERA) == newValue ? this : withYear(1 - year)); } throw new DateTimeException(\"Unsupported field: \" + field.getName()); } return field.doWith(this, newValue); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_with_adjustment() { final OffsetTime sample = OffsetTime.of(23, 5, OFFSET_PONE); WithAdjuster adjuster = new WithAdjuster() { @Override public Temporal doWithAdjustment(Temporal dateTime) { return sample; } }; assertEquals(TEST_11_30_59_500_PONE.with(adjuster), sample); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_atTime_Local() { OffsetDate t = OffsetDate.of(2008, 6, 30, OFFSET_PTWO); assertEquals(t.atTime(LocalTime.of(11, 30)), OffsetDateTime.of(2008, 6, 30, 11, 30, OFFSET_PTWO)); } ",
        "focal_tgt": "@Override public LocalDateTime atTime(LocalTime time) { return LocalDateTime.of(this, time); } ",
        "focal_src": "@Override public LocalDateTime atTime(LocalTime localTime) { return LocalDateTime.of(this, localTime); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_atTime_Local() { OffsetDate t = OffsetDate.of(2008, 6, 30, OFFSET_PTWO); assertEquals(t.atTime(LocalTime.of(11, 30)), LocalDateTime.of(2008, 6, 30, 11, 30).atZone(OFFSET_PTWO)); } "
    },
    {
        "test_src": "@Test public void testGetIntervalDayList1() { Date fromDate = DateUtil.string2Date(FROMSTRING, DatePattern.COMMON_DATE_AND_TIME); Date toDate = DateUtil.string2Date(TOSTRING, DatePattern.COMMON_DATE_AND_TIME); LOGGER.debug(JsonUtil.format(DateExtensionUtil.getIntervalDayList(fromDate, toDate))); } ",
        "focal_tgt": "public static List < Date > getIntervalDayList(String fromDateString, String toDateString, String datePattern) { Validate.notBlank(fromDateString, \"fromDateString can't be null/empty!\"); Validate.notBlank(toDateString, \"toDateString can't be null/empty!\"); Validate.notBlank(datePattern, \"datePattern can't be null/empty!\"); Date fromDate = DateUtil.toDate(fromDateString, datePattern); Date toDate = DateUtil.toDate(toDateString, datePattern); return getIntervalDayList(fromDate, toDate); } ",
        "focal_src": "public static List < Date > getIntervalDayList(String fromDateString, String toDateString, String datePattern) { Validate.notBlank(fromDateString, \"fromDateString can't be null/empty!\"); Validate.notBlank(toDateString, \"toDateString can't be null/empty!\"); Validate.notBlank(datePattern, \"datePattern can't be null/empty!\"); Date fromDate = DateUtil.string2Date(fromDateString, datePattern); Date toDate = DateUtil.string2Date(toDateString, datePattern); return getIntervalDayList(fromDate, toDate); } ",
        "test_tgt": "@Test public void testGetIntervalDayList1() { Date fromDate = DateUtil.toDate(FROMSTRING, DatePattern.COMMON_DATE_AND_TIME); Date toDate = DateUtil.toDate(TOSTRING, DatePattern.COMMON_DATE_AND_TIME); LOGGER.debug(JsonUtil.format(DateExtensionUtil.getIntervalDayList(fromDate, toDate))); } "
    },
    {
        "test_src": "@Test public void testMaybeSignalForMoreConnections()throws SecurityException, NoSuchMethodException, IllegalArgumentException, IllegalAccessException, InvocationTargetException { expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.size()).andReturn(1).anyTimes(); expect(mockPartition.getMaxConnections()).andReturn(10).anyTimes(); mockPartition.lockAlmostFullLock(); expectLastCall().once(); mockPartition.almostFullSignal(); expectLastCall().once(); mockPartition.unlockAlmostFullLock(); expectLastCall().once(); replay(mockPartition, mockConnectionHandles); Method method = testClass.getClass().getDeclaredMethod(\"maybeSignalForMoreConnections\", ConnectionPartition.class); method.setAccessible(true); method.invoke(testClass, new Object[] { mockPartition }); verify(mockPartition, mockConnectionHandles); reset(mockPartition, mockConnectionHandles); expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).anyTimes(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.size()).andReturn(1).anyTimes(); expect(mockPartition.getMaxConnections()).andReturn(10).anyTimes(); mockPartition.lockAlmostFullLock(); expectLastCall().once(); mockPartition.almostFullSignal(); expectLastCall().andThrow(new RuntimeException()).once(); mockPartition.unlockAlmostFullLock(); expectLastCall().once(); replay(mockPartition, mockConnectionHandles); try { method.invoke(testClass, new Object[] { mockPartition }); fail(\"Should have thrown an exception\"); } catch(Throwable t) { } verify(mockPartition, mockConnectionHandles); } ",
        "focal_tgt": "private void maybeSignalForMoreConnections(ConnectionPartition connectionPartition) { if( ! this.poolShuttingDown && ! connectionPartition.isUnableToCreateMoreTransactions() && connectionPartition.getFreeConnections().size() * 100 / connectionPartition.getMaxConnections() < this.poolAvailabilityThreshold) { this.poolWatchThreadSignalQueue.offer(new Object()); } } ",
        "focal_src": "private void maybeSignalForMoreConnections(ConnectionPartition connectionPartition) { if( ! this.poolShuttingDown && ! connectionPartition.isUnableToCreateMoreTransactions() && connectionPartition.getFreeConnections().size() * 100 / connectionPartition.getMaxConnections() < this.poolAvailabilityThreshold) { try { this.poolWatchThreadWasSignalled = true; connectionPartition.lockAlmostFullLock(); connectionPartition.almostFullSignal(); } finally { connectionPartition.unlockAlmostFullLock(); } } } ",
        "test_tgt": "@Test public void testMaybeSignalForMoreConnections()throws SecurityException, NoSuchMethodException, IllegalArgumentException, IllegalAccessException, InvocationTargetException { expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.size()).andReturn(1).anyTimes(); expect(mockPartition.getMaxConnections()).andReturn(10).anyTimes(); replay(mockPartition, mockConnectionHandles); Method method = testClass.getClass().getDeclaredMethod(\"maybeSignalForMoreConnections\", ConnectionPartition.class); method.setAccessible(true); method.invoke(testClass, new Object[] { mockPartition }); verify(mockPartition, mockConnectionHandles); reset(mockPartition, mockConnectionHandles); expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).anyTimes(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnectionHandles.size()).andReturn(1).anyTimes(); expect(mockPartition.getMaxConnections()).andReturn(10).anyTimes(); replay(mockPartition, mockConnectionHandles); try { method.invoke(testClass, new Object[] { mockPartition }); fail(\"Should have thrown an exception\"); } catch(Throwable t) { } verify(mockPartition, mockConnectionHandles); } "
    },
    {
        "test_src": "@Test public void testDestroy() { MulticastSocket socket = registry.getMutilcastSocket(); assertFalse(socket.isClosed()); registry.destroy(); socket = registry.getMutilcastSocket(); assertTrue(socket.isClosed()); } ",
        "focal_tgt": "@Override public void destroy() { super.destroy(); try { if(cleanFuture != null) { cleanFuture.cancel(true); } } catch(Throwable t) { logger.warn(t.getMessage(), t); } try { multicastSocket.leaveGroup(multicastAddress); multicastSocket.close(); } catch(Throwable t) { logger.warn(t.getMessage(), t); } ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod); } ",
        "focal_src": "@Override public void destroy() { super.destroy(); try { if(cleanFuture != null) { cleanFuture.cancel(true); } } catch(Throwable t) { logger.warn(t.getMessage(), t); } try { mutilcastSocket.leaveGroup(mutilcastAddress); mutilcastSocket.close(); } catch(Throwable t) { logger.warn(t.getMessage(), t); } ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod); } ",
        "test_tgt": "@Test public void testDestroy() { MulticastSocket socket = registry.getMulticastSocket(); assertFalse(socket.isClosed()); registry.destroy(); socket = registry.getMulticastSocket(); assertTrue(socket.isClosed()); } "
    },
    {
        "test_src": "@Test public void getPartitionProperties() { for(String partitionId : expectedPartitionIds) { StepVerifier.create(client.getPartitionProperties(partitionId)).assertNext(properties -> { Assert.assertEquals(eventHubName, properties.eventHubName()); Assert.assertEquals(partitionId, properties.id()); }).verifyComplete(); } } ",
        "focal_tgt": "@ServiceMethod(returns = ReturnType.SINGLE)public PartitionProperties getPartitionProperties(String partitionId) { return client.getPartitionProperties(partitionId).block(retry.getTryTimeout()); } ",
        "focal_src": "@ServiceMethod(returns = ReturnType.SINGLE)public PartitionProperties getPartitionProperties(String partitionId) { return client.getPartitionProperties(partitionId).block(retry.tryTimeout()); } ",
        "test_tgt": "@Test public void getPartitionProperties() { for(String partitionId : expectedPartitionIds) { StepVerifier.create(client.getPartitionProperties(partitionId)).assertNext(properties -> { Assert.assertEquals(eventHubName, properties.getEventHubName()); Assert.assertEquals(partitionId, properties.getId()); }).verifyComplete(); } } "
    },
    {
        "test_src": "@Test@SuppressWarnings(\"unchecked\")public void testTriggerStackTraceSample()throws Exception { CompletableFuture < StackTraceSample > sampleFuture = new FlinkCompletableFuture < > (); StackTraceSampleCoordinator sampleCoordinator = mock(StackTraceSampleCoordinator.class); when(sampleCoordinator.triggerStackTraceSample(any(ExecutionVertex[].class), anyInt(), any(Time.class), anyInt())).thenReturn(sampleFuture); ExecutionGraph graph = mock(ExecutionGraph.class); when(graph.getState()).thenReturn(JobStatus.RUNNING); when(graph.getExecutor()).thenReturn(new Executor() { @Override public void execute(Runnable runnable) { runnable.run(); } }); ExecutionVertex[]taskVertices = new ExecutionVertex[4]; ExecutionJobVertex jobVertex = mock(ExecutionJobVertex.class); when(jobVertex.getJobId()).thenReturn(new JobID()); when(jobVertex.getJobVertexId()).thenReturn(new JobVertexID()); when(jobVertex.getGraph()).thenReturn(graph); when(jobVertex.getTaskVertices()).thenReturn(taskVertices); taskVertices[0] = mockExecutionVertex(jobVertex, 0); taskVertices[1] = mockExecutionVertex(jobVertex, 1); taskVertices[2] = mockExecutionVertex(jobVertex, 2); taskVertices[3] = mockExecutionVertex(jobVertex, 3); int numSamples = 100; Time delayBetweenSamples = Time.milliseconds(100L); BackPressureStatsTracker tracker = new BackPressureStatsTracker(sampleCoordinator, 9999, numSamples, delayBetweenSamples); assertTrue(\"Failed to trigger\", tracker.triggerStackTraceSample(jobVertex)); verify(sampleCoordinator).triggerStackTraceSample(eq(taskVertices), eq(numSamples), eq(delayBetweenSamples), eq(BackPressureStatsTracker.MAX_STACK_TRACE_DEPTH)); assertFalse(\"Unexpected trigger\", tracker.triggerStackTraceSample(jobVertex)); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isEmpty()); verify(sampleCoordinator).triggerStackTraceSample(eq(taskVertices), eq(numSamples), eq(delayBetweenSamples), eq(BackPressureStatsTracker.MAX_STACK_TRACE_DEPTH)); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isEmpty()); Map < ExecutionAttemptID, List < StackTraceElement[] > > traces = new HashMap < > (); for(ExecutionVertex vertex : taskVertices) { List < StackTraceElement[] > taskTraces = new ArrayList < > (); for(int i = 0; i < taskVertices.length; i ++ ) { taskTraces.add(createStackTrace(i <= vertex.getParallelSubtaskIndex())); } traces.put(vertex.getCurrentExecutionAttempt().getAttemptId(), taskTraces); } int sampleId = 1231; int endTime = 841; StackTraceSample sample = new StackTraceSample(sampleId, 0, endTime, traces); sampleFuture.complete(sample); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isDefined()); OperatorBackPressureStats stats = tracker.getOperatorBackPressureStats(jobVertex).get(); assertEquals(sampleId, stats.getSampleId()); assertEquals(endTime, stats.getEndTimestamp()); assertEquals(taskVertices.length, stats.getNumberOfSubTasks()); for(int i = 0; i < taskVertices.length; i ++ ) { double ratio = stats.getBackPressureRatio(i); assertEquals((i + 1) / ((double)4), ratio, 0.0); } } ",
        "focal_tgt": "@SuppressWarnings(\"unchecked\")public boolean triggerStackTraceSample(ExecutionJobVertex vertex) { synchronized(lock) { if(shutDown) { return false; } if( ! pendingStats.contains(vertex) && ! vertex.getGraph().getState().isGloballyTerminalState()) { Executor executor = vertex.getGraph().getFutureExecutor(); if(executor != null) { pendingStats.add(vertex); if(LOG.isDebugEnabled()) { LOG.debug(\"Triggering stack trace sample for tasks: \" + Arrays.toString(vertex.getTaskVertices())); } Future < StackTraceSample > sample = coordinator.triggerStackTraceSample(vertex.getTaskVertices(), numSamples, delayBetweenSamples, MAX_STACK_TRACE_DEPTH); sample.handleAsync(new StackTraceSampleCompletionCallback(vertex), executor); return true; } } return false; } } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public boolean triggerStackTraceSample(ExecutionJobVertex vertex) { synchronized(lock) { if(shutDown) { return false; } if( ! pendingStats.contains(vertex) && ! vertex.getGraph().getState().isGloballyTerminalState()) { Executor executor = vertex.getGraph().getExecutor(); if(executor != null) { pendingStats.add(vertex); if(LOG.isDebugEnabled()) { LOG.debug(\"Triggering stack trace sample for tasks: \" + Arrays.toString(vertex.getTaskVertices())); } Future < StackTraceSample > sample = coordinator.triggerStackTraceSample(vertex.getTaskVertices(), numSamples, delayBetweenSamples, MAX_STACK_TRACE_DEPTH); sample.handleAsync(new StackTraceSampleCompletionCallback(vertex), executor); return true; } } return false; } } ",
        "test_tgt": "@Test@SuppressWarnings(\"unchecked\")public void testTriggerStackTraceSample()throws Exception { CompletableFuture < StackTraceSample > sampleFuture = new FlinkCompletableFuture < > (); StackTraceSampleCoordinator sampleCoordinator = mock(StackTraceSampleCoordinator.class); when(sampleCoordinator.triggerStackTraceSample(any(ExecutionVertex[].class), anyInt(), any(Time.class), anyInt())).thenReturn(sampleFuture); ExecutionGraph graph = mock(ExecutionGraph.class); when(graph.getState()).thenReturn(JobStatus.RUNNING); when(graph.getFutureExecutor()).thenReturn(new Executor() { @Override public void execute(Runnable runnable) { runnable.run(); } }); ExecutionVertex[]taskVertices = new ExecutionVertex[4]; ExecutionJobVertex jobVertex = mock(ExecutionJobVertex.class); when(jobVertex.getJobId()).thenReturn(new JobID()); when(jobVertex.getJobVertexId()).thenReturn(new JobVertexID()); when(jobVertex.getGraph()).thenReturn(graph); when(jobVertex.getTaskVertices()).thenReturn(taskVertices); taskVertices[0] = mockExecutionVertex(jobVertex, 0); taskVertices[1] = mockExecutionVertex(jobVertex, 1); taskVertices[2] = mockExecutionVertex(jobVertex, 2); taskVertices[3] = mockExecutionVertex(jobVertex, 3); int numSamples = 100; Time delayBetweenSamples = Time.milliseconds(100L); BackPressureStatsTracker tracker = new BackPressureStatsTracker(sampleCoordinator, 9999, numSamples, delayBetweenSamples); assertTrue(\"Failed to trigger\", tracker.triggerStackTraceSample(jobVertex)); verify(sampleCoordinator).triggerStackTraceSample(eq(taskVertices), eq(numSamples), eq(delayBetweenSamples), eq(BackPressureStatsTracker.MAX_STACK_TRACE_DEPTH)); assertFalse(\"Unexpected trigger\", tracker.triggerStackTraceSample(jobVertex)); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isEmpty()); verify(sampleCoordinator).triggerStackTraceSample(eq(taskVertices), eq(numSamples), eq(delayBetweenSamples), eq(BackPressureStatsTracker.MAX_STACK_TRACE_DEPTH)); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isEmpty()); Map < ExecutionAttemptID, List < StackTraceElement[] > > traces = new HashMap < > (); for(ExecutionVertex vertex : taskVertices) { List < StackTraceElement[] > taskTraces = new ArrayList < > (); for(int i = 0; i < taskVertices.length; i ++ ) { taskTraces.add(createStackTrace(i <= vertex.getParallelSubtaskIndex())); } traces.put(vertex.getCurrentExecutionAttempt().getAttemptId(), taskTraces); } int sampleId = 1231; int endTime = 841; StackTraceSample sample = new StackTraceSample(sampleId, 0, endTime, traces); sampleFuture.complete(sample); assertTrue(tracker.getOperatorBackPressureStats(jobVertex).isDefined()); OperatorBackPressureStats stats = tracker.getOperatorBackPressureStats(jobVertex).get(); assertEquals(sampleId, stats.getSampleId()); assertEquals(endTime, stats.getEndTimestamp()); assertEquals(taskVertices.length, stats.getNumberOfSubTasks()); for(int i = 0; i < taskVertices.length; i ++ ) { double ratio = stats.getBackPressureRatio(i); assertEquals((i + 1) / ((double)4), ratio, 0.0); } } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_getID() { ZoneOffset offset = ZoneOffset.ofHoursMinutesSeconds(1, 0, 0); assertEquals(offset.getID(), \"+01:00\"); offset = ZoneOffset.ofHoursMinutesSeconds(1, 2, 3); assertEquals(offset.getID(), \"+01:02:03\"); offset = ZoneOffset.UTC; assertEquals(offset.getID(), \"Z\"); } ",
        "focal_tgt": "public String getId() { return id; } ",
        "focal_src": "public String getID() { return id; } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_getID() { ZoneOffset offset = ZoneOffset.ofHoursMinutesSeconds(1, 0, 0); assertEquals(offset.getId(), \"+01:00\"); offset = ZoneOffset.ofHoursMinutesSeconds(1, 2, 3); assertEquals(offset.getId(), \"+01:02:03\"); offset = ZoneOffset.UTC; assertEquals(offset.getId(), \"Z\"); } "
    },
    {
        "test_src": "@SuppressWarnings(\"nls\")@Test public void testIdFromName() { assertIdFromName(\"EricWittmann\", \"Eric Wittmann\"); assertIdFromName(\"DeloitteTouche\", \"Deloitte & Touche\"); assertIdFromName(\"JBoss_Overlord\", \"JBoss_Overlord\"); assertIdFromName(\"Red--Hat\", \"!Red--Hat?\"); assertIdFromName(\"Org.With.Periods\", \"Org.With.Periods\"); assertIdFromName(\"my-project\", \"my-project\"); assertIdFromName(\"MyInjectionimgsrca.fsdn.comsdtopicsspace_64.pngaltSpacetitleSpaceheight64width64\", \"My Injection: <img src=\\\\\\\"//a.fsdn.com/sd/topics/space_64.png\\\\\\\" alt=\\\\\\\"Space\\\\\\\" title=\\\\\\\"Space\\\\\\\" height=\\\\\\\"64\\\\\\\" width=\\\\\\\"64\\\\\\\">\"); assertIdFromName(\"1.0.7-SNAPSHOT\", \"1.0.7-SNAPSHOT\"); assertIdFromName(\"2.1.0_Final\", \"2.1.0_Final\"); } ",
        "focal_tgt": "public static final String idFromName(String name) { Transliterator tr = Transliterator.getInstance(\"Any-Latin; Latin-ASCII\"); return removeNonWord(tr.transliterate(name)); } ",
        "focal_src": "public static final String idFromName(String name) { Transliterator tr = Transliterator.getInstance(\"Any-Latin\"); return removeNonWord(tr.transliterate(name)); } ",
        "test_tgt": "@SuppressWarnings(\"nls\")@Test public void testIdFromName() { assertIdFromName(\"EricWittmann\", \"Eric Wittmann\"); assertIdFromName(\"DeloitteTouche\", \"Deloitte & Touche\"); assertIdFromName(\"JBoss_Overlord\", \"JBoss_Overlord\"); assertIdFromName(\"Red--Hat\", \"!Red--Hat?\"); assertIdFromName(\"Org.With.Periods\", \"Org.With.Periods\"); assertIdFromName(\"my-project\", \"my-project\"); assertIdFromName(\"MyInjectionimgsrca.fsdn.comsdtopicsspace_64.pngaltSpacetitleSpaceheight64width64\", \"My Injection: <img src=\\\\\\\"//a.fsdn.com/sd/topics/space_64.png\\\\\\\" alt=\\\\\\\"Space\\\\\\\" title=\\\\\\\"Space\\\\\\\" height=\\\\\\\"64\\\\\\\" width=\\\\\\\"64\\\\\\\">\"); assertIdFromName(\"1.0.7-SNAPSHOT\", \"1.0.7-SNAPSHOT\"); assertIdFromName(\"2.1.0_Final\", \"2.1.0_Final\"); assertIdFromName(\"Teparados\", \"T para dos\"); assertIdFromName(\"Cajdladvoih\", \"  \"); } "
    },
    {
        "test_src": "@Test public void testParseMessageAction() { byte[]serverHelloDoneMsg = { 0x0e, 0x00, 0x00, 0x00 }; handler.initializeProtocolMessage(); int endPointer = handler.parseMessage(serverHelloDoneMsg, 0); ServerHelloDoneMessage message = handler.getProtocolMessage(); assertNotNull(\"Confirm that parseMessage didn't return 'NULL'\", endPointer); assertEquals(\"Confirm expected message type: \\\"ServerHelloDone\\\"\", HandshakeMessageType.SERVER_HELLO_DONE, message.getHandshakeMessageType()); assertEquals(\"Confirm expected message length of \\\"0\\\"\", new Integer(0), message.getLength().getValue()); assertEquals(\"Confirm the correct value of endPointer representing the \" + \"actual number of message bytes\", serverHelloDoneMsg.length, endPointer); } ",
        "focal_tgt": "@Override public int parseMessageAction(byte[]message, int pointer) { if(message[pointer] != HandshakeMessageType.SERVER_KEY_EXCHANGE.getValue()) { throw new InvalidMessageTypeException(HandshakeMessageType.SERVER_KEY_EXCHANGE); } HandshakeMessageFields protocolMessageFields = (HandshakeMessageFields)protocolMessage.getMessageFields(); protocolMessage.setType(message[pointer]); int currentPointer = pointer + HandshakeByteLength.MESSAGE_TYPE; int nextPointer = currentPointer + HandshakeByteLength.MESSAGE_TYPE_LENGTH; int length = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessageFields.setLength(length); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int pLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setpLength(pLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getpLength().getValue(); BigInteger p = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setP(p); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int gLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setgLength(gLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getgLength().getValue(); BigInteger g = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setG(g); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int publicKeyLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKeyLength(publicKeyLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getPublicKeyLength().getValue(); BigInteger publicKey = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKey(publicKey); byte[]dhParams = ArrayConverter.concatenate(ArrayConverter.intToBytes(protocolMessage.getpLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getP().getValue()), ArrayConverter.intToBytes(protocolMessage.getgLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getG().getValue()), ArrayConverter.intToBytes(protocolMessage.getPublicKeyLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getPublicKey().getValue())); InputStream is = new ByteArrayInputStream(dhParams); try { ServerDHParams publicKeyParameters = ServerDHParams.parse(is); tlsContext.setServerDHParameters(publicKeyParameters); currentPointer = nextPointer; nextPointer ++ ; HashAlgorithm ha = HashAlgorithm.getHashAlgorithm(message[currentPointer]); protocolMessage.setHashAlgorithm(ha.getValue()); currentPointer = nextPointer; nextPointer ++ ; SignatureAlgorithm sa = SignatureAlgorithm.getSignatureAlgorithm(message[currentPointer]); protocolMessage.setSignatureAlgorithm(sa.getValue()); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.SIGNATURE_LENGTH; int signatureLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setSignatureLength(signatureLength); currentPointer = nextPointer; nextPointer = currentPointer + signatureLength; protocolMessage.setSignature(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setCompleteResultingMessage(Arrays.copyOfRange(message, pointer, nextPointer)); return nextPointer; } catch(IOException ex) { throw new WorkflowExecutionException(\"DH public key parsing failed\", ex); } } ",
        "focal_src": "@Override public int parseMessageAction(byte[]message, int pointer) { if(message[pointer] != HandshakeMessageType.SERVER_KEY_EXCHANGE.getValue()) { throw new InvalidMessageTypeException(HandshakeMessageType.SERVER_KEY_EXCHANGE); } protocolMessage.setType(message[pointer]); int currentPointer = pointer + HandshakeByteLength.MESSAGE_TYPE; int nextPointer = currentPointer + HandshakeByteLength.MESSAGE_TYPE_LENGTH; int length = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setLength(length); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int pLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setpLength(pLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getpLength().getValue(); BigInteger p = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setP(p); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int gLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setgLength(gLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getgLength().getValue(); BigInteger g = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setG(g); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int publicKeyLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKeyLength(publicKeyLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getPublicKeyLength().getValue(); BigInteger publicKey = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKey(publicKey); byte[]dhParams = ArrayConverter.concatenate(ArrayConverter.intToBytes(protocolMessage.getpLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getP().getValue()), ArrayConverter.intToBytes(protocolMessage.getgLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getG().getValue()), ArrayConverter.intToBytes(protocolMessage.getPublicKeyLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getPublicKey().getValue())); InputStream is = new ByteArrayInputStream(dhParams); try { ServerDHParams publicKeyParameters = ServerDHParams.parse(is); tlsContext.setServerDHParameters(publicKeyParameters); currentPointer = nextPointer; nextPointer ++ ; HashAlgorithm ha = HashAlgorithm.getHashAlgorithm(message[currentPointer]); protocolMessage.setHashAlgorithm(ha.getValue()); currentPointer = nextPointer; nextPointer ++ ; SignatureAlgorithm sa = SignatureAlgorithm.getSignatureAlgorithm(message[currentPointer]); protocolMessage.setSignatureAlgorithm(sa.getValue()); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.SIGNATURE_LENGTH; int signatureLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setSignatureLength(signatureLength); currentPointer = nextPointer; nextPointer = currentPointer + signatureLength; protocolMessage.setSignature(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setCompleteResultingMessage(Arrays.copyOfRange(message, pointer, nextPointer)); return nextPointer; } catch(IOException ex) { throw new WorkflowExecutionException(\"DH public key parsing failed\", ex); } } ",
        "test_tgt": "@Test public void testParseMessageAction() { byte[]serverHelloDoneMsg = { 0x0e, 0x00, 0x00, 0x00 }; handler.initializeProtocolMessage(); int endPointer = handler.parseMessage(serverHelloDoneMsg, 0); ServerHelloDoneMessage message = handler.getProtocolMessage(); HandshakeMessageFields handshakeMessageFields = (HandshakeMessageFields)message.getMessageFields(); assertNotNull(\"Confirm that parseMessage didn't return 'NULL'\", endPointer); assertEquals(\"Confirm expected message type: \\\"ServerHelloDone\\\"\", HandshakeMessageType.SERVER_HELLO_DONE, message.getHandshakeMessageType()); assertEquals(\"Confirm expected message length of \\\"0\\\"\", new Integer(0), handshakeMessageFields.getLength().getValue()); assertEquals(\"Confirm the correct value of endPointer representing the \" + \"actual number of message bytes\", serverHelloDoneMsg.length, endPointer); } "
    },
    {
        "test_src": "@Test public void createFile()throws Exception { doNothing().when(mFileSystemMasterClient).createFile(any(AlluxioURI.class), any(CreateFileOptions.class)); URIStatus status = new URIStatus(new FileInfo()); AlluxioURI file = new AlluxioURI(\"/file\"); GetStatusOptions getStatusOptions = GetStatusOptions.defaults().setLoadMetadataType(LoadMetadataType.Never); when(mFileSystemMasterClient.getStatus(file, getStatusOptions)).thenReturn(status); CreateFileOptions options = CreateFileOptions.defaults(); FileOutStream out = mFileSystem.createFile(file, options); verify(mFileSystemMasterClient).createFile(file, options); assertEquals(out.mUri, file); verifyFilesystemContextAcquiredAndReleased(); } ",
        "focal_tgt": "void createFile(AlluxioURI path, CreateFilePOptions options)throws AlluxioStatusException; ",
        "focal_src": "void createFile(AlluxioURI path, CreateFileOptions options)throws AlluxioStatusException; ",
        "test_tgt": "@Test public void createFile()throws Exception { doNothing().when(mFileSystemMasterClient).createFile(any(AlluxioURI.class), any(CreateFilePOptions.class)); URIStatus status = new URIStatus(new FileInfo()); AlluxioURI file = new AlluxioURI(\"/file\"); GetStatusPOptions getStatusOptions = GetStatusPOptions.newBuilder().setLoadMetadataType(LoadMetadataPType.NEVER).build(); when(mFileSystemMasterClient.getStatus(file, getStatusOptions)).thenReturn(status); FileOutStream out = mFileSystem.createFile(file, CreateFilePOptions.getDefaultInstance()); verify(mFileSystemMasterClient).createFile(file, CreateFilePOptions.getDefaultInstance()); assertEquals(out.mUri, file); verifyFilesystemContextAcquiredAndReleased(); } "
    },
    {
        "test_src": "@Test(expectedExceptions = NullPointerException.class)public void test_print_nullAppendable()throws Exception { FlexiDateTime dt = new FlexiDateTime(null, null, null, null, null).withFieldValue(DayOfMonth.rule(), 3); NumberPrinterParser pp = new NumberPrinterParser(DayOfMonth.rule(), 1, 2, SignStyle.NEVER); pp.print((Appendable)null, dt, locale); } ",
        "focal_tgt": "public void print(FlexiDateTime dateTime, Appendable appendable, DateTimeFormatSymbols symbols)throws IOException { appendable.append(literal); } ",
        "focal_src": "public void print(Appendable appendable, FlexiDateTime dateTime, Locale locale)throws IOException { appendable.append(literal); } ",
        "test_tgt": "@Test(expectedExceptions = NullPointerException.class)public void test_print_nullAppendable()throws Exception { FlexiDateTime dt = new FlexiDateTime(null, null, null, null, null).withFieldValue(DayOfMonth.rule(), 3); NumberPrinterParser pp = new NumberPrinterParser(DayOfMonth.rule(), 1, 2, SignStyle.NEVER); pp.print(dt, (Appendable)null, symbols); } "
    },
    {
        "test_src": "@Test public final void testProcess1() { BoundWriter bw = new BoundWriter(\"bound\", 2); bw.setWriter(testBufferedWriter); bw.process(new Bound(20.123456, - 21.987654, 22.555555, - 23.234567, \"originstring\")); try { testBufferedWriter.flush(); } catch(IOException e) { e.printStackTrace(); fail(\"IOException\"); } String regexMatch = \"^\\\\s*<bound\\\\s*\" + \"box=['\\\"]-23.23457,-21.98765,22.55556,20.12346['\\\"]\\\\s*\" + \"origin=['\\\"]originstring['\\\"]/>\\\\s*$\"; assertTrue(testWriter.toString().matches(regexMatch)); } ",
        "focal_tgt": "public void process(Bound bound) { if(legacyBound) { processLegacy(bound); } else { processRegular(bound); } } ",
        "focal_src": "public void process(Bound bound) { if(bound.getOrigin() != \"\") { beginOpenElement(); addAttribute(\"box\", String.format(Locale.US, \"%.5f,%.5f,%.5f,%.5f\", bound.getBottom(), bound.getLeft(), bound.getTop(), bound.getRight())); addAttribute(\"origin\", bound.getOrigin()); endOpenElement(true); } } ",
        "test_tgt": "@Test public final void testProcess1() { BoundWriter bw = new BoundWriter(\"bound\", 2, true); bw.setWriter(testBufferedWriter); bw.process(new Bound(20.123456, - 21.987654, 22.555555, - 23.234567, \"originstring\")); try { testBufferedWriter.flush(); } catch(IOException e) { e.printStackTrace(); fail(\"IOException\"); } String regexMatch = \"^\\\\s*<bound\\\\s*\" + \"box=['\\\"]-23.23457,-21.98765,22.55556,20.12346['\\\"]\\\\s*\" + \"origin=['\\\"]originstring['\\\"]/>\\\\s*$\"; assertTrue(testWriter.toString().matches(regexMatch)); } "
    },
    {
        "test_src": "@Test public void testParse2() { File file = find_test_file(\"../smalldata/junit/syn_2659x1049.csv.gz\"); NFSFileVec nfs = NFSFileVec.make(file); Frame fr = null; Vec vz = null; try { fr = ParseDataset2.parse(Key.make(\"syn.hex\"), new Key[] { nfs._key }); assertEquals(fr.numCols(), 1050); assertEquals(fr.numRows(), 2659); double[]sums = new Sum().doAll(fr)._sums; assertEquals(3949, sums[0], EPSILON); assertEquals(3986, sums[1], EPSILON); assertEquals(3993, sums[2], EPSILON); Vec v0 = fr.vecs()[0]; Vec v1 = fr.vecs()[1]; vz = v0.makeZero(); new PairSum().doAll(vz, v0, v1); fr.delete(); fr = new Frame(new String[] { \"tmp\" }, new Vec[] { vz }); sums = new Sum().doAll(fr)._sums; assertEquals(3949 + 3986, sums[0], EPSILON); } finally { nfs.remove(); if(vz != null)vz.remove(); if(fr != null)fr.delete(); } } ",
        "focal_tgt": "public static Frame parse(Key okey, Key ... keys) { return parse(okey, keys, true, true); } ",
        "focal_src": "static public Frame parse(Key dest, Key ... srcs) { throw H2O.unimpl(); } ",
        "test_tgt": "@Test public void testParse2() { File file = find_test_file(\"../smalldata/junit/syn_2659x1049.csv.gz\"); NFSFileVec nfs = NFSFileVec.make(file); Frame fr = null; Vec vz = null; try { fr = ParseDataset2.parse(Key.make(\"syn.hex\"), nfs._key); assertEquals(fr.numCols(), 1050); assertEquals(fr.numRows(), 2659); double[]sums = new Sum().doAll(fr)._sums; assertEquals(3949, sums[0], EPSILON); assertEquals(3986, sums[1], EPSILON); assertEquals(3993, sums[2], EPSILON); Vec v0 = fr.vecs()[0]; Vec v1 = fr.vecs()[1]; vz = v0.makeZero(); new PairSum().doAll(vz, v0, v1); fr.delete(); fr = new Frame(new String[] { \"tmp\" }, new Vec[] { vz }); sums = new Sum().doAll(fr)._sums; assertEquals(3949 + 3986, sums[0], EPSILON); } finally { nfs.remove(); if(vz != null)vz.remove(); if(fr != null)fr.delete(); } } "
    },
    {
        "test_src": "@Test public final void testProcess3() { testOsmWriter.process(new NodeContainer(new Node(1234, 0, new Date(), new OsmUser(12, \"OsmosisTest\"), new ArrayList < Tag > (), 20, 20))); } ",
        "focal_tgt": "public void process(EntityContainer entityContainer) { EntityContainer writeableContainer; Entity entity; Collection < Tag > sortedTags; writeableContainer = entityContainer.getWriteableInstance(); entity = writeableContainer.getEntity(); sortedTags = sortTags(entity.getTags()); entity.getTags().clear(); entity.getTags().addAll(sortedTags); sink.process(writeableContainer); } ",
        "focal_src": "public void process(EntityContainer entityContainer) { entityContainer.process(this); } ",
        "test_tgt": "@Test public final void testProcess3() { testOsmWriter.process(new NodeContainer(new Node(1234, 0, new Date(), new OsmUser(12, \"OsmosisTest\"), new ArrayList < Tag > (), 20, 20))); } "
    },
    {
        "test_src": "@Test public void testAnalyze()throws Exception { System.out.println(\"analyze\"); File file = new File(this.getClass().getClassLoader().getResource(\"struts2-core-2.1.2.jar\").getPath()); Dependency result = new Dependency(file); FileNameAnalyzer instance = new FileNameAnalyzer(); instance.analyze(result); assertTrue(result.getVendorEvidence().toString().toLowerCase().contains(\"struts\")); } ",
        "focal_tgt": "void analyze(Dependency dependency, Engine engine)throws AnalysisException; ",
        "focal_src": "void analyze(Dependency dependency)throws AnalysisException; ",
        "test_tgt": "@Test public void testAnalyze()throws Exception { System.out.println(\"analyze\"); File file = new File(this.getClass().getClassLoader().getResource(\"struts2-core-2.1.2.jar\").getPath()); Dependency result = new Dependency(file); FileNameAnalyzer instance = new FileNameAnalyzer(); instance.analyze(result, null); assertTrue(result.getVendorEvidence().toString().toLowerCase().contains(\"struts\")); } "
    },
    {
        "test_src": "@Test(expected = IllegalStateException.class)public void handleHeadTest()throws IOException, JSONException, RestServiceException, URISyntaxException { AdminBlobStorageService adminBlobStorageService = getAdminBlobStorageService(); MessageInfo messageInfo = createMessageInfo(RestMethod.HEAD, \"/\", new JSONObject()); adminBlobStorageService.handleMessage(messageInfo); } ",
        "focal_tgt": "public void handleHead(MessageInfo messageInfo) { throw new IllegalStateException(\"handleHead() not implemented in \" + this.getClass().getSimpleName()); } ",
        "focal_src": "private void handleHead(MessageInfo messageInfo) { throw new IllegalStateException(\"handleHead() not implemented in \" + this.getClass().getSimpleName()); } ",
        "test_tgt": "@Test(expected = IllegalStateException.class)public void handleHeadTest()throws IOException, JSONException, RestServiceException, URISyntaxException { AdminBlobStorageService adminBlobStorageService = getAdminBlobStorageService(); MessageInfo messageInfo = createMessageInfo(RestMethod.HEAD, \"/\", new JSONObject()); adminBlobStorageService.handleHead(messageInfo); } "
    },
    {
        "test_src": "@Test public void testDeleteCorpus()throws InterruptedException, FileNotFoundException { String id = \"foo\"; String corpus = \"cName\"; server.enqueue(new MockResponse().addHeader(CONTENT_TYPE, HttpMediaType.APPLICATION_JSON).setBody(\"{}\")); service.deleteCorpus(id, corpus).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(\"DELETE\", request.getMethod()); assertEquals(String.format(PATH_CORPUS, id, corpus), request.getPath()); } ",
        "focal_tgt": "public ServiceCall < Void > deleteCorpus(DeleteCorpusOptions deleteCorpusOptions) { Validator.notNull(deleteCorpusOptions, \"deleteCorpusOptions cannot be null\"); RequestBuilder builder = RequestBuilder.delete(String.format(\"/v1/customizations/%s/corpora/%s\", deleteCorpusOptions.customizationId(), deleteCorpusOptions.corpusName())); return createServiceCall(builder.build(), ResponseConverterUtils.getVoid()); } ",
        "focal_src": "public ServiceCall < Void > deleteCorpus(String customizationId, String corpusName) { Validator.notNull(customizationId, \"customizationId cannot be null\"); Validator.notNull(corpusName, \"corpusName cannot be null\"); RequestBuilder requestBuilder = RequestBuilder.delete(String.format(PATH_CORPUS, customizationId, corpusName)); return createServiceCall(requestBuilder.build(), ResponseConverterUtils.getVoid()); } ",
        "test_tgt": "@Test public void testDeleteCorpus()throws InterruptedException, FileNotFoundException { String id = \"foo\"; String corpus = \"cName\"; server.enqueue(new MockResponse().addHeader(CONTENT_TYPE, HttpMediaType.APPLICATION_JSON).setBody(\"{}\")); DeleteCorpusOptions deleteOptions = new DeleteCorpusOptions.Builder().customizationId(id).corpusName(corpus).build(); service.deleteCorpus(deleteOptions).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(\"DELETE\", request.getMethod()); assertEquals(String.format(PATH_CORPUS, id, corpus), request.getPath()); } "
    },
    {
        "test_src": "@Test public void saveCTLSchemaTest()throws Exception { this.loginKaaAdmin(); CTLSchemaDto beta = client.saveCTLSchema(getResourceAsString(TEST_CTL_SCHEMA_BETA), null, null); Assert.assertNotNull(beta.getId()); this.loginTenantDeveloper(tenantDeveloperUser); CTLSchemaDto alpha = client.saveCTLSchema(getResourceAsString(TEST_CTL_SCHEMA_ALPHA), tenantDeveloperDto.getTenantId(), null); Assert.assertNotNull(alpha.getId()); } ",
        "focal_tgt": "List < EventClassFamilyVersionDto > getEventClassFamilyVersions(String eventClassFamilyId)throws ControlServiceException; ",
        "focal_src": "CTLSchemaDto saveCTLSchema(CTLSchemaDto schema)throws ControlServiceException; ",
        "test_tgt": "@Test public void saveCTLSchemaTest()throws Exception { this.loginKaaAdmin(); CTLSchemaDto beta = client.saveCTLSchemaWithAppToken(getResourceAsString(TEST_CTL_SCHEMA_BETA), null, null); Assert.assertNotNull(beta.getId()); this.loginTenantDeveloper(tenantDeveloperUser); CTLSchemaDto alpha = client.saveCTLSchemaWithAppToken(getResourceAsString(TEST_CTL_SCHEMA_ALPHA), tenantDeveloperDto.getTenantId(), null); Assert.assertNotNull(alpha.getId()); } "
    },
    {
        "test_src": "@Test public void handleFailure()throws Exception { Map map = new HashMap < String, Boolean > (); map.put(\"Key\", true); assertThat(client.handleFailure(map).get()).isEqualTo(true); } ",
        "focal_tgt": "public CompletableFuture < Boolean > handleFailure(Set nodes) { return router.sendMessageAndGetCompletable(CorfuMsgType.MANAGEMENT_FAILURE_DETECTED.payloadMsg(new FailureDetectorMsg(nodes))); } ",
        "focal_src": "public CompletableFuture < Boolean > handleFailure(Map nodes) { return router.sendMessageAndGetCompletable(CorfuMsgType.MANAGEMENT_FAILURE_DETECTED.payloadMsg(new FailureDetectorMsg(nodes))); } ",
        "test_tgt": "@Test public void handleFailure()throws Exception { Set < String > set = new HashSet < > (); set.add(\"Key\"); assertThat(client.handleFailure(set).get()).isEqualTo(true); } "
    },
    {
        "test_src": "@Test public void testGetValue() { assertEquals(\"5,8,7,6\", ResourceBundleUtil.getValue(BASE_NAME, \"config_test_array\")); assertEquals(\"5,8,7,6\", ResourceBundleUtil.getValue(\"messages.feilong-core-test\", \"config_test_array\")); } ",
        "focal_tgt": "public static String getValue(String baseName, String key, Locale locale, Object ... arguments) { ResourceBundle resourceBundle = getResourceBundle(baseName, locale); return getValue(resourceBundle, key, arguments); } ",
        "focal_src": "public static < T > T getValue(String baseName, String key, Class < T > typeClass) { String value = getValue(baseName, key); return ConvertUtil.convert(value, typeClass); } ",
        "test_tgt": "@Test public void testGetValue() { assertEquals(\"5,8,7,6\", getValue(BASE_NAME, \"config_test_array\")); assertEquals(\"5,8,7,6\", getValue(\"messages.feilong-core-test\", \"config_test_array\")); } "
    },
    {
        "test_src": "@Test(expectedExceptions = NullPointerException.class, groups = { \"tck\" })public void test_print_nullCalendrical() { DateTimeFormatters.isoDate().print((DateTimeAccessor)null); } ",
        "focal_tgt": "public String print(TemporalAccessor dateTime) { StringBuilder buf = new StringBuilder(32); printTo(dateTime, buf); return buf.toString(); } ",
        "focal_src": "public String print(DateTimeAccessor dateTime) { StringBuilder buf = new StringBuilder(32); printTo(dateTime, buf); return buf.toString(); } ",
        "test_tgt": "@Test(expectedExceptions = NullPointerException.class, groups = { \"tck\" })public void test_print_nullCalendrical() { DateTimeFormatters.isoDate().print((TemporalAccessor)null); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_equals() { OffsetDateTime odtA = OffsetDateTime.of(2010, 3, 31, 1, 0, OFFSET_0200); ZoneOffsetTransition a1 = new ZoneOffsetTransition(odtA, OFFSET_0300); ZoneOffsetTransition a2 = new ZoneOffsetTransition(odtA, OFFSET_0300); OffsetDateTime odtB = OffsetDateTime.of(2010, 10, 31, 1, 0, OFFSET_0300); ZoneOffsetTransition b = new ZoneOffsetTransition(odtB, OFFSET_0200); assertEquals(a1.equals(a1), true); assertEquals(a1.equals(a2), true); assertEquals(a1.equals(b), false); assertEquals(a2.equals(a1), true); assertEquals(a2.equals(a2), true); assertEquals(a2.equals(b), false); assertEquals(b.equals(a1), false); assertEquals(b.equals(a2), false); assertEquals(b.equals(b), true); assertEquals(a1.equals(\"\"), false); assertEquals(a1.equals(null), false); } ",
        "focal_tgt": "@Override public boolean equals(Object other) { if(other == this) { return true; } if(other instanceof ZoneOffsetTransition) { ZoneOffsetTransition d = (ZoneOffsetTransition)other; return transition.equals(d.transition) && offsetBefore.equals(d.offsetBefore) && offsetAfter.equals(d.offsetAfter); } return false; } ",
        "focal_src": "@Override public boolean equals(Object other) { if(other == this) { return true; } if(other instanceof ZoneOffsetTransition) { ZoneOffsetTransition d = (ZoneOffsetTransition)other; return transition.equals(d.transition) && transitionAfter.getOffset().equals(d.transitionAfter.getOffset()); } return false; } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_equals() { LocalDateTime ldtA = LocalDateTime.of(2010, 3, 31, 1, 0); ZoneOffsetTransition a1 = new ZoneOffsetTransition(ldtA, OFFSET_0200, OFFSET_0300); ZoneOffsetTransition a2 = new ZoneOffsetTransition(ldtA, OFFSET_0200, OFFSET_0300); LocalDateTime ldtB = LocalDateTime.of(2010, 10, 31, 1, 0); ZoneOffsetTransition b = new ZoneOffsetTransition(ldtB, OFFSET_0300, OFFSET_0200); assertEquals(a1.equals(a1), true); assertEquals(a1.equals(a2), true); assertEquals(a1.equals(b), false); assertEquals(a2.equals(a1), true); assertEquals(a2.equals(a2), true); assertEquals(a2.equals(b), false); assertEquals(b.equals(a1), false); assertEquals(b.equals(a2), false); assertEquals(b.equals(b), true); assertEquals(a1.equals(\"\"), false); assertEquals(a1.equals(null), false); } "
    },
    {
        "test_src": "@Test public void testCommit()throws SQLException { sqlSessionTemplate.commit(); assertNoCommit(); sqlSessionTemplate.commit(true); assertNoCommit(); sqlSessionTemplate.commit(false); assertNoCommit(); connection.close(); } ",
        "focal_tgt": "public void commit() { throw new UnsupportedOperationException(\"Manual commit is not allowed over a Spring managed SqlSessio\"); } ",
        "focal_src": "public void commit() { } ",
        "test_tgt": "@Test(expected = UnsupportedOperationException.class)public void testCommit()throws SQLException { try { sqlSessionTemplate.commit(); } finally { connection.close(); } } "
    },
    {
        "test_src": "@Test public void completeUfsFileTest()throws Exception { String uniqPath = PathUtils.uniqPath(); UnderFileSystemManager manager = new UnderFileSystemManager(); long id = manager.createFile(SESSION_ID, new AlluxioURI(uniqPath)); Mockito.verify(mMockUfs).create(Mockito.contains(uniqPath)); manager.completeFile(SESSION_ID, id); Mockito.verify(mMockUfs).rename(Mockito.contains(uniqPath), Mockito.eq(uniqPath)); } ",
        "focal_tgt": "public long completeUfsFile(long sessionId, long tempUfsFileId, String user, String group)throws FileDoesNotExistException, IOException { return mUnderFileSystemManager.completeFile(sessionId, tempUfsFileId, user, group); } ",
        "focal_src": "public long completeUfsFile(long sessionId, long tempUfsFileId)throws FileDoesNotExistException, IOException { return mUnderFileSystemManager.completeFile(sessionId, tempUfsFileId); } ",
        "test_tgt": "@Test public void completeUfsFileTest()throws Exception { String uniqPath = PathUtils.uniqPath(); UnderFileSystemManager manager = new UnderFileSystemManager(); long id = manager.createFile(SESSION_ID, new AlluxioURI(uniqPath)); Mockito.verify(mMockUfs).create(Mockito.contains(uniqPath)); manager.completeFile(SESSION_ID, id, null, null); Mockito.verify(mMockUfs).rename(Mockito.contains(uniqPath), Mockito.eq(uniqPath)); } "
    },
    {
        "test_src": "@Test public void testVisitLabels()throws Exception { RawAttributeMapper rawMapper = RawAttributeMapper.of(setupGenRule()); try { rawMapper.visitLabels(new AttributeMap.AcceptsLabelAttribute() { @Override public void acceptLabelAttribute(Label label, Attribute attribute) { } }); fail(\"Expected label visitation to fail since one attribute is configurable\"); } catch(IllegalArgumentException e) { assertThat(e).hasCauseThat().hasMessageThat().containsMatch(\".*SelectorList cannot be cast to .*java\\\\.util\\\\.List\"); } } ",
        "focal_tgt": "Collection < DepEdge > visitLabels()throws InterruptedException; ",
        "focal_src": "void visitLabels(AcceptsLabelAttribute observer)throws InterruptedException; ",
        "test_tgt": "@Test public void testVisitLabels()throws Exception { RawAttributeMapper rawMapper = RawAttributeMapper.of(setupGenRule()); try { rawMapper.visitLabels(); fail(\"Expected label visitation to fail since one attribute is configurable\"); } catch(IllegalArgumentException e) { assertThat(e).hasCauseThat().hasMessageThat().containsMatch(\".*SelectorList cannot be cast to .*java\\\\.util\\\\.List\"); } } "
    },
    {
        "test_src": "@Test@SuppressWarnings(\"unchecked\")public void testSave() { User currUser = getTestUser(); currUser.setUserName(\"new name\"); currUser.setOwners(null); userApiController.save(currUser, currUser); User user = (User)userApiController.getOneDetail(currUser.getUserId()).get(\"user\"); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userApiController.save(admin, temp); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userApiController.save(admin, temp); currUser.setFollowersStr(\"temp1, temp2\"); userApiController.save(currUser, currUser); List < UserApiController.UserSearchResult > followers = (List < UserApiController.UserSearchResult > )userApiController.getOneDetail(currUser.getUserId()).get(\"followers\"); assertThat(followers.size(), is(2)); assertThat(followers.get(0).getId(), is(\"temp1\")); } ",
        "focal_tgt": "@RequestMapping(\"/save\")@PreAuthorize(\"hasAnyRole('A') or #user.id == #updatedUser.id\")public String save(User user, @RequestBody User updatedUser) { checkArgument(updatedUser.validate()); if(user.getRole() == Role.USER) { User updatedUserInDb = userService.getOne(updatedUser.getUserId()); checkNotNull(updatedUserInDb); updatedUser.setRole(updatedUserInDb.getRole()); checkArgument(updatedUserInDb.getId().equals(updatedUser.getId()), \"Illegal request to update user:%s\", updatedUser); } save(updatedUser); return returnSuccess(); } ",
        "focal_src": "@ResponseBody@RequestMapping(\"/save\")@PreAuthorize(\"hasAnyRole('A') or #user.id == #updatedUser.id\")public String save(User user, @RequestBody User updatedUser) { checkArgument(updatedUser.validate()); if(user.getRole() == Role.USER) { User updatedUserInDb = userService.getOne(updatedUser.getUserId()); checkNotNull(updatedUserInDb); updatedUser.setRole(updatedUserInDb.getRole()); checkArgument(updatedUserInDb.getId().equals(updatedUser.getId()), \"Illegal request to update user:%s\", updatedUser); } save(updatedUser); return returnSuccess(); } ",
        "test_tgt": "@Test@SuppressWarnings(\"unchecked\")public void testSave() { User currUser = getTestUser(); currUser.setUserName(\"new name\"); currUser.setOwners(null); userApiController.save(currUser, currUser); User user = userApiController.getOne(currUser.getUserId()); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userApiController.save(admin, temp); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userApiController.save(admin, temp); currUser.setFollowersStr(\"temp1, temp2\"); userApiController.save(currUser, currUser); user = userApiController.getOne(currUser.getUserId()); assertThat(user.getFollowers().size(), is(2)); assertThat(user.getFollowers().get(0).getUserId(), is(\"temp1\")); } "
    },
    {
        "test_src": "@Test public void testGetById()throws SolrServerException, IOException { ArgumentCaptor < SolrRequest > captor = ArgumentCaptor.forClass(SolrRequest.class); QueryResponse responseMock = Mockito.mock(QueryResponse.class); SolrDocumentList resultList = new SolrDocumentList(); Mockito.when(responseMock.getResults()).thenReturn(resultList); Mockito.when(solrClientMock.request(captor.capture(), Matchers.anyString())).thenReturn(new NamedList < Object > ()); DocumentWithIndexAnnotations result = solrTemplate.getById(\"myId\", DocumentWithIndexAnnotations.class); Mockito.verify(solrClientMock, Mockito.times(1)).request(captor.capture(), Matchers.anyString()); Assert.assertNull(result); Assert.assertEquals(\"myId\", captor.getValue().getParams().get(\"ids\")); Assert.assertEquals(\"/get\", captor.getValue().getPath()); } ",
        "focal_tgt": "@Override public < T > T getById(Serializable id, Class < T > clazz) { return getById(getSolrCoreOrBeanCollection(clazz), id, clazz); } ",
        "focal_src": "@Override public < T > T getById(Serializable id, Class < T > clazz) { Assert.notNull(id, \"Id must not be 'null'.\"); Collection < T > result = getById(Collections.singletonList(id), clazz); if(result.isEmpty()) { return null; } return result.iterator().next(); } ",
        "test_tgt": "@Test@SuppressWarnings( { \"rawtypes\", \"unchecked\" })public void testGetById()throws SolrServerException, IOException { ArgumentCaptor < List > captor = ArgumentCaptor.forClass(List.class); solrTemplate.getById(\"myId\", DocumentWithIndexAnnotations.class); Mockito.verify(solrClientMock, Mockito.times(1)).getById(eq(\"core1\"), captor.capture()); Assert.assertThat((List < String > )captor.getValue(), IsCollectionContaining.hasItems(\"myId\")); } "
    },
    {
        "test_src": "@Test public void testTimeOutRecords() { faultTolerancyBuffer.setTIMEOUT(1000); StreamRecord record1 = (new StreamRecord(1)).setId(\"1\"); record1.setField(0, new StringValue(\"V1\")); StreamRecord record2 = (new StreamRecord(1)).setId(\"1\"); record2.setField(0, new StringValue(\"V2\")); StreamRecord record3 = (new StreamRecord(1)).setId(\"1\"); record3.setField(0, new StringValue(\"V3\")); faultTolerancyBuffer.addRecord(record1); faultTolerancyBuffer.addRecord(record2); try { Thread.sleep(500); } catch(Exception e) { } faultTolerancyBuffer.addRecord(record3); Long record1TS = faultTolerancyBuffer.getRecordTimestamps().get(record1.getId()); Long record2TS = faultTolerancyBuffer.getRecordTimestamps().get(record2.getId()); Long record3TS = faultTolerancyBuffer.getRecordTimestamps().get(record3.getId()); faultTolerancyBuffer.ackRecord(record1.getId()); faultTolerancyBuffer.ackRecord(record1.getId()); faultTolerancyBuffer.ackRecord(record1.getId()); faultTolerancyBuffer.ackRecord(record2.getId()); faultTolerancyBuffer.ackRecord(record3.getId()); faultTolerancyBuffer.ackRecord(record3.getId()); try { Thread.sleep(501); } catch(InterruptedException e) { } List < String > timedOutRecords = faultTolerancyBuffer.timeoutRecords(System.currentTimeMillis()); System.out.println(\"timedOutRecords: \" + timedOutRecords); assertEquals(1, timedOutRecords.size()); assertFalse(timedOutRecords.contains(record1.getId())); assertFalse(faultTolerancyBuffer.getRecordsByTime().containsKey(record1TS)); assertFalse(faultTolerancyBuffer.getRecordsByTime().containsKey(record2TS)); assertTrue(faultTolerancyBuffer.getRecordBuffer().containsKey(record2.getId())); assertTrue(faultTolerancyBuffer.getAckCounter().containsKey(record2.getId())); assertTrue(faultTolerancyBuffer.getRecordTimestamps().containsKey(record2.getId())); System.out.println(faultTolerancyBuffer.getAckCounter()); try { Thread.sleep(100); } catch(InterruptedException e) { } timedOutRecords = faultTolerancyBuffer.timeoutRecords(System.currentTimeMillis()); assertEquals(null, timedOutRecords); try { Thread.sleep(900); } catch(InterruptedException e) { } timedOutRecords = faultTolerancyBuffer.timeoutRecords(System.currentTimeMillis()); assertEquals(2, timedOutRecords.size()); System.out.println(faultTolerancyBuffer.getAckCounter()); System.out.println(\"---------\"); } ",
        "focal_tgt": "private void timeoutRecords() { Long currentTime = System.currentTimeMillis(); if(timeOfLastUpdate + TIMEOUT < currentTime) { List < String > timedOutRecords = new LinkedList < String > (); Map < Long, Set < String > > timedOut = recordsByTime.subMap(0L, currentTime - TIMEOUT); for(Set < String > recordSet : timedOut.values()) { if( ! recordSet.isEmpty()) { for(String recordID : recordSet) { timedOutRecords.add(recordID); } } } recordsByTime.keySet().removeAll(timedOut.keySet()); for(String recordID : timedOutRecords) { failRecord(recordID); } } } ",
        "focal_src": "List < String > timeoutRecords(Long currentTime) { if(timeOfLastUpdate + TIMEOUT < currentTime) { List < String > timedOutRecords = new LinkedList < String > (); Map < Long, Set < String > > timedOut = recordsByTime.subMap(0L, currentTime - TIMEOUT); for(Set < String > recordSet : timedOut.values()) { if( ! recordSet.isEmpty()) { for(String recordID : recordSet) { timedOutRecords.add(recordID); } } } recordsByTime.keySet().removeAll(timedOut.keySet()); for(String recordID : timedOutRecords) { failRecord(recordID); } timeOfLastUpdate = currentTime; return timedOutRecords; } return null; } ",
        "test_tgt": "@Test public void testTimeOutRecords() { } "
    },
    {
        "test_src": "@Test public void testGetFormat()throws SQLException { assertThat(\"testGetFormat 0\", bs.getFormat(), notNullValue()); assertThat(\"testGetFormat 1\", bs.getFormat(), equalTo(BitstreamFormat.findUnknown(context))); } ",
        "focal_tgt": "public BitstreamFormat getFormat(Context context)throws SQLException { return getBitstreamService().getFormat(context, this); } ",
        "focal_src": "public BitstreamFormat getFormat() { return bitstreamFormat; } ",
        "test_tgt": "@Test public void testGetFormat()throws SQLException { assertThat(\"testGetFormat 0\", bs.getFormat(context), notNullValue()); assertThat(\"testGetFormat 1\", bs.getFormat(context), equalTo(bitstreamFormatService.findUnknown(context))); } "
    },
    {
        "test_src": "@Test public void testRegisterTimerEventInSeconds()throws Exception { Runnable r = new Runnable() { @Override public void run() { slaveLooper.exitLoop(); globalValue = 10; } }; long startTime = System.nanoTime(); int intervalSeconds = 1; slaveLooper.registerTimerEventInSeconds(intervalSeconds, r); slaveLooper.loop(); long endTime = System.nanoTime(); Assert.assertTrue(endTime - startTime - (long)intervalSeconds * SECONDS_TO_NANOSECONDS >= 0); Assert.assertEquals(10, globalValue); } ",
        "focal_tgt": "private void registerTimerEvent(Duration timer, Runnable task) { nioLooper.registerTimerEvent(timer, task); } ",
        "focal_src": "public void registerTimerEventInSeconds(long timerInSeconds, Runnable task) { nioLooper.registerTimerEventInSeconds(timerInSeconds, task); } ",
        "test_tgt": "@Test public void testRegisterTimerEventInSeconds()throws Exception { Runnable r = new Runnable() { @Override public void run() { slaveLooper.exitLoop(); globalValue = 10; } }; long startTime = System.nanoTime(); Duration interval = Duration.ofSeconds(1); slaveLooper.registerTimerEvent(interval, r); slaveLooper.loop(); long endTime = System.nanoTime(); Assert.assertTrue(endTime - startTime - interval.toNanos() >= 0); Assert.assertEquals(10, globalValue); } "
    },
    {
        "test_src": "@Test public void testSaveOrUpdateUserDetail() { ModelMap model = new ModelMap(); User currUser = getTestUser(); currUser.setUserName(\"new name\"); userController.saveOrUpdateUserDetail(currUser, model, currUser, null); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); User user = (User)model.get(\"user\"); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userController.saveOrUpdateUserDetail(admin, model, temp, null); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userController.saveOrUpdateUserDetail(admin, model, temp, null); model.clear(); userController.saveOrUpdateUserDetail(currUser, model, currUser, \"temp1, temp2\"); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); user = (User)model.get(\"user\"); assertThat(user.getFollowers().size(), is(2)); assertThat(user.getFollowers().get(0).getUserId(), is(\"temp1\")); } ",
        "focal_tgt": "@RequestMapping(\"/save\")@PreAuthorize(\"hasAnyRole('A') or #user.id == #updatedUser.id\")public String saveUser(User user, ModelMap model, @ModelAttribute(\"user\")User updatedUser) { checkArgument(updatedUser.validate()); if(user.getRole() == Role.USER) { User updatedUserInDb = userService.getUserById(updatedUser.getUserId()); checkNotNull(updatedUserInDb); updatedUser.setRole(updatedUserInDb.getRole()); checkArgument(updatedUserInDb.getId().equals(updatedUser.getId()), \"Illegal request to update user:%s\", updatedUser); } saveUser(updatedUser); model.clear(); if(user.getId().equals(updatedUser.getId())) { return \"redirect:/\"; } else { return \"redirect:/user/\"; } } ",
        "focal_src": "@RequestMapping(\"/save\")@PreAuthorize(\"hasAnyRole('A') or #user.id == #updatedUser.id\")public String saveOrUpdateUserDetail(User user, ModelMap model, @ModelAttribute(\"user\")User updatedUser, @RequestParam(required = false)String followersStr) { checkArgument(updatedUser.validate()); if(user.getRole() == Role.USER) { User updatedUserInDb = userService.getUserById(updatedUser.getUserId()); checkNotNull(updatedUserInDb); updatedUser.setRole(updatedUserInDb.getRole()); checkArgument(updatedUserInDb.getId().equals(updatedUser.getId()), \"Illegal request to update user:%s\", updatedUser); } if(updatedUser.exist()) { userService.saveUser(updatedUser, followersStr); } else { userService.saveUser(updatedUser); } model.clear(); if(user.getId().equals(updatedUser.getId())) { return \"redirect:/\"; } else { return \"redirect:/user/\"; } } ",
        "test_tgt": "@Test public void testSaveOrUpdateUserDetail() { ModelMap model = new ModelMap(); User currUser = getTestUser(); currUser.setUserName(\"new name\"); userController.saveUser(currUser, model, currUser); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); User user = (User)model.get(\"user\"); assertThat(user.getUserName(), is(\"new name\")); assertThat(user.getPassword(), is(currUser.getPassword())); User admin = getAdminUser(); User temp = new User(\"temp1\", \"temp1\", \"temp1\", \"temp@nhn.com\", Role.USER); userController.saveUser(admin, model, temp); temp = new User(\"temp2\", \"temp2\", \"temp2\", \"temp@nhn.com\", Role.USER); userController.saveUser(admin, model, temp); model.clear(); currUser.setFollowersStr(\"temp1, temp2\"); userController.saveUser(currUser, model, currUser); userController.getUserDetail(getTestUser(), model, currUser.getUserId()); user = (User)model.get(\"user\"); assertThat(user.getFollowers().size(), is(2)); assertThat(user.getFollowers().get(0).getUserId(), is(\"temp1\")); } "
    },
    {
        "test_src": "@Test public void testRowKeys()throws Exception { int hoursAgo = 1; List < Object > groups = Collections.emptyList(); rowKeyBuilder = new SaltyRowKeyBuilder(saltDivisor, periodsPerHour); long oldest = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hoursAgo); ProfileMeasurement m = new ProfileMeasurement(\"profile\", \"entity\", oldest, periodsPerHour); m.setValue(22); List < byte[] > expectedKeys = new ArrayList < > (); for(int i = 0; i < (hoursAgo * periodsPerHour) + 1; i ++ ) { byte[]rk = rowKeyBuilder.rowKey(m, groups); expectedKeys.add(rk); ProfilePeriod next = m.getPeriod().next(); m = new ProfileMeasurement(\"profile\", \"entity\", next.getTimeInMillis(), periodsPerHour); } List < byte[] > actualKeys = rowKeyBuilder.rowKeys(measurement.getProfileName(), measurement.getEntity(), groups, hoursAgo, TimeUnit.HOURS); for(int i = 0; i < actualKeys.size(); i ++ ) { byte[]actual = actualKeys.get(i); byte[]expected = expectedKeys.get(i); assertThat(actual, equalTo(expected)); } } ",
        "focal_tgt": "@Override public List < byte[] > rowKeys(String profile, String entity, List < Object > groups, long durationAgo, TimeUnit unit) { List < byte[] > rowKeys = new ArrayList < > (); long endTime = System.currentTimeMillis(); long startTime = endTime - unit.toMillis(durationAgo); ProfilePeriod period = new ProfilePeriod(startTime, periodDurationMillis, TimeUnit.MILLISECONDS); while(period.getStartTimeMillis() <= endTime) { byte[]k = rowKey(profile, entity, period, groups); rowKeys.add(k); period = period.next(); } return rowKeys; } ",
        "focal_src": "@Override public List < byte[] > rowKeys(String profile, String entity, List < Object > groups, long durationAgo, TimeUnit unit) { List < byte[] > rowKeys = new ArrayList < > (); long endTime = System.currentTimeMillis(); long startTime = endTime - unit.toMillis(durationAgo); ProfilePeriod period = new ProfilePeriod(startTime, periodsPerHour); while(period.getTimeInMillis() <= endTime) { byte[]k = rowKey(profile, entity, period, groups); rowKeys.add(k); period = period.next(); } return rowKeys; } ",
        "test_tgt": "@Test public void testRowKeys()throws Exception { int hoursAgo = 1; List < Object > groups = Collections.emptyList(); rowKeyBuilder = new SaltyRowKeyBuilder(saltDivisor, periodDuration, periodUnits); long oldest = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hoursAgo); ProfileMeasurement m = new ProfileMeasurement(\"profile\", \"entity\", oldest, periodDuration, periodUnits); m.setValue(22); List < byte[] > expectedKeys = new ArrayList < > (); for(int i = 0; i < (hoursAgo * 4) + 1; i ++ ) { byte[]rk = rowKeyBuilder.rowKey(m, groups); expectedKeys.add(rk); ProfilePeriod next = m.getPeriod().next(); m = new ProfileMeasurement(\"profile\", \"entity\", next.getStartTimeMillis(), periodDuration, periodUnits); } List < byte[] > actualKeys = rowKeyBuilder.rowKeys(measurement.getProfileName(), measurement.getEntity(), groups, hoursAgo, TimeUnit.HOURS); for(int i = 0; i < actualKeys.size(); i ++ ) { byte[]actual = actualKeys.get(i); byte[]expected = expectedKeys.get(i); assertThat(actual, equalTo(expected)); } } "
    },
    {
        "test_src": "@Test public void testHypergeometricCdf() { logger.info(\"HypergeometricCdf\"); int k = 3; int n = 10; int Kp = 30; int Np = 100; double expResult = 0.65401998866081; double result = DiscreteDistributions.HypergeometricCdf(k, n, Kp, Np); assertEquals(expResult, result, TestConfiguration.DOUBLE_ACCURACY_HIGH); } ",
        "focal_tgt": "public static double hypergeometricCdf(int k, int n, int Kp, int Np) { if(k < 0 || n < 0 || Kp < 0 || Np < 0) { throw new IllegalArgumentException(\"All the parameters must be positive.\"); } Kp = Math.max(k, Kp); Np = Math.max(n, Np); double probabilitySum = approxHypergeometricCdf(k, n, Kp, Np); return probabilitySum; } ",
        "focal_src": "public static double HypergeometricCdf(int k, int n, int Kp, int Np) { if(k < 0 || n < 0 || Kp < 0 || Np < 0) { throw new IllegalArgumentException(\"All the parameters must be positive.\"); } Kp = Math.max(k, Kp); Np = Math.max(n, Np); double probabilitySum = approxHypergeometricCdf(k, n, Kp, Np); return probabilitySum; } ",
        "test_tgt": "@Test public void testHypergeometricCdf() { logger.info(\"HypergeometricCdf\"); int k = 3; int n = 10; int Kp = 30; int Np = 100; double expResult = 0.65401998866081; double result = DiscreteDistributions.hypergeometricCdf(k, n, Kp, Np); assertEquals(expResult, result, TestConfiguration.DOUBLE_ACCURACY_HIGH); } "
    },
    {
        "test_src": "@Test(groups = { \"integration\", \"live\" }, singleThreaded = true, dependsOnMethods = \"testAddIpPermissionsFromSpec\")public void testDeleteSecurityGroup() { ComputeService computeService = view.getComputeService(); Optional < SecurityGroupExtension > securityGroupExtension = computeService.getSecurityGroupExtension(); assertTrue(securityGroupExtension.isPresent(), \"security group extension was not present\"); Optional < SecurityGroup > optGroup = getGroup(securityGroupExtension.get()); assertTrue(optGroup.isPresent()); SecurityGroup group = optGroup.get(); assertTrue(securityGroupExtension.get().removeSecurityGroup(group.getId())); } ",
        "focal_tgt": "@Named(\"deleteSecurityGroup\")@GET@QueryParams(keys = \"command\", values = \"deleteSecurityGroup\")@Consumes(MediaType.APPLICATION_JSON)@Fallback(VoidOnNotFoundOr404.class)void deleteSecurityGroup(@QueryParam(\"id\")String id); ",
        "focal_src": "@Named(\"deleteSecurityGroup\")@GET@QueryParams(keys = \"command\", values = \"deleteSecurityGroup\")@Fallback(VoidOnNotFoundOr404.class)void deleteSecurityGroup(@QueryParam(\"id\")String id); ",
        "test_tgt": "@Test(groups = { \"integration\", \"live\" }, singleThreaded = true, dependsOnMethods = \"testAddIpPermissionsFromSpec\")public void testDeleteSecurityGroup() { skipIfSecurityGroupsNotSupported(); ComputeService computeService = view.getComputeService(); Optional < SecurityGroupExtension > securityGroupExtension = computeService.getSecurityGroupExtension(); assertTrue(securityGroupExtension.isPresent(), \"security group extension was not present\"); Optional < SecurityGroup > optGroup = getGroup(securityGroupExtension.get()); assertTrue(optGroup.isPresent()); SecurityGroup group = optGroup.get(); assertTrue(securityGroupExtension.get().removeSecurityGroup(group.getId())); } "
    },
    {
        "test_src": "@Test public void instanceOf() { assertTrue(BLN_O.instanceOf(AAT_ZM)); assertFalse(AAT_ZM.instanceOf(BLN_O)); assertTrue(DBL_O.instanceOf(DBL_ZM)); assertFalse(DBL_ZM.instanceOf(DBL_O)); final SeqType f = FuncType.get(DEC_ZO, BLN_O).seqType(); assertFalse(f.instanceOf(ITR_O)); assertTrue(f.instanceOf(ITEM_O)); assertTrue(f.instanceOf(f)); assertTrue(f.instanceOf(FUNC_ZO)); assertFalse(FUNC_O.instanceOf(f)); assertFalse(f.instanceOf(FuncType.get(DEC_ZO, BLN_O, ITR_O).seqType())); assertFalse(f.instanceOf(FuncType.get(DEC_ZO, AAT_O).seqType())); assertFalse(f.instanceOf(FuncType.get(BLN_O, BLN_O).seqType())); final MapType m = MapType.get(AtomType.STR, ITR_O); assertTrue(m.instanceOf(m)); assertTrue(m.instanceOf(AtomType.ITEM)); assertTrue(m.instanceOf(ANY_FUNC)); assertTrue(m.instanceOf(ANY_MAP)); assertTrue(m.instanceOf(MapType.get(AtomType.AAT, ITR_O))); assertTrue(m.instanceOf(MapType.get(AtomType.STR, ITR_O))); assertTrue(m.instanceOf(MapType.get(AtomType.STR, ITR_ZO))); assertTrue(m.instanceOf(MapType.get(AtomType.ITR, ITEM_ZM))); assertFalse(m.instanceOf(ANY_ARRAY)); assertFalse(m.instanceOf(MapType.get(AtomType.STR, BLN_O))); final ArrayType a = ArrayType.get(ITR_O); assertTrue(a.instanceOf(a)); assertTrue(a.instanceOf(AtomType.ITEM)); assertTrue(a.instanceOf(ANY_FUNC)); assertTrue(a.instanceOf(ANY_ARRAY)); assertTrue(a.instanceOf(ArrayType.get(ITR_O))); assertTrue(a.instanceOf(ArrayType.get(ITR_O))); assertTrue(a.instanceOf(ArrayType.get(ITR_ZO))); assertFalse(a.instanceOf(ANY_MAP)); assertFalse(a.instanceOf(ArrayType.get(BLN_O))); assertTrue(ATT_O.instanceOf(NOD_O)); assertTrue(ATT_O.instanceOf(ATT_O)); assertFalse(ATT_O.instanceOf(ELM_O)); assertFalse(ELM_O.instanceOf(f)); assertFalse(NOD_O.instanceOf(ELM_O)); assertFalse(ITEM_O.instanceOf(ELM_O)); assertTrue(ELM_O.instanceOf(ITEM_O)); } ",
        "focal_tgt": "public boolean instanceOf(final SeqType st) { return zero() ? st.mayBeEmpty() : (st.type == AtomType.ITEM || type.instanceOf(st.type)) && occ.instanceOf(st.occ) && (st.kind == null || kind != null && kind.intersect(st.kind) != null); } ",
        "focal_src": "public boolean instanceOf(final SeqType st) { if(zero())return st.mayBeEmpty(); final Type type1 = type, type2 = st.type; final Test kind1 = kind, kind2 = st.kind; return(type2 == AtomType.ITEM || type1.instanceOf(type2)) && occ.instanceOf(st.occ) && (kind2 == null || kind1 != null && kind1.intersect(kind2) != null); } ",
        "test_tgt": "@Test public void instanceOf() { assertTrue(BLN_O.instanceOf(AAT_ZM)); assertFalse(AAT_ZM.instanceOf(BLN_O)); assertTrue(DBL_O.instanceOf(DBL_ZM)); assertFalse(DBL_ZM.instanceOf(DBL_O)); final SeqType f = FuncType.get(DEC_ZO, BLN_O).seqType(); assertFalse(f.instanceOf(ITR_O)); assertTrue(f.instanceOf(ITEM_O)); assertTrue(f.instanceOf(FUNC_O)); assertTrue(f.instanceOf(f)); assertTrue(f.instanceOf(FUNC_ZO)); assertFalse(FUNC_O.instanceOf(f)); assertFalse(f.instanceOf(FuncType.get(DEC_ZO, BLN_O, ITR_O).seqType())); assertFalse(f.instanceOf(FuncType.get(DEC_ZO, AAT_O).seqType())); assertFalse(f.instanceOf(FuncType.get(BLN_O, BLN_O).seqType())); final MapType m = MapType.get(AtomType.STR, ITR_O); assertTrue(m.instanceOf(m)); assertTrue(m.instanceOf(AtomType.ITEM)); assertTrue(m.instanceOf(ANY_FUNC)); assertTrue(m.instanceOf(ANY_MAP)); assertTrue(m.instanceOf(MapType.get(AtomType.AAT, ITR_O))); assertTrue(m.instanceOf(MapType.get(AtomType.STR, ITR_O))); assertTrue(m.instanceOf(MapType.get(AtomType.STR, ITR_ZO))); assertFalse(m.instanceOf(MapType.get(AtomType.ITR, ITEM_ZM))); assertFalse(m.instanceOf(ANY_ARRAY)); assertFalse(m.instanceOf(MapType.get(AtomType.STR, BLN_O))); final ArrayType a = ArrayType.get(ITR_O); assertTrue(a.instanceOf(a)); assertTrue(a.instanceOf(AtomType.ITEM)); assertTrue(a.instanceOf(ANY_FUNC)); assertTrue(a.instanceOf(ANY_ARRAY)); assertTrue(a.instanceOf(ArrayType.get(ITR_O))); assertTrue(a.instanceOf(ArrayType.get(ITR_O))); assertTrue(a.instanceOf(ArrayType.get(ITR_ZO))); assertFalse(a.instanceOf(ANY_MAP)); assertFalse(a.instanceOf(ArrayType.get(BLN_O))); assertTrue(ATT_O.instanceOf(NOD_O)); assertTrue(ATT_O.instanceOf(ATT_O)); assertFalse(ATT_O.instanceOf(ELM_O)); assertFalse(ELM_O.instanceOf(f)); assertFalse(NOD_O.instanceOf(ELM_O)); assertFalse(ITEM_O.instanceOf(ELM_O)); assertTrue(ELM_O.instanceOf(ITEM_O)); } "
    },
    {
        "test_src": "@Test public void getConstructorStartTest() { YangPluginConfig pluginConfig = new YangPluginConfig(); String method = getConstructorStart(CLASS_NAME, pluginConfig); assertThat(true, is(method.contains(PUBLIC + SPACE + CLASS_NAME + IMPL + OPEN_PARENTHESIS + CLASS_NAME + BUILDER + SPACE + BUILDER.toLowerCase() + OBJECT + CLOSE_PARENTHESIS + SPACE + OPEN_CURLY_BRACKET + NEW_LINE))); } ",
        "focal_tgt": "public static String getConstructorStart(String yangName, YangPluginConfig pluginConfig) { String javadoc = getConstructorString(yangName, pluginConfig); String constructor = FOUR_SPACE_INDENTATION + PUBLIC + SPACE + getCapitalCase(DEFAULT) + yangName + OPEN_PARENTHESIS + yangName + BUILDER + SPACE + BUILDER.toLowerCase() + OBJECT + CLOSE_PARENTHESIS + SPACE + OPEN_CURLY_BRACKET + NEW_LINE; return javadoc + constructor; } ",
        "focal_src": "public static String getConstructorStart(String yangName, YangPluginConfig pluginConfig) { String javadoc = getConstructorString(yangName, pluginConfig); String constructor = FOUR_SPACE_INDENTATION + PUBLIC + SPACE + yangName + IMPL + OPEN_PARENTHESIS + yangName + BUILDER + SPACE + BUILDER.toLowerCase() + OBJECT + CLOSE_PARENTHESIS + SPACE + OPEN_CURLY_BRACKET + NEW_LINE; return javadoc + constructor; } ",
        "test_tgt": "@Test public void getConstructorStartTest() { YangPluginConfig pluginConfig = new YangPluginConfig(); String method = getConstructorStart(CLASS_NAME, pluginConfig); assertThat(true, is(method.contains(PUBLIC + SPACE + \"Default\" + CLASS_NAME + OPEN_PARENTHESIS + CLASS_NAME + BUILDER + SPACE + BUILDER.toLowerCase() + OBJECT + CLOSE_PARENTHESIS + SPACE + OPEN_CURLY_BRACKET + NEW_LINE))); } "
    },
    {
        "test_src": "@Test public void testCreateCommand()throws GenieException { final String id = UUID.randomUUID().toString(); final Command command = new Command.Builder(COMMAND_1_NAME, COMMAND_1_USER, COMMAND_1_VERSION, CommandStatus.ACTIVE, COMMAND_1_EXECUTABLE, COMMAND_1_CHECK_DELAY).withId(id).build(); final String createdId = this.service.createCommand(command); Assert.assertThat(createdId, Matchers.is(id)); final Command created = this.service.getCommand(id); Assert.assertNotNull(this.service.getCommand(id)); Assert.assertEquals(id, created.getId().orElseThrow(IllegalArgumentException :: new)); Assert.assertEquals(COMMAND_1_NAME, created.getName()); Assert.assertEquals(COMMAND_1_USER, created.getUser()); Assert.assertEquals(CommandStatus.ACTIVE, created.getStatus()); Assert.assertEquals(COMMAND_1_EXECUTABLE, created.getExecutable()); Assert.assertThat(COMMAND_1_CHECK_DELAY, Matchers.is(created.getCheckDelay())); Assert.assertFalse(created.getMemory().isPresent()); this.service.deleteCommand(id); try { this.service.getCommand(id); Assert.fail(\"Should have thrown exception\"); } catch(final GenieException ge) { Assert.assertEquals(HttpURLConnection.HTTP_NOT_FOUND, ge.getErrorCode()); } } ",
        "focal_tgt": "@PostMapping(consumes = MediaType.APPLICATION_JSON_VALUE)@ResponseStatus(HttpStatus.CREATED)public ResponseEntity < Void > createCommand(@RequestBody@Valid final Command command)throws GenieException { log.debug(\"called to create new command configuration {}\", command); final String id = this.commandService.createCommand(DtoAdapters.toV4CommandRequest(command)); final HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setLocation(ServletUriComponentsBuilder.fromCurrentRequest().path(\"/{id}\").buildAndExpand(id).toUri()); return new ResponseEntity < > (httpHeaders, HttpStatus.CREATED); } ",
        "focal_src": "@PostMapping(consumes = MediaType.APPLICATION_JSON_VALUE)@ResponseStatus(HttpStatus.CREATED)public ResponseEntity < Void > createCommand(@RequestBody final Command command)throws GenieException { log.debug(\"called to create new command configuration {}\", command); final String id = this.commandService.createCommand(command); final HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setLocation(ServletUriComponentsBuilder.fromCurrentRequest().path(\"/{id}\").buildAndExpand(id).toUri()); return new ResponseEntity < > (httpHeaders, HttpStatus.CREATED); } ",
        "test_tgt": "@Test public void testCreateCommand()throws GenieException { final String id = UUID.randomUUID().toString(); final CommandRequest command = new CommandRequest.Builder(new CommandMetadata.Builder(COMMAND_1_NAME, COMMAND_1_USER, CommandStatus.ACTIVE).withVersion(COMMAND_1_VERSION).build(), COMMAND_1_EXECUTABLE).withRequestedId(id).withCheckDelay(COMMAND_1_CHECK_DELAY).build(); final String createdId = this.service.createCommand(command); Assert.assertThat(createdId, Matchers.is(id)); final Command created = this.service.getCommand(id); Assert.assertNotNull(this.service.getCommand(id)); Assert.assertEquals(id, created.getId()); Assert.assertEquals(COMMAND_1_NAME, created.getMetadata().getName()); Assert.assertEquals(COMMAND_1_USER, created.getMetadata().getUser()); Assert.assertEquals(CommandStatus.ACTIVE, created.getMetadata().getStatus()); Assert.assertEquals(COMMAND_1_EXECUTABLE, created.getExecutable()); Assert.assertThat(COMMAND_1_CHECK_DELAY, Matchers.is(created.getCheckDelay())); Assert.assertFalse(created.getMemory().isPresent()); this.service.deleteCommand(id); try { this.service.getCommand(id); Assert.fail(\"Should have thrown exception\"); } catch(final GenieException ge) { Assert.assertEquals(HttpURLConnection.HTTP_NOT_FOUND, ge.getErrorCode()); } } "
    },
    {
        "test_src": "@Test public void testPackAlignments()throws Exception { AlignmentInterval interval = getAlignmentInterval(); Map < String, List < Row > > result = (new AlignmentPacker()).packAlignments(interval, new AlignmentTrack.RenderOptions(AlignmentDataManager.ExperimentType.OTHER)); assertEquals(1, result.size()); for(List < Row > alignmentrows : result.values()) { for(Row alignmentrow : alignmentrows) { List < Alignment > alignments = alignmentrow.alignments; for(int ii = 1; ii < alignments.size(); ii ++ ) { assertTrue(alignments.get(ii).getAlignmentStart() > alignments.get(ii - 1).getAlignmentStart()); assertTrue(alignments.get(ii).getAlignmentStart() - alignments.get(ii - 1).getAlignmentEnd() >= AlignmentPacker.MIN_ALIGNMENT_SPACING); } } } } ",
        "focal_tgt": "public PackedAlignments packAlignments(AlignmentInterval interval, AlignmentTrack.RenderOptions renderOptions) { LinkedHashMap < String, List < Row > > packedAlignments = new LinkedHashMap < String, List < Row > > (); List < Alignment > alList = interval.getAlignments(); if(renderOptions.linkedReads) { alList = linkByTag(alList, renderOptions.linkByTag); } if(renderOptions.groupByOption == null) { List < Row > alignmentRows = new ArrayList < > (10000); pack(alList, renderOptions, alignmentRows); packedAlignments.put(\"\", alignmentRows); } else { Map < String, List < Alignment > > groupedAlignments = new HashMap < String, List < Alignment > > (); Iterator < Alignment > iter = alList.iterator(); while(iter.hasNext()) { Alignment alignment = iter.next(); String groupKey = getGroupValue(alignment, renderOptions); if(groupKey == null) { groupKey = NULL_GROUP_VALUE; } List < Alignment > groupList = groupedAlignments.get(groupKey); if(groupList == null) { groupList = new ArrayList < > (1000); groupedAlignments.put(groupKey, groupList); } groupList.add(alignment); } List < String > keys = new ArrayList < String > (groupedAlignments.keySet()); Comparator < String > groupComparator = getGroupComparator(renderOptions.groupByOption); Collections.sort(keys, groupComparator); for(String key : keys) { List < Row > alignmentRows = new ArrayList < > (10000); List < Alignment > group = groupedAlignments.get(key); pack(group, renderOptions, alignmentRows); packedAlignments.put(key, alignmentRows); } } List < AlignmentInterval > tmp = new ArrayList < AlignmentInterval > (); tmp.add(interval); return new PackedAlignments(tmp, packedAlignments); } ",
        "focal_src": "public PackedAlignments packAlignments(AlignmentInterval interval, AlignmentTrack.RenderOptions renderOptions) { LinkedHashMap < String, List < Row > > packedAlignments = new LinkedHashMap < String, List < Row > > (); List < Alignment > alList = interval.getAlignments(); if(renderOptions.isLinkedReads()) { alList = linkByTag(alList, renderOptions.getLinkByTag()); } if(renderOptions.groupByOption == null) { List < Row > alignmentRows = new ArrayList < > (10000); pack(alList, renderOptions, alignmentRows); packedAlignments.put(\"\", alignmentRows); } else { Map < String, List < Alignment > > groupedAlignments = new HashMap < String, List < Alignment > > (); Iterator < Alignment > iter = alList.iterator(); while(iter.hasNext()) { Alignment alignment = iter.next(); String groupKey = getGroupValue(alignment, renderOptions); if(groupKey == null) { groupKey = NULL_GROUP_VALUE; } List < Alignment > groupList = groupedAlignments.get(groupKey); if(groupList == null) { groupList = new ArrayList < > (1000); groupedAlignments.put(groupKey, groupList); } groupList.add(alignment); } List < String > keys = new ArrayList < String > (groupedAlignments.keySet()); Comparator < String > groupComparator = getGroupComparator(renderOptions.groupByOption); Collections.sort(keys, groupComparator); for(String key : keys) { List < Row > alignmentRows = new ArrayList < > (10000); List < Alignment > group = groupedAlignments.get(key); pack(group, renderOptions, alignmentRows); packedAlignments.put(key, alignmentRows); } } List < AlignmentInterval > tmp = new ArrayList < AlignmentInterval > (); tmp.add(interval); return new PackedAlignments(tmp, packedAlignments); } ",
        "test_tgt": "@Test public void testPackAlignments()throws Exception { AlignmentInterval interval = getAlignmentInterval(); Map < String, List < Row > > result = (new AlignmentPacker()).packAlignments(interval, (new AlignmentTrack.RenderOptions())); assertEquals(1, result.size()); for(List < Row > alignmentrows : result.values()) { for(Row alignmentrow : alignmentrows) { List < Alignment > alignments = alignmentrow.alignments; for(int ii = 1; ii < alignments.size(); ii ++ ) { assertTrue(alignments.get(ii).getAlignmentStart() > alignments.get(ii - 1).getAlignmentStart()); assertTrue(alignments.get(ii).getAlignmentStart() - alignments.get(ii - 1).getAlignmentEnd() >= AlignmentPacker.MIN_ALIGNMENT_SPACING); } } } } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" }, dataProvider = \"calendars\")public < C extends Chrono < C > > void test_ChronoLocalDateTimeSerialization(C chrono)throws Exception { LocalDateTime ref = LocalDate.of(2000, 1, 5).atTime(12, 1, 2, 3); ChronoLocalDateTime < C > orginal = chrono.date(ref).atTime(ref.getTime()); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(baos); out.writeObject(orginal); out.close(); ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream in = new ObjectInputStream(bais); @SuppressWarnings(\"unchecked\")ChronoLocalDateTime < C > ser = (ChronoLocalDateTime < C > )in.readObject(); assertEquals(ser, orginal, \"deserialized date is wrong\"); } ",
        "focal_tgt": "@Override public long between(Temporal temporal1, Temporal temporal2) { return temporal1.periodUntil(temporal2, this); } ",
        "focal_src": "@Override public < R extends Temporal > SimplePeriod between(R dateTime1, R dateTime2) { return new SimplePeriod(dateTime1.periodUntil(dateTime2, this), this); } ",
        "test_tgt": "@Test(groups = { \"tck\" }, dataProvider = \"calendars\")public void test_ChronoLocalDateTimeSerialization(Chronology chrono)throws Exception { LocalDateTime ref = LocalDate.of(2000, 1, 5).atTime(12, 1, 2, 3); ChronoLocalDateTime < ? > orginal = chrono.date(ref).atTime(ref.toLocalTime()); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(baos); out.writeObject(orginal); out.close(); ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream in = new ObjectInputStream(bais); @SuppressWarnings(\"unchecked\")ChronoLocalDateTime < ? > ser = (ChronoLocalDateTime < ? > )in.readObject(); assertEquals(ser, orginal, \"deserialized date is wrong\"); } "
    },
    {
        "test_src": "@Test public void testAdd() { for(int i = 0; i < 4000; ++ i) { final byte[]key = token(\"keyAdd\" + i); final int size = i; final long pointer = i + 5000L; cache.add(key, size, pointer); assertCacheEntry(key, size, pointer); } } ",
        "focal_tgt": "private void add(final BasicUpdate u, final boolean merged) { if(u == null)return; if( ! merged) { if(recent instanceof StructuralUpdate)struct.add((StructuralUpdate)recent); else val.add(recent); } recent = u; } ",
        "focal_src": "private boolean add(final BasicUpdate u, final boolean merged) { if(u == null)return false; if( ! merged) { if(recent instanceof StructuralUpdate)struct.add((StructuralUpdate)recent); else val.add(recent); } recent = u; return true; } ",
        "test_tgt": "@Test public void testAdd() { for(int i = 0; i < 4000; ++ i) { final byte[]key = token(\"keyAdd\" + i); final long pointer = i + 5000L; cache.add(key, i, pointer); assertCacheEntry(key, i, pointer); } } "
    },
    {
        "test_src": "@Test public void testNotNull() { assertTrue(instance.notNull(\"name\").getQueryCriterions().contains(new NotNullCriterion(\"name\"))); } ",
        "focal_tgt": "public CriteriaQuery notNull(String propName) { criterion = criterion.and(criterionBuilder.notNull(propName)); return this; } ",
        "focal_src": "public CriteriaQuery notNull(String propName) { addCriterion(criterionBuilder.notNull(propName)); return this; } ",
        "test_tgt": "@Test public void testNotNull() { assertEquals(new NotNullCriterion(\"name\"), instance.notNull(\"name\").getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void setSelectedDatabaseConnection() { AbstractSqoopJobEntryController controller = new TestSqoopJobEntryController(); String database = \"testing\"; controller.setSelectedDatabaseConnection(database); assertNull(\"Setting a database to one that doesn't exist in the JobMeta should not work\", controller.getConfig().getDatabase()); controller.getJobMeta().addDatabase(new DatabaseMeta(database, \"MYSQL\", null, null, null, null, null, null)); controller.setSelectedDatabaseConnection(database); assertEquals(database, controller.getConfig().getDatabase()); } ",
        "focal_tgt": "public void setSelectedDatabaseConnection(DatabaseItem selectedDatabaseConnection) { DatabaseItem old = this.selectedDatabaseConnection; this.selectedDatabaseConnection = selectedDatabaseConnection; DatabaseMeta databaseMeta = this.selectedDatabaseConnection == null ? null : jobMeta.findDatabase(this.selectedDatabaseConnection.getName()); boolean validDatabaseSelected = databaseMeta != null; setDatabaseInteractionButtonsDisabled( ! validDatabaseSelected); updateDatabaseItemsList(); if( ! suppressEventHandling && (old == null && this.selectedDatabaseConnection != null || ! old.equals(this.selectedDatabaseConnection))) { if(validDatabaseSelected) { try { getConfig().setConnectionInfo(databaseMeta.getName(), databaseMeta.getURL(), databaseMeta.getUsername(), databaseMeta.getPassword()); } catch(KettleDatabaseException ex) { sqoopJobEntry.logError(BaseMessages.getString(AbstractSqoopJobEntry.class, \"ErrorConfiguringDatabaseConnection\"), ex); } } else { getConfig().copyConnectionInfoFromAdvanced(); } } firePropertyChange(\"selectedDatabaseConnection\", old, this.selectedDatabaseConnection); } ",
        "focal_src": "public void setSelectedDatabaseConnection(String selected) { updateSelectedDatabase(selected, true); } ",
        "test_tgt": "@Test public void setSelectedDatabaseConnection()throws KettleDatabaseException { AbstractSqoopJobEntryController controller = new TestSqoopJobEntryController(); String connect = \"jdbc:bogus://bogus\"; String username = \"username\"; String password = \"password\"; controller.getConfig().setConnect(connect); controller.getConfig().setUsername(username); controller.getConfig().setPassword(password); String connectAdvanced = \"jdbc:advanced://bogus\"; String usernameAdvanced = \"advanced_user\"; String passwordAdvanced = \"super password!\"; controller.getConfig().setConnectFromAdvanced(connectAdvanced); controller.getConfig().setUsernameFromAdvanced(usernameAdvanced); controller.getConfig().setPasswordFromAdvanced(passwordAdvanced); DatabaseItem test = new DatabaseItem(\"test\"); DatabaseMeta database = new DatabaseMeta(test.getName(), \"MYSQL\", null, null, null, null, null, null); controller.getJobMeta().addDatabase(database); controller.setSelectedDatabaseConnection(test); assertEquals(test, controller.getSelectedDatabaseConnection()); assertEquals(test.getName(), controller.getConfig().getDatabase()); assertEquals(database.getURL(), controller.getConfig().getConnect()); assertEquals(database.getUsername(), controller.getConfig().getUsername()); assertEquals(database.getPassword(), controller.getConfig().getPassword()); assertEquals(connectAdvanced, controller.getConfig().getConnectFromAdvanced()); assertEquals(usernameAdvanced, controller.getConfig().getUsernameFromAdvanced()); assertEquals(passwordAdvanced, controller.getConfig().getPasswordFromAdvanced()); controller.setSelectedDatabaseConnection(controller.USE_ADVANCED_OPTIONS); assertEquals(controller.USE_ADVANCED_OPTIONS, controller.getSelectedDatabaseConnection()); assertNull(controller.getConfig().getDatabase()); assertEquals(connectAdvanced, controller.getConfig().getConnect()); assertEquals(usernameAdvanced, controller.getConfig().getUsername()); assertEquals(passwordAdvanced, controller.getConfig().getPassword()); assertEquals(connectAdvanced, controller.getConfig().getConnectFromAdvanced()); assertEquals(usernameAdvanced, controller.getConfig().getUsernameFromAdvanced()); assertEquals(passwordAdvanced, controller.getConfig().getPasswordFromAdvanced()); controller.setSelectedDatabaseConnection(test); assertEquals(test, controller.getSelectedDatabaseConnection()); assertEquals(test.getName(), controller.getConfig().getDatabase()); assertEquals(database.getURL(), controller.getConfig().getConnect()); assertEquals(database.getUsername(), controller.getConfig().getUsername()); assertEquals(database.getPassword(), controller.getConfig().getPassword()); assertEquals(connectAdvanced, controller.getConfig().getConnectFromAdvanced()); assertEquals(usernameAdvanced, controller.getConfig().getUsernameFromAdvanced()); assertEquals(passwordAdvanced, controller.getConfig().getPasswordFromAdvanced()); } "
    },
    {
        "test_src": "@Test public void create()throws Exception { TransformRequest transformRequest = new TransformRequest(); transformRequest.setScript(\"sqlContext.sql(\\\"SELECT * FROM invalid\\\")\"); TransformResponse transformResponse = new TransformResponse(); transformResponse.setProgress(0.0); transformResponse.setStatus(TransformResponse.Status.PENDING); transformResponse.setTable(\"results\"); TransformService transformService = Mockito.mock(TransformService.class); Mockito.when(transformService.execute(transformRequest)).thenReturn(transformResponse); SparkShellTransformController controller = new SparkShellTransformController(); controller.idleMonitorService = Mockito.mock(IdleMonitorService.class); controller.transformService = transformService; Response response = controller.create(transformRequest); Assert.assertEquals(Response.Status.OK, response.getStatusInfo()); Assert.assertEquals(transformResponse, response.getEntity()); } ",
        "focal_tgt": "@POST@Consumes(MediaType.APPLICATION_JSON)@Produces(MediaType.APPLICATION_JSON)@ApiOperation(\"Queries a Hive table and applies a series of transformations on the rows.\")@ApiResponses( { @ApiResponse(code = 200, message = \"Returns the status of the transformation.\", response = TransformResponse.class), @ApiResponse(code = 400, message = \"The request could not be parsed.\", response = TransformResponse.class), @ApiResponse(code = 500, message = \"There was a problem processing the data.\", response = TransformResponse.class) })@Nonnull public Response create(@ApiParam(value = \"The request indicates the transformations to apply to the source table and how the user wishes the results to be displayed. Exactly one parent or source\" + \" must be specified.\", required = true)@Nullable final TransformRequest request) { if(request == null || request.getScript() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingScript\"); } if(request.getParent() != null) { if(request.getParent().getScript() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingParentScript\"); } if(request.getParent().getTable() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingParentTable\"); } } try { TransformResponse response = this.transformService.execute(request); return Response.ok(response).build(); } catch(final ScriptException e) { return error(Response.Status.INTERNAL_SERVER_ERROR, e); } } ",
        "focal_src": "@POST@Consumes(MediaType.APPLICATION_JSON)@Produces(MediaType.APPLICATION_JSON)@ApiOperation(\"Queries a Hive table and applies a series of transformations on the rows.\")@ApiResponses( { @ApiResponse(code = 200, message = \"Returns the status of the transformation.\", response = TransformResponse.class), @ApiResponse(code = 400, message = \"The request could not be parsed.\", response = TransformResponse.class), @ApiResponse(code = 500, message = \"There was a problem processing the data.\", response = TransformResponse.class) })@Nonnull public Response create(@ApiParam(value = \"The request indicates the transformations to apply to the source table and how the user wishes the results to be displayed. Exactly one parent or source\" + \" must be specified.\", required = true)@Nullable final TransformRequest request) { idleMonitorService.reset(); if(request == null || request.getScript() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingScript\"); } if(request.getParent() != null) { if(request.getParent().getScript() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingParentScript\"); } if(request.getParent().getTable() == null) { return error(Response.Status.BAD_REQUEST, \"transform.missingParentTable\"); } } try { TransformResponse response = this.transformService.execute(request); return Response.ok(response).build(); } catch(ScriptException e) { return error(Response.Status.INTERNAL_SERVER_ERROR, e.getMessage()); } finally { idleMonitorService.reset(); } } ",
        "test_tgt": "@Test public void create()throws Exception { TransformRequest transformRequest = new TransformRequest(); transformRequest.setScript(\"sqlContext.sql(\\\"SELECT * FROM invalid\\\")\"); TransformResponse transformResponse = new TransformResponse(); transformResponse.setProgress(0.0); transformResponse.setStatus(TransformResponse.Status.PENDING); transformResponse.setTable(\"results\"); TransformService transformService = Mockito.mock(TransformService.class); Mockito.when(transformService.execute(transformRequest)).thenReturn(transformResponse); SparkShellTransformController controller = new SparkShellTransformController(); controller.transformService = transformService; Response response = controller.create(transformRequest); Assert.assertEquals(Response.Status.OK, response.getStatusInfo()); Assert.assertEquals(transformResponse, response.getEntity()); } "
    },
    {
        "test_src": "@Test public void testRelinquish() { setUpLeadershipService(PartitionManager.NUM_PARTITIONS); expect(leadershipService.withdraw(anyString())).andReturn(CompletableFuture.completedFuture(null)).times(7); replay(leadershipService); partitionManager.activate(); leaderListener.event(event); verify(leadershipService); } ",
        "focal_tgt": "private void rebalance() { int activeNodes = (int)clusterService.getNodes().stream().filter(node -> ControllerNode.State.ACTIVE == clusterService.getState(node.id())).count(); int myShare = (int)Math.ceil((double)NUM_PARTITIONS / activeNodes); List < Leadership > myPartitions = leadershipService.getLeaderBoard().values().stream().filter(l -> clusterService.getLocalNode().id().equals(l.leader())).filter(l -> l.topic().startsWith(ELECTION_PREFIX)).collect(Collectors.toList()); int relinquish = myPartitions.size() - myShare; if(relinquish <= 0) { return; } for(int i = 0; i < relinquish; i ++ ) { String topic = myPartitions.get(i).topic(); leadershipService.withdraw(topic); executor.schedule(() -> recontest(topic), BACKOFF_TIME, TimeUnit.SECONDS); } } ",
        "focal_src": "private void relinquish() { int activeNodes = (int)clusterService.getNodes().stream().filter(n -> clusterService.getState(n.id()) == ControllerNode.State.ACTIVE).count(); int myShare = (int)Math.ceil((double)NUM_PARTITIONS / activeNodes); List < Leadership > myPartitions = leadershipService.getLeaderBoard().values().stream().filter(l -> clusterService.getLocalNode().id().equals(l.leader())).filter(l -> l.topic().startsWith(ELECTION_PREFIX)).collect(Collectors.toList()); int relinquish = myPartitions.size() - myShare; if(relinquish <= 0) { return; } for(int i = 0; i < relinquish; i ++ ) { String topic = myPartitions.get(i).topic(); leadershipService.withdraw(topic); executor.schedule(() -> recontest(topic), BACKOFF_TIME, TimeUnit.SECONDS); } } ",
        "test_tgt": "@Test public void testRebalance() { setUpLeadershipService(PartitionManager.NUM_PARTITIONS); expect(leadershipService.withdraw(anyString())).andReturn(CompletableFuture.completedFuture(null)).times(7); replay(leadershipService); partitionManager.activate(); partitionManager.doRebalance(); verify(leadershipService); } "
    },
    {
        "test_src": "@Test(groups = { \"observerMethod\" })public void testRemoveObserver() { EventManager eventManager = new EventManager(); Observer < DangerCall > observer = new AnObserver < DangerCall > (); eventManager.addObserver(observer, DangerCall.class); eventManager.removeObserver(observer, DangerCall.class); assert eventManager.getObservers(new MetaDataCache(), new DangerCall()).isEmpty(); } ",
        "focal_tgt": "public < T > void removeObserver(Observer < T > observer, Class < T > eventType, Annotation ... bindings) { List < EventObserver < ? > > observers = registeredObservers.get(eventType); EventObserver < T > eventObserver = new EventObserver < T > (manager.getMetaDataCache(), observer, eventType, bindings); observers.remove(eventObserver); } ",
        "focal_src": "public < T > void removeObserver(Observer < T > observer, Class < T > eventType, Annotation ... bindings) { List < EventObserver < ? > > observers = registeredObservers.get(eventType); EventObserver < T > eventObserver = new EventObserver < T > (observer, eventType, bindings); observers.remove(eventObserver); } ",
        "test_tgt": "@Test(groups = { \"observerMethod\" })public void testRemoveObserver() { EventManager eventManager = new EventManager(manager); Observer < DangerCall > observer = new AnObserver < DangerCall > (); eventManager.addObserver(observer, DangerCall.class); eventManager.removeObserver(observer, DangerCall.class); assert eventManager.getObservers(new DangerCall()).isEmpty(); } "
    },
    {
        "test_src": "@SuppressWarnings(\"unchecked\")@Test public void testRepairSurvivors() { InitiatorMailbox mailbox = mock(InitiatorMailbox.class); SpPromoteAlgo term = new SpPromoteAlgo(null, mailbox, \"Test\"); SpPromoteAlgo.ReplicaRepairStruct r1 = new SpPromoteAlgo.ReplicaRepairStruct(); r1.m_maxSpHandleSeen = 3L; SpPromoteAlgo.ReplicaRepairStruct r2 = new SpPromoteAlgo.ReplicaRepairStruct(); r2.m_maxSpHandleSeen = 5L; SpPromoteAlgo.ReplicaRepairStruct r3 = new SpPromoteAlgo.ReplicaRepairStruct(); r3.m_maxSpHandleSeen = 2L; term.m_replicaRepairStructs.put(1L, r1); term.m_replicaRepairStructs.put(2L, r2); term.m_replicaRepairStructs.put(3L, r3); long spHandles[] = new long[] { 0L, 1L, 2L, 3L, 4L, 5L }; Iv2RepairLogResponseMessage msgs[] = new Iv2RepairLogResponseMessage[6]; for(int i = 1; i < spHandles.length; ++ i) { msgs[i] = makeResponse(spHandles[i]); term.m_repairLogUnion.add(msgs[i]); } term.repairSurvivors(); List < Long > repair3 = new ArrayList < Long > (); repair3.add(3L); verify(mailbox).repairReplicasWith(repair3, msgs[3]); List < Long > repair4And5 = new ArrayList < Long > (); repair4And5.add(1L); repair4And5.add(3L); verify(mailbox).repairReplicasWith(repair4And5, msgs[4]); verify(mailbox).repairReplicasWith(repair4And5, msgs[5]); verify(mailbox, times(3)).repairReplicasWith(any(repair3.getClass()), any(Iv2RepairLogResponseMessage.class)); } ",
        "focal_tgt": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"Skipping repair message creation for cancelled Term.\"); return; } int queued = 0; tmLog.info(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { List < Long > needsRepair = new ArrayList < Long > (5); for(Entry < Long, ReplicaRepairStruct > entry : m_replicaRepairStructs.entrySet()) { if(entry.getValue().needs(li.getHandle())) { ++ queued; tmLog.debug(m_whoami + \"repairing \" + entry.getKey() + \". Max seen \" + entry.getValue().m_maxSpHandleSeen + \". Repairing with \" + li.getHandle()); needsRepair.add(entry.getKey()); } } if( ! needsRepair.isEmpty()) { m_mailbox.repairReplicasWith(needsRepair, li.getPayload()); } } tmLog.info(m_whoami + \"finished queuing \" + queued + \" replica repair messages.\"); m_promotionResult.done(m_maxSeenTxnId); } ",
        "focal_src": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"Skipping repair message creation for cancelled Term.\"); return; } int queued = 0; tmLog.info(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { List < Long > needsRepair = new ArrayList < Long > (5); for(Entry < Long, ReplicaRepairStruct > entry : m_replicaRepairStructs.entrySet()) { if(entry.getValue().needs(li.getHandle())) { ++ queued; tmLog.debug(m_whoami + \"repairing \" + entry.getKey() + \". Max seen \" + entry.getValue().m_maxSpHandleSeen + \". Repairing with \" + li.getHandle()); needsRepair.add(entry.getKey()); } } if( ! needsRepair.isEmpty()) { m_mailbox.repairReplicasWith(needsRepair, li); } } tmLog.info(m_whoami + \"finished queuing \" + queued + \" replica repair messages.\"); m_promotionResult.done(m_maxSeenTxnId); } ",
        "test_tgt": "@SuppressWarnings(\"unchecked\")@Test public void testRepairSurvivors() { InitiatorMailbox mailbox = mock(InitiatorMailbox.class); SpPromoteAlgo term = new SpPromoteAlgo(null, mailbox, \"Test\"); SpPromoteAlgo.ReplicaRepairStruct r1 = new SpPromoteAlgo.ReplicaRepairStruct(); r1.m_maxSpHandleSeen = 3L; SpPromoteAlgo.ReplicaRepairStruct r2 = new SpPromoteAlgo.ReplicaRepairStruct(); r2.m_maxSpHandleSeen = 5L; SpPromoteAlgo.ReplicaRepairStruct r3 = new SpPromoteAlgo.ReplicaRepairStruct(); r3.m_maxSpHandleSeen = 2L; term.m_replicaRepairStructs.put(1L, r1); term.m_replicaRepairStructs.put(2L, r2); term.m_replicaRepairStructs.put(3L, r3); long spHandles[] = new long[] { 0L, 1L, 2L, 3L, 4L, 5L }; Iv2RepairLogResponseMessage msgs[] = new Iv2RepairLogResponseMessage[6]; for(int i = 1; i < spHandles.length; ++ i) { msgs[i] = makeResponse(spHandles[i]); term.m_repairLogUnion.add(msgs[i]); } term.repairSurvivors(); List < Long > repair3 = new ArrayList < Long > (); repair3.add(3L); verify(mailbox).repairReplicasWith(repair3, msgs[3].getPayload()); List < Long > repair4And5 = new ArrayList < Long > (); repair4And5.add(1L); repair4And5.add(3L); verify(mailbox).repairReplicasWith(repair4And5, msgs[4].getPayload()); verify(mailbox).repairReplicasWith(repair4And5, msgs[5].getPayload()); verify(mailbox, times(3)).repairReplicasWith(any(repair3.getClass()), any(VoltMessage.class)); } "
    },
    {
        "test_src": "@Test public void createDirectory()throws Exception { AlluxioURI dir = new AlluxioURI(\"/dir\"); CreateDirectoryPOptions createDirectoryOptions = CreateDirectoryPOptions.getDefaultInstance(); doNothing().when(mFileSystemMasterClient).createDirectory(dir, createDirectoryOptions); mFileSystem.createDirectory(dir, createDirectoryOptions); verify(mFileSystemMasterClient).createDirectory(dir, createDirectoryOptions); verifyFilesystemContextAcquiredAndReleased(); } ",
        "focal_tgt": "@POST@Path(PATH_PARAM + CREATE_DIRECTORY)@ReturnType(\"java.lang.Void\")@Consumes(MediaType.APPLICATION_JSON)public Response createDirectory(@PathParam(\"path\")final String path, final CreateDirectoryPOptions options) { return RestUtils.call((RestUtils.RestCallable < Void > )() -> { if(options == null) { mFileSystem.createDirectory(new AlluxioURI(path)); } else { mFileSystem.createDirectory(new AlluxioURI(path), options); } return null; }, ServerConfiguration.global()); } ",
        "focal_src": "@POST@Path(PATH_PARAM + CREATE_DIRECTORY)@ReturnType(\"java.lang.Void\")@Consumes(MediaType.APPLICATION_JSON)public Response createDirectory(@PathParam(\"path\")final String path, final CreateDirectoryPOptions options) { return RestUtils.call(new RestUtils.RestCallable < Void > () { @Override public Void call()throws Exception { if(options == null) { mFileSystem.createDirectory(new AlluxioURI(path), CreateDirectoryPOptions.getDefaultInstance()); } else { mFileSystem.createDirectory(new AlluxioURI(path), options); } return null; } }, ServerConfiguration.global()); } ",
        "test_tgt": "@Test public void createDirectory()throws Exception { AlluxioURI dir = new AlluxioURI(\"/dir\"); CreateDirectoryPOptions createDirectoryOptions = CreateDirectoryPOptions.getDefaultInstance(); doNothing().when(mFileSystemMasterClient).createDirectory(dir, FileSystemOptions.createDirectoryDefaults(mConf).toBuilder().mergeFrom(createDirectoryOptions).build()); mFileSystem.createDirectory(dir, createDirectoryOptions); verify(mFileSystemMasterClient).createDirectory(dir, FileSystemOptions.createDirectoryDefaults(mConf).toBuilder().mergeFrom(createDirectoryOptions).build()); verifyFilesystemContextAcquiredAndReleased(); } "
    },
    {
        "test_src": "@Test public void testGetRepeatMode()throws InterruptedException { final int testRepeatMode = MediaPlaylistAgent.REPEAT_MODE_GROUP; mMockAgent.setRepeatMode(testRepeatMode); final CountDownLatch latch = new CountDownLatch(1); final SessionCallback sessionCallback = new SessionCallback() { @Override public void onRepeatModeChanged(MediaSession2 session, MediaPlaylistAgent playlistAgent, int repeatMode) { assertEquals(mMockAgent, playlistAgent); assertEquals(testRepeatMode, repeatMode); latch.countDown(); } }; try(MediaSession2 session = new MediaSession2.Builder(mContext).setPlayer(mPlayer).setPlaylistAgent(mMockAgent).setId(\"testGetRepeatMode\").setSessionCallback(sHandlerExecutor, sessionCallback).build()) { mMockAgent.notifyRepeatModeChanged(); assertTrue(latch.await(TIMEOUT_MS, TimeUnit.MILLISECONDS)); } } ",
        "focal_tgt": "public@RepeatMode int getRepeatMode() { synchronized(mLock) { return mRepeatMode; } } ",
        "focal_src": "public@RepeatMode int getRepeatMode() { return MediaPlaylistAgent.REPEAT_MODE_NONE; } ",
        "test_tgt": "@Ignore@Test public void testGetRepeatMode()throws InterruptedException { final int testRepeatMode = MediaPlaylistAgent.REPEAT_MODE_GROUP; mMockAgent.setRepeatMode(testRepeatMode); final CountDownLatch latch = new CountDownLatch(1); final SessionCallback sessionCallback = new SessionCallback() { @Override public void onRepeatModeChanged(MediaSession2 session, MediaPlaylistAgent playlistAgent, int repeatMode) { assertEquals(mMockAgent, playlistAgent); assertEquals(testRepeatMode, repeatMode); latch.countDown(); } }; try(MediaSession2 session = new MediaSession2.Builder(mContext).setPlayer(mPlayer).setPlaylistAgent(mMockAgent).setId(\"testGetRepeatMode\").setSessionCallback(sHandlerExecutor, sessionCallback).build()) { mMockAgent.notifyRepeatModeChanged(); assertTrue(latch.await(TIMEOUT_MS, TimeUnit.MILLISECONDS)); } } "
    },
    {
        "test_src": "@Test public void createSession() { when(reactor.process()).thenReturn(true); when(reactor.connectionToHost(connectionHandler.getHostname(), connectionHandler.getProtocolPort(), connectionHandler)).thenReturn(connectionProtonJ); when(connectionProtonJ.session()).thenReturn(session); when(session.attachments()).thenReturn(record); StepVerifier.create(connection.createSession(SESSION_NAME)).assertNext(s -> { Assert.assertNotNull(s); Assert.assertEquals(SESSION_NAME, s.getSessionName()); Assert.assertTrue(s instanceof ReactorSession); Assert.assertSame(session, ((ReactorSession)s).session()); }).verifyComplete(); StepVerifier.create(connection.createSession(SESSION_NAME)).assertNext(s -> { Assert.assertNotNull(s); Assert.assertEquals(SESSION_NAME, s.getSessionName()); Assert.assertTrue(s instanceof ReactorSession); Assert.assertSame(session, ((ReactorSession)s).session()); }).verifyComplete(); verify(record, Mockito.times(1)).set(Handler.class, Handler.class, sessionHandler); } ",
        "focal_tgt": "@Override public Mono < AmqpSession > createSession(String sessionName) { AmqpSession existingSession = sessionMap.get(sessionName); if(existingSession != null) { return Mono.just(existingSession); } return connectionMono.map(connection -> sessionMap.computeIfAbsent(sessionName, key -> { final SessionHandler handler = handlerProvider.createSessionHandler(connectionId, getHost(), sessionName, connectionOptions.getRetry().getTryTimeout()); final Session session = connection.session(); BaseHandler.setHandler(session, handler); return new ReactorSession(session, handler, sessionName, reactorProvider, handlerProvider, getCBSNode(), tokenManagerProvider, connectionOptions.getRetry().getTryTimeout()); })); } ",
        "focal_src": "@Override public Mono < AmqpSession > createSession(String sessionName) { AmqpSession existingSession = sessionMap.get(sessionName); if(existingSession != null) { return Mono.just(existingSession); } return connectionMono.map(connection -> sessionMap.computeIfAbsent(sessionName, key -> { final SessionHandler handler = handlerProvider.createSessionHandler(connectionId, getHost(), sessionName, connectionOptions.getRetry().getTryTimeout()); final Session session = connection.session(); BaseHandler.setHandler(session, handler); return new ReactorSession(session, handler, sessionName, reactorProvider, handlerProvider, getCBSNode(), tokenResourceProvider, connectionOptions.getRetry().getTryTimeout()); })); } ",
        "test_tgt": "@Test public void createSession() { when(reactor.process()).thenReturn(true); when(reactor.connectionToHost(connectionHandler.getHostname(), connectionHandler.getProtocolPort(), connectionHandler)).thenReturn(connectionProtonJ); when(connectionProtonJ.session()).thenReturn(session); when(session.attachments()).thenReturn(record); StepVerifier.create(connection.createSession(SESSION_NAME)).assertNext(s -> { Assert.assertNotNull(s); Assert.assertEquals(SESSION_NAME, s.getSessionName()); Assert.assertTrue(s instanceof ReactorSession); Assert.assertSame(session, ((ReactorSession)s).session()); }).verifyComplete(); StepVerifier.create(connection.createSession(SESSION_NAME)).assertNext(s -> { Assert.assertNotNull(s); Assert.assertEquals(SESSION_NAME, s.getSessionName()); Assert.assertTrue(s instanceof ReactorSession); Assert.assertSame(session, ((ReactorSession)s).session()); }).verifyComplete(); verify(record, Mockito.times(1)).set(Handler.class, Handler.class, sessionHandler); } "
    },
    {
        "test_src": "@Test public void listStatus()throws Exception { AlluxioURI file = new AlluxioURI(\"/file\"); List < URIStatus > infos = new ArrayList < > (); infos.add(new URIStatus(new FileInfo())); ListStatusPOptions listStatusOptions = ListStatusPOptions.getDefaultInstance(); when(mFileSystemMasterClient.listStatus(file, listStatusOptions)).thenReturn(infos); assertSame(infos, mFileSystem.listStatus(file, listStatusOptions)); verify(mFileSystemMasterClient).listStatus(file, listStatusOptions); verifyFilesystemContextAcquiredAndReleased(); } ",
        "focal_tgt": "@POST@Path(PATH_PARAM + LIST_STATUS)@ReturnType(\"java.util.List<alluxio.client.file.URIStatus>\")public Response listStatus(@PathParam(\"path\")final String path, final ListStatusPOptions options) { return RestUtils.call(new RestUtils.RestCallable < List < URIStatus > > () { @Override public List < URIStatus > call()throws Exception { if(options == null) { return mFileSystem.listStatus(new AlluxioURI(path)); } else { return mFileSystem.listStatus(new AlluxioURI(path), options); } } }, ServerConfiguration.global()); } ",
        "focal_src": "@POST@Path(PATH_PARAM + LIST_STATUS)@ReturnType(\"java.util.List<alluxio.client.file.URIStatus>\")public Response listStatus(@PathParam(\"path\")final String path, final ListStatusPOptions options) { return RestUtils.call(new RestUtils.RestCallable < List < URIStatus > > () { @Override public List < URIStatus > call()throws Exception { if(options == null) { return mFileSystem.listStatus(new AlluxioURI(path), ListStatusPOptions.getDefaultInstance()); } else { return mFileSystem.listStatus(new AlluxioURI(path), options); } } }, ServerConfiguration.global()); } ",
        "test_tgt": "@Test public void listStatus()throws Exception { AlluxioURI file = new AlluxioURI(\"/file\"); List < URIStatus > infos = new ArrayList < > (); infos.add(new URIStatus(new FileInfo())); ListStatusPOptions listStatusOptions = ListStatusPOptions.getDefaultInstance(); when(mFileSystemMasterClient.listStatus(file, FileSystemOptions.listStatusDefaults(mConf).toBuilder().mergeFrom(listStatusOptions).build())).thenReturn(infos); assertSame(infos, mFileSystem.listStatus(file, listStatusOptions)); verify(mFileSystemMasterClient).listStatus(file, FileSystemOptions.listStatusDefaults(mConf).toBuilder().mergeFrom(listStatusOptions).build()); verifyFilesystemContextAcquiredAndReleased(); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_doAdjustment() { assertEquals(DayOfWeek.MONDAY.doAdjustment(LocalDate.of(2012, 9, 2)), LocalDate.of(2012, 8, 27)); assertEquals(DayOfWeek.MONDAY.doAdjustment(LocalDate.of(2012, 9, 3)), LocalDate.of(2012, 9, 3)); assertEquals(DayOfWeek.MONDAY.doAdjustment(LocalDate.of(2012, 9, 4)), LocalDate.of(2012, 9, 3)); assertEquals(DayOfWeek.MONDAY.doAdjustment(LocalDate.of(2012, 9, 10)), LocalDate.of(2012, 9, 10)); assertEquals(DayOfWeek.MONDAY.doAdjustment(LocalDate.of(2012, 9, 11)), LocalDate.of(2012, 9, 10)); } ",
        "focal_tgt": "@Override public DateTime doWithAdjustment(DateTime calendrical) { return calendrical.with(DAY_OF_MONTH, dayOfMonth); } ",
        "focal_src": "@Override public DateTime doAdjustment(DateTime calendrical) { return calendrical.with(DAY_OF_MONTH, dayOfMonth); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_doAdjustment() { assertEquals(DayOfWeek.MONDAY.doWithAdjustment(LocalDate.of(2012, 9, 2)), LocalDate.of(2012, 8, 27)); assertEquals(DayOfWeek.MONDAY.doWithAdjustment(LocalDate.of(2012, 9, 3)), LocalDate.of(2012, 9, 3)); assertEquals(DayOfWeek.MONDAY.doWithAdjustment(LocalDate.of(2012, 9, 4)), LocalDate.of(2012, 9, 3)); assertEquals(DayOfWeek.MONDAY.doWithAdjustment(LocalDate.of(2012, 9, 10)), LocalDate.of(2012, 9, 10)); assertEquals(DayOfWeek.MONDAY.doWithAdjustment(LocalDate.of(2012, 9, 11)), LocalDate.of(2012, 9, 10)); } "
    },
    {
        "test_src": "@Test public void testGetApplicationsForCommand()throws GenieException { Assert.assertEquals(1, this.service.getApplicationsForCommand(COMMAND_1_ID).stream().filter(application -> APP_1_ID.equals(application.getId().orElseThrow(IllegalArgumentException :: new))).count()); } ",
        "focal_tgt": "@GetMapping(value = \"/{id}/applications\", produces = MediaTypes.HAL_JSON_VALUE)@ResponseStatus(HttpStatus.OK)public List < ApplicationResource > getApplicationsForCommand(@PathVariable(\"id\")final String id)throws GenieException { log.debug(\"Called with id {}\", id); return this.commandService.getApplicationsForCommand(id).stream().map(DtoAdapters :: toV3Application).map(this.applicationResourceAssembler :: toResource).collect(Collectors.toList()); } ",
        "focal_src": "@GetMapping(value = \"/{id}/applications\", produces = MediaTypes.HAL_JSON_VALUE)@ResponseStatus(HttpStatus.OK)public List < ApplicationResource > getApplicationsForCommand(@PathVariable(\"id\")final String id)throws GenieException { log.debug(\"Called with id {}\", id); return this.commandService.getApplicationsForCommand(id).stream().map(this.applicationResourceAssembler :: toResource).collect(Collectors.toList()); } ",
        "test_tgt": "@Test public void testGetApplicationsForCommand()throws GenieException { Assert.assertEquals(1, this.service.getApplicationsForCommand(COMMAND_1_ID).stream().filter(application -> APP_1_ID.equals(application.getId())).count()); } "
    },
    {
        "test_src": "@Test public void testApplyDeltaToLaterStockCandidates() { final Candidate earlierCandidate; final Candidate candidate; final Candidate evenLaterCandidate; final Candidate evenLaterCandidateWithDifferentWarehouse; { final MaterialDescriptor materialDescr = MaterialDescriptor.builder().productDescriptor(createProductDescriptor()).warehouseId(WAREHOUSE_ID).quantity(new BigDecimal(\"10\")).date(t2).build(); candidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(materialDescr).build(); candidateRepository.addOrUpdateOverwriteStoredSeqNo(candidate); final MaterialDescriptor earlierMaterialDescr = materialDescr.withDate(t1); earlierCandidate = candidateRepository.addOrUpdateOverwriteStoredSeqNo(Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(earlierMaterialDescr).build()); final MaterialDescriptor laterMaterialDescr = materialDescr.withDate(t3); final Candidate laterCandidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(laterMaterialDescr).build(); candidateRepository.addOrUpdateOverwriteStoredSeqNo(laterCandidate); final MaterialDescriptor evenLatermaterialDescr = materialDescr.withQuantity(new BigDecimal(\"12\")).withDate(t4); evenLaterCandidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(evenLatermaterialDescr).build(); candidateRepository.addOrUpdateOverwriteStoredSeqNo(evenLaterCandidate); final MaterialDescriptor evenLatermaterialDescrWithDifferentWarehouse = evenLatermaterialDescr.withWarehouseId(OTHER_WAREHOUSE_ID); evenLaterCandidateWithDifferentWarehouse = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(evenLatermaterialDescrWithDifferentWarehouse).build(); candidateRepository.addOrUpdateOverwriteStoredSeqNo(evenLaterCandidateWithDifferentWarehouse); } stockCandidateService.applyDeltaToLaterStockCandidates(createProductDescriptor(), WAREHOUSE_ID, t2, earlierCandidate.getGroupId(), new BigDecimal(\"3\")); DispoTestUtils.retrieveAllRecords().forEach(r -> assertThat(r.getMD_Candidate_GroupId(), greaterThan(0))); final Candidate earlierCandidateAfterChange = candidateRepository.retrieveLatestMatchOrNull(mkStockUntilSegment(t1, WAREHOUSE_ID)); assertThat(earlierCandidateAfterChange).isNotNull(); assertThat(earlierCandidateAfterChange.getQuantity()).isEqualTo(earlierCandidate.getQuantity()); assertThat(earlierCandidateAfterChange.getGroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate candidateRecordAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t2).get(0); assertThat(candidateRecordAfterChange.getQty()).isEqualByComparingTo(\"10\"); assertThat(candidateRecordAfterChange.getMD_Candidate_GroupId(), not(is(earlierCandidate.getGroupId()))); final Candidate laterCandidateAfterChange = candidateRepository.retrieveLatestMatchOrNull(mkStockUntilSegment(t3, WAREHOUSE_ID)); assertThat(laterCandidateAfterChange).isNotNull(); assertThat(laterCandidateAfterChange.getQuantity()).isEqualByComparingTo(\"13\"); assertThat(laterCandidateAfterChange.getGroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate evenLaterCandidateRecordAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t4, PRODUCT_ID, WAREHOUSE_ID).get(0); assertThat(evenLaterCandidateRecordAfterChange.getQty()).isEqualByComparingTo(\"15\"); assertThat(evenLaterCandidateRecordAfterChange.getMD_Candidate_GroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate evenLaterCandidateWithDifferentWarehouseAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t4, PRODUCT_ID, OTHER_WAREHOUSE_ID).get(0); assertThat(evenLaterCandidateWithDifferentWarehouseAfterChange.getQty()).isEqualByComparingTo(\"12\"); assertThat(evenLaterCandidateWithDifferentWarehouseAfterChange.getMD_Candidate_GroupId(), not(is(earlierCandidate.getGroupId()))); } ",
        "focal_tgt": "@VisibleForTesting void applyDeltaToLaterStockCandidates(@NonNull final ProductDescriptor productDescriptor, @NonNull final Integer warehouseId, @NonNull final Date date, @NonNull final Integer groupId, @NonNull final BigDecimal delta) { final CandidatesQuery segment = CandidatesQuery.builder().type(CandidateType.STOCK).materialDescr(MaterialDescriptor.builderForQuery().date(date).productDescriptor(productDescriptor).warehouseId(warehouseId).dateOperator(DateOperator.AFTER).build()).build(); final List < Candidate > candidatesToUpdate = candidateRepository.retrieveOrderedByDateAndSeqNo(segment); for(final Candidate candidate : candidatesToUpdate) { final BigDecimal newQty = candidate.getQuantity().add(delta); candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(candidate.withQuantity(newQty).withGroupId(groupId)); } } ",
        "focal_src": "@VisibleForTesting void applyDeltaToLaterStockCandidates(@NonNull final ProductDescriptor productDescriptor, @NonNull final Integer warehouseId, @NonNull final Date date, @NonNull final Integer groupId, @NonNull final BigDecimal delta) { final CandidatesQuery segment = CandidatesQuery.builder().type(CandidateType.STOCK).materialDescr(MaterialDescriptor.builderForQuery().date(date).productDescriptor(productDescriptor).warehouseId(warehouseId).dateOperator(DateOperator.AFTER).build()).build(); final List < Candidate > candidatesToUpdate = candidateRepository.retrieveOrderedByDateAndSeqNo(segment); for(final Candidate candidate : candidatesToUpdate) { final BigDecimal newQty = candidate.getQuantity().add(delta); candidateRepository.addOrUpdateOverwriteStoredSeqNo(candidate.withQuantity(newQty).withGroupId(groupId)); } } ",
        "test_tgt": "@Test public void testApplyDeltaToLaterStockCandidates() { final Candidate earlierCandidate; final Candidate candidate; final Candidate evenLaterCandidate; final Candidate evenLaterCandidateWithDifferentWarehouse; { final MaterialDescriptor materialDescr = MaterialDescriptor.builder().complete(true).productDescriptor(createProductDescriptor()).warehouseId(WAREHOUSE_ID).quantity(new BigDecimal(\"10\")).date(t2).build(); candidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(materialDescr).build(); candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(candidate); final MaterialDescriptor earlierMaterialDescr = materialDescr.withDate(t1); earlierCandidate = candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(earlierMaterialDescr).build()); final MaterialDescriptor laterMaterialDescr = materialDescr.withDate(t3); final Candidate laterCandidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(laterMaterialDescr).build(); candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(laterCandidate); final MaterialDescriptor evenLatermaterialDescr = materialDescr.withQuantity(new BigDecimal(\"12\")).withDate(t4); evenLaterCandidate = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(evenLatermaterialDescr).build(); candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(evenLaterCandidate); final MaterialDescriptor evenLatermaterialDescrWithDifferentWarehouse = evenLatermaterialDescr.withWarehouseId(OTHER_WAREHOUSE_ID); evenLaterCandidateWithDifferentWarehouse = Candidate.builder().type(CandidateType.STOCK).clientId(org.getAD_Client_ID()).orgId(org.getAD_Org_ID()).materialDescr(evenLatermaterialDescrWithDifferentWarehouse).build(); candidateRepositoryCommands.addOrUpdateOverwriteStoredSeqNo(evenLaterCandidateWithDifferentWarehouse); } stockCandidateService.applyDeltaToLaterStockCandidates(createProductDescriptor(), WAREHOUSE_ID, t2, earlierCandidate.getGroupId(), new BigDecimal(\"3\")); DispoTestUtils.retrieveAllRecords().forEach(r -> assertThat(r.getMD_Candidate_GroupId(), greaterThan(0))); final Candidate earlierCandidateAfterChange = candidateRepository.retrieveLatestMatchOrNull(mkStockUntilSegment(t1, WAREHOUSE_ID)); assertThat(earlierCandidateAfterChange).isNotNull(); assertThat(earlierCandidateAfterChange.getQuantity()).isEqualTo(earlierCandidate.getQuantity()); assertThat(earlierCandidateAfterChange.getGroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate candidateRecordAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t2).get(0); assertThat(candidateRecordAfterChange.getQty()).isEqualByComparingTo(\"10\"); assertThat(candidateRecordAfterChange.getMD_Candidate_GroupId(), not(is(earlierCandidate.getGroupId()))); final Candidate laterCandidateAfterChange = candidateRepository.retrieveLatestMatchOrNull(mkStockUntilSegment(t3, WAREHOUSE_ID)); assertThat(laterCandidateAfterChange).isNotNull(); assertThat(laterCandidateAfterChange.getQuantity()).isEqualByComparingTo(\"13\"); assertThat(laterCandidateAfterChange.getGroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate evenLaterCandidateRecordAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t4, PRODUCT_ID, WAREHOUSE_ID).get(0); assertThat(evenLaterCandidateRecordAfterChange.getQty()).isEqualByComparingTo(\"15\"); assertThat(evenLaterCandidateRecordAfterChange.getMD_Candidate_GroupId()).isEqualTo(earlierCandidate.getGroupId()); final I_MD_Candidate evenLaterCandidateWithDifferentWarehouseAfterChange = DispoTestUtils.filter(CandidateType.STOCK, t4, PRODUCT_ID, OTHER_WAREHOUSE_ID).get(0); assertThat(evenLaterCandidateWithDifferentWarehouseAfterChange.getQty()).isEqualByComparingTo(\"12\"); assertThat(evenLaterCandidateWithDifferentWarehouseAfterChange.getMD_Candidate_GroupId(), not(is(earlierCandidate.getGroupId()))); } "
    },
    {
        "test_src": "@Test public void convolve() { Kernel2D_I32 kernel = FactoryKernel.random2D_I32(7, 3, 0, 20, rand); kernel.offset = 1; ImageUInt8 input = new ImageUInt8(15, 16); ImageMiscOps.fillUniform(input, rand, 0, 50); ImageUInt8 output = new ImageUInt8(15, 16); ConvolveNormalizedNaive.convolve(kernel, input, output); for(int y = 0; y < output.height; y ++ ) { for(int x = 0; x < output.width; x ++ ) { int expected = convolve(x, y, kernel, input); int found = output.get(x, y); assertEquals(x + \" \" + y, expected, found); } } } ",
        "focal_tgt": "public static void convolve(Kernel2D_F32 kernel, GrayF32 image, GrayF32 dest, int skip) { checkParameters(image, dest, skip); if(kernel.width >= image.width) { ConvolveDownNormalizedNaive.convolve(kernel, image, dest, skip); } else { ConvolveDownNoBorder.convolve(kernel, image, dest, skip); ConvolveDownNormalized_JustBorder.convolve(kernel, image, dest, skip); } } ",
        "focal_src": "public static void convolve(Kernel2D_F32 kernel, ImageFloat32 image, ImageFloat32 dest, int skip) { checkParameters(image, dest, skip); if(kernel.width >= image.width) { ConvolveDownNormalizedNaive.convolve(kernel, image, dest, skip); } else { ConvolveDownNoBorder.convolve(kernel, image, dest, skip); ConvolveDownNormalized_JustBorder.convolve(kernel, image, dest, skip); } } ",
        "test_tgt": "@Test public void convolve() { Kernel2D_I32 kernel = FactoryKernel.random2D_I32(7, 3, 0, 20, rand); kernel.offset = 1; GrayU8 input = new GrayU8(15, 16); ImageMiscOps.fillUniform(input, rand, 0, 50); GrayU8 output = new GrayU8(15, 16); ConvolveNormalizedNaive.convolve(kernel, input, output); for(int y = 0; y < output.height; y ++ ) { for(int x = 0; x < output.width; x ++ ) { int expected = convolve(x, y, kernel, input); int found = output.get(x, y); assertEquals(x + \" \" + y, expected, found); } } } "
    },
    {
        "test_src": "@Test public void testGetReferenceBeans() { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(TestBean.class); ReferenceAnnotationBeanPostProcessor beanPostProcessor = context.getBean(BEAN_NAME, ReferenceAnnotationBeanPostProcessor.class); Collection < ReferenceBean < ? > > referenceBeans = beanPostProcessor.getReferenceBeans(); Assert.assertEquals(3, referenceBeans.size()); ReferenceBean < ? > referenceBean = referenceBeans.iterator().next(); TestBean testBean = context.getBean(TestBean.class); Assert.assertEquals(referenceBean.get(), testBean.getDemoServiceFromAncestor()); Assert.assertEquals(referenceBean.get(), testBean.getDemoServiceFromParent()); Assert.assertEquals(referenceBean.get(), testBean.getDemoService()); } ",
        "focal_tgt": "public Collection < ReferenceBean < ? > > getReferenceBeans() { return referenceBeanCache.values(); } ",
        "focal_src": "public Collection < ReferenceBean < ? > > getReferenceBeans() { return this.referenceBeansCache.values(); } ",
        "test_tgt": "@Test public void testGetReferenceBeans() { ReferenceAnnotationBeanPostProcessor beanPostProcessor = context.getBean(BEAN_NAME, ReferenceAnnotationBeanPostProcessor.class); Collection < ReferenceBean < ? > > referenceBeans = beanPostProcessor.getReferenceBeans(); Assert.assertEquals(1, referenceBeans.size()); ReferenceBean < ? > referenceBean = referenceBeans.iterator().next(); TestBean testBean = context.getBean(TestBean.class); Assert.assertNotNull(referenceBean.get()); } "
    },
    {
        "test_src": "@Test public void toOriginal() { String hexStringUpperCase = \"5B7B2264617465223A313333343037323035323038312C2273696D706C65536B75436F6D6D616E64223A7B22636F6465223A223331373830392D313030222C22666F625069726365223A323139392C226964223A353636372C226C6973745072696365223A323139392C226E616D65223A2241495220464F52434520312048494748204C5558204D4158204149522027303820515320E7A9BAE5869BE4B880E58FB7EFBC88E99990E9878FE58F91E594AEEFBC89227D7D5D\"; hexStringUpperCase = \"5B7B22636F6465223A224B3034383031222C226964223A3730302C226E616D65223A22E697B6E5B09AE6ACBEE992A5E58C99E689A3227D2C7B22636F6465223A2231333433363143222C226964223A35362C226E616D65223A22E58AB2E985B7E688B7E5A496436875636B205461796C6F7220416C6C2053746172204261636B205A6970227D5D\"; byte[]hexBytesToBytes = ByteUtil.hexBytesToBytes(hexStringUpperCase.getBytes()); LOGGER.info(new String(hexBytesToBytes)); LOGGER.info(StringUtil.toOriginal(hexStringUpperCase)); } ",
        "focal_tgt": "@Deprecated public static String toOriginal(String hexStringUpperCase, String charsetName) { byte[]hexBytesToBytes = ByteUtil.hexBytesToBytes(hexStringUpperCase.getBytes()); String original = newString(hexBytesToBytes, charsetName); LOGGER.debug(\"hexStringUpperCase:[{}],original:[{}]\", hexStringUpperCase, original); return original; } ",
        "focal_src": "@Deprecated public static String toOriginal(String hexStringUpperCase, String charsetName) { byte[]hexBytesToBytes = ByteUtil.hexBytesToBytes(hexStringUpperCase.getBytes()); String original = newString(hexBytesToBytes, charsetName); LOGGER.debug(\"hexStringUpperCase:{},original:{}\", hexStringUpperCase, original); return original; } ",
        "test_tgt": "@Test public void toOriginal() { String hexStringUpperCase = \"5B7B2264617465223A313333343037323035323038312C2273696D706C65536B75436F6D6D616E64223A7B22636F6465223A223331373830392D313030222C22666F625069726365223A323139392C226964223A353636372C226C6973745072696365223A323139392C226E616D65223A2241495220464F52434520312048494748204C5558204D4158204149522027303820515320E7A9BAE5869BE4B880E58FB7EFBC88E99990E9878FE58F91E594AEEFBC89227D7D5D\"; hexStringUpperCase = \"5B7B22636F6465223A224B3034383031222C226964223A3730302C226E616D65223A22E697B6E5B09AE6ACBEE992A5E58C99E689A3227D2C7B22636F6465223A2231333433363143222C226964223A35362C226E616D65223A22E58AB2E985B7E688B7E5A496436875636B205461796C6F7220416C6C2053746172204261636B205A6970227D5D\"; byte[]hexBytesToBytes = ByteUtil.hexBytesToBytes(hexStringUpperCase.getBytes()); LOGGER.info(new String(hexBytesToBytes)); LOGGER.info(StringUtil.toOriginal(hexStringUpperCase, CharsetType.UTF8)); } "
    },
    {
        "test_src": "@Test public void refreshToken_expiredAccessToken() { refreshToken(\"expired-access-token\", \"refresh-token\", \"auth-code\"); verify(authStore).setLoggedIn(true); verify(listener).onNewAuthToken(argThat(hasProperty(\"accessToken\", is(\"refreshed-access-token\")))); verify(listener).onNewAuthToken(argThat(hasProperty(\"refreshToken\", is(\"refresh-token\")))); } ",
        "focal_tgt": "private void refreshToken(String accessToken, String refreshToken, String authCode) { Retrofit retrofit = GhostApiUtils.getRetrofit(\"http://blog.com\", Helpers.getProdHttpClient()); MockRetrofit mockRetrofit = Helpers.getMockRetrofit(retrofit, Helpers.getIdealNetworkBehavior()); BehaviorDelegate < GhostApiService > delegate = mockRetrofit.create(GhostApiService.class); GhostApiService api = new MockGhostApiService(delegate, true); when(credSource.getGhostAuthCode(any())).thenReturn(Observable.just(authCode)); AuthToken token = new AuthToken(); token.setAccessToken(accessToken); token.setRefreshToken(refreshToken); AuthService authService = new AuthService(api, credSource, credSink); authService.listen(listener); authService.refreshToken(token); } ",
        "focal_src": "private void refreshToken(String accessToken, String refreshToken, String authCode) { Retrofit retrofit = GhostApiUtils.getRetrofit(\"http://blog.com\", Helpers.getProdHttpClient()); MockRetrofit mockRetrofit = Helpers.getMockRetrofit(retrofit, Helpers.getIdealNetworkBehavior()); BehaviorDelegate < GhostApiService > delegate = mockRetrofit.create(GhostApiService.class); GhostApiService api = new MockGhostApiService(delegate, true); when(credSource.getGhostAuthCode(any())).thenReturn(Observable.just(authCode)); AuthToken token = new AuthToken(); token.setAccessToken(accessToken); token.setRefreshToken(refreshToken); AuthService authService = new AuthService(api, credSource, authStore); authService.listen(listener); authService.refreshToken(token); } ",
        "test_tgt": "@Test public void refreshToken_expiredAccessToken() { refreshToken(\"expired-access-token\", \"refresh-token\", \"auth-code\"); verify(credSink).setLoggedIn(true); verify(listener).onNewAuthToken(argThat(hasProperty(\"accessToken\", is(\"refreshed-access-token\")))); verify(listener).onNewAuthToken(argThat(hasProperty(\"refreshToken\", is(\"refresh-token\")))); } "
    },
    {
        "test_src": "@Test public void testCreateSSLEngineFactory()throws Exception { Configuration serverConfig = new Configuration(); serverConfig.setBoolean(SecurityOptions.SSL_ENABLED, true); serverConfig.setString(SecurityOptions.SSL_KEYSTORE, \"src/test/resources/local127.keystore\"); serverConfig.setString(SecurityOptions.SSL_KEYSTORE_PASSWORD, \"password\"); serverConfig.setString(SecurityOptions.SSL_KEY_PASSWORD, \"password\"); serverConfig.setString(SecurityOptions.SSL_PROTOCOL, \"TLSv1\"); serverConfig.setString(SecurityOptions.SSL_ALGORITHMS, \"TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA256\"); final SSLEngineFactory serverSSLEngineFactory = SSLUtils.createServerSSLEngineFactory(serverConfig); final SSLEngine sslEngine = serverSSLEngineFactory.createSSLEngine(); assertThat(Arrays.asList(sslEngine.getEnabledProtocols()), contains(\"TLSv1\")); assertThat(Arrays.asList(sslEngine.getEnabledCipherSuites()), containsInAnyOrder(\"TLS_DHE_RSA_WITH_AES_128_CBC_SHA\", \"TLS_DHE_RSA_WITH_AES_128_CBC_SHA256\")); } ",
        "focal_tgt": "public static SSLEngineFactory createRestServerSSLEngineFactory(final Configuration config)throws Exception { SSLContext sslContext = createRestServerSSLContext(config); if(sslContext == null) { throw new IllegalConfigurationException(\"SSL is not enabled for REST endpoints.\"); } return new SSLEngineFactory(sslContext, getEnabledProtocols(config), getEnabledCipherSuites(config), false); } ",
        "focal_src": "private static SSLEngineFactory createSSLEngineFactory(final Configuration config, final boolean clientMode)throws Exception { final SSLContext sslContext = clientMode ? createSSLClientContext(config) : createSSLServerContext(config); checkState(sslContext != null, \"%s it not enabled\", SecurityOptions.SSL_ENABLED.key()); return new SSLEngineFactory(sslContext, getEnabledProtocols(config), getEnabledCipherSuites(config), clientMode); } ",
        "test_tgt": "@Test public void testCreateSSLEngineFactory()throws Exception { Configuration serverConfig = createInternalSslConfigWithKeyAndTrustStores(); serverConfig.setString(SecurityOptions.SSL_PROTOCOL, \"TLSv1\"); serverConfig.setString(SecurityOptions.SSL_ALGORITHMS, \"TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA256\"); final SSLEngineFactory serverSSLEngineFactory = SSLUtils.createInternalServerSSLEngineFactory(serverConfig); final SSLEngine sslEngine = serverSSLEngineFactory.createSSLEngine(); assertEquals(1, sslEngine.getEnabledProtocols().length); assertEquals(\"TLSv1\", sslEngine.getEnabledProtocols()[0]); assertEquals(2, sslEngine.getEnabledCipherSuites().length); assertThat(sslEngine.getEnabledCipherSuites(), arrayContainingInAnyOrder(\"TLS_DHE_RSA_WITH_AES_128_CBC_SHA\", \"TLS_DHE_RSA_WITH_AES_128_CBC_SHA256\")); } "
    },
    {
        "test_src": "@Test public void addEdge_nodesNotInGraph() { graph.addNode(N1); assertTrue(graph.addEdge(E15, N1, N5)); assertTrue(graph.addEdge(E41, N4, N1)); assertTrue(graph.addEdge(E23, N2, N3)); assertThat(graph.nodes()).containsExactly(N1, N5, N4, N2, N3).inOrder(); assertThat(graph.edges()).containsExactly(E15, E41, E23).inOrder(); assertThat(graph.edgesConnecting(N1, N5)).containsExactly(E15); assertThat(graph.edgesConnecting(N4, N1)).containsExactly(E41); assertThat(graph.edgesConnecting(N2, N3)).containsExactly(E23); assertThat(graph.edgesConnecting(N3, N2)).isEmpty(); } ",
        "focal_tgt": "@CanIgnoreReturnValue boolean addEdge(String e, Integer n1, Integer n2) { network.addNode(n1); network.addNode(n2); return network.addEdge(e, n1, n2); } ",
        "focal_src": "@CanIgnoreReturnValue boolean addEdge(String e, Integer n1, Integer n2) { graph.addNode(n1); graph.addNode(n2); return graph.addEdge(e, n1, n2); } ",
        "test_tgt": "@Test public void addEdge_nodesNotInGraph() { network.addNode(N1); assertTrue(network.addEdge(E15, N1, N5)); assertTrue(network.addEdge(E41, N4, N1)); assertTrue(network.addEdge(E23, N2, N3)); assertThat(network.nodes()).containsExactly(N1, N5, N4, N2, N3).inOrder(); assertThat(network.edges()).containsExactly(E15, E41, E23).inOrder(); assertThat(network.edgesConnecting(N1, N5)).containsExactly(E15); assertThat(network.edgesConnecting(N4, N1)).containsExactly(E41); assertThat(network.edgesConnecting(N2, N3)).containsExactly(E23); assertThat(network.edgesConnecting(N3, N2)).isEmpty(); } "
    },
    {
        "test_src": "@Test public void gaussian() { for(int totalOrder = 1; totalOrder <= 4; totalOrder ++ ) { for(int orderX = 0; orderX <= totalOrder; orderX ++ ) { int orderY = totalOrder - orderX; SteerableKernel < Kernel2D_F32 > alg = FactorySteerable.gaussian(Kernel2D_F32.class, orderX, orderY, 10); Kernel2D_F32 k = alg.compute(0.1); boolean notZero = false; for(int y = 0; y < k.width; y ++ ) { for(int x = 0; x < k.width; x ++ ) { if(k.get(x, y) != 0)notZero = true; } } assertTrue(notZero); } } } ",
        "focal_tgt": "public static < K extends Kernel2D > SteerableKernel < K > gaussian(Class < K > kernelType, int orderX, int orderY, double sigma, int radius) { if(orderX < 0 || orderX > 4)throw new IllegalArgumentException(\"derivX must be from 0 to 4 inclusive.\"); if(orderY < 0 || orderY > 4)throw new IllegalArgumentException(\"derivT must be from 0 to 4 inclusive.\"); int order = orderX + orderY; if(order > 4) { throw new IllegalArgumentException(\"The total order of x and y can't be greater than 4\"); } int maxOrder = Math.max(orderX, orderY); if(sigma <= 0)sigma = (float)FactoryKernelGaussian.sigmaForRadius(radius, maxOrder); else if(radius <= 0)radius = FactoryKernelGaussian.radiusForSigma(sigma, maxOrder); Class kernel1DType = FactoryKernel.get1DType(kernelType); Kernel1D kerX = FactoryKernelGaussian.derivativeK(kernel1DType, orderX, sigma, radius); Kernel1D kerY = FactoryKernelGaussian.derivativeK(kernel1DType, orderY, sigma, radius); Kernel2D kernel = GKernelMath.convolve(kerY, kerX); Kernel2D[]basis = new Kernel2D[order + 1]; ImageBase image = GKernelMath.convertToImage(kernel); ImageBase imageRotated = image._createNew(image.width, image.height); float centerX = image.width / 2; float centerY = image.height / 2; basis[0] = kernel; double angleStep = Math.PI / basis.length; for(int index = 1; index <= order; index ++ ) { float angle = (float)(angleStep * index); GeneralizedImageOps.fill(imageRotated, 0); DistortImageOps.rotate(image, imageRotated, TypeInterpolate.BILINEAR, centerX, centerY, angle); basis[index] = GKernelMath.convertToKernel(imageRotated); } SteerableKernel < K > ret; if(kernelType == Kernel2D_F32.class)ret = (SteerableKernel < K > )new SteerableKernel_F32(); else ret = (SteerableKernel < K > )new SteerableKernel_I32(); ret.setBasis(FactorySteerCoefficients.polynomial(order), basis); return ret; } ",
        "focal_src": "public static < K extends Kernel2D > SteerableKernel < K > gaussian(Class < K > kernelType, int orderX, int orderY, int radius) { if(orderX < 0 || orderX > 4)throw new IllegalArgumentException(\"derivX must be from 0 to 4 inclusive.\"); if(orderY < 0 || orderY > 4)throw new IllegalArgumentException(\"derivT must be from 0 to 4 inclusive.\"); int order = orderX + orderY; if(order > 4) { throw new IllegalArgumentException(\"The total order of x and y can't be greater than 4\"); } int maxOrder = Math.max(orderX, orderY); float sigma = (float)FactoryKernelGaussian.sigmaForRadius(radius, maxOrder); Class kernel1DType = FactoryKernel.get1DType(kernelType); Kernel1D kerX = FactoryKernelGaussian.derivativeK(kernel1DType, orderX, sigma, radius); Kernel1D kerY = FactoryKernelGaussian.derivativeK(kernel1DType, orderY, sigma, radius); Kernel2D kernel = GKernelMath.convolve(kerY, kerX); Kernel2D[]basis = new Kernel2D[order + 1]; ImageBase image = GKernelMath.convertToImage(kernel); ImageBase imageRotated = image._createNew(image.width, image.height); float centerX = image.width / 2; float centerY = image.height / 2; basis[0] = kernel; double angleStep = Math.PI / basis.length; for(int index = 1; index <= order; index ++ ) { float angle = (float)(angleStep * index); GeneralizedImageOps.fill(imageRotated, 0); DistortImageOps.rotate(image, imageRotated, TypeInterpolate.BILINEAR, centerX, centerY, angle); basis[index] = GKernelMath.convertToKernel(imageRotated); } SteerableKernel < K > ret; if(kernelType == Kernel2D_F32.class)ret = (SteerableKernel < K > )new SteerableKernel_F32(); else ret = (SteerableKernel < K > )new SteerableKernel_I32(); ret.setBasis(FactorySteerCoefficients.polynomial(order), basis); return ret; } ",
        "test_tgt": "@Test public void gaussian() { for(int totalOrder = 1; totalOrder <= 4; totalOrder ++ ) { for(int orderX = 0; orderX <= totalOrder; orderX ++ ) { int orderY = totalOrder - orderX; SteerableKernel < Kernel2D_F32 > alg = FactorySteerable.gaussian(Kernel2D_F32.class, orderX, orderY, - 1, 10); Kernel2D_F32 k = alg.compute(0.1); boolean notZero = false; for(int y = 0; y < k.width; y ++ ) { for(int x = 0; x < k.width; x ++ ) { if(k.get(x, y) != 0)notZero = true; } } assertTrue(notZero); } } } "
    },
    {
        "test_src": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = TestUtils.getConfig(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler instance = new Modeler(dbName, conf); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); trainingParameters.setModelerClass(MultinomialNaiveBayes.class); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); trainingParameters.setDataTransformerClass(DummyXMinMaxNormalizer.class); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorClass(null); trainingParameters.setFeatureSelectorTrainingParameters(null); instance.fit(trainingData, trainingParameters); MultinomialNaiveBayes.ValidationMetrics vm = (MultinomialNaiveBayes.ValidationMetrics)instance.validate(trainingData); instance.setValidationMetrics(vm); double expResult2 = 0.8; Assert.assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); logger.info(\"validate\"); instance = new Modeler(dbName, conf); instance.validate(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); trainingData.delete(); validationData.delete(); } ",
        "focal_tgt": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(Class < ML > modelerClass, ML.AbstractTrainingParameters modelerTrainingParameters, Class < FS > featureSelectorClass, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = Configuration.getConfiguration(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier instance = new TextClassifier(dbName, conf); TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerClass(modelerClass); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerClass(null); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorClass(featureSelectorClass); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); trainingParameters.setTextExtractorClass(NgramsExtractor.class); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); instance.fit(dataset, trainingParameters); ValidationMetrics vm = instance.validate(dataset); instance.setValidationMetrics(vm); assertEquals(expectedF1score, ((AbstractClassifier.AbstractValidationMetrics)vm).getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = new TextClassifier(dbName, conf); Dataframe validationData = null; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "focal_src": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(Class < ML > modelerClass, ML.AbstractTrainingParameters modelerTrainingParameters, Class < FS > featureSelectorClass, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score) { Configuration conf = TestUtils.getConfig(); String dbName = this.getClass().getSimpleName(); Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier instance = new TextClassifier(dbName, conf); TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerClass(modelerClass); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerClass(null); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorClass(featureSelectorClass); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); trainingParameters.setTextExtractorClass(NgramsExtractor.class); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); instance.fit(dataset, trainingParameters); ValidationMetrics vm = instance.validate(dataset); instance.setValidationMetrics(vm); assertEquals(expectedF1score, ((AbstractClassifier.AbstractValidationMetrics)vm).getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = new TextClassifier(dbName, conf); Dataframe validationData = null; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.delete(); } ",
        "test_tgt": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration conf = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(conf); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String dbName = this.getClass().getSimpleName(); Modeler instance = new Modeler(dbName, conf); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); trainingParameters.setModelerClass(MultinomialNaiveBayes.class); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); trainingParameters.setDataTransformerClass(DummyXMinMaxNormalizer.class); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorClass(null); trainingParameters.setFeatureSelectorTrainingParameters(null); instance.fit(trainingData, trainingParameters); MultinomialNaiveBayes.ValidationMetrics vm = (MultinomialNaiveBayes.ValidationMetrics)instance.validate(trainingData); instance.setValidationMetrics(vm); double expResult2 = 0.8; Assert.assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); logger.info(\"validate\"); instance = new Modeler(dbName, conf); instance.validate(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); trainingData.delete(); validationData.delete(); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_previous() { assertEquals(QuarterOfYear.Q1.previous(), QuarterOfYear.Q4); assertEquals(QuarterOfYear.Q2.previous(), QuarterOfYear.Q1); assertEquals(QuarterOfYear.Q3.previous(), QuarterOfYear.Q2); assertEquals(QuarterOfYear.Q4.previous(), QuarterOfYear.Q3); } ",
        "focal_tgt": "public QuarterOfYear minus(long quarters) { return plus( - (quarters % 4)); } ",
        "focal_src": "public QuarterOfYear previous() { return roll( - 1); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_plus_long_unitMultiples() { for(int i = 1; i <= 4; i ++ ) { assertEquals(QuarterOfYear.of(i).plus(1, YEARS), QuarterOfYear.of(i)); assertEquals(QuarterOfYear.of(i).plus(1, DECADES), QuarterOfYear.of(i)); assertEquals(QuarterOfYear.of(i).plus(1, CENTURIES), QuarterOfYear.of(i)); assertEquals(QuarterOfYear.of(i).plus(1, MILLENNIA), QuarterOfYear.of(i)); } } "
    },
    {
        "test_src": "@Test public void setAttributeTest()throws Exception { mFileSystemMaster.create(NESTED_FILE_URI, sNestedFileOptions); mFileSystemMaster.setAttribute(NESTED_FILE_URI, SetAttributeOptions.defaults()); Assert.assertEquals(1, mCounters.get(MasterSource.SET_ATTRIBUTE_OPS).getCount()); } ",
        "focal_tgt": "public void setAttribute(AlluxioURI path, SetAttributeOptions options)throws FileDoesNotExistException, AccessControlException, InvalidPathException { MasterContext.getMasterSource().incSetAttributeOps(1); boolean rootRequired = options.getOwner() != null; boolean ownerRequired = (options.getGroup() != null) || (options.getPermission() != Constants.INVALID_PERMISSION); synchronized(mInodeTree) { mPermissionChecker.checkSetAttributePermission(path, rootRequired, ownerRequired); long fileId = mInodeTree.getInodeByPath(path).getId(); long opTimeMs = System.currentTimeMillis(); Inode < ? > targetInode = mInodeTree.getInodeByPath(path); if(options.isRecursive() && targetInode.isDirectory()) { List < Inode < ? > > inodeChildren = mInodeTree.getInodeChildrenRecursive((InodeDirectory)targetInode); for(Inode < ? > inode : inodeChildren) { mPermissionChecker.checkSetAttributePermission(mInodeTree.getPath(inode), rootRequired, ownerRequired); } for(Inode < ? > inode : inodeChildren) { long id = inode.getId(); setAttributeInternal(id, opTimeMs, options); journalSetAttribute(id, opTimeMs, options); } } setAttributeInternal(fileId, opTimeMs, options); journalSetAttribute(fileId, opTimeMs, options); } } ",
        "focal_src": "public void setAttribute(AlluxioURI path, SetAttributeOptions options)throws FileDoesNotExistException, AccessControlException, InvalidPathException { MasterContext.getMasterSource().incSetAttributeOps(1); boolean rootRequired = options.getOwner() != null; boolean ownerRequired = (options.getGroup() != null) || (options.getPermission() != Constants.INVALID_PERMISSION); synchronized(mInodeTree) { checkSetAttributePermission(path, rootRequired, ownerRequired); long fileId = mInodeTree.getInodeByPath(path).getId(); long opTimeMs = System.currentTimeMillis(); Inode < ? > targetInode = mInodeTree.getInodeByPath(path); if(options.isRecursive() && targetInode.isDirectory()) { List < Inode < ? > > inodeChildren = mInodeTree.getInodeChildrenRecursive((InodeDirectory)targetInode); for(Inode < ? > inode : inodeChildren) { checkSetAttributePermission(mInodeTree.getPath(inode), rootRequired, ownerRequired); } for(Inode < ? > inode : inodeChildren) { long id = inode.getId(); setAttributeInternal(id, opTimeMs, options); journalSetAttribute(id, opTimeMs, options); } } setAttributeInternal(fileId, opTimeMs, options); journalSetAttribute(fileId, opTimeMs, options); } } ",
        "test_tgt": "@Test public void setAttributeTest()throws Exception { mFileSystemMaster.createFile(NESTED_FILE_URI, sNestedFileOptions); mFileSystemMaster.setAttribute(NESTED_FILE_URI, SetAttributeOptions.defaults()); Assert.assertEquals(1, mCounters.get(MasterSource.SET_ATTRIBUTE_OPS).getCount()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should compare when patient and identifier and type is null\", method = \"equals(Object)\")public void equals_shouldCompareWhenPatientAndIdentifierAndTypeIsNull()throws Exception { Patient patient = new Patient(); PatientIdentifier second = new PatientIdentifier(); second.setIdentifier(\"EXAMPLE IDENTIFIER\"); second.setPatient(patient); second.setIdentifierType(new PatientIdentifierType(1)); PatientIdentifier first = new PatientIdentifier(); Assert.assertNull(first.getPatient()); Assert.assertNull(first.getIdentifier()); Assert.assertNull(first.getIdentifierType()); Assert.assertFalse(first + \" and \" + second + \" should not equal.\", second.equals(first)); first.setIdentifier(\"EXAMPLE IDENTIFIER\"); first.setPatient(patient); first.setIdentifierType(new PatientIdentifierType(1)); Assert.assertTrue(first + \" and \" + second + \" should be equal.\", second.equals(first)); } ",
        "focal_tgt": "@Override public boolean equals(Object obj) { if(obj instanceof ConceptComplex) { ConceptComplex c = (ConceptComplex)obj; return(this.getConceptId().equals(c.getConceptId())); } else if(obj instanceof Concept) { return OpenmrsUtil.nullSafeEquals(((Concept)obj).getConceptId(), this.getConceptId()); } return obj == this; } ",
        "focal_src": "@Override public boolean equals(Object obj) { if(obj instanceof ConceptComplex) { ConceptComplex c = (ConceptComplex)obj; return(this.getConceptId().equals(c.getConceptId())); } else if(obj instanceof Concept) { if(obj.equals(this))return true; } return obj == this; } ",
        "test_tgt": "@Test@Verifies(value = \"should compare when patient and identifier and type is null\", method = \"equals(Object)\")public void equals_shouldCompareWhenPatientAndIdentifierAndTypeIsNull()throws Exception { Patient patient = new Patient(); PatientIdentifier second = new PatientIdentifier(); second.setIdentifier(\"EXAMPLE IDENTIFIER\"); second.setPatient(patient); second.setIdentifierType(new PatientIdentifierType(1)); PatientIdentifier first = new PatientIdentifier(); Assert.assertNull(first.getPatient()); Assert.assertNull(first.getIdentifier()); Assert.assertNull(first.getIdentifierType()); Assert.assertFalse(first + \" and \" + second + \" should not equal.\", second.equals(first)); } "
    },
    {
        "test_src": "@Test public void function() { String func = query(_INSPECT_FUNCTION.args(\" true#0\")); query(func + \"/@name/data()\", \"true\"); query(func + \"/@uri/data()\", \"http://www.w3.org/2005/xpath-functions\"); query(func + \"/return/@type/data()\", \"xs:boolean\"); query(func + \"/return/@occurrence/data()\", \"\"); func = query(_INSPECT_FUNCTION.args(\" map { }\")); query(func + \"/@name/data()\", \"\"); query(func + \"/@uri/data()\", \"\"); query(func + \"/argument/@type/data()\", \"xs:anyAtomicType\"); query(func + \"/return/@type/data()\", \"item()\"); query(func + \"/return/@occurrence/data()\", \"*\"); func = query(_INSPECT_FUNCTION.args(\" function($a as xs:int) as xs:integer { $a + 1 }\")); query(func + \"/@name/data()\", \"\"); query(func + \"/@uri/data()\", \"\"); query(func + \"/argument/@name/data()\", \"\"); query(func + \"/argument/@type/data()\", \"xs:int\"); query(func + \"/return/@type/data()\", \"xs:integer\"); query(func + \"/return/@occurrence/data()\", \"\"); func = query(\"declare %private function Q{U}f($v as xs:int) as xs:integer {$v};\" + _INSPECT_FUNCTION.args(\" Q{U}f#1\")); query(func + \"/@name/data()\", \"f\"); query(func + \"/@uri/data()\", \"U\"); query(func + \"/argument/@name/data()\", \"v\"); query(func + \"/argument/@type/data()\", \"xs:int\"); query(func + \"/annotation/@name/data()\", \"private\"); query(func + \"/annotation/@uri/data()\", \"http://www.w3.org/2012/xquery\"); query(func + \"/return/@type/data()\", \"xs:integer\"); query(func + \"/return/@occurrence/data()\", \"\"); query(_INSPECT_FUNCTION.args(\" %db:f function() {()}\") + \"/annotation/@name = 'db:f'\", \"true\"); } ",
        "focal_tgt": "private Expr function(final QNm name, final Expr ... exprs)throws QueryException { final InputInfo ii = info(); final ExprList argList = new ExprList().add(exprs); final int[]holes = argumentList(argList, name.string()); final Expr[]args = argList.finish(); alter = FUNCUNKNOWN_X; alterFunc = name; alterPos = pos; final Expr ret; if(holes != null) { final int card = args.length + holes.length; final Expr lit = Functions.getLiteral(name, card, qc, sc, ii, false); final Expr f = lit != null ? lit : unknownLit(name, card, ii); ret = new PartFunc(sc, ii, f, args, holes); if(lit != null && (lit instanceof XQFunctionExpr ? ((XQFunctionExpr)f).annotations() : ((FuncLit)lit).annotations()).contains(Annotation.UPDATING))qc.updating(); } else { final TypedFunc f = Functions.get(name, args, qc, sc, ii); if(f == null) { ret = null; } else { if(f.anns.contains(Annotation.UPDATING))qc.updating(); ret = f.fun; } } if(ret != null)alter = null; return ret; } ",
        "focal_src": "private Expr function(final QNm name, final Expr ... exprs)throws QueryException { final InputInfo ii = info(); final ExprList argList = new ExprList().add(exprs); final int[]holes = argumentList(argList, name.string()); final Expr[]args = argList.finish(); alter = FUNCUNKNOWN_X; alterFunc = name; alterPos = pos; final Expr ret; if(holes != null) { final int card = args.length + holes.length; final Expr lit = Functions.getLiteral(name, card, qc, sc, ii, false); final Expr f = lit != null ? lit : unknownLit(name, card, ii); ret = new PartFunc(sc, ii, f, args, holes); if(lit != null && (lit instanceof XQFunctionExpr ? ((XQFunctionExpr)f).annotations() : ((FuncLit)lit).annotations()).contains(Ann.Q_UPDATING))qc.updating(); } else { final TypedFunc f = Functions.get(name, args, qc, sc, ii); if(f == null) { ret = null; } else { if(f.ann.contains(Ann.Q_UPDATING))qc.updating(); ret = f.fun; } } if(ret != null)alter = null; return ret; } ",
        "test_tgt": "@Test public void function() { String func = query(_INSPECT_FUNCTION.args(\" true#0\")); query(func + \"/@name/data()\", \"true\"); query(func + \"/@uri/data()\", \"http://www.w3.org/2005/xpath-functions\"); query(func + \"/return/@type/data()\", \"xs:boolean\"); query(func + \"/return/@occurrence/data()\", \"\"); func = query(_INSPECT_FUNCTION.args(\" map { }\")); query(func + \"/@name/data()\", \"\"); query(func + \"/@uri/data()\", \"\"); query(func + \"/argument/@type/data()\", \"xs:anyAtomicType\"); query(func + \"/return/@type/data()\", \"item()\"); query(func + \"/return/@occurrence/data()\", \"*\"); func = query(_INSPECT_FUNCTION.args(\" function($a as xs:int) as xs:integer { $a + 1 }\")); query(func + \"/@name/data()\", \"\"); query(func + \"/@uri/data()\", \"\"); query(func + \"/argument/@name/data()\", \"\"); query(func + \"/argument/@type/data()\", \"xs:int\"); query(func + \"/return/@type/data()\", \"xs:integer\"); query(func + \"/return/@occurrence/data()\", \"\"); func = query(\"declare %private function Q{U}f($v as xs:int) as xs:integer {$v};\" + _INSPECT_FUNCTION.args(\" Q{U}f#1\")); query(func + \"/@name/data()\", \"f\"); query(func + \"/@uri/data()\", \"U\"); query(func + \"/argument/@name/data()\", \"v\"); query(func + \"/argument/@type/data()\", \"xs:int\"); query(func + \"/annotation/@name/data()\", \"private\"); query(func + \"/annotation/@uri/data()\", \"http://www.w3.org/2012/xquery\"); query(func + \"/return/@type/data()\", \"xs:integer\"); query(func + \"/return/@occurrence/data()\", \"\"); query(\"declare namespace x='x';\" + _INSPECT_FUNCTION.args(\" %x:x function() {()}\") + \"/annotation\", \"\"); } "
    },
    {
        "test_src": "@Test public void testGetNeighborsND() { defaultSetup(); initSP(); int[]result = sp.getNeighborsND(new SparseBinaryMatrix < Column > (new int[] { 9, 5 }), 2, 3, true); int[]expected = new int[] { 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44 }; for(int i = 0; i < result.length; i ++ ) { assertEquals(expected[i], result[i]); } System.out.println(ArrayUtils.print1DArray(result)); } ",
        "focal_tgt": "public < M extends SparseMatrix > int[]getNeighborsND(M poolerMem, int columnIndex, int radius, boolean wrapAround) { int[]columnCoords = poolerMem.computeCoordinates(columnIndex); List < int[] > dimensionCoords = new ArrayList < int[] > (); for(int i = 0; i < inputDimensions.length; i ++ ) { int[]range = ArrayUtils.range(columnCoords[i] - radius, columnCoords[i] + radius + 1); int[]curRange = new int[range.length]; if(wrapAround) { for(int j = 0; j < curRange.length; j ++ ) { curRange[j] = (int)ArrayUtils.positiveRemainder(range[j], inputDimensions[i]); } } else { curRange = range; } dimensionCoords.add(ArrayUtils.unique(curRange)); } List < TIntList > neighborList = ArrayUtils.dimensionsToCoordinateList(dimensionCoords); TIntList neighbors = new TIntArrayList(neighborList.size()); for(int i = 0; i < neighborList.size(); i ++ ) { int flatIndex = poolerMem.computeIndex(neighborList.get(i).toArray()); if(flatIndex == columnIndex)continue; neighbors.add(flatIndex); } return neighbors.toArray(); } ",
        "focal_src": "public int[]getNeighborsND(SparseMatrix < Column > poolerMem, int columnIndex, int radius, boolean wrapAround) { int[]columnCoords = poolerMem.computeCoordinates(columnIndex); List < int[] > dimensionCoords = new ArrayList < int[] > (); for(int i = 0; i < inputDimensions.length; i ++ ) { int[]range = ArrayUtils.range(columnCoords[0] - radius, columnCoords[0] + radius + 1); int[]curRange = new int[range.length]; if(wrapAround) { for(int j = 0; j < curRange.length; j ++ ) { curRange[j] = (int)ArrayUtils.positiveRemainder(range[j], inputDimensions[i]); } } else { curRange = range; } dimensionCoords.add(ArrayUtils.unique(curRange)); } List < TIntList > neighborList = ArrayUtils.dimensionsToCoordinateList(dimensionCoords); TIntList neighbors = new TIntArrayList(neighborList.size()); for(int i = 0; i < neighborList.size(); i ++ ) { int flatIndex = poolerMem.computeIndex(neighborList.get(i).toArray()); if(flatIndex == columnIndex)continue; neighbors.add(flatIndex); } return neighbors.toArray(); } ",
        "test_tgt": "@Test public void testGetNeighborsND() { defaultSetup(); parameters.setInputDimensions(new int[] { 9, 5 }); initSP(); int[]result = sp.getNeighborsND(new SparseBinaryMatrix(new int[] { 9, 5 }), 2, 3, true); int[]expected = new int[] { 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44 }; for(int i = 0; i < result.length; i ++ ) { assertEquals(expected[i], result[i]); } defaultSetup(); parameters.setInputDimensions(new int[] { 5, 7, 2 }); initSP(); int[]dimensions = new int[] { 5, 7, 2 }; SparseBinaryMatrix layout = new SparseBinaryMatrix(dimensions); int radius = 1; int x = 1; int y = 3; int z = 2; int columnIndex = layout.computeIndex(new int[] { z, y, x }); int[]neighbors = sp.getNeighborsND(layout, columnIndex, radius, true); String expect = \"[18, 19, 20, 21, 22, 23, 32, 33, 34, 36, 37, 46, 47, 48, 49, 50, 51]\"; assertEquals(expect, ArrayUtils.print1DArray(neighbors)); } "
    },
    {
        "test_src": "@Test public void testValidate()throws GenieException { this.validate(this.c); } ",
        "focal_tgt": "public < E > void validate(final E entity) { final Set < ConstraintViolation < E > > violations = validator.validate(entity); if( ! violations.isEmpty()) { throw new ConstraintViolationException(violations); } } ",
        "focal_src": "public < E > void validate(final E entity)throws GenieException { genieValidator.validate(entity); } ",
        "test_tgt": "@Test public void testValidate() { this.validate(this.c); } "
    },
    {
        "test_src": "@Test public void mount()throws Exception { AlluxioURI alluxioPath = new AlluxioURI(\"/t\"); AlluxioURI ufsPath = new AlluxioURI(\"/u\"); MountOptions mountOptions = MountOptions.defaults(); doNothing().when(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); mFileSystem.mount(alluxioPath, ufsPath, mountOptions); verify(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); verifyFilesystemContextAcquiredAndReleased(); } ",
        "focal_tgt": "void mount(AlluxioURI alluxioPath, AlluxioURI ufsPath, MountPOptions options)throws IOException, AlluxioException; ",
        "focal_src": "void mount(AlluxioURI alluxioPath, AlluxioURI ufsPath, MountOptions options)throws IOException, AlluxioException; ",
        "test_tgt": "@Test public void mount()throws Exception { AlluxioURI alluxioPath = new AlluxioURI(\"/t\"); AlluxioURI ufsPath = new AlluxioURI(\"/u\"); MountPOptions mountOptions = MountPOptions.getDefaultInstance(); doNothing().when(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); mFileSystem.mount(alluxioPath, ufsPath, mountOptions); verify(mFileSystemMasterClient).mount(alluxioPath, ufsPath, mountOptions); verifyFilesystemContextAcquiredAndReleased(); } "
    },
    {
        "test_src": "@Test public void fullView_Transform() { IntrinsicParameters param = new IntrinsicParameters().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 0.05); PointTransform_F32 adjToDist = LensDistortionOps.fullView(param, null, true); PointTransform_F32 distToAdj = LensDistortionOps.fullView(param, null, false); checkBorderOutside(adjToDist, distToAdj); param = new IntrinsicParameters().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial( - 0.1, - 0.05); adjToDist = LensDistortionOps.fullView(param, null, true); distToAdj = LensDistortionOps.fullView(param, null, false); checkBorderOutside(adjToDist, distToAdj); } ",
        "focal_tgt": "private static PointTransform_F64 adjustmentTransform_F64(IntrinsicParameters param, IntrinsicParameters paramAdj, boolean adjToDistorted, PointTransform_F64 remove_p_to_p, DenseMatrix64F A) { DenseMatrix64F A_inv = null; if( ! adjToDistorted || paramAdj != null) { A_inv = new DenseMatrix64F(3, 3); if( ! CommonOps.invert(A, A_inv)) { throw new RuntimeException(\"Failed to invert adjustment matrix. Probably bad.\"); } } if(paramAdj != null) { PerspectiveOps.adjustIntrinsic(param, A_inv, paramAdj); } if(adjToDistorted) { PointTransform_F64 add_p_to_p = distortTransform(param).distort_F64(true, true); PointTransformHomography_F64 adjust = new PointTransformHomography_F64(A); return new SequencePointTransform_F64(adjust, add_p_to_p); } else { PointTransformHomography_F64 adjust = new PointTransformHomography_F64(A_inv); return new SequencePointTransform_F64(remove_p_to_p, adjust); } } ",
        "focal_src": "public static PointTransform_F32 fullView(IntrinsicParameters param, IntrinsicParameters paramAdj, boolean adjToDistorted) { PointTransform_F32 remove_p_to_p = distortTransform(param).undistort_F32(true, true); RectangleLength2D_F32 bound = DistortImageOps.boundBox_F32(param.width, param.height, new PointToPixelTransform_F32(remove_p_to_p)); double scaleX = bound.width / param.width; double scaleY = bound.height / param.height; double scale = Math.max(scaleX, scaleY); double deltaX = bound.x0; double deltaY = bound.y0; DenseMatrix64F A = new DenseMatrix64F(3, 3, true, scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1); return adjustmentTransform(param, paramAdj, adjToDistorted, remove_p_to_p, A); } ",
        "test_tgt": "@Test public void transform_F32_fullView() { IntrinsicParameters param = new IntrinsicParameters().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 0.05); PointTransform_F32 adjToDist = LensDistortionOps.transform_F32(AdjustmentType.FULL_VIEW, param, null, true); PointTransform_F32 distToAdj = LensDistortionOps.transform_F32(AdjustmentType.FULL_VIEW, param, null, false); checkBorderOutside(adjToDist, distToAdj); param = new IntrinsicParameters().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial( - 0.1, - 0.05); adjToDist = LensDistortionOps.transform_F32(AdjustmentType.FULL_VIEW, param, null, true); distToAdj = LensDistortionOps.transform_F32(AdjustmentType.FULL_VIEW, param, null, false); checkBorderOutside(adjToDist, distToAdj); } "
    },
    {
        "test_src": "@Test(expected = APIException.class)@Verifies(value = \"should throw error when privilege is core privilege\", method = \"purgePrivilege(Privilege)\")public void purgePrivilege_shouldThrowErrorWhenPrivilegeIsCorePrivilege()throws Exception { Context.getUserService().purgePrivilege(new Privilege(OpenmrsConstants.PRIV_ADD_COHORTS)); } ",
        "focal_tgt": "@Authorized( { PrivilegeConstants.PURGE_PRIVILEGES })public void purgePrivilege(Privilege privilege)throws APIException; ",
        "focal_src": "@Authorized( { OpenmrsConstants.PRIV_PURGE_PRIVILEGES })public void purgePrivilege(Privilege privilege)throws APIException; ",
        "test_tgt": "@Test(expected = APIException.class)@Verifies(value = \"should throw error when privilege is core privilege\", method = \"purgePrivilege(Privilege)\")public void purgePrivilege_shouldThrowErrorWhenPrivilegeIsCorePrivilege()throws Exception { Context.getUserService().purgePrivilege(new Privilege(PrivilegeConstants.ADD_COHORTS)); } "
    },
    {
        "test_src": "@Test public void testSolve() { System.out.println(\"solve\"); double[][]A = { { 0.9000, 0.4000, 0.0000 }, { 0.4000, 0.5000, 0.3000 }, { 0.0000, 0.3000, 0.8000 } }; double[]b = { 0.5, 0.5, 0.5 }; LUDecomposition lu = new LUDecomposition(A); double[]x = new double[b.length]; lu.solve(b, x); BandMatrix instance = new BandMatrix(3, 1, 1); for(int i = 0; i < A.length; i ++ ) { for(int j = 0; j < A[i].length; j ++ )if(A[i][j] != 0.0)instance.set(i, j, A[i][j]); } instance.decompose(); double[]result = new double[b.length]; instance.solve(b, result); assertEquals(result.length, x.length); for(int i = 0; i < x.length; i ++ ) { assertEquals(result[i], x[i], 1E-7); } instance.improve(b, result); for(int i = 0; i < x.length; i ++ ) { assertEquals(result[i], x[i], 1E-15); } } ",
        "focal_tgt": "public void solve(double[]b) { int m = lu.nrows(); int n = lu.ncols(); if(m != n) { throw new UnsupportedOperationException(\"The matrix is not square.\"); } if(b.length != m) { throw new IllegalArgumentException(String.format(\"Row dimensions do not agree: A is %d x %d, but b is %d x 1\", lu.nrows(), lu.ncols(), b.length)); } if(isSingular()) { throw new RuntimeException(\"Matrix is singular.\"); } double[]x = new double[b.length]; for(int i = 0; i < m; i ++ ) { x[i] = b[piv[i]]; } for(int k = 0; k < n; k ++ ) { for(int i = k + 1; i < n; i ++ ) { x[i] -= x[k] * lu.get(i, k); } } for(int k = n - 1; k >= 0; k -- ) { x[k] /= lu.get(k, k); for(int i = 0; i < k; i ++ ) { x[i] -= x[k] * lu.get(i, k); } } for(int i = 0; i < m; i ++ ) { b[i] = x[i]; } } ",
        "focal_src": "public void solve(double[]b) { solve(b.clone(), b); } ",
        "test_tgt": "@Test public void testSolve() { System.out.println(\"solve\"); double[][]A = { { 0.9000, 0.4000, 0.0000 }, { 0.4000, 0.5000, 0.3000 }, { 0.0000, 0.3000, 0.8000 } }; double[]b = { 0.5, 0.5, 0.5 }; DenseMatrix a = Matrix.newInstance(A); LU lu = a.lu(); double[]x = b.clone(); lu.solve(x); BandMatrix instance = new BandMatrix(3, 1, 1); for(int i = 0; i < A.length; i ++ ) { for(int j = 0; j < A[i].length; j ++ )if(A[i][j] != 0.0)instance.set(i, j, A[i][j]); } instance.decompose(); double[]result = new double[b.length]; instance.solve(b, result); assertEquals(result.length, x.length); for(int i = 0; i < x.length; i ++ ) { assertEquals(result[i], x[i], 1E-7); } instance.improve(b, result); for(int i = 0; i < x.length; i ++ ) { assertEquals(result[i], x[i], 1E-15); } } "
    },
    {
        "test_src": "@Test public void testTerminateAllConnections()throws SQLException { expect(mockConnectionHandles.poll()).andReturn(mockConnection).times(2).andReturn(null).once(); mockConnection.internalClose(); expectLastCall().once().andThrow(new SQLException()).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); replay(mockConnectionsScheduler, mockKeepAliveScheduler, mockPartition, mockConnectionHandles, mockConnection); testClass.terminateAllConnections(); verify(mockConnectionsScheduler, mockKeepAliveScheduler, mockPartition, mockConnectionHandles, mockConnection); } ",
        "focal_tgt": "protected void terminateAllConnections() { for(int i = 0; i < this.partitionCount; i ++ ) { ConnectionHandle conn; while((conn = this.partitions[i].getFreeConnections().poll()) != null) { postDestroyConnection(conn); try { conn.internalClose(); } catch(SQLException e) { logger.error(e); } } } } ",
        "focal_src": "protected void terminateAllConnections() { for(int i = 0; i < this.partitionCount; i ++ ) { ConnectionHandle conn; while((conn = this.partitions[i].getFreeConnections().poll()) != null) { this.partitions[i].updateCreatedConnections( - 1); try { conn.internalClose(); } catch(SQLException e) { logger.error(e); } } this.partitions[i].setUnableToCreateMoreTransactions(false); } } ",
        "test_tgt": "@Test public void testTerminateAllConnections()throws SQLException { expect(mockConnectionHandles.poll()).andReturn(mockConnection).times(2).andReturn(null).once(); mockConnection.internalClose(); expectLastCall().once().andThrow(new SQLException()).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition).anyTimes(); replay(mockConnectionsScheduler, mockKeepAliveScheduler, mockPartition, mockConnectionHandles, mockConnection); testClass.terminateAllConnections(); verify(mockConnectionsScheduler, mockKeepAliveScheduler, mockPartition, mockConnectionHandles, mockConnection); } "
    },
    {
        "test_src": "@Test public void getLogSchemaVersionsByApplicationIdTest()throws Exception { LogSchemaDto logSchemaDto = createLogSchema(); SchemaVersions schemaVersions = client.getSchemaVersionsByApplicationId(logSchemaDto.getApplicationId()); List < SchemaDto > found = schemaVersions.getLogSchemaVersions(); Assert.assertEquals(2, found.size()); } ",
        "focal_tgt": "List < VersionDto > getLogSchemaVersionsByApplicationId(String applicationId)throws ControlServiceException; ",
        "focal_src": "List < SchemaDto > getLogSchemaVersionsByApplicationId(String applicationId)throws ControlServiceException; ",
        "test_tgt": "@Test public void getLogSchemaVersionsByApplicationIdTest()throws Exception { LogSchemaDto logSchemaDto = createLogSchema(); SchemaVersions schemaVersions = client.getSchemaVersionsByApplicationId(logSchemaDto.getApplicationId()); List < VersionDto > found = schemaVersions.getLogSchemaVersions(); Assert.assertEquals(2, found.size()); } "
    },
    {
        "test_src": "@Test public void testGeoPos() { doReturn(Arrays.asList(new Object[] { geoCoordinates })).when(nativeConnection).exec(); super.testGeoPos(); } ",
        "focal_tgt": "@Override public List < Point > geoPos(byte[]key, byte[] ... members) { List < Point > result = delegate.geoPos(key, members); if(isFutureConversion()) { addResultConverter(identityConverter); } return result; } ",
        "focal_src": "@Override public List < GeoCoordinate > geoPos(byte[]key, byte[] ... members) { List < GeoCoordinate > result = delegate.geoPos(key, members); if(isFutureConversion()) { addResultConverter(identityConverter); } return result; } ",
        "test_tgt": "@Test public void testGeoPos() { doReturn(Arrays.asList(points)).when(nativeConnection).exec(); super.testGeoPos(); } "
    },
    {
        "test_src": "@Test public void boundary() { run(\"geo:boundary(<gml:Polygon><gml:outerBoundaryIs><gml:LinearRing>\" + \"<gml:coordinates>11,11 18,11 18,18 11,18 11,11</gml:coordinates>\" + \"</gml:LinearRing></gml:outerBoundaryIs></gml:Polygon>)\", \"<gml:LineString xmlns:gml=\\\"http://www.opengis.net/gml\\\">\" + \"<gml:coordinates>11.0,11.0 18.0,11.0 18.0,18.0 11.0,18.0 \" + \"11.0,11.0</gml:coordinates></gml:LineString>\"); run(\"geo:boundary(\" + \"<gml:Point><gml:coordinates>2,3</gml:coordinates></gml:Point>)\", \"<gml:MultiGeometry xmlns:gml=\\\"http://www.opengis.net/gml\\\"/>\"); error(\"geo:boundary(text {'a'})\", FUNTYPE.qname()); error(\"geo:boundary(a)\", NOCTX.qname()); error(\"geo:boundary(<gml:geo/>)\", GeoErrors.qname(1)); error(\"geo:boundary(<gml:Point><gml:pos>1 2</gml:pos></gml:Point>)\", GeoErrors.qname(2)); } ",
        "focal_tgt": "private byte[]boundary(final String ct)throws QueryException { int i = ct.toLowerCase(Locale.ENGLISH).indexOf(BOUNDARY_IS); if(i == - 1)throw HC_REQ_X.get(info, \"No separation boundary specified\"); String b = ct.substring(i + BOUNDARY_IS.length()); if(b.charAt(0) == '\"') { i = b.lastIndexOf('\"'); b = b.substring(1, i); } return token(b); } ",
        "focal_src": "private byte[]boundary(final String ct)throws QueryException { int i = ct.toLowerCase(Locale.ENGLISH).indexOf(BOUNDARY_IS); if(i == - 1)throw HC_REQ.get(info, \"No separation boundary specified\"); String b = ct.substring(i + BOUNDARY_IS.length()); if(b.charAt(0) == '\"') { i = b.lastIndexOf('\"'); b = b.substring(1, i); } return token(b); } ",
        "test_tgt": "@Test public void boundary() { run(\"geo:boundary(<gml:Polygon><gml:outerBoundaryIs><gml:LinearRing>\" + \"<gml:coordinates>11,11 18,11 18,18 11,18 11,11</gml:coordinates>\" + \"</gml:LinearRing></gml:outerBoundaryIs></gml:Polygon>)\", \"<gml:LineString xmlns:gml=\\\"http://www.opengis.net/gml\\\">\" + \"<gml:coordinates>11.0,11.0 18.0,11.0 18.0,18.0 11.0,18.0 \" + \"11.0,11.0</gml:coordinates></gml:LineString>\"); run(\"geo:boundary(\" + \"<gml:Point><gml:coordinates>2,3</gml:coordinates></gml:Point>)\", \"<gml:MultiGeometry xmlns:gml=\\\"http://www.opengis.net/gml\\\"/>\"); error(\"geo:boundary(text {'a'})\", EXPTYPE_X_X_X.qname()); error(\"geo:boundary(a)\", NOCTX_X.qname()); error(\"geo:boundary(<gml:geo/>)\", GeoErrors.qname(1)); error(\"geo:boundary(<gml:Point><gml:pos>1 2</gml:pos></gml:Point>)\", GeoErrors.qname(2)); } "
    },
    {
        "test_src": "@Test public void query() { contains(_CLIENT_EXECUTE.args(conn(), new ShowUsers()), S_USERINFO[0]); query(\"let $a := \" + conn() + \", $b := \" + conn() + \" return \" + _CLIENT_QUERY.args(\"$a\", \"1\") + '+' + _CLIENT_QUERY.args(\"$b\", \"2\"), \"3\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; $a*2\\\"\", \" map { 'a': 1 }\"), \"2\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; count($a)\\\"\", \" map { 'a': () }\"), \"0\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; count($a)\\\"\", \" map { 'a': (1 to 5) }\"), \"5\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; $a\\\"\", \" map { 'a': (1,<a/>,'a') }\"), \"1\\n<a/>\\na\"); error(_CLIENT_QUERY.args(conn(), \"x\"), NOCTX_X); } ",
        "focal_tgt": "void query(final String path)throws IOException { final HTTPContext http = session.http; context.options.set(MainOptions.QUERYPATH, path); context.options.set(MainOptions.SERIALIZER, http.sopts()); http.initResponse(); for(final Command cmd : cmds) { if(cmd instanceof XQuery) { final XQuery xq = (XQuery)cmd; if(value != null)xq.bind(null, value, NodeType.DOC.toString()); xq.http(http); for(final Entry < String, String[] > e : vars.entrySet()) { final String key = e.getKey(); final String[]val = e.getValue(); if(val.length == 2)xq.bind(key, val[0], val[1]); if(val.length == 1)xq.bind(key, val[0]); } http.sopts().assign(xq.parameters(context)); http.initResponse(); } run(cmd, http.res.getOutputStream()); } } ",
        "focal_src": "void query(final String path)throws IOException { final HTTPContext http = session.http; context.options.set(MainOptions.QUERYPATH, path); context.options.set(MainOptions.SERIALIZER, http.sopts()); http.initResponse(); for(final Command cmd : cmds) { if(cmd instanceof XQuery) { final XQuery xq = (XQuery)cmd; if(value != null)xq.bind(null, value, NodeType.DOC.toString()); xq.http(http); for(final Entry < String, String[] > e : vars.entrySet()) { final String key = e.getKey(); final String[]val = e.getValue(); if(val.length == 2)xq.bind(key, val[0], val[1]); if(val.length == 1)xq.bind(key, val[0]); } http.sopts().parse(xq.parameters(context)); http.initResponse(); } run(cmd, http.res.getOutputStream()); } } ",
        "test_tgt": "@Test public void query() { contains(_CLIENT_EXECUTE.args(conn(), new ShowUsers()), S_USERINFO[0]); query(\"let $a := \" + conn() + \", $b := \" + conn() + \" return \" + _CLIENT_QUERY.args(\"$a\", \"1\") + '+' + _CLIENT_QUERY.args(\"$b\", \"2\"), \"3\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; $a*2\\\"\", \" map { 'a': 1 }\"), \"2\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; count($a)\\\"\", \" map { 'a': () }\"), \"0\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare variable $a external; count($a)\\\"\", \" map { 'a': (1 to 5) }\"), \"5\"); query(_CLIENT_QUERY.args(conn(), \"\\\"declare context item external; .\\\"\", \" map { '': (1,<a/>,'a') }\"), \"1\\n<a/>\\na\"); query(_CLIENT_QUERY.args(conn(), \"\\\"xs:hexBinary('41')\\\"\"), \"A\"); query(_CLIENT_QUERY.args(conn(), \"\\\"xs:base64Binary('QQ==')\\\"\"), \"A\"); query(_CLIENT_QUERY.args(conn(), \"\\\"\" + SerializerOptions.METHOD.arg(\"text\") + \"<xml/>\\\"\"), \"<xml/>\"); query(_CLIENT_QUERY.args(conn(), \"\\\"\" + SerializerOptions.ENCODING.arg(\"US-ASCII\") + \"''\\\"\"), \"\"); query(_CLIENT_QUERY.args(conn(), \"\\\"xs:base64Binary('QQ==')\\\"\"), \"A\"); error(_CLIENT_QUERY.args(conn(), \"\\\"function(){}\\\"\"), BXCL_FITEM_X); error(_CLIENT_QUERY.args(conn(), \"true#0\"), BXCL_FITEM_X); error(_CLIENT_QUERY.args(conn(), \"[]\"), BXCL_FITEM_X); error(_CLIENT_QUERY.args(conn(), \"map{}\"), BXCL_FITEM_X); error(_CLIENT_QUERY.args(conn(), \"x\"), NOCTX_X); } "
    },
    {
        "test_src": "@Test public void testInAbbrevJournalNames_case1()throws Exception { String input = \"Nature\"; List < OffsetPosition > journalsPositions = target.inAbbrevJournalNames(input); assertNotNull(journalsPositions); assertThat(journalsPositions, hasSize(1)); assertThat(journalsPositions.get(0).start, is(0)); } ",
        "focal_tgt": "public List < OffsetPosition > tokenPositionsAbbrevJournalNames(List < LayoutToken > s) { if(abbrevJournalPattern == null) { initJournals(); } List < OffsetPosition > results = abbrevJournalPattern.matchLayoutToken(s); return results; } ",
        "focal_src": "public List < OffsetPosition > inAbbrevJournalNames(String s) { if(abbrevJournalPattern == null) { initJournals(); } List < OffsetPosition > results = abbrevJournalPattern.matcher(s); return results; } ",
        "test_tgt": "@Test public void testInAbbrevJournalNames_case1()throws Exception { String input = \"Nature\"; List < OffsetPosition > journalsPositions = target.tokenPositionsAbbrevJournalNames(input); assertNotNull(journalsPositions); assertThat(journalsPositions, hasSize(1)); assertThat(journalsPositions.get(0).start, is(0)); } "
    },
    {
        "test_src": "@Ignore@Test public void testListDir()throws IOException, Exception { FileOperationService.MkdirRequest request = new FileOperationService.MkdirRequest(); request.path = \"/tmp1\"; fileBrowserService.fileOps().mkdir(request, httpHeaders, uriInfo); Response response = fileBrowserService.fileOps().listdir(\"/\", httpHeaders, uriInfo); JSONArray statuses = (JSONArray)response.getEntity(); System.out.println(response.getEntity()); Assert.assertEquals(200, response.getStatus()); Assert.assertTrue(statuses.size() > 0); System.out.println(statuses); } ",
        "focal_tgt": "@GET@Path(\"/listdir\")@Produces(MediaType.APPLICATION_JSON)public Response listdir(@QueryParam(\"path\")String path)throws Exception { try { return Response.ok(HdfsApi.fileStatusToJSON(getApi(context).listdir(path))).build(); } catch(FileNotFoundException ex) { return Response.ok(Response.Status.NOT_FOUND.getStatusCode()).entity(ex.getMessage()).build(); } catch(Throwable ex) { throw new Exception(ex.getMessage()); } } ",
        "focal_src": "@GET@Path(\"/listdir\")@Produces(MediaType.APPLICATION_JSON)public Response listdir(@QueryParam(\"path\")String path, @Context HttpHeaders headers, @Context UriInfo ui)throws Exception { try { return Response.ok(HdfsApi.fileStatusToJSON(getApi(context).listdir(path))).build(); } catch(FileNotFoundException ex) { return Response.ok(Response.Status.NOT_FOUND.getStatusCode()).entity(ex.getMessage()).build(); } catch(Throwable ex) { throw new Exception(ex.getMessage()); } } ",
        "test_tgt": "@Test public void testListDir()throws Exception { FileOperationService.MkdirRequest request = new FileOperationService.MkdirRequest(); request.path = \"/tmp1\"; fileBrowserService.fileOps().mkdir(request); Response response = fileBrowserService.fileOps().listdir(\"/\"); JSONArray statuses = (JSONArray)response.getEntity(); System.out.println(response.getEntity()); Assert.assertEquals(200, response.getStatus()); Assert.assertTrue(statuses.size() > 0); System.out.println(statuses); } "
    },
    {
        "test_src": "@Test public void testWrite()throws Exception { byte[]rowKey1 = mapper.rowKey(tuple1); ColumnList cols1 = mapper.columns(tuple1); List < Mutation > mutations1 = client.constructMutationReq(rowKey1, cols1, Durability.SYNC_WAL); client.batchMutate(mutations1); HBaseProjectionCriteria criteria = new HBaseProjectionCriteria(); criteria.addColumnFamily(WidgetMapper.CF_STRING); Get get1 = client.constructGetRequests(rowKey1, criteria); Result[]results = client.batchGet(Arrays.asList(get1)); Assert.assertEquals(1, results.length); assertEquals(1, results.length); assertEquals(widget1, toWidget(results[0])); } ",
        "focal_tgt": "private void write(ProfileMeasurement m, List < Object > groups) { byte[]rowKey = rowKeyBuilder.rowKey(m, groups); ColumnList cols = columnBuilder.columns(m); hbaseClient.addMutation(rowKey, cols, Durability.SKIP_WAL); hbaseClient.mutate(); } ",
        "focal_src": "private void write(ProfileMeasurement m, List < Object > groups) { byte[]rowKey = rowKeyBuilder.rowKey(m, groups); ColumnList cols = columnBuilder.columns(m); List < Mutation > mutations = hbaseClient.constructMutationReq(rowKey, cols, Durability.SKIP_WAL); hbaseClient.batchMutate(mutations); } ",
        "test_tgt": "@Test public void testWrite()throws Exception { client.addMutation(rowKey1, cols1, Durability.SYNC_WAL); client.mutate(); HBaseProjectionCriteria criteria = new HBaseProjectionCriteria(); criteria.addColumnFamily(WidgetMapper.CF_STRING); client.addGet(rowKey1, criteria); Result[]results = client.getAll(); Assert.assertEquals(1, results.length); assertEquals(1, results.length); assertEquals(widget1, toWidget(results[0])); } "
    },
    {
        "test_src": "@Test public void resolvePath() { final String path = query(_FILE_RESOLVE_PATH.args(PATH1)); final String can = new File(PATH1).getAbsolutePath(); assertEquals(path.toLowerCase(Locale.ENGLISH), can.toLowerCase(Locale.ENGLISH)); } ",
        "focal_tgt": "private Str resolvePath(final QueryContext ctx)throws QueryException { final File path = checkFile(0, ctx); final File abs = path.getAbsoluteFile(); return Str.get(abs.isDirectory() ? dir(abs.getPath()) : abs.getPath()); } ",
        "focal_src": "private Str resolvePath(final QueryContext ctx)throws QueryException { final File path = checkFile(0, ctx); final String abs = path.getAbsolutePath(); return Str.get(path.isDirectory() ? dir(abs) : abs); } ",
        "test_tgt": "@Test public void resolvePath() { final String path = query(_FILE_RESOLVE_PATH.args(PATH1)); final String can = new File(PATH1).getAbsolutePath(); assertEquals(path.toLowerCase(Locale.ENGLISH), can.toLowerCase(Locale.ENGLISH)); query(ENDS_WITH.args(_FILE_RESOLVE_PATH.args(\".\"), File.separator), \"true\"); } "
    },
    {
        "test_src": "@Test public void testObtainInternalConnection()throws SQLException, ClassNotFoundException { expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); DataSource mockDataSourceBean = EasyMock.createNiceMock(DataSource.class); expect(this.mockConfig.getDatasourceBean()).andReturn(mockDataSourceBean).anyTimes(); expect(mockConfig.getJdbcUrl()).andReturn(\"jdbc:mock:driver\").anyTimes(); mockConfig.setAcquireRetryDelayInMs(1); CustomHook testHook = new CustomHook(); expect(mockConfig.getConnectionHook()).andReturn(testHook).anyTimes(); expect(this.mockPool.getDbIsDown()).andReturn(new AtomicBoolean()).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).once().andReturn(null).once(); replay(this.mockPool, mockConfig, mockDataSourceBean); this.testClass.obtainInternalConnection(mockConnection); assertEquals(1, testHook.fail); assertEquals(1, testHook.acquire); reset(this.mockPool, mockDataSourceBean); expect(this.mockPool.getDbIsDown()).andReturn(new AtomicBoolean()).anyTimes(); expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).once().andReturn(this.mockConnection).once(); int count = 1; mockConfig.setConnectionHook(null); replay(this.mockPool, mockDataSourceBean); assertEquals(this.mockConnection, this.testClass.obtainInternalConnection(mockConnection)); reset(this.mockPool, mockDataSourceBean); expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).anyTimes(); replay(this.mockPool, mockDataSourceBean); count = 99; mockConfig.setAcquireRetryAttempts(2); try { this.testClass.obtainInternalConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } count = 99; mockConfig.setAcquireRetryAttempts(2); mockConfig.setAcquireRetryDelayInMs(7000); final Thread currentThread = Thread.currentThread(); try { new Thread(new Runnable() { public void run() { while( ! currentThread.getState().equals(State.TIMED_WAITING)) { try { Thread.sleep(50); } catch(InterruptedException e) { e.printStackTrace(); } } currentThread.interrupt(); } }).start(); this.testClass.obtainInternalConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } mockConfig.setAcquireRetryDelayInMs(10); } ",
        "focal_tgt": "protected Connection obtainInternalConnection(ConnectionHandle connectionHandle)throws SQLException { boolean tryAgain = false; Connection result = null; String url = this.getConfig().getJdbcUrl(); int acquireRetryAttempts = this.getConfig().getAcquireRetryAttempts(); long acquireRetryDelayInMs = this.getConfig().getAcquireRetryDelayInMs(); AcquireFailConfig acquireConfig = new AcquireFailConfig(); acquireConfig.setAcquireRetryAttempts(new AtomicInteger(acquireRetryAttempts)); acquireConfig.setAcquireRetryDelayInMs(acquireRetryDelayInMs); acquireConfig.setLogMessage(\"Failed to acquire connection to \" + url); ConnectionHook connectionHook = this.getConfig().getConnectionHook(); do { result = null; try { result = this.obtainRawInternalConnection(); tryAgain = false; if(acquireRetryAttempts != this.getConfig().getAcquireRetryAttempts()) { logger.info(\"Successfully re-established connection to \" + url); } this.getDbIsDown().set(false); if(connectionHook != null) { connectionHook.onAcquire(connectionHandle); } ConnectionHandle.sendInitSQL(result, this.getConfig().getInitSQL()); } catch(SQLException e) { if(connectionHook != null) { tryAgain = connectionHook.onAcquireFail(e, acquireConfig); } else { logger.error(String.format(\"Failed to acquire connection to %s. Sleeping for %d ms. Attempts left: %d\", url, acquireRetryDelayInMs, acquireRetryAttempts), e); try { if(acquireRetryAttempts > 0) { Thread.sleep(acquireRetryDelayInMs); } tryAgain = (acquireRetryAttempts -- ) > 0; } catch(InterruptedException e1) { tryAgain = false; } } if( ! tryAgain) { throw e; } } } while(tryAgain); return result; } ",
        "focal_src": "protected Connection obtainInternalConnection(ConnectionHandle connectionHandle)throws SQLException { boolean tryAgain = false; Connection result = null; String url = this.getConfig().getJdbcUrl(); int acquireRetryAttempts = this.getConfig().getAcquireRetryAttempts(); long acquireRetryDelayInMs = this.getConfig().getAcquireRetryDelayInMs(); AcquireFailConfig acquireConfig = new AcquireFailConfig(); acquireConfig.setAcquireRetryAttempts(new AtomicInteger(acquireRetryAttempts)); acquireConfig.setAcquireRetryDelayInMs(acquireRetryDelayInMs); acquireConfig.setLogMessage(\"Failed to acquire connection to \" + url); ConnectionHook connectionHook = this.getConfig().getConnectionHook(); do { result = null; try { result = this.obtainRawInternalConnection(); tryAgain = false; if(acquireRetryAttempts != this.getConfig().getAcquireRetryAttempts()) { logger.info(\"Successfully re-established connection to \" + url); } this.getDbIsDown().set(false); if(connectionHook != null) { connectionHook.onAcquire(connectionHandle); } ConnectionHandle.sendInitSQL(result, this.getConfig().getInitSQL()); } catch(SQLException e) { if(connectionHook != null) { tryAgain = connectionHook.onAcquireFail(e, acquireConfig); } else { logger.error(String.format(\"Failed to acquire connection to %s. Sleeping for %d ms. Attempts left: %d\", url, acquireRetryDelayInMs, acquireRetryAttempts), e); try { Thread.sleep(acquireRetryDelayInMs); if(acquireRetryAttempts > - 1) { tryAgain = (acquireRetryAttempts -- ) != 0; } } catch(InterruptedException e1) { tryAgain = false; } } if( ! tryAgain) { throw e; } } } while(tryAgain); return result; } ",
        "test_tgt": "@Test public void testObtainInternalConnection()throws SQLException, ClassNotFoundException { expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); DataSource mockDataSourceBean = EasyMock.createNiceMock(DataSource.class); expect(this.mockConfig.getDatasourceBean()).andReturn(mockDataSourceBean).anyTimes(); expect(mockConfig.getJdbcUrl()).andReturn(\"jdbc:mock:driver\").anyTimes(); mockConfig.setAcquireRetryDelayInMs(1); CustomHook testHook = new CustomHook(); expect(mockConfig.getConnectionHook()).andReturn(testHook).anyTimes(); expect(this.mockPool.getDbIsDown()).andReturn(new AtomicBoolean()).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).once().andReturn(null).once(); replay(this.mockPool, mockConfig, mockDataSourceBean); this.testClass.obtainInternalConnection(mockConnection); assertEquals(1, testHook.fail); assertEquals(1, testHook.acquire); reset(this.mockPool, mockDataSourceBean); expect(this.mockPool.getDbIsDown()).andReturn(new AtomicBoolean()).anyTimes(); expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).once().andReturn(this.mockConnection).once(); int count = 1; mockConfig.setConnectionHook(null); replay(this.mockPool, mockDataSourceBean); assertEquals(this.mockConnection, this.testClass.obtainInternalConnection(mockConnection)); reset(this.mockPool, mockDataSourceBean); expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).anyTimes(); replay(this.mockPool, mockDataSourceBean); count = 99; mockConfig.setAcquireRetryAttempts(2); try { this.testClass.obtainInternalConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } count = 99; mockConfig.setAcquireRetryAttempts(2); mockConfig.setAcquireRetryDelayInMs(7000); final Thread currentThread = Thread.currentThread(); try { new Thread(new Runnable() { public void run() { while( ! currentThread.getState().equals(State.TIMED_WAITING)) { try { Thread.sleep(50); } catch(InterruptedException e) { e.printStackTrace(); } } currentThread.interrupt(); } }).start(); this.testClass.obtainInternalConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } reset(this.mockPool, mockDataSourceBean, mockConfig); expect(this.mockPool.getConfig()).andReturn(mockConfig).anyTimes(); expect(mockDataSourceBean.getConnection()).andThrow(new SQLException()).anyTimes(); mockConfig.setAcquireRetryAttempts(0); replay(this.mockPool, mockDataSourceBean, mockConfig); count = 99; try { this.testClass.obtainInternalConnection(mockConnection); fail(\"Should have thrown an exception\"); } catch(SQLException e) { } mockConfig.setAcquireRetryDelayInMs(10); } "
    },
    {
        "test_src": "@Test public void testHasNext()throws ServiceException, InterruptedException { final AbstractInvokable memOwner = new DummyInvokable(); reader = new CollectionReader < PactInteger > (objects); SpillingResettableIterator < PactInteger > iterator = new SpillingResettableIterator < PactInteger > (memman, ioman, reader, SpillingResettableIterator.MIN_BUFFER_SIZE * SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS, deserializer, memOwner); try { iterator.open(); } catch(IOException e) { Assert.fail(\"Could not open resettable iterator:\" + e.getMessage()); } int cnt = 0; while(iterator.hasNext()) { iterator.hasNext(); iterator.next(); cnt ++ ; } Assert.assertTrue(cnt + \" elements read from iterator, but \" + NUM_TESTRECORDS + \" expected\", cnt == NUM_TESTRECORDS); iterator.close(); } ",
        "focal_tgt": "@Override public boolean hasNext() { if(this.traversalStack.isEmpty()) { if(this.numVisitedEntryVertices < 0) { return false; } ++ this.numVisitedEntryVertices; if(this.forward) { if(this.managementGraph.getNumberOfInputVertices(this.startStage) <= this.numVisitedEntryVertices) { return false; } } else { if(this.managementGraph.getNumberOfOutputVertices(this.startStage) <= this.numVisitedEntryVertices) { return false; } } } return true; } ",
        "focal_src": "@Override public boolean hasNext() { if(traversalStack.isEmpty()) { if(numVisitedEntryVertices < 0) { return false; } numVisitedEntryVertices ++ ; if(forward) { if(managementGraph.getNumberOfInputVertices(this.startStage) <= numVisitedEntryVertices) { return false; } } else { if(managementGraph.getNumberOfOutputVertices(this.startStage) <= numVisitedEntryVertices) { return false; } } } return true; } ",
        "test_tgt": "@Test public void testHasNext()throws ServiceException, InterruptedException { final AbstractInvokable memOwner = new DummyInvokable(); reader = new CollectionIterator < PactInteger > (objects); SpillingResettableIterator < PactInteger > iterator = new SpillingResettableIterator < PactInteger > (memman, ioman, reader, SpillingResettableIterator.MIN_BUFFER_SIZE * SpillingResettableIterator.MINIMUM_NUMBER_OF_BUFFERS, deserializer, memOwner); try { iterator.open(); } catch(IOException e) { Assert.fail(\"Could not open resettable iterator:\" + e.getMessage()); } int cnt = 0; while(iterator.hasNext()) { iterator.hasNext(); iterator.next(); cnt ++ ; } Assert.assertTrue(cnt + \" elements read from iterator, but \" + NUM_TESTRECORDS + \" expected\", cnt == NUM_TESTRECORDS); iterator.close(); } "
    },
    {
        "test_src": "@Test public void serialize() { for(final String[]test : TOCSV) { final String query = test[1].isEmpty() ? _CSV_SERIALIZE.args(test[0]) : _CSV_SERIALIZE.args(test[0], \" {\" + test[1] + \"}\"); if(test.length == 2) { error(query, Err.BXCS_CONFSEP, Err.ELMOPTION); } else { query(query, test[2]); } } } ",
        "focal_tgt": "public final void serialize(final Item item)throws IOException { openResult(); if(item instanceof ANode) { final Type type = item.type; if(type == NodeType.ATT)SERATTR.thrwIO(item); if(type == NodeType.NSP)SERNS.thrwIO(item); serialize((ANode)item); } else if(item instanceof FItem) { SERFUNC.thrwIO(item.description()); } else { finishElement(); atomic(item); } closeResult(); } ",
        "focal_src": "public final void serialize(final Item item)throws IOException { openResult(); if(item instanceof ANode) { final Type type = item.type; if(type == NodeType.ATT)SERATTR.thrwSerial(item); if(type == NodeType.NSP)SERNS.thrwSerial(item); serialize((ANode)item); } else if(item instanceof FItem) { SERFUNC.thrwSerial(item.description()); } else { finishElement(); atomic(item); } closeResult(); } ",
        "test_tgt": "@Test public void serialize() { for(final String[]test : TOCSV) { final String query = test[1].isEmpty() ? _CSV_SERIALIZE.args(test[0]) : _CSV_SERIALIZE.args(test[0], \" {\" + test[1] + \"}\"); if(test.length == 2) { error(query, Err.BXCS_CONFSEP, Err.INVALIDOPT); } else { query(query, test[2]); } } } "
    },
    {
        "test_src": "@Test public void encodeJsonTest() { Set < String > escapedChars = new HashSet < > (); escapedChars.add(\"\\\"\"); escapedChars.add(\"/\"); escapedChars.add(\"\\\\\"); for(char i = 32; i < 128; i ++ ) { String s = String.valueOf(i); Assert.assertEquals(\"\\\"\" + (escapedChars.contains(s) ? \"\\\\\" : \"\") + s + \"\\\"\", FormatUtils.encodeJson(s)); } } ",
        "focal_tgt": "public static String encodeJson(String input) { return \"\\\"\" + StringEscapeUtils.escapeJava(input) + \"\\\"\"; } ",
        "focal_src": "public static String encodeJson(String input) { return \"\\\"\" + StringEscapeUtils.escapeJson(input) + \"\\\"\"; } ",
        "test_tgt": "@Test public void encodeJsonTest() { Set < String > escapedChars = new HashSet < > (); escapedChars.add(\"\\\"\"); escapedChars.add(\"\\\\\"); for(char i = 32; i < 128; i ++ ) { String s = String.valueOf(i); Assert.assertEquals(\"\\\"\" + (escapedChars.contains(s) ? \"\\\\\" : \"\") + s + \"\\\"\", FormatUtils.encodeJson(s)); } } "
    },
    {
        "test_src": "@Test public void testWrap_StringInt() { assertNull(WordUtils.wrap(null, 20)); assertNull(WordUtils.wrap(null, - 1)); assertEquals(\"\", WordUtils.wrap(\"\", 20)); assertEquals(\"\", WordUtils.wrap(\"\", - 1)); final String systemNewLine = System.lineSeparator(); String input = \"Here is one line of text that is going to be wrapped after 20 columns.\"; String expected = \"Here is one line of\" + systemNewLine + \"text that is going\" + systemNewLine + \"to be wrapped after\" + systemNewLine + \"20 columns.\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"Click here to jump to the commons website - http://commons.apache.org\"; expected = \"Click here to jump\" + systemNewLine + \"to the commons\" + systemNewLine + \"website -\" + systemNewLine + \"http://commons.apache.org\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"Click here, http://commons.apache.org, to jump to the commons website\"; expected = \"Click here,\" + systemNewLine + \"http://commons.apache.org,\" + systemNewLine + \"to jump to the\" + systemNewLine + \"commons website\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"word1 word2 word3\"; expected = \"word1 \" + systemNewLine + \"word2 \" + systemNewLine + \"word3\"; assertEquals(expected, WordUtils.wrap(input, 7)); } ",
        "focal_tgt": "public static String wrap(final String str, int wrapLength, String newLineStr, final boolean wrapLongWords, String wrapOn) { if(str == null) { return null; } if(newLineStr == null) { newLineStr = System.lineSeparator(); } if(wrapLength < 1) { wrapLength = 1; } if(StringUtils.isBlank(wrapOn)) { wrapOn = \" \"; } final Pattern patternToWrapOn = Pattern.compile(wrapOn); final int inputLineLength = str.length(); int offset = 0; final StringBuilder wrappedLine = new StringBuilder(inputLineLength + 32); while(offset < inputLineLength) { int spaceToWrapAt = - 1; Matcher matcher = patternToWrapOn.matcher(str.substring(offset, Math.min((int)Math.min(Integer.MAX_VALUE, offset + wrapLength + 1L), inputLineLength))); if(matcher.find()) { if(matcher.start() == 0) { offset += matcher.end(); continue; } spaceToWrapAt = matcher.start() + offset; } if(inputLineLength - offset <= wrapLength) { break; } while(matcher.find()) { spaceToWrapAt = matcher.start() + offset; } if(spaceToWrapAt >= offset) { wrappedLine.append(str, offset, spaceToWrapAt); wrappedLine.append(newLineStr); offset = spaceToWrapAt + 1; } else { if(wrapLongWords) { wrappedLine.append(str, offset, wrapLength + offset); wrappedLine.append(newLineStr); offset += wrapLength; } else { matcher = patternToWrapOn.matcher(str.substring(offset + wrapLength)); if(matcher.find()) { spaceToWrapAt = matcher.start() + offset + wrapLength; } if(spaceToWrapAt >= 0) { wrappedLine.append(str, offset, spaceToWrapAt); wrappedLine.append(newLineStr); offset = spaceToWrapAt + 1; } else { wrappedLine.append(str, offset, str.length()); offset = inputLineLength; } } } } wrappedLine.append(str, offset, str.length()); return wrappedLine.toString(); } ",
        "focal_src": "public static String wrap(final String str, int wrapLength, String newLineStr, final boolean wrapLongWords, String wrapOn) { if(str == null) { return null; } if(newLineStr == null) { newLineStr = System.lineSeparator(); } if(wrapLength < 1) { wrapLength = 1; } if(StringUtils.isBlank(wrapOn)) { wrapOn = \" \"; } final Pattern patternToWrapOn = Pattern.compile(wrapOn); final int inputLineLength = str.length(); int offset = 0; final StringBuilder wrappedLine = new StringBuilder(inputLineLength + 32); while(offset < inputLineLength) { int spaceToWrapAt = - 1; Matcher matcher = patternToWrapOn.matcher(str.substring(offset, Math.min(offset + wrapLength + 1, inputLineLength))); if(matcher.find()) { if(matcher.start() == 0) { offset += matcher.end(); continue; } spaceToWrapAt = matcher.start() + offset; } if(inputLineLength - offset <= wrapLength) { break; } while(matcher.find()) { spaceToWrapAt = matcher.start() + offset; } if(spaceToWrapAt >= offset) { wrappedLine.append(str, offset, spaceToWrapAt); wrappedLine.append(newLineStr); offset = spaceToWrapAt + 1; } else { if(wrapLongWords) { wrappedLine.append(str, offset, wrapLength + offset); wrappedLine.append(newLineStr); offset += wrapLength; } else { matcher = patternToWrapOn.matcher(str.substring(offset + wrapLength)); if(matcher.find()) { spaceToWrapAt = matcher.start() + offset + wrapLength; } if(spaceToWrapAt >= 0) { wrappedLine.append(str, offset, spaceToWrapAt); wrappedLine.append(newLineStr); offset = spaceToWrapAt + 1; } else { wrappedLine.append(str, offset, str.length()); offset = inputLineLength; } } } } wrappedLine.append(str, offset, str.length()); return wrappedLine.toString(); } ",
        "test_tgt": "@Test public void testWrap_StringInt() { assertNull(WordUtils.wrap(null, 20)); assertNull(WordUtils.wrap(null, - 1)); assertEquals(\"\", WordUtils.wrap(\"\", 20)); assertEquals(\"\", WordUtils.wrap(\"\", - 1)); final String systemNewLine = System.lineSeparator(); String input = \"Here is one line of text that is going to be wrapped after 20 columns.\"; String expected = \"Here is one line of\" + systemNewLine + \"text that is going\" + systemNewLine + \"to be wrapped after\" + systemNewLine + \"20 columns.\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"Click here to jump to the commons website - http://commons.apache.org\"; expected = \"Click here to jump\" + systemNewLine + \"to the commons\" + systemNewLine + \"website -\" + systemNewLine + \"http://commons.apache.org\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"Click here, http://commons.apache.org, to jump to the commons website\"; expected = \"Click here,\" + systemNewLine + \"http://commons.apache.org,\" + systemNewLine + \"to jump to the\" + systemNewLine + \"commons website\"; assertEquals(expected, WordUtils.wrap(input, 20)); input = \"word1 word2 word3\"; expected = \"word1 \" + systemNewLine + \"word2 \" + systemNewLine + \"word3\"; assertEquals(expected, WordUtils.wrap(input, 7)); } "
    },
    {
        "test_src": "@Test public void testEntrySet()throws Exception { List < ParameterizedHeader > valuesFoo = new ArrayList < ParameterizedHeader > (); valuesFoo.add(new ParameterizedHeader(\"foo1\")); valuesFoo.add(new ParameterizedHeader(\"foo2\")); map.put(\"foo\", valuesFoo); List < ParameterizedHeader > valuesBar = new ArrayList < ParameterizedHeader > (); valuesBar.add(new ParameterizedHeader(\"bar1\")); valuesBar.add(new ParameterizedHeader(\"bar2\")); map.put(\"bar\", valuesBar); Set < Entry < String, List < ParameterizedHeader > > > entrySet = map.entrySet(); assertEquals(2, entrySet.size()); } ",
        "focal_tgt": "@Override public Set < Map.Entry < K, V > > entrySet() { final Set < Map.Entry < K, V > > es = entrySet; return(es != null ? es : (entrySet = (Set < Map.Entry < K, V > > )new EntrySet())); } ",
        "focal_src": "@Override public Set < Map.Entry < K, V > > entrySet() { Set < Map.Entry < K, V > > es = entrySet; return(es != null ? es : (entrySet = (Set < Map.Entry < K, V > > )new EntrySet())); } ",
        "test_tgt": "@Test public void testEntrySet()throws Exception { List < ParameterizedHeader > valuesFoo = new ArrayList < > (); valuesFoo.add(new ParameterizedHeader(\"foo1\")); valuesFoo.add(new ParameterizedHeader(\"foo2\")); map.put(\"foo\", valuesFoo); List < ParameterizedHeader > valuesBar = new ArrayList < > (); valuesBar.add(new ParameterizedHeader(\"bar1\")); valuesBar.add(new ParameterizedHeader(\"bar2\")); map.put(\"bar\", valuesBar); Set < Entry < String, List < ParameterizedHeader > > > entrySet = map.entrySet(); assertEquals(2, entrySet.size()); } "
    },
    {
        "test_src": "@Test public void testNextBytes()throws Exception { byte[]result = RandomUtils.nextBytes(20); assertEquals(20, result.length); } ",
        "focal_tgt": "public static byte[]nextBytes(final int count) { Validate.isTrue(count >= 0, \"Count cannot be negative.\"); final byte[]result = new byte[count]; RANDOM.nextBytes(result); return result; } ",
        "focal_src": "public static byte[]nextBytes(int count) { Validate.isTrue(count >= 0, \"Count cannot be negative.\"); byte[]result = new byte[count]; RANDOM.nextBytes(result); return result; } ",
        "test_tgt": "@Test public void testNextBytes()throws Exception { final byte[]result = RandomUtils.nextBytes(20); assertEquals(20, result.length); } "
    },
    {
        "test_src": "@Test public void testGetCpu() { System.out.println(\"getCpu\"); prepareTestData(123); double result = instance.getCpu(); System.out.println(result); assertTrue(result >= 0); } ",
        "focal_tgt": "public double getCpu()throws PerfMonException { double ret = - 1; String value = getData(CPU); if(value != null)ret = Double.parseDouble(value); if(ret < 0)throwNotSupportedMetricException(\"cpu\"); return ret; } ",
        "focal_src": "public double getCpu() { double ret; String value = getData(CPU); if(value != null) { ret = Double.parseDouble(value); } else { ret = AGENT_ERROR; } return ret; } ",
        "test_tgt": "@Test public void testGetCpu()throws PerfMonException { System.out.println(\"getCpu\"); prepareTestData(123); double result = instance.getCpu(); System.out.println(result); assertTrue(result >= 0); } "
    },
    {
        "test_src": "@Test(expected = Exception.class)public void testUpdateInterfaceMap()throws Exception { isisChannelHandler.updateInterfaceMap(isisProcessList); assertThat(isisChannelHandler, is(notNullValue())); } ",
        "focal_tgt": "public void updateInterfaceMap(List < IsisProcess > isisProcesses) { for(IsisProcess isisUpdatedProcess : isisProcesses) { for(IsisInterface isisUpdatedInterface : isisUpdatedProcess.isisInterfaceList()) { IsisInterface isisInterface = isisInterfaceMap.get(isisUpdatedInterface.interfaceIndex()); if(isisInterface == null) { isisInterfaceMap.put(isisUpdatedInterface.interfaceIndex(), isisUpdatedInterface); interfaceIps.add(isisUpdatedInterface.interfaceIpAddress()); } else { if(isisInterface.intermediateSystemName() != isisUpdatedInterface.intermediateSystemName()) { isisInterface.setIntermediateSystemName(isisUpdatedInterface.intermediateSystemName()); } if(isisInterface.reservedPacketCircuitType() != isisUpdatedInterface.reservedPacketCircuitType()) { isisInterface.setReservedPacketCircuitType(isisUpdatedInterface.reservedPacketCircuitType()); isisInterface.removeNeighbors(); } if(isisInterface.circuitId() != isisUpdatedInterface.circuitId()) { isisInterface.setCircuitId(isisUpdatedInterface.circuitId()); } if(isisInterface.networkType() != isisUpdatedInterface.networkType()) { isisInterface.setNetworkType(isisUpdatedInterface.networkType()); isisInterface.removeNeighbors(); } if(isisInterface.areaAddress() != isisUpdatedInterface.areaAddress()) { isisInterface.setAreaAddress(isisUpdatedInterface.areaAddress()); } if(isisInterface.holdingTime() != isisUpdatedInterface.holdingTime()) { isisInterface.setHoldingTime(isisUpdatedInterface.holdingTime()); } if(isisInterface.helloInterval() != isisUpdatedInterface.helloInterval()) { isisInterface.setHelloInterval(isisUpdatedInterface.helloInterval()); isisInterface.stopHelloSender(); isisInterface.startHelloSender(channel); } isisInterfaceMap.put(isisInterface.interfaceIndex(), isisInterface); } } } } ",
        "focal_src": "public void updateInterfaceMap(List < IsisProcess > isisProcesses) { for(IsisProcess isisUpdatedProcess : isisProcesses) { for(IsisInterface isisUpdatedInterface : isisUpdatedProcess.isisInterfaceList()) { IsisInterface isisInterface = isisInterfaceMap.get(isisUpdatedInterface.interfaceIndex()); if(isisInterface == null) { isisInterfaceMap.put(isisInterface.interfaceIndex(), isisInterface); interfaceIps.add(isisInterface.interfaceIpAddress()); } else { isisInterface.setReservedPacketCircuitType(isisUpdatedInterface.reservedPacketCircuitType()); isisInterface.setNetworkType(isisUpdatedInterface.networkType()); isisInterface.setHoldingTime(isisUpdatedInterface.holdingTime()); isisInterface.setHelloInterval(isisUpdatedInterface.helloInterval()); isisInterfaceMap.put(isisInterface.interfaceIndex(), isisInterface); } } } } ",
        "test_tgt": "@Test(expected = Exception.class)public void testUpdateInterfaceMap()throws Exception { IsisInterface isisInterface = new DefaultIsisInterface(); IsisInterface isisInterface1 = new DefaultIsisInterface(); isisInterface.setInterfaceIpAddress(ip4Address); isisInterface.setInterfaceIndex(1); isisInterfaceList.add(isisInterface); IsisProcess isisProcess = new DefaultIsisProcess(); isisProcess.setIsisInterfaceList(isisInterfaceList); isisProcessList.add(isisProcess); isisChannelHandler.updateInterfaceMap(isisProcessList); assertThat(isisChannelHandler, is(notNullValue())); isisProcessList = new ArrayList < > (); isisInterface1.setInterfaceIpAddress(ip4Address); isisInterface1.setInterfaceIndex(1); isisInterface1.setInterfaceIpAddress(ip4Address); isisInterface1.setInterfaceIndex(1); isisInterface1.setSystemId(\"9999.9999.9999\"); isisInterface1.setIntermediateSystemName(\"router\"); isisInterface1.setReservedPacketCircuitType(3); isisInterface1.setCircuitId(\"10\"); isisInterface1.setNetworkType(IsisNetworkType.BROADCAST); isisInterface1.setAreaAddress(\"490001\"); isisInterface1.setHoldingTime(50); isisInterface1.setHelloInterval(10); isisInterfaceList.add(isisInterface1); isisProcess.setIsisInterfaceList(isisInterfaceList); isisProcessList.add(isisProcess); isisChannelHandler.updateInterfaceMap(isisProcessList); assertThat(isisChannelHandler, is(notNullValue())); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should ignore voided patient identifier\", method = \"checkPatientIdentifiers(Patient)\")public void checkPatientIdentifiers_shouldIgnoreVoidedPatientIdentifier()throws Exception { Patient patient = new Patient(); PatientIdentifier patientIdentifier = new PatientIdentifier(); patientIdentifier.setIdentifierType(Context.getPatientService().getAllPatientIdentifierTypes(false).get(0)); patientIdentifier.setLocation(new Location(1)); patientIdentifier.setVoided(true); patientIdentifier.setVoidedBy(Context.getAuthenticatedUser()); patientIdentifier.setVoidReason(\"Testing whether voided identifiers are ignored\"); patient.addIdentifier(patientIdentifier); patientIdentifier = new PatientIdentifier(); patientIdentifier.setIdentifier(\"a non empty string\"); patientIdentifier.setIdentifierType(Context.getPatientService().getAllPatientIdentifierTypes(false).get(0)); patientIdentifier.setLocation(new Location(1)); patientIdentifier.setVoided(false); patientIdentifier.setVoidedBy(Context.getAuthenticatedUser()); patientIdentifier.setVoidReason(\"Testing whether voided identifiers are ignored\"); patient.addIdentifier(patientIdentifier); Context.getPatientService().checkPatientIdentifiers(patient); } ",
        "focal_tgt": "@Override@Transactional(readOnly = true)public void checkPatientIdentifiers(Patient patient)throws PatientIdentifierException { if( ! patient.getVoided() && patient.getActiveIdentifiers().isEmpty()) { throw new InsufficientIdentifiersException(\"At least one nonvoided Patient Identifier is required\"); } List < PatientIdentifier > identifiers = new Vector < PatientIdentifier > (); identifiers.addAll(patient.getIdentifiers()); List < String > identifiersUsed = new Vector < String > (); List < PatientIdentifierType > requiredTypes = Context.getPatientService().getPatientIdentifierTypes(null, null, true, null); if(requiredTypes == null) { requiredTypes = new ArrayList < PatientIdentifierType > (); } List < PatientIdentifierType > foundRequiredTypes = new ArrayList < PatientIdentifierType > (); for(PatientIdentifier pi : identifiers) { if(pi.getVoided()) { continue; } try { PatientIdentifierValidator.validateIdentifier(pi); } catch(BlankIdentifierException bie) { patient.removeIdentifier(pi); throw bie; } for(PatientIdentifierType requiredType : requiredTypes) { if(pi.getIdentifierType().equals(requiredType)) { foundRequiredTypes.add(requiredType); requiredTypes.remove(requiredType); break; } } if(identifiersUsed.contains(pi.getIdentifier() + \" id type #: \" + pi.getIdentifierType().getPatientIdentifierTypeId())) { throw new DuplicateIdentifierException(\"This patient has two identical identifiers of type \" + pi.getIdentifierType().getName() + \": \" + pi.getIdentifier(), pi); } else { identifiersUsed.add(pi.getIdentifier() + \" id type #: \" + pi.getIdentifierType().getPatientIdentifierTypeId()); } } if( ! requiredTypes.isEmpty()) { String missingNames = \"\"; for(PatientIdentifierType pit : requiredTypes) { missingNames += (missingNames.length() > 0) ? \", \" + pit.getName() : pit.getName(); } throw new MissingRequiredIdentifierException(\"Patient is missing the following required identifier(s): \" + missingNames); } } ",
        "focal_src": "@Override@Transactional(readOnly = true)public void checkPatientIdentifiers(Patient patient)throws PatientIdentifierException { if( ! patient.isVoided() && patient.getActiveIdentifiers().isEmpty()) { throw new InsufficientIdentifiersException(\"At least one nonvoided Patient Identifier is required\"); } List < PatientIdentifier > identifiers = new Vector < PatientIdentifier > (); identifiers.addAll(patient.getIdentifiers()); List < String > identifiersUsed = new Vector < String > (); List < PatientIdentifierType > requiredTypes = Context.getPatientService().getPatientIdentifierTypes(null, null, true, null); if(requiredTypes == null) { requiredTypes = new ArrayList < PatientIdentifierType > (); } List < PatientIdentifierType > foundRequiredTypes = new ArrayList < PatientIdentifierType > (); for(PatientIdentifier pi : identifiers) { if(pi.isVoided()) { continue; } try { PatientIdentifierValidator.validateIdentifier(pi); } catch(BlankIdentifierException bie) { patient.removeIdentifier(pi); throw bie; } for(PatientIdentifierType requiredType : requiredTypes) { if(pi.getIdentifierType().equals(requiredType)) { foundRequiredTypes.add(requiredType); requiredTypes.remove(requiredType); break; } } if(identifiersUsed.contains(pi.getIdentifier() + \" id type #: \" + pi.getIdentifierType().getPatientIdentifierTypeId())) { throw new DuplicateIdentifierException(\"This patient has two identical identifiers of type \" + pi.getIdentifierType().getName() + \": \" + pi.getIdentifier(), pi); } else { identifiersUsed.add(pi.getIdentifier() + \" id type #: \" + pi.getIdentifierType().getPatientIdentifierTypeId()); } } if( ! requiredTypes.isEmpty()) { String missingNames = \"\"; for(PatientIdentifierType pit : requiredTypes) { missingNames += (missingNames.length() > 0) ? \", \" + pit.getName() : pit.getName(); } throw new MissingRequiredIdentifierException(\"Patient is missing the following required identifier(s): \" + missingNames); } } ",
        "test_tgt": "@Test@Verifies(value = \"should ignore voided patient identifier\", method = \"checkPatientIdentifiers(Patient)\")public void checkPatientIdentifiers_shouldIgnoreVoidedPatientIdentifier()throws Exception { Patient patient = new Patient(); PatientIdentifier patientIdentifier = new PatientIdentifier(); patientIdentifier.setIdentifierType(Context.getPatientService().getAllPatientIdentifierTypes(false).get(0)); patientIdentifier.setLocation(new Location(1)); patientIdentifier.setVoided(true); patientIdentifier.setVoidedBy(Context.getAuthenticatedUser()); patientIdentifier.setVoidReason(\"Testing whether voided identifiers are ignored\"); patient.addIdentifier(patientIdentifier); patientIdentifier = new PatientIdentifier(); patientIdentifier.setIdentifier(\"a non empty string\"); patientIdentifier.setIdentifierType(Context.getPatientService().getAllPatientIdentifierTypes(false).get(0)); patientIdentifier.setLocation(new Location(1)); patientIdentifier.setVoided(false); patientIdentifier.setVoidedBy(Context.getAuthenticatedUser()); patientIdentifier.setVoidReason(\"Testing whether voided identifiers are ignored\"); patient.addIdentifier(patientIdentifier); Context.getPatientService().checkPatientIdentifiers(patient); } "
    },
    {
        "test_src": "@Test public void cacheBlockTest()throws Exception { final int fileId = mTfs.createFile(new TachyonURI(\"/testFile\")); final int blockSize = (int)WORKER_CAPACITY_BYTES / 10; final long blockId0 = mTfs.getBlockId(fileId, 0); final long blockId1 = mTfs.getBlockId(fileId, 1); String filename = mWorkerServiceHandler.requestBlockLocation(USER_ID, blockId0, blockSize); createBlockFile(filename, blockSize); mWorkerServiceHandler.cacheBlock(USER_ID, blockId0); Assert.assertEquals(blockSize, mMasterInfo.getUsedBytes()); Exception exception = null; try { mWorkerServiceHandler.cacheBlock(USER_ID, blockId1); } catch(TException e) { exception = e; } Assert.assertNotNull(exception); } ",
        "focal_tgt": "public synchronized void cacheBlock(long blockId)throws IOException { mustConnect(); try { mClient.cacheBlock(mUserId, blockId); } catch(FileDoesNotExistException e) { throw new IOException(e); } catch(BlockInfoException e) { throw new IOException(e); } catch(TException e) { mConnected = false; throw new IOException(e); } } ",
        "focal_src": "public synchronized void cacheBlock(long blockId)throws IOException { mustConnect(); try { mClient.cacheBlock(mMasterClient.getUserId(), blockId); } catch(FileDoesNotExistException e) { throw new IOException(e); } catch(BlockInfoException e) { throw new IOException(e); } catch(TException e) { mConnected = false; throw new IOException(e); } } ",
        "test_tgt": "@Test public void cacheBlockTest()throws Exception { ClientOptions options = new ClientOptions.Builder(new TachyonConf()).build(); mTfs.getOutStream(new TachyonURI(\"/testFile\"), options); TachyonFile file = mTfs.open(new TachyonURI(\"/testFile\")); final int blockSize = (int)WORKER_CAPACITY_BYTES / 10; final long blockId0 = BlockId.createBlockId(BlockId.getContainerId(file.getFileId()), 0); final long blockId1 = BlockId.createBlockId(BlockId.getContainerId(file.getFileId()), 1); String filename = mWorkerServiceHandler.requestBlockLocation(USER_ID, blockId0, blockSize); createBlockFile(filename, blockSize); mWorkerServiceHandler.cacheBlock(USER_ID, blockId0); Assert.assertEquals(blockSize, mBlockMasterClient.getUsedBytes()); Exception exception = null; try { mWorkerServiceHandler.cacheBlock(USER_ID, blockId1); } catch(TException e) { exception = e; } Assert.assertNotNull(exception); } "
    },
    {
        "test_src": "@Test public void testColSum() { System.out.println(\"colSum\"); double[][]A = { { 0.7220180, 0.07121225, 0.6881997 }, { - 0.2648886, - 0.89044952, 0.3700456 }, { - 0.6391588, 0.44947578, 0.6240573 } }; double[]r = { - 0.1820294, - 0.3697615, 1.6823026 }; double[]result = Math.colSum(A); for(int i = 0; i < r.length; i ++ ) { assertEquals(result[i], r[i], 1E-7); } } ",
        "focal_tgt": "public static double[]colSums(double[][]data) { double[]x = data[0].clone(); for(int i = 1; i < data.length; i ++ ) { for(int j = 0; j < x.length; j ++ ) { x[j] += data[i][j]; } } return x; } ",
        "focal_src": "public static double[]colSum(double[][]data) { double[]x = data[0].clone(); for(int i = 1; i < data.length; i ++ ) { for(int j = 0; j < x.length; j ++ ) { x[j] += data[i][j]; } } return x; } ",
        "test_tgt": "@Test public void testColSums() { System.out.println(\"colSums\"); double[][]A = { { 0.7220180, 0.07121225, 0.6881997 }, { - 0.2648886, - 0.89044952, 0.3700456 }, { - 0.6391588, 0.44947578, 0.6240573 } }; double[]r = { - 0.1820294, - 0.3697615, 1.6823026 }; double[]result = Math.colSums(A); for(int i = 0; i < r.length; i ++ ) { assertEquals(result[i], r[i], 1E-7); } } "
    },
    {
        "test_src": "@Test public void setAsText_shouldSetUsingUuid() { PersonEditor editor = new PersonEditor(); editor.setAsText(\"da7f524f-27ce-4bb2-86d6-6d1d05312bd5\"); Assert.assertNotNull(editor.getValue()); } ",
        "focal_tgt": "@Override protected Drug getExistingObject() { return conceptService.getDrug(EXISTING_ID); } ",
        "focal_src": "@Test public void setAsText_shouldSetUsingUuid() { DrugEditor drugEditor = new DrugEditor(); drugEditor.setAsText(\"3cfcf118-931c-46f7-8ff6-7b876f0d4202\"); Assert.assertNotNull(drugEditor.getValue()); } ",
        "test_tgt": "@Override@Ignore(\"to investigate, this behavior deviates from most openmrs propertyeditors\")@Test(expected = IllegalArgumentException.class)public void shouldFailToSetTheEditorValueIfGivenUuidDoesNotExist() { editor.setAsText(getNonExistingObjectUuid()); } "
    },
    {
        "test_src": "@Test public void setUserFromLoginModuleTest()throws Exception { Configuration conf = new Configuration(); Permission permission = Permission.defaults(); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); permission.setUserFromThriftClient(conf); verifyPermission(\"\", \"\", (short)0777, permission); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); conf.set(Constants.SECURITY_LOGIN_USERNAME, \"test_login_user\"); conf.set(Constants.SECURITY_GROUP_MAPPING, IdentityUserGroupsMapping.class.getName()); Whitebox.setInternalState(LoginUser.class, \"sLoginUser\", (String)null); permission.setUserFromLoginModule(conf); verifyPermission(\"test_login_user\", \"test_login_user\", (short)0777, permission); } ",
        "focal_tgt": "public Permission setOwnerFromLoginModule(Configuration conf)throws IOException { if( ! SecurityUtils.isAuthenticationEnabled(conf)) { return this; } String user = LoginUser.get(conf).getName(); mOwner = user; mGroup = CommonUtils.getPrimaryGroupName(conf, user); return this; } ",
        "focal_src": "public Permission setUserFromLoginModule(Configuration conf)throws IOException { if( ! SecurityUtils.isAuthenticationEnabled(conf)) { return this; } String loginUserName = LoginUser.get(conf).getName(); mUserName = loginUserName; mGroupName = CommonUtils.getPrimaryGroupName(conf, loginUserName); return this; } ",
        "test_tgt": "@Test public void setUserFromLoginModuleTest()throws Exception { Configuration conf = new Configuration(); Permission permission = Permission.defaults(); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); permission.setOwnerFromThriftClient(conf); verifyPermission(\"\", \"\", (short)0777, permission); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); conf.set(Constants.SECURITY_LOGIN_USERNAME, \"test_login_user\"); conf.set(Constants.SECURITY_GROUP_MAPPING, IdentityUserGroupsMapping.class.getName()); Whitebox.setInternalState(LoginUser.class, \"sLoginUser\", (String)null); permission.setOwnerFromLoginModule(conf); verifyPermission(\"test_login_user\", \"test_login_user\", (short)0777, permission); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should properly set the date\", method = \"setDate(int,int,int,null,null,null)\")public void setDate_shouldProperlySetTheDate()throws Exception { Assert.fail(\"Not yet implemented\"); } ",
        "focal_tgt": "public void setDate(Calendar calendar) { setDate(calendar.get(Calendar.YEAR), calendar.get(Calendar.MONTH) + 1, calendar.get(Calendar.DAY_OF_MONTH), false, false, false); } ",
        "focal_src": "public void setDate(Calendar calendar) { setDate(calendar.get(Calendar.YEAR), calendar.get(Calendar.MONTH) + 1, calendar.get(Calendar.DAY_OF_MONTH), false, false, false); setApproximated(0); } ",
        "test_tgt": "@Test@Verifies(value = \"should properly set the date\", method = \"setDate(int,int,int,null,null,null)\")public void setDate_shouldProperlySetTheDate()throws Exception { ApproximateDate approximateDate = new ApproximateDate(); approximateDate.setDate(1988, 9, 15, false, false, false); Calendar cal = Calendar.getInstance(); cal.set(1988, 9, 15); Assert.fail(\"Not yet implemented\"); } "
    },
    {
        "test_src": "@Test public void testGetConfigsForCluster()throws GenieException { Assert.assertEquals(1, this.service.getConfigsForCluster(CLUSTER_1_ID).size()); } ",
        "focal_tgt": "@Override@Transactional(readOnly = true)public Set < String > getConfigsForCluster(@NotBlank(message = \"No cluster id sent. Cannot retrieve configurations.\")final String id)throws GenieException { if(LOG.isDebugEnabled()) { LOG.debug(\"called\"); } final Cluster cluster = this.clusterRepo.findOne(id); if(cluster != null) { return cluster.getConfigs(); } else { throw new GenieNotFoundException(\"No cluster with id \" + id + \" exists.\"); } } ",
        "focal_src": "@Override@Transactional(readOnly = true)public Set < String > getConfigsForCluster(@NotBlank(message = \"No cluster id sent. Cannot retrieve configurations.\")final String id)throws GenieException { LOG.debug(\"called\"); final Cluster cluster = this.clusterRepo.findOne(id); if(cluster != null) { return cluster.getConfigs(); } else { throw new GenieNotFoundException(\"No cluster with id \" + id + \" exists.\"); } } ",
        "test_tgt": "@Test@Ignore public void testGetConfigsForCluster()throws GenieException { } "
    },
    {
        "test_src": "@Test public void addAllAsync_manyTimesRoundTheRing()throws Exception { RingbufferConfig c = config.getRingbufferConfig(ringbuffer.getName()); Random random = new Random(); for(int iteration = 0; iteration < 1000; iteration ++ ) { List < String > items = randomList(max(1, random.nextInt(c.getCapacity()))); long previousTailSeq = ringbuffer.tailSequence(); long result = ringbuffer.addAllAsync(items, OVERWRITE).get(); assertEquals(previousTailSeq + items.size(), ringbuffer.tailSequence()); if(ringbuffer.tailSequence() < c.getCapacity()) { assertEquals(0, ringbuffer.headSequence()); } else { assertEquals(ringbuffer.tailSequence() - c.getCapacity() + 1, ringbuffer.headSequence()); } assertEquals(ringbuffer.tailSequence(), result); long startSequence = previousTailSeq + 1; for(int k = 0; k < items.size(); k ++ ) { assertEquals(items.get(k), ringbuffer.readOne(startSequence + k)); } } } ",
        "focal_tgt": "CompletionStage < Long > addAllAsync(@Nonnull Collection < ? extends E > collection, @Nonnull OverflowPolicy overflowPolicy); ",
        "focal_src": "ICompletableFuture < Long > addAllAsync(@Nonnull Collection < ? extends E > collection, @Nonnull OverflowPolicy overflowPolicy); ",
        "test_tgt": "@Test public void addAllAsync_manyTimesRoundTheRing()throws Exception { RingbufferConfig c = config.getRingbufferConfig(ringbuffer.getName()); Random random = new Random(); for(int iteration = 0; iteration < 1000; iteration ++ ) { List < String > items = randomList(max(1, random.nextInt(c.getCapacity()))); long previousTailSeq = ringbuffer.tailSequence(); long result = ringbuffer.addAllAsync(items, OVERWRITE).toCompletableFuture().get(); assertEquals(previousTailSeq + items.size(), ringbuffer.tailSequence()); if(ringbuffer.tailSequence() < c.getCapacity()) { assertEquals(0, ringbuffer.headSequence()); } else { assertEquals(ringbuffer.tailSequence() - c.getCapacity() + 1, ringbuffer.headSequence()); } assertEquals(ringbuffer.tailSequence(), result); long startSequence = previousTailSeq + 1; for(int k = 0; k < items.size(); k ++ ) { assertEquals(items.get(k), ringbuffer.readOne(startSequence + k)); } } } "
    },
    {
        "test_src": "@Test public void cloneTest()throws CloneNotSupportedException { StringBuilder sb = new StringBuilder(); boolean pass = true; int status = 200; List < String > type = Arrays.asList(\"text/plain\", \"text/html\"); List < String > encoding = Arrays.asList(\"gzip\", \"compress\"); List < String > lang = Arrays.asList(\"en-US\", \"en-GB\", \"zh-CN\"); String name = \"name_1\"; String value = \"value_1\"; Cookie ck1 = new Cookie(name, value); NewCookie nck1 = new NewCookie(ck1); List < String > cookies = Arrays.asList(nck1.toString().toLowerCase()); Response.ResponseBuilder respb1 = Response.status(status).header(\"Content-type\", \"text/plain\").header(\"Content-type\", \"text/html\").header(\"Content-Language\", \"en-US\").header(\"Content-Language\", \"en-GB\").header(\"Content-Language\", \"zh-CN\").header(\"Cache-Control\", \"no-transform\").header(\"Set-Cookie\", \"name_1=value_1;version=1\"); Response.ResponseBuilder respb2 = respb1.clone(); Response resp2 = respb2.build(); String tmp = verifyResponse(resp2, null, status, encoding, lang, type, null, null, cookies); if(tmp.endsWith(\"false\")) { pass = false; System.out.println(\"### \" + sb.toString()); fail(); } sb.append(tmp).append(newline); String content = \"TestOnly\"; Response resp1 = respb1.entity(content).cookie((NewCookie)null).build(); tmp = verifyResponse(resp1, content, status, encoding, lang, type, null, null, null); if(tmp.endsWith(\"false\")) { pass = false; System.out.println(\"### \" + sb.toString()); fail(); } MultivaluedMap < java.lang.String, java.lang.Object > mvp = resp1.getMetadata(); if(mvp.containsKey(\"Set-Cookie\")) { pass = false; sb.append(\"Response contains unexpected Set-Cookie: \").append(mvp.getFirst(\"Set-Cookie\").toString()).append(newline); System.out.println(\"### \" + sb.toString()); fail(); } sb.append(tmp).append(newline); assertTrue(pass); } ",
        "focal_tgt": "@Override public Object clone() { KeyComparatorHashMap < K, V > result = null; try { result = (KeyComparatorHashMap < K, V > )super.clone(); result.table = new Entry[table.length]; result.entrySet = null; result.modCount = 0; result.size = 0; result.init(); result.putAllForCreate(this); } catch(final CloneNotSupportedException e) { } return result; } ",
        "focal_src": "@Override public Object clone() { KeyComparatorHashMap < K, V > result = null; try { result = (KeyComparatorHashMap < K, V > )super.clone(); } catch(CloneNotSupportedException e) { } result.table = new Entry[table.length]; result.entrySet = null; result.modCount = 0; result.size = 0; result.init(); result.putAllForCreate(this); return result; } ",
        "test_tgt": "@Test public void cloneTest()throws CloneNotSupportedException { StringBuilder sb = new StringBuilder(); int status = 200; List < String > type = Arrays.asList(\"text/plain\", \"text/html\"); List < String > encoding = Arrays.asList(\"gzip\", \"compress\"); List < String > lang = Arrays.asList(\"en-US\", \"en-GB\", \"zh-CN\"); String name = \"name_1\"; String value = \"value_1\"; Cookie ck1 = new Cookie(name, value); NewCookie nck1 = new NewCookie(ck1); List < String > cookies = Arrays.asList(nck1.toString().toLowerCase()); Response.ResponseBuilder respb1 = Response.status(status).header(\"Content-type\", \"text/plain\").header(\"Content-type\", \"text/html\").header(\"Content-Language\", \"en-US\").header(\"Content-Language\", \"en-GB\").header(\"Content-Language\", \"zh-CN\").header(\"Cache-Control\", \"no-transform\").header(\"Set-Cookie\", \"name_1=value_1;version=1\"); Response.ResponseBuilder respb2 = respb1.clone(); Response resp2 = respb2.build(); String tmp = verifyResponse(resp2, null, status, encoding, lang, type, null, null, cookies); if(tmp.endsWith(\"false\")) { System.out.println(\"### \" + sb.toString()); fail(); } sb.append(tmp).append(newline); String content = \"TestOnly\"; Response resp1 = respb1.entity(content).cookie((NewCookie)null).build(); tmp = verifyResponse(resp1, content, status, encoding, lang, type, null, null, null); if(tmp.endsWith(\"false\")) { System.out.println(\"### \" + sb.toString()); fail(); } MultivaluedMap < java.lang.String, java.lang.Object > mvp = resp1.getMetadata(); if(mvp.containsKey(\"Set-Cookie\")) { sb.append(\"Response contains unexpected Set-Cookie: \").append(mvp.getFirst(\"Set-Cookie\").toString()).append(newline); System.out.println(\"### \" + sb.toString()); fail(); } sb.append(tmp).append(newline); } "
    },
    {
        "test_src": "@Test public void updateFileHandleTest()throws IOException { File dir = new File(baseDir + File.separator + \"File1\"); dir.mkdirs(); File createFile = new File(dir + \"testFile\"); createFile.createNewFile(); File createSourceFile = new File(dir + \"sourceTestFile\"); createSourceFile.createNewFile(); FileSystemUtil.updateFileHandle(createFile, \"This is to append a text to the file first1\\n\", false); FileSystemUtil.updateFileHandle(createFile, \"This is next second line\\n\", false); FileSystemUtil.updateFileHandle(createFile, \"This is next third line in the file\", false); FileSystemUtil.appendFileContents(createFile, createSourceFile); FileSystemUtil.updateFileHandle(createFile, null, true); } ",
        "focal_tgt": "public static void updateFileHandle(File inputFile, String contentTobeAdded, boolean isClose)throws IOException { FileWriter fileWriter = new FileWriter(inputFile, true); PrintWriter outputPrintWriter = new PrintWriter(fileWriter, true); if( ! isClose) { outputPrintWriter.write(contentTobeAdded); outputPrintWriter.flush(); outputPrintWriter.close(); } else { fileWriter.flush(); fileWriter.close(); } } ",
        "focal_src": "public static void updateFileHandle(File inputFile, String contentTobeAdded, boolean isClose)throws IOException { FileWriter fileWriter = new FileWriter(inputFile, true); PrintWriter outputPrintWriter = new PrintWriter(fileWriter); if( ! isClose) { outputPrintWriter.write(contentTobeAdded); outputPrintWriter.flush(); outputPrintWriter.close(); } else { fileWriter.flush(); fileWriter.close(); } } ",
        "test_tgt": "@Test public void updateFileHandleTest()throws IOException { File dir = new File(BASE_PKG + File.separator + \"File1\"); dir.mkdirs(); File createFile = new File(dir + \"testFile\"); createFile.createNewFile(); File createSourceFile = new File(dir + \"sourceTestFile\"); createSourceFile.createNewFile(); FileSystemUtil.updateFileHandle(createFile, \"This is to append a text to the file first1\\n\", false); FileSystemUtil.updateFileHandle(createFile, \"This is next second line\\n\", false); FileSystemUtil.updateFileHandle(createFile, \"This is next third line in the file\", false); FileSystemUtil.appendFileContents(createFile, createSourceFile); FileSystemUtil.updateFileHandle(createFile, null, true); } "
    },
    {
        "test_src": "@Test public void sort() { array(_ARRAY_SORT.args(\" [1,4,6,5,3]\"), \"[1, 3, 4, 5, 6]\"); array(_ARRAY_SORT.args(\" [(1,0), (1,1), (0,1), (0,0)]\"), \"[(0, 0), (0, 1), (1, 0), (1, 1)]\"); array(_ARRAY_SORT.args(\" [1,-2,5,10,-10,10,8]\", \" abs#1\"), \"[1, -2, 5, 8, 10, -10, 10]\"); } ",
        "focal_tgt": "private void sort(final QueryContext qc)throws QueryException { List < Value[] > tuples = new ArrayList < > (); while(sub.next(qc)) { final int kl = keys.length; final Item[]key = new Item[kl]; for(int k = 0; k < kl; k ++ )key[k] = keys[k].expr.atomItem(qc, keys[k].info); tuples.add(key); final int rl = refs.length; final Value[]vals = new Value[rl]; for(int r = 0; r < rl; r ++ )vals[r] = refs[r].value(qc); tuples.add(vals); } final int len = tuples.size() > > > 1; final Item[][]ks = new Item[len][]; perm = new Integer[len]; tpls = new Value[len][]; for(int i = 0; i < len; i ++ ) { perm[i] = i; tpls[i] = tuples.get(i << 1 | 1); ks[i] = (Item[])tuples.get(i << 1); } tuples = null; try { Arrays.sort(perm, new Comparator < Integer > () { @Override public int compare(final Integer x, final Integer y) { try { final Item[]a = ks[x], b = ks[y]; final int kl = keys.length; for(int k = 0; k < kl; k ++ ) { final Key key = keys[k]; Item m = a[k], n = b[k]; if(m == Dbl.NAN || m == Flt.NAN)m = null; if(n == Dbl.NAN || n == Flt.NAN)n = null; if(m != null && n != null && ! m.comparable(n))throw castError(n, m.type, key.info); final int c = m == null ? n == null ? 0 : key.least ? - 1 : 1 : n == null ? key.least ? 1 : - 1 : m.diff(n, key.coll, key.info); if(c != 0)return key.desc ? - c : c; } return 0; } catch(final QueryException ex) { throw new QueryRTException(ex); } } }); } catch(final QueryRTException ex) { throw ex.getCause(); } } ",
        "focal_src": "private void sort(final QueryContext qc)throws QueryException { List < Value[] > tuples = new ArrayList < > (); while(sub.next(qc)) { final int kl = keys.length; final Item[]key = new Item[kl]; for(int k = 0; k < kl; k ++ )key[k] = keys[k].expr.atomItem(qc, keys[k].info); tuples.add(key); final int rl = refs.length; final Value[]vals = new Value[rl]; for(int r = 0; r < rl; r ++ )vals[r] = refs[r].value(qc); tuples.add(vals); } final int len = tuples.size() > > > 1; final Item[][]ks = new Item[len][]; perm = new Integer[len]; tpls = new Value[len][]; for(int i = 0; i < len; i ++ ) { perm[i] = i; tpls[i] = tuples.get(i << 1 | 1); ks[i] = (Item[])tuples.get(i << 1); } tuples = null; try { Arrays.sort(perm, new Comparator < Integer > () { @Override public int compare(final Integer x, final Integer y) { try { final Item[]a = ks[x], b = ks[y]; final int kl = keys.length; for(int k = 0; k < kl; k ++ ) { final Key or = keys[k]; Item m = a[k], n = b[k]; if(m == Dbl.NAN || m == Flt.NAN)m = null; if(n == Dbl.NAN || n == Flt.NAN)n = null; if(m != null && n != null && ! m.comparable(n))throw castError(n, m.type, or.info); final int c = m == null ? n == null ? 0 : or.least ? - 1 : 1 : n == null ? or.least ? 1 : - 1 : m.diff(n, or.coll, or.info); if(c != 0)return or.desc ? - c : c; } return 0; } catch(final QueryException ex) { throw new QueryRTException(ex); } } }); } catch(final QueryRTException ex) { throw ex.getCause(); } } ",
        "test_tgt": "@Test public void sort() { array(_ARRAY_SORT.args(\" [1,4,6,5,3]\"), \"[1, 3, 4, 5, 6]\"); array(_ARRAY_SORT.args(\" [(1,0), (1,1), (0,1), (0,0)]\"), \"[(0, 0), (0, 1), (1, 0), (1, 1)]\"); array(_ARRAY_SORT.args(\" [1,-2,5,10,-10,10,8]\", \"\", \" abs#1\"), \"[1, -2, 5, 8, 10, -10, 10]\"); } "
    },
    {
        "test_src": "@Test public void testResetYearEnd() { Calendar resetYearEnd = CalendarUtil.resetYearEnd(DateUtil.toCalendar(new Date())); LOGGER.debug(CalendarUtil.toString(resetYearEnd, DatePattern.COMMON_DATE_AND_TIME_WITH_MILLISECOND)); } ",
        "focal_tgt": "public static Calendar resetYearEnd(Calendar calendar) { Validate.notNull(calendar, \"calendar can't be null!\"); calendar.set(Calendar.MONTH, Calendar.DECEMBER); calendar.set(Calendar.DAY_OF_MONTH, 31); return resetDayEnd(calendar); } ",
        "focal_src": "public static Calendar resetYearEnd(Calendar calendar) { Validate.notNull(calendar, \"calendar can't be null!\"); calendar.set(Calendar.MONTH, Calendar.DECEMBER); calendar.set(Calendar.DAY_OF_MONTH, 31); calendar.set(Calendar.HOUR_OF_DAY, 23); return resetDayEnd(calendar); } ",
        "test_tgt": "@Test public void testResetYearEnd() { Date date = DateUtil.toDate(\"2016\", DatePattern.yyyy); Calendar resetYearEnd = CalendarUtil.resetYearEnd(DateUtil.toCalendar(date)); assertEquals(\"2016-12-31 23:59:59.999\", CalendarUtil.toString(resetYearEnd, DatePattern.COMMON_DATE_AND_TIME_WITH_MILLISECOND)); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_atZone_resolver() { LocalDateTime t = LocalDateTime.of(2008, 6, 30, 11, 30); assertEquals(t.atZone(ZONE_PARIS, ZoneResolvers.postTransition()), ZonedDateTime.of(LocalDateTime.of(2008, 6, 30, 11, 30), ZONE_PARIS)); } ",
        "focal_tgt": "@Override public ZonedDateTime atZone(ZoneId zone) { return ZonedDateTime.of(this, zone); } ",
        "focal_src": "@Override public ZonedDateTime atZone(ZoneId zone) { return ZonedDateTime.of(this, zone, ZoneResolvers.postGapPreOverlap()); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_atZone_Offset() { LocalDateTime t = LocalDateTime.of(2008, 6, 30, 11, 30); assertEquals(t.atZone(OFFSET_PTWO), ZonedDateTime.of(LocalDateTime.of(2008, 6, 30, 11, 30), OFFSET_PTWO)); } "
    },
    {
        "test_src": "@Test(expected = APIException.class)@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = Context.getOrderService().getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); Context.getOrderService().saveOrderFrequency(orderFrequency); } ",
        "focal_tgt": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw new APIException(\"This order frequency cannot be edited because it is already in use\"); } } return dao.saveOrderFrequency(orderFrequency); } ",
        "focal_src": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw new APIException(\"This order frequency cannot be edited because it is already in use\"); } } ValidateUtil.validate(orderFrequency); return dao.saveOrderFrequency(orderFrequency); } ",
        "test_tgt": "@Test@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = Context.getOrderService().getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); expectedException.expect(APIException.class); expectedException.expectMessage(\"This order frequency cannot be edited because it is already in use\"); Context.getOrderService().saveOrderFrequency(orderFrequency); } "
    },
    {
        "test_src": "@TestInfo(level = TestLevel.PARTIAL_OK, purpose = \"Verifies that getPolicyTree method returns the root node of \" + \"the valid policy tree.\", targets = { @TestTarget(methodName = \"getPolicyTree\", methodArgs = { }) })public final void testGetPolicyTree01()throws Exception { TrustAnchor ta = TestUtils.getTrustAnchor(); if(ta == null) { fail(getName() + \": not performed (could not create test TrustAnchor)\"); } PolicyNode pn = TestUtils.getPolicyTree(); PKIXCertPathValidatorResult vr = new PKIXCertPathValidatorResult(ta, pn, testPublicKey); assertSame(pn, vr.getPolicyTree()); } ",
        "focal_tgt": "public static PolicyNode getPolicyTree() { return new PolicyNode() { final PolicyNode parent = this; public int getDepth() { return 0; } public boolean isCritical() { return false; } public String getValidPolicy() { return null; } public PolicyNode getParent() { return null; } public Iterator < PolicyNode > getChildren() { PolicyNode child = new PolicyNode() { public int getDepth() { return 1; } public boolean isCritical() { return false; } public String getValidPolicy() { return null; } public PolicyNode getParent() { return parent; } public Iterator < PolicyNode > getChildren() { return null; } public Set < String > getExpectedPolicies() { return null; } public Set < ? extends PolicyQualifierInfo > getPolicyQualifiers() { return null; } }; HashSet < PolicyNode > s = new HashSet < PolicyNode > (); s.add(child); return s.iterator(); } public Set < String > getExpectedPolicies() { return null; } public Set < ? extends PolicyQualifierInfo > getPolicyQualifiers() { return null; } }; } ",
        "focal_src": "public static PolicyNode getPolicyTree() { return new PolicyNode() { final PolicyNode parent = this; public int getDepth() { return 0; } public boolean isCritical() { return false; } public String getValidPolicy() { return null; } public PolicyNode getParent() { return null; } public Iterator getChildren() { PolicyNode child = new PolicyNode() { public int getDepth() { return 1; } public boolean isCritical() { return false; } public String getValidPolicy() { return null; } public PolicyNode getParent() { return parent; } public Iterator getChildren() { return null; } public Set getExpectedPolicies() { return null; } public Set getPolicyQualifiers() { return null; } }; HashSet < PolicyNode > s = new HashSet < PolicyNode > (); s.add(child); return s.iterator(); } public Set getExpectedPolicies() { return null; } public Set getPolicyQualifiers() { return null; } }; } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.PARTIAL_COMPLETE, notes = \"Verifies that getPolicyTree method returns the root node of the valid policy tree.\", method = \"getPolicyTree\", args = { })public final void testGetPolicyTree01()throws Exception { TrustAnchor ta = TestUtils.getTrustAnchor(); if(ta == null) { fail(getName() + \": not performed (could not create test TrustAnchor)\"); } PolicyNode pn = TestUtils.getPolicyTree(); PKIXCertPathValidatorResult vr = new PKIXCertPathValidatorResult(ta, pn, testPublicKey); assertSame(pn, vr.getPolicyTree()); } "
    },
    {
        "test_src": "@Test public void setUserFromThriftClientTest()throws Exception { Configuration conf = new Configuration(); Permission permission = Permission.defaults(); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); permission.setUserFromThriftClient(conf); verifyPermission(\"\", \"\", (short)0777, permission); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); conf.set(Constants.SECURITY_GROUP_MAPPING, IdentityUserGroupsMapping.class.getName()); AuthenticatedClientUser.set(\"test_client_user\"); permission.setUserFromThriftClient(conf); verifyPermission(\"test_client_user\", \"test_client_user\", (short)0777, permission); } ",
        "focal_tgt": "public Permission setOwnerFromThriftClient(Configuration conf)throws IOException { if( ! SecurityUtils.isAuthenticationEnabled(conf)) { return this; } User user = AuthenticatedClientUser.get(conf); Preconditions.checkNotNull(user, ExceptionMessage.AUTHORIZED_CLIENT_USER_IS_NULL.getMessage()); mOwner = user.getName(); mGroup = CommonUtils.getPrimaryGroupName(conf, user.getName()); return this; } ",
        "focal_src": "public Permission setUserFromThriftClient(Configuration conf)throws IOException { if( ! SecurityUtils.isAuthenticationEnabled(conf)) { return this; } User user = AuthenticatedClientUser.get(conf); Preconditions.checkNotNull(user, ExceptionMessage.AUTHORIZED_CLIENT_USER_IS_NULL.getMessage()); mUserName = user.getName(); mGroupName = CommonUtils.getPrimaryGroupName(conf, user.getName()); return this; } ",
        "test_tgt": "@Test public void setUserFromThriftClientTest()throws Exception { Configuration conf = new Configuration(); Permission permission = Permission.defaults(); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName()); permission.setOwnerFromThriftClient(conf); verifyPermission(\"\", \"\", (short)0777, permission); conf.set(Constants.SECURITY_AUTHENTICATION_TYPE, AuthType.SIMPLE.getAuthName()); conf.set(Constants.SECURITY_GROUP_MAPPING, IdentityUserGroupsMapping.class.getName()); AuthenticatedClientUser.set(\"test_client_user\"); permission.setOwnerFromThriftClient(conf); verifyPermission(\"test_client_user\", \"test_client_user\", (short)0777, permission); } "
    },
    {
        "test_src": "@Test public void testRestart() { server.occupie(); CertificateMutator mut = new FixedCertificateMutator(); server.start(\"\", mut.getServerCertificateKeypair().getCertificateFile(), mut.getServerCertificateKeypair().getKeyFile()); server.serverIsRunning(); } ",
        "focal_tgt": "public synchronized void restart(String prefix, File certificateFile, File keyFile) { if( ! this.isFree()) { if(p != null) { stop(); } try { id = LogFileIDManager.getInstance().getID(); String command = (prefix + restartServerCommand).replace(\"[id]\", \"\" + id); command = command.replace(\"[output]\", ConfigManager.getInstance().getConfig().getTracesFolder().getAbsolutePath()); command = command.replace(\"[port]\", \"\" + port); command = command.replace(\"[cert]\", \"\" + certificateFile.getAbsolutePath()); command = command.replace(\"[key]\", \"\" + keyFile.getAbsolutePath()); LOG.log(Level.INFO, \"Starting Server:\" + command); long time = System.currentTimeMillis(); Runtime rt = Runtime.getRuntime(); p = rt.exec(command); errorGobbler = new StreamGobbler(p.getErrorStream(), \"ERR\", accepted); outputGobbler = new StreamGobbler(p.getInputStream(), \"OUT\", accepted); errorGobbler.start(); outputGobbler.start(); procmon = ProcMon.create(p); while( ! outputGobbler.accepted()) { try { Thread.sleep(50); } catch(InterruptedException ex) { Logger.getLogger(TLSServer.class.getName()).log(Level.SEVERE, null, ex); } if(System.currentTimeMillis() - time >= ConfigManager.getInstance().getConfig().getTimeout()) { throw new TimeoutException(\"Timeout in StreamGobler, Server never finished starting\"); } } } catch(IOException t) { t.printStackTrace(); } } else { throw new IllegalStateException(\"Cant restart a not marked Server. Occupie it first!\"); } } ",
        "focal_src": "public synchronized void restart(String prefix, File certificateFile, File keyFile) { if( ! this.isFree()) { if(p != null) { stop(); } try { id = LogFileIDManager.getInstance().getID(); String command = (prefix + restartServerCommand).replace(\"[id]\", \"\" + id); command = command.replace(\"[output]\", ConfigManager.getInstance().getConfig().getTracesFolder().getAbsolutePath()); command = command.replace(\"[port]\", \"\" + port); command = command.replace(\"[cert]\", \"\" + certificateFile.getAbsolutePath()); command = command.replace(\"[key]\", \"\" + keyFile.getAbsolutePath()); LOG.log(Level.FINE, \"Starting Server:\" + command); long time = System.currentTimeMillis(); Runtime rt = Runtime.getRuntime(); p = rt.exec(command); errorGobbler = new StreamGobbler(p.getErrorStream(), \"ERR\", accepted); outputGobbler = new StreamGobbler(p.getInputStream(), \"OUT\", accepted); errorGobbler.start(); outputGobbler.start(); procmon = ProcMon.create(p); while( ! outputGobbler.accepted()) { try { Thread.sleep(50); } catch(InterruptedException ex) { Logger.getLogger(TLSServer.class.getName()).log(Level.SEVERE, null, ex); } if(System.currentTimeMillis() - time >= ConfigManager.getInstance().getConfig().getTimeout()) { throw new RuntimeException(\"Timeout in StreamGobler, Server never finished starting\"); } } } catch(IOException t) { t.printStackTrace(); } } else { throw new IllegalStateException(\"Cant restart a not marked Server. Occupie it first!\"); } } ",
        "test_tgt": "@Test public void testRestart() { server.occupie(); CertificateMutator mut = new FixedCertificateMutator(); ServerCertificateStructure cert = mut.getServerCertificateStructure(); server.start(\"\", cert.getCertificateFile(), cert.getKeyFile()); server.serverIsRunning(); } "
    },
    {
        "test_src": "@Test public void copyTest()throws Exception { storeCopier.copy(new StoreFindTokenFactory(STORE_KEY_FACTORY).getNewFindToken()); storeCopier.close(); StoreMetrics storeMetrics = new StoreMetrics(new MetricRegistry()); Files.copy(new File(srcDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), new File(tgtDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), StandardCopyOption.REPLACE_EXISTING); BlobStore tgt = new BlobStore(STORE_ID, storeConfig, null, null, DISK_IO_SCHEDULER, StoreTestUtils.DEFAULT_DISK_SPACE_ALLOCATOR, storeMetrics, storeMetrics, tgtDir.getAbsolutePath(), STORE_CAPACITY, STORE_KEY_FACTORY, null, null, time); tgt.start(); try { StoreKey[]failKeys = { expiredId, deletedId }; for(StoreKey key : failKeys) { try { tgt.get(Collections.singletonList(key), EnumSet.allOf(StoreGetOptions.class)); fail(\"Should have failed to get \" + key); } catch(StoreException e) { assertEquals(\"Unexpected StoreErrorCode\", StoreErrorCodes.ID_Not_Found, e.getErrorCode()); } } StoreInfo storeInfo = tgt.get(Collections.singletonList(putId), EnumSet.noneOf(StoreGetOptions.class)); MessageInfo messageInfo = storeInfo.getMessageReadSetInfo().get(0); assertEquals(\"Size does not match\", putData.length, messageInfo.getSize()); assertEquals(\"Size does not match\", putData.length, storeInfo.getMessageReadSet().sizeInBytes(0)); assertFalse(\"Should not be deleted or expired\", messageInfo.isDeleted() || messageInfo.isExpired()); ByteBufferChannel channel = new ByteBufferChannel(ByteBuffer.allocate(putData.length)); storeInfo.getMessageReadSet().writeTo(0, channel, 0, putData.length); assertArrayEquals(\"Data put does not match data copied\", putData, channel.getBuffer().array()); } finally { tgt.shutdown(); } } ",
        "focal_tgt": "public Pair < FindToken, Boolean > copy(FindToken startToken)throws Exception { boolean sourceHasProblems = false; FindToken lastToken; FindToken token = startToken; do { lastToken = token; FindInfo findInfo = src.findEntriesSince(lastToken, fetchSizeInBytes); List < MessageInfo > messageInfos = findInfo.getMessageEntries(); for(MessageInfo messageInfo : messageInfos) { logger.trace(\"Processing {} - isDeleted: {}, isExpired {}\", messageInfo.getStoreKey(), messageInfo.isDeleted(), messageInfo.isExpired()); if( ! messageInfo.isExpired() && ! messageInfo.isDeleted()) { if(messageInfo.getSize() > Integer.MAX_VALUE) { throw new IllegalStateException(\"Cannot copy blobs whose size > Integer.MAX_VALUE\"); } if(tgt.findMissingKeys(Collections.singletonList(messageInfo.getStoreKey())).size() == 1) { int size = (int)messageInfo.getSize(); StoreInfo storeInfo = src.get(Collections.singletonList(messageInfo.getStoreKey()), EnumSet.allOf(StoreGetOptions.class)); MessageReadSet readSet = storeInfo.getMessageReadSet(); byte[]buf = new byte[size]; readSet.writeTo(0, new ByteBufferChannel(ByteBuffer.wrap(buf)), 0, size); Message message = new Message(messageInfo, new ByteArrayInputStream(buf)); for(Transformer transformer : transformers) { TransformationOutput tfmOutput = transformer.transform(message); if(tfmOutput.getException() != null) { throw tfmOutput.getException(); } else { message = tfmOutput.getMsg(); } if(message == null) { break; } } if(message == null) { logger.trace(\"Dropping {} because the transformers did not return a message\", messageInfo.getStoreKey()); continue; } MessageFormatWriteSet writeSet = new MessageFormatWriteSet(message.getStream(), Collections.singletonList(message.getMessageInfo()), false); tgt.put(writeSet); MessageInfo tgtMsgInfo = message.getMessageInfo(); if(tgtMsgInfo.isTtlUpdated()) { TtlUpdateMessageFormatInputStream stream = new TtlUpdateMessageFormatInputStream(tgtMsgInfo.getStoreKey(), tgtMsgInfo.getAccountId(), tgtMsgInfo.getContainerId(), tgtMsgInfo.getExpirationTimeInMs(), tgtMsgInfo.getOperationTimeMs()); MessageInfo updateMsgInfo = new MessageInfo(tgtMsgInfo.getStoreKey(), stream.getSize(), false, true, tgtMsgInfo.getExpirationTimeInMs(), tgtMsgInfo.getAccountId(), tgtMsgInfo.getContainerId(), tgtMsgInfo.getOperationTimeMs()); writeSet = new MessageFormatWriteSet(stream, Collections.singletonList(updateMsgInfo), false); tgt.updateTtl(writeSet); } logger.trace(\"Copied {} as {}\", messageInfo.getStoreKey(), tgtMsgInfo.getStoreKey()); } else if( ! messageInfo.isTtlUpdated()) { logger.warn(\"Found a duplicate entry for {} while copying data\", messageInfo.getStoreKey()); sourceHasProblems = true; } } } token = findInfo.getFindToken(); double percentBytesRead = src.isEmpty() ? 100.0 : token.getBytesRead() * 100.0 / src.getSizeInBytes(); logger.info(\"[{}] [{}] {}% copied\", Thread.currentThread().getName(), storeId, df.format(percentBytesRead)); } while( ! token.equals(lastToken)); return new Pair < > (token, sourceHasProblems); } ",
        "focal_src": "public Pair < FindToken, Boolean > copy(FindToken startToken)throws Exception { boolean sourceHasProblems = false; FindToken lastToken; FindToken token = startToken; do { lastToken = token; FindInfo findInfo = src.findEntriesSince(lastToken, fetchSizeInBytes); List < MessageInfo > messageInfos = findInfo.getMessageEntries(); for(MessageInfo messageInfo : messageInfos) { logger.trace(\"Processing {} - isDeleted: {}, isExpired {}\", messageInfo.getStoreKey(), messageInfo.isDeleted(), messageInfo.isExpired()); if( ! messageInfo.isExpired() && ! messageInfo.isDeleted()) { if(messageInfo.getSize() > Integer.MAX_VALUE) { throw new IllegalStateException(\"Cannot copy blobs whose size > Integer.MAX_VALUE\"); } if(tgt.findMissingKeys(Collections.singletonList(messageInfo.getStoreKey())).size() == 1) { int size = (int)messageInfo.getSize(); StoreInfo storeInfo = src.get(Collections.singletonList(messageInfo.getStoreKey()), EnumSet.allOf(StoreGetOptions.class)); MessageReadSet readSet = storeInfo.getMessageReadSet(); byte[]buf = new byte[size]; readSet.writeTo(0, new ByteBufferChannel(ByteBuffer.wrap(buf)), 0, size); Message message = new Message(messageInfo, new ByteArrayInputStream(buf)); for(Transformer transformer : transformers) { TransformationOutput tfmOutput = transformer.transform(message); if(tfmOutput.getException() != null) { throw tfmOutput.getException(); } else { message = tfmOutput.getMsg(); } if(message == null) { break; } } if(message == null) { logger.trace(\"Dropping {} because the transformers did not return a message\", messageInfo.getStoreKey()); continue; } MessageFormatWriteSet writeSet = new MessageFormatWriteSet(message.getStream(), Collections.singletonList(message.getMessageInfo()), false); tgt.put(writeSet); logger.trace(\"Copied {} as {}\", messageInfo.getStoreKey(), message.getMessageInfo().getStoreKey()); } else { logger.warn(\"Found a duplicate entry for {} while copying data\", messageInfo.getStoreKey()); sourceHasProblems = true; } } } token = findInfo.getFindToken(); double percentBytesRead = src.isEmpty() ? 100.0 : token.getBytesRead() * 100.0 / src.getSizeInBytes(); logger.info(\"[{}] [{}] {}% copied\", Thread.currentThread().getName(), storeId, df.format(percentBytesRead)); } while( ! token.equals(lastToken)); return new Pair < > (token, sourceHasProblems); } ",
        "test_tgt": "@Test public void copyTest()throws Exception { storeCopier.copy(new StoreFindTokenFactory(STORE_KEY_FACTORY).getNewFindToken()); storeCopier.close(); StoreMetrics storeMetrics = new StoreMetrics(new MetricRegistry()); Files.copy(new File(srcDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), new File(tgtDir, StoreDescriptor.STORE_DESCRIPTOR_FILENAME).toPath(), StandardCopyOption.REPLACE_EXISTING); BlobStore tgt = new BlobStore(STORE_ID, storeConfig, null, null, DISK_IO_SCHEDULER, StoreTestUtils.DEFAULT_DISK_SPACE_ALLOCATOR, storeMetrics, storeMetrics, tgtDir.getAbsolutePath(), STORE_CAPACITY, STORE_KEY_FACTORY, null, null, time); tgt.start(); try { StoreKey[]failKeys = { expiredId, deletedId, putTtlUpdatedAndDeletedId }; for(StoreKey key : failKeys) { try { tgt.get(Collections.singletonList(key), EnumSet.allOf(StoreGetOptions.class)); fail(\"Should have failed to get \" + key); } catch(StoreException e) { assertEquals(\"Unexpected StoreErrorCode\", StoreErrorCodes.ID_Not_Found, e.getErrorCode()); } } Map < StoreKey, Pair < byte[], Long > > successKeys = new HashMap < > (); successKeys.put(permanentPutId, new Pair < > (permanentPutData, Utils.Infinite_Time)); successKeys.put(putAndTtlUpdatedId, new Pair < > (putAndTtlUpdatedData, Utils.Infinite_Time)); successKeys.put(temporaryPutId, new Pair < > (temporaryPutData, temporaryPutExpiryTimeMs)); for(Map.Entry < StoreKey, Pair < byte[], Long > > entry : successKeys.entrySet()) { StoreInfo storeInfo = tgt.get(Collections.singletonList(entry.getKey()), EnumSet.noneOf(StoreGetOptions.class)); MessageInfo messageInfo = storeInfo.getMessageReadSetInfo().get(0); byte[]data = entry.getValue().getFirst(); assertEquals(\"Size does not match\", data.length, messageInfo.getSize()); assertEquals(\"Size does not match\", data.length, storeInfo.getMessageReadSet().sizeInBytes(0)); assertFalse(\"Should not be deleted or expired\", messageInfo.isDeleted() || messageInfo.isExpired()); assertEquals(\"Ttl update flag not as expected\", putAndTtlUpdatedId.equals(entry.getKey()), messageInfo.isTtlUpdated()); assertEquals(\"Expiration time does not match\", entry.getValue().getSecond().longValue(), messageInfo.getExpirationTimeInMs()); ByteBufferChannel channel = new ByteBufferChannel(ByteBuffer.allocate(data.length)); storeInfo.getMessageReadSet().writeTo(0, channel, 0, data.length); assertArrayEquals(\"Data put does not match data copied\", data, channel.getBuffer().array()); } } finally { tgt.shutdown(); } } "
    },
    {
        "test_src": "@Test public void getRootPackageTest() { conflictResolver.setPrefixForIdentifier(null); String rootPackage = getRootPackage((byte)1, CHILD_PACKAGE, DATE1, conflictResolver); assertThat(rootPackage.equals(DEFAULT_BASE_PKG + PERIOD + VERSION_NUMBER + PERIOD + CHILD_WITH_PERIOD + PERIOD + DATE_WITH_REV1), is(true)); } ",
        "focal_tgt": "public static String getRootPackage(byte version, String nameSpace, Date revision, YangToJavaNamingConflictUtil conflictResolver) { String pkg; pkg = DEFAULT_BASE_PKG; pkg = pkg + PERIOD; pkg = pkg + getYangVersion(version); pkg = pkg + PERIOD; pkg = pkg + getPkgFromNameSpace(nameSpace, conflictResolver); pkg = pkg + PERIOD; pkg = pkg + getYangRevisionStr(revision); return pkg.toLowerCase(); } ",
        "focal_src": "public static String getRootPackage(byte version, String nameSpace, String revision, YangToJavaNamingConflictUtil conflictResolver) { String pkg; pkg = DEFAULT_BASE_PKG; pkg = pkg + PERIOD; pkg = pkg + getYangVersion(version); pkg = pkg + PERIOD; pkg = pkg + getPkgFromNameSpace(nameSpace, conflictResolver); pkg = pkg + PERIOD; pkg = pkg + getYangRevisionStr(revision); return pkg.toLowerCase(); } ",
        "test_tgt": "@Test public void getRootPackageTest()throws ParseException { conflictResolver.setPrefixForIdentifier(null); Date date = simpleDateFormat.parse(DATE1); String rootPackage = getRootPackage((byte)1, CHILD_PACKAGE, date, conflictResolver); assertThat(rootPackage.equals(DEFAULT_BASE_PKG + PERIOD + VERSION_NUMBER + PERIOD + CHILD_WITH_PERIOD + PERIOD + DATE_WITH_REV1), is(true)); } "
    },
    {
        "test_src": "@Test public void testSubscribe() { final AtomicReference < URL > args = new AtomicReference < URL > (); registry.subscribe(consumerUrl, new NotifyListener() { public void notify(List < URL > urls) { args.set(urls.get(0)); } }); assertEquals(serviceUrl.toFullString(), args.get().toFullString()); Map < URL, Set < NotifyListener > > arg = registry.getSubscribed(); assertEquals(consumerUrl, arg.keySet().iterator().next()); } ",
        "focal_tgt": "@Override public void subscribe(URL url, NotifyListener listener) { this.subscribedUrl = url; List < URL > urls = new ArrayList < URL > (); urls.add(url.setProtocol(\"mockprotocol\").removeParameter(Constants.CATEGORY_KEY).addParameter(Constants.METHODS_KEY, \"sayHello\")); listener.notify(urls); } ",
        "focal_src": "public void subscribe(URL url, NotifyListener listener) { this.subscribedUrl = url; List < URL > urls = new ArrayList < URL > (); urls.add(url.setProtocol(\"mockprotocol\").removeParameter(Constants.CATEGORY_KEY).addParameter(Constants.METHODS_KEY, \"sayHello\")); listener.notify(urls); } ",
        "test_tgt": "@Test public void testSubscribe() { final AtomicReference < URL > args = new AtomicReference < URL > (); registry.subscribe(consumerUrl, new NotifyListener() { @Override public void notify(List < URL > urls) { args.set(urls.get(0)); } }); assertEquals(serviceUrl.toFullString(), args.get().toFullString()); Map < URL, Set < NotifyListener > > arg = registry.getSubscribed(); assertEquals(consumerUrl, arg.keySet().iterator().next()); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_withLaterOffsetAtOverlap_notAtOverlap() { OffsetDateTime odt = OffsetDateTime.of(TEST_LOCAL_2008_06_30_11_30_59_500, OFFSET_0200); ZonedDateTime base = ZonedDateTime.of(odt, ZONE_PARIS); ZonedDateTime test = base.withLaterOffsetAtOverlap(); assertEquals(test, base); } ",
        "focal_tgt": "@Override public ZonedDateTime withLaterOffsetAtOverlap() { ZoneOffsetTransition trans = getZone().getRules().getTransition(getDateTime()); if(trans != null) { ZoneOffset laterOffset = trans.getOffsetAfter(); if(laterOffset.equals(offset) == false) { return new ZonedDateTime(dateTime, laterOffset, zoneId); } } return this; } ",
        "focal_src": "@Override public ZonedDateTime withLaterOffsetAtOverlap() { ZoneOffsetTransition trans = getZone().getRules().getTransition(getDateTime()); if(trans != null) { ZoneOffset offset = trans.getOffsetAfter(); if(offset.equals(getOffset()) == false) { OffsetDateTime newDT = dateTime.withOffsetSameLocal(offset); return new ZonedDateTime(newDT, zone); } } return this; } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_withLaterOffsetAtOverlap_notAtOverlap() { ZonedDateTime base = ZonedDateTime.ofStrict(TEST_LOCAL_2008_06_30_11_30_59_500, OFFSET_0200, ZONE_PARIS); ZonedDateTime test = base.withLaterOffsetAtOverlap(); assertEquals(test, base); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_with_adjustment() { final OffsetDateTime sample = OffsetDateTime.of(2012, 3, 4, 23, 5, OFFSET_PONE); DateTimeAdjuster adjuster = new DateTimeAdjuster() { @Override public AdjustableDateTime makeAdjustmentTo(AdjustableDateTime calendrical) { return sample; } }; assertEquals(TEST_2008_6_30_11_30_59_000000500.with(adjuster), sample); } ",
        "focal_tgt": "public ChronoDate with(DateTimeAdjuster adjuster) { return(ChronoDate)adjuster.doAdjustment(this); } ",
        "focal_src": "public ChronoDate with(DateTimeAdjuster adjuster) { return(ChronoDate)adjuster.makeAdjustmentTo(this); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_with_adjustment() { final OffsetDateTime sample = OffsetDateTime.of(2012, 3, 4, 23, 5, OFFSET_PONE); DateTimeAdjuster adjuster = new DateTimeAdjuster() { @Override public AdjustableDateTime doAdjustment(AdjustableDateTime calendrical) { return sample; } }; assertEquals(TEST_2008_6_30_11_30_59_000000500.with(adjuster), sample); } "
    },
    {
        "test_src": "@Test public void compareTo_shouldFailIfStartOrEndDateDoNotMatch()throws Exception { CohortMembership firstMembership = new CohortMembership(4); CohortMembership secondMembership = new CohortMembership(4); Cohort cohort = new Cohort(1); firstMembership.setCohort(cohort); secondMembership.setCohort(cohort); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); Date oneDate = dateFormat.parse(\"2017-01-01 00:00:00\"); Date twoDate = dateFormat.parse(\"2017-01-31 00:00:00\"); firstMembership.setStartDate(oneDate); secondMembership.setStartDate(twoDate); assertEquals( - 1, firstMembership.compareTo(secondMembership)); secondMembership.setStartDate(oneDate); secondMembership.setEndDate(twoDate); assertEquals( - 1, firstMembership.compareTo(secondMembership)); } ",
        "focal_tgt": "@Override public int compareTo(CohortMembership o) { int ret = this.getVoided().compareTo(o.getVoided()); if(ret == 0) { ret = OpenmrsUtil.compareWithNullAsLowest(getCohort() == null ? null : getCohort().getId(), o.getCohort() == null ? null : o.getCohort().getId()); } if(ret == 0) { ret = this.getPatientId().compareTo(o.getPatientId()); } if(ret == 0) { ret = OpenmrsUtil.compare(this.getStartDate(), o.getStartDate()); } if(ret == 0) { ret = OpenmrsUtil.compareWithNullAsLatest(this.getEndDate(), o.getEndDate()); } return ret; } ",
        "focal_src": "@Override public int compareTo(CohortMembership o) { if((this.getVoided() && ! o.getVoided()) || ( ! this.isActive() && o.isActive())) { return 1; } else if(( ! this.getVoided() && o.getVoided()) || (this.isActive() && ! o.isActive())) { return - 1; } int ret = OpenmrsUtil.compareWithNullAsGreatest(this.getCohort().getCohortId(), o.getCohort().getCohortId()); if(ret != 0) { return ret; } ret = this.getPatientId().compareTo(o.getPatientId()); if(ret != 0) { return ret; } ret = OpenmrsUtil.compareWithNullAsEarliest(this.getEndDate(), o.getEndDate()); if(ret != 0) { return ret; } return OpenmrsUtil.compare(this.getStartDate(), o.getStartDate()); } ",
        "test_tgt": "@Test public void compareTo_shouldFailIfStartOrEndDateDoNotMatch()throws Exception { CohortMembership firstMembership = new CohortMembership(4); CohortMembership secondMembership = new CohortMembership(4); Cohort cohort = new Cohort(1); firstMembership.setCohort(cohort); secondMembership.setCohort(cohort); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); Date oneDate = dateFormat.parse(\"2017-01-01 00:00:00\"); Date twoDate = dateFormat.parse(\"2017-01-31 00:00:00\"); firstMembership.setStartDate(oneDate); secondMembership.setStartDate(oneDate); secondMembership.setEndDate(twoDate); assertEquals(1, firstMembership.compareTo(secondMembership)); assertEquals( - 1, secondMembership.compareTo(firstMembership)); } "
    },
    {
        "test_src": "@Test public void getWorker() { List < BlockWorkerInfo > workerInfoList = new ArrayList < > (); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker1\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker2\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 2 * (long)Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker3\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 3 * (long)Constants.GB, 0)); RoundRobinPolicy policy = new RoundRobinPolicy(); Assert.assertNotEquals(policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost(), policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost()); } ",
        "focal_tgt": "WorkerNetAddress getWorker(GetWorkerOptions options)throws UnavailableException; ",
        "focal_src": "WorkerNetAddress getWorker(GetWorkerOptions options); ",
        "test_tgt": "@Test public void getWorker()throws Exception { List < BlockWorkerInfo > workerInfoList = new ArrayList < > (); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker1\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker2\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 2 * (long)Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker3\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 3 * (long)Constants.GB, 0)); RoundRobinPolicy policy = new RoundRobinPolicy(); Assert.assertNotEquals(policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost(), policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost()); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_matchesCalendrical_ymd_date() { LocalDate date = LocalDate.of(2008, 6, 30); assertEquals(DateTimeField.of(YEAR, 2008).matchesCalendrical(date), true); assertEquals(DateTimeField.of(YEAR, 2006).matchesCalendrical(date), false); assertEquals(DateTimeField.of(MONTH_OF_YEAR, 6).matchesCalendrical(date), true); assertEquals(DateTimeField.of(MONTH_OF_YEAR, 7).matchesCalendrical(date), false); assertEquals(DateTimeField.of(MONTH_OF_YEAR, - 1).matchesCalendrical(date), false); assertEquals(DateTimeField.of(DAY_OF_MONTH, 30).matchesCalendrical(date), true); assertEquals(DateTimeField.of(DAY_OF_MONTH, 12).matchesCalendrical(date), false); assertEquals(DateTimeField.of(DAY_OF_WEEK, 1).matchesCalendrical(date), true); assertEquals(DateTimeField.of(DAY_OF_WEEK, 2).matchesCalendrical(date), false); assertEquals(DateTimeField.of(HOUR_OF_DAY, 2).matchesCalendrical(date), false); } ",
        "focal_tgt": "public boolean matches(Calendrical calendrical) { return this.equals(calendrical.get(rule)); } ",
        "focal_src": "public boolean matchesCalendrical(Calendrical calendrical) { return this.equals(calendrical.get(rule)); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_matches() { LocalDate date = LocalDate.of(2008, 6, 30); assertEquals(DateTimeField.of(YEAR, 2008).matches(DateTimeField.of(YEAR, 2008)), true); assertEquals(DateTimeField.of(YEAR, 2008).matches(DateTimeField.of(YEAR, 2012)), false); assertEquals(DateTimeField.of(YEAR, 2008).matches(DateTimeField.of(MONTH_OF_YEAR, 2008)), false); assertEquals(DateTimeField.of(YEAR, 2008).matches(date), true); assertEquals(DateTimeField.of(YEAR, 2012).matches(date), false); assertEquals(DateTimeField.of(MONTH_OF_YEAR, 6).matches(date), true); assertEquals(DateTimeField.of(MONTH_OF_YEAR, 7).matches(date), false); assertEquals(DateTimeField.of(MONTH_OF_YEAR, - 1).matches(date), false); assertEquals(DateTimeField.of(DAY_OF_MONTH, 30).matches(date), true); assertEquals(DateTimeField.of(DAY_OF_MONTH, 12).matches(date), false); assertEquals(DateTimeField.of(DAY_OF_WEEK, 1).matches(date), true); assertEquals(DateTimeField.of(DAY_OF_WEEK, 2).matches(date), false); assertEquals(DateTimeField.of(HOUR_OF_DAY, 2).matches(date), false); } "
    },
    {
        "test_src": "@Test public void testCreateThumbnail_FFII_Transcoding()throws IOException { File inputFile = new File(\"test-resources/Thumbnailator/grid.jpg\"); File outputFile = File.createTempFile(\"thumbnailator-testing-\", \".png\"); outputFile.deleteOnExit(); Thumbnailator.createThumbnail(inputFile, outputFile, 50, 50); assertTrue(outputFile.exists()); BufferedImage img = ImageIO.read(outputFile); assertEquals(\"png\", ImageIO.getImageReaders(ImageIO.createImageInputStream(outputFile)).next().getFormatName()); assertEquals(50, img.getWidth()); assertEquals(50, img.getHeight()); } ",
        "focal_tgt": "public static void createThumbnail(InputStream is, OutputStream os, int width, int height)throws IOException { Thumbnailator.createThumbnail(is, os, ThumbnailParameter.ORIGINAL_FORMAT, width, height); } ",
        "focal_src": "public static void createThumbnail(InputStream is, OutputStream os, int width, int height)throws IOException { validateDimensions(width, height); if(is == null) { throw new NullPointerException(\"InputStream is null.\"); } else if(os == null) { throw new NullPointerException(\"OutputStream is null.\"); } ThumbnailParameter param = new ThumbnailParameter(new Dimension(width, height), true, ThumbnailParameter.ORIGINAL_FORMAT, ThumbnailParameter.DEFAULT_FORMAT_TYPE, ThumbnailParameter.DEFAULT_QUALITY, BufferedImage.TYPE_INT_ARGB, null, Resizers.PROGRESSIVE); Thumbnailator.createThumbnail(new StreamThumbnailTask(param, is, os)); } ",
        "test_tgt": "@Test public void testCreateThumbnail_FFII_Transcoding_Jpeg_Png()throws IOException { File inputFile = new File(\"test-resources/Thumbnailator/grid.jpg\"); File outputFile = File.createTempFile(\"thumbnailator-testing-\", \".png\"); outputFile.deleteOnExit(); Thumbnailator.createThumbnail(inputFile, outputFile, 50, 50); assertTrue(outputFile.exists()); BufferedImage img = ImageIO.read(outputFile); assertEquals(\"png\", ImageIO.getImageReaders(ImageIO.createImageInputStream(outputFile)).next().getFormatName()); assertEquals(50, img.getWidth()); assertEquals(50, img.getHeight()); } "
    },
    {
        "test_src": "@Test public void testParseMessageAction() { byte[]serverHelloDoneMsg = { 0x0e, 0x00, 0x00, 0x00 }; handler.initializeProtocolMessage(); int endPointer = handler.parseMessage(serverHelloDoneMsg, 0); ServerHelloDoneMessage message = handler.getProtocolMessage(); HandshakeMessageFields handshakeMessageFields = (HandshakeMessageFields)message.getMessageFields(); assertNotNull(\"Confirm that parseMessage didn't return 'NULL'\", endPointer); assertEquals(\"Confirm expected message type: \\\"ServerHelloDone\\\"\", HandshakeMessageType.SERVER_HELLO_DONE, message.getHandshakeMessageType()); assertEquals(\"Confirm expected message length of \\\"0\\\"\", new Integer(0), handshakeMessageFields.getLength().getValue()); assertEquals(\"Confirm the correct value of endPointer representing the \" + \"actual number of message bytes\", serverHelloDoneMsg.length, endPointer); } ",
        "focal_tgt": "@Override public int parseMessageAction(byte[]message, int pointer) { if(message[pointer] != HandshakeMessageType.SERVER_KEY_EXCHANGE.getValue()) { throw new InvalidMessageTypeException(HandshakeMessageType.SERVER_KEY_EXCHANGE); } HandshakeMessageFields protocolMessageFields = protocolMessage.getMessageFields(); protocolMessage.setType(message[pointer]); int currentPointer = pointer + HandshakeByteLength.MESSAGE_TYPE; int nextPointer = currentPointer + HandshakeByteLength.MESSAGE_TYPE_LENGTH; int length = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessageFields.setLength(length); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int pLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setpLength(pLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getpLength().getValue(); BigInteger p = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setP(p); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int gLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setgLength(gLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getgLength().getValue(); BigInteger g = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setG(g); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int publicKeyLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKeyLength(publicKeyLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getPublicKeyLength().getValue(); BigInteger publicKey = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKey(publicKey); byte[]dhParams = ArrayConverter.concatenate(ArrayConverter.intToBytes(protocolMessage.getpLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getP().getValue()), ArrayConverter.intToBytes(protocolMessage.getgLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getG().getValue()), ArrayConverter.intToBytes(protocolMessage.getPublicKeyLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getPublicKey().getValue())); InputStream is = new ByteArrayInputStream(dhParams); try { ServerDHParams publicKeyParameters = ServerDHParams.parse(is); tlsContext.setServerDHParameters(publicKeyParameters); currentPointer = nextPointer; nextPointer ++ ; HashAlgorithm ha = HashAlgorithm.getHashAlgorithm(message[currentPointer]); protocolMessage.setHashAlgorithm(ha.getValue()); currentPointer = nextPointer; nextPointer ++ ; SignatureAlgorithm sa = SignatureAlgorithm.getSignatureAlgorithm(message[currentPointer]); protocolMessage.setSignatureAlgorithm(sa.getValue()); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.SIGNATURE_LENGTH; int signatureLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setSignatureLength(signatureLength); currentPointer = nextPointer; nextPointer = currentPointer + signatureLength; protocolMessage.setSignature(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setCompleteResultingMessage(Arrays.copyOfRange(message, pointer, nextPointer)); return nextPointer; } catch(IOException ex) { throw new WorkflowExecutionException(\"DH public key parsing failed\", ex); } } ",
        "focal_src": "@Override public int parseMessageAction(byte[]message, int pointer) { if(message[pointer] != HandshakeMessageType.SERVER_KEY_EXCHANGE.getValue()) { throw new InvalidMessageTypeException(HandshakeMessageType.SERVER_KEY_EXCHANGE); } HandshakeMessageFields protocolMessageFields = (HandshakeMessageFields)protocolMessage.getMessageFields(); protocolMessage.setType(message[pointer]); int currentPointer = pointer + HandshakeByteLength.MESSAGE_TYPE; int nextPointer = currentPointer + HandshakeByteLength.MESSAGE_TYPE_LENGTH; int length = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessageFields.setLength(length); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int pLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setpLength(pLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getpLength().getValue(); BigInteger p = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setP(p); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int gLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setgLength(gLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getgLength().getValue(); BigInteger g = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setG(g); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.DH_PARAM_LENGTH; int publicKeyLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKeyLength(publicKeyLength); currentPointer = nextPointer; nextPointer = currentPointer + protocolMessage.getPublicKeyLength().getValue(); BigInteger publicKey = new BigInteger(1, Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setPublicKey(publicKey); byte[]dhParams = ArrayConverter.concatenate(ArrayConverter.intToBytes(protocolMessage.getpLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getP().getValue()), ArrayConverter.intToBytes(protocolMessage.getgLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getG().getValue()), ArrayConverter.intToBytes(protocolMessage.getPublicKeyLength().getValue(), HandshakeByteLength.DH_PARAM_LENGTH), BigIntegers.asUnsignedByteArray(protocolMessage.getPublicKey().getValue())); InputStream is = new ByteArrayInputStream(dhParams); try { ServerDHParams publicKeyParameters = ServerDHParams.parse(is); tlsContext.setServerDHParameters(publicKeyParameters); currentPointer = nextPointer; nextPointer ++ ; HashAlgorithm ha = HashAlgorithm.getHashAlgorithm(message[currentPointer]); protocolMessage.setHashAlgorithm(ha.getValue()); currentPointer = nextPointer; nextPointer ++ ; SignatureAlgorithm sa = SignatureAlgorithm.getSignatureAlgorithm(message[currentPointer]); protocolMessage.setSignatureAlgorithm(sa.getValue()); currentPointer = nextPointer; nextPointer = currentPointer + HandshakeByteLength.SIGNATURE_LENGTH; int signatureLength = ArrayConverter.bytesToInt(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setSignatureLength(signatureLength); currentPointer = nextPointer; nextPointer = currentPointer + signatureLength; protocolMessage.setSignature(Arrays.copyOfRange(message, currentPointer, nextPointer)); protocolMessage.setCompleteResultingMessage(Arrays.copyOfRange(message, pointer, nextPointer)); return nextPointer; } catch(IOException ex) { throw new WorkflowExecutionException(\"DH public key parsing failed\", ex); } } ",
        "test_tgt": "@Test public void testParseMessageAction() { byte[]serverHelloDoneMsg = { 0x0e, 0x00, 0x00, 0x00 }; handler.initializeProtocolMessage(); int endPointer = handler.parseMessage(serverHelloDoneMsg, 0); ServerHelloDoneMessage message = handler.getProtocolMessage(); HandshakeMessageFields handshakeMessageFields = message.getMessageFields(); assertNotNull(\"Confirm that parseMessage didn't return 'NULL'\", endPointer); assertEquals(\"Confirm expected message type: \\\"ServerHelloDone\\\"\", HandshakeMessageType.SERVER_HELLO_DONE, message.getHandshakeMessageType()); assertEquals(\"Confirm expected message length of \\\"0\\\"\", new Integer(0), handshakeMessageFields.getLength().getValue()); assertEquals(\"Confirm the correct value of endPointer representing the \" + \"actual number of message bytes\", serverHelloDoneMsg.length, endPointer); } "
    },
    {
        "test_src": "@Test public void testPredict() { System.out.println(\"predict\"); for(int lambda = 0; lambda <= 20; lambda += 2) { int n = longley.length; LOOCV loocv = new LOOCV(n); double rss = 0.0; for(int i = 0; i < n; i ++ ) { double[][]trainx = Math.slice(longley, loocv.train[i]); double[]trainy = Math.slice(y, loocv.train[i]); RidgeRegression ridge = new RidgeRegression(trainx, trainy, 0.01 * lambda); double r = y[loocv.test[i]] - ridge.predict(longley[loocv.test[i]]); rss += r * r; } System.out.format(\"LOOCV MSE with lambda %.2f = %.3f%n\", 0.01 * lambda, rss / n); } } ",
        "focal_tgt": "@Override public int predict(double[]x, double[]posteriori) { Arrays.fill(posteriori, 0.0); for(int i = 0; i < trees.length; i ++ ) { posteriori[trees[i].predict(x)] += alpha[i]; } double sum = MathEx.sum(posteriori); for(int i = 0; i < k; i ++ ) { posteriori[i] /= sum; } return MathEx.whichMax(posteriori); } ",
        "focal_src": "@Override public int predict(double[]x, double[]posteriori) { Arrays.fill(posteriori, 0.0); for(int i = 0; i < trees.length; i ++ ) { posteriori[trees[i].predict(x)] += alpha[i]; } double sum = Math.sum(posteriori); for(int i = 0; i < k; i ++ ) { posteriori[i] /= sum; } return Math.whichMax(posteriori); } ",
        "test_tgt": "@Test public void testPredict() { System.out.println(\"predict\"); for(int lambda = 0; lambda <= 20; lambda += 2) { int n = longley.length; LOOCV loocv = new LOOCV(n); double rss = 0.0; for(int i = 0; i < n; i ++ ) { double[][]trainx = MathEx.slice(longley, loocv.train[i]); double[]trainy = MathEx.slice(y, loocv.train[i]); RidgeRegression ridge = new RidgeRegression(trainx, trainy, 0.01 * lambda); double r = y[loocv.test[i]] - ridge.predict(longley[loocv.test[i]]); rss += r * r; } System.out.format(\"LOOCV MSE with lambda %.2f = %.3f%n\", 0.01 * lambda, rss / n); } } "
    },
    {
        "test_src": "@Test public void testAdd() { } ",
        "focal_tgt": "void add(StorageOperation operation)throws DataCorruptionException { ensureInitializedAndNotClosed(); checkSegmentId(operation); checkValidOperation(operation); this.operations.addLast(operation); if(operation instanceof MergeBatchOperation) { this.mergeBatchCount ++ ; } else if(operation instanceof StreamSegmentSealOperation) { this.hasSealPending = true; } this.outstandingLength += operation.getLength(); this.lastAddedOffset = operation.getStreamSegmentOffset() + operation.getLength(); } ",
        "focal_src": "void add(StorageOperation operation)throws DataCorruptionException { ensureInitializedAndNotClosed(); checkSegmentId(operation); checkOffset(operation); this.operations.addLast(operation); if(operation instanceof MergeBatchOperation) { this.mergeBatchCount ++ ; } else if(operation instanceof StreamSegmentSealOperation) { this.hasSealPending = true; } this.outstandingLength += operation.getLength(); this.lastAddedOffset = operation.getStreamSegmentOffset() + operation.getLength(); } ",
        "test_tgt": "@Test public void testAddWithBadInput()throws Exception { final long badBatchId = 12345; final long badParentId = 56789; final String badParentName = \"Foo_Parent\"; final String badBatchName = \"Foo_Batch\"; @Cleanup TestContext context = new TestContext(DEFAULT_CONFIG); context.storage.create(context.segmentMetadata.getName(), TIMEOUT).join(); context.storage.create(context.batchMetadata.getName(), TIMEOUT).join(); context.segmentAggregator.initialize(TIMEOUT).join(); context.batchAggregator.initialize(TIMEOUT).join(); context.containerMetadata.mapStreamSegmentId(badParentName, badParentId); UpdateableSegmentMetadata badBatchMeta = context.containerMetadata.mapStreamSegmentId(badBatchName, badBatchId, badParentId); badBatchMeta.setDurableLogLength(0); badBatchMeta.setStorageLength(0); context.storage.create(badBatchMeta.getName(), TIMEOUT).join(); AssertExtensions.assertThrows(\"add() allowed a MergeBatchOperation on the batch segment.\", () -> context.batchAggregator.add(generateSimpleMergeBatch(BATCH_ID, context)), ex -> ex instanceof IllegalArgumentException); AssertExtensions.assertThrows(\"add() allowed a MergeBatchOperation on the parent for a Batch that did not have it as a parent.\", () -> context.batchAggregator.add(generateSimpleMergeBatch(badBatchId, context)), ex -> ex instanceof IllegalArgumentException); AssertExtensions.assertThrows(\"add() allowed a StreamSegmentSealOperation for a non-sealed segment.\", () -> { @Cleanup SegmentAggregator badBatchAggregator = new SegmentAggregator(badBatchMeta, context.dataSource, context.storage, DEFAULT_CONFIG, context.stopwatch); badBatchAggregator.initialize(TIMEOUT).join(); badBatchAggregator.add(generateSimpleSeal(badBatchId, context)); }, ex -> ex instanceof DataCorruptionException); StorageOperation batchAppend1 = generateAppendAndUpdateMetadata(0, BATCH_ID, context); context.batchAggregator.add(batchAppend1); context.batchAggregator.add(generateSealAndUpdateMetadata(BATCH_ID, context)); AssertExtensions.assertThrows(\"add() allowed operation after seal.\", () -> context.batchAggregator.add(generateSimpleAppend(BATCH_ID, context)), ex -> ex instanceof DataCorruptionException); StorageOperation parentAppend1 = generateAppendAndUpdateMetadata(0, SEGMENT_ID, context); context.segmentAggregator.add(parentAppend1); AssertExtensions.assertThrows(\"add() allowed an operation beyond the DurableLogOffset (offset).\", () -> { StreamSegmentAppendOperation badAppend = new StreamSegmentAppendOperation(context.segmentMetadata.getId(), \"foo\".getBytes(), APPEND_CONTEXT); badAppend.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength()); context.segmentAggregator.add(badAppend); }, ex -> ex instanceof DataCorruptionException); context.segmentMetadata.setDurableLogLength(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength() + 1); AssertExtensions.assertThrows(\"add() allowed an operation beyond the DurableLogOffset (offset+length).\", () -> { StreamSegmentAppendOperation badAppend = new StreamSegmentAppendOperation(context.segmentMetadata.getId(), \"foo\".getBytes(), APPEND_CONTEXT); badAppend.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength()); context.segmentAggregator.add(badAppend); }, ex -> ex instanceof DataCorruptionException); AssertExtensions.assertThrows(\"add() allowed an operation with wrong offset (too small).\", () -> { StreamSegmentAppendOperation badOffsetAppend = new StreamSegmentAppendOperation(context.segmentMetadata.getId(), \"foo\".getBytes(), APPEND_CONTEXT); badOffsetAppend.setStreamSegmentOffset(0); context.segmentAggregator.add(badOffsetAppend); }, ex -> ex instanceof DataCorruptionException); AssertExtensions.assertThrows(\"add() allowed an operation with wrong offset (too large).\", () -> { StreamSegmentAppendOperation badOffsetAppend = new StreamSegmentAppendOperation(context.segmentMetadata.getId(), \"foo\".getBytes(), APPEND_CONTEXT); badOffsetAppend.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength() + 1); context.segmentAggregator.add(badOffsetAppend); }, ex -> ex instanceof DataCorruptionException); AssertExtensions.assertThrows(\"add() allowed an operation with wrong offset (too large, but no pending operations).\", () -> { @Cleanup SegmentAggregator badBatchAggregator = new SegmentAggregator(badBatchMeta, context.dataSource, context.storage, DEFAULT_CONFIG, context.stopwatch); badBatchMeta.setDurableLogLength(100); badBatchAggregator.initialize(TIMEOUT).join(); StreamSegmentAppendOperation badOffsetAppend = new StreamSegmentAppendOperation(context.segmentMetadata.getId(), \"foo\".getBytes(), APPEND_CONTEXT); badOffsetAppend.setStreamSegmentOffset(1); context.segmentAggregator.add(badOffsetAppend); }, ex -> ex instanceof DataCorruptionException); AssertExtensions.assertThrows(\"add() allowed an Append operation with wrong Segment Id.\", () -> { StreamSegmentAppendOperation badIdAppend = new StreamSegmentAppendOperation(Integer.MAX_VALUE, \"foo\".getBytes(), APPEND_CONTEXT); badIdAppend.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength()); context.segmentAggregator.add(badIdAppend); }, ex -> ex instanceof IllegalArgumentException); AssertExtensions.assertThrows(\"add() allowed a StreamSegmentSealOperation with wrong SegmentId.\", () -> { StreamSegmentSealOperation badIdSeal = new StreamSegmentSealOperation(Integer.MAX_VALUE); badIdSeal.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength()); context.segmentAggregator.add(badIdSeal); }, ex -> ex instanceof IllegalArgumentException); AssertExtensions.assertThrows(\"add() allowed a MergeBatchOperation with wrong SegmentId.\", () -> { MergeBatchOperation badIdMerge = new MergeBatchOperation(Integer.MAX_VALUE, context.batchMetadata.getId()); badIdMerge.setStreamSegmentOffset(parentAppend1.getStreamSegmentOffset() + parentAppend1.getLength()); badIdMerge.setLength(1); context.segmentAggregator.add(badIdMerge); }, ex -> ex instanceof IllegalArgumentException); } "
    },
    {
        "test_src": "@Test public void testCreateStream()throws ExecutionException, InterruptedException { String streamResourceURI = getURI() + \"v1/scopes/\" + scope1 + \"/streams\"; when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); Response response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); StreamProperty streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest4)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected2, streamResponseActual); response.close(); final CreateStreamRequest streamRequest = new CreateStreamRequest(); streamRequest.setStreamName(NameUtils.getInternalNameForStream(\"stream\")); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus2); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(streamRequest)).invoke(); assertEquals(\"Create Stream Status\", 400, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest5)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected3, streamResponseActual); response.close(); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus2); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Create Stream Status\", 409, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus3); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest2)).invoke(); assertEquals(\"Create Stream Status\", 500, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus4); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest3)).invoke(); assertEquals(\"Create Stream Status for non-existent scope\", 404, response.getStatus()); response.close(); } ",
        "focal_tgt": "@Override public void createStream(final String scopeName, final CreateStreamRequest createStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"createStream\"); String streamName = createStreamRequest.getStreamName(); try { NameUtils.validateUserStreamName(streamName); } catch(IllegalArgumentException | NullPointerException e) { log.warn(\"Create stream failed due to invalid stream name {}\", streamName); asyncResponse.resume(Response.status(Status.BAD_REQUEST).build()); LoggerHelpers.traceLeave(log, \"createStream\", traceId); return; } try { authenticateAuthorize(scopeName + \"/\" + streamName, READ_UPDATE); } catch(AuthException e) { log.warn(\"Create stream for {} failed due to authentication failure.\", streamName); asyncResponse.resume(Response.status(Status.fromStatusCode(e.getResponseCode())).build()); LoggerHelpers.traceLeave(log, \"createStream\", traceId); return; } StreamConfiguration streamConfiguration = ModelHelper.getCreateStreamConfig(createStreamRequest); controllerService.createStream(scopeName, streamName, streamConfiguration, System.currentTimeMillis()).thenApply(streamStatus -> { Response resp = null; if(streamStatus.getStatus() == CreateStreamStatus.Status.SUCCESS) { log.info(\"Successfully created stream: {}/{}\", scopeName, streamName); resp = Response.status(Status.CREATED).entity(ModelHelper.encodeStreamResponse(scopeName, streamName, streamConfiguration)).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.STREAM_EXISTS) { log.warn(\"Stream already exists: {}/{}\", scopeName, streamName); resp = Response.status(Status.CONFLICT).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Scope not found: {}\", scopeName); resp = Response.status(Status.NOT_FOUND).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.INVALID_STREAM_NAME) { log.warn(\"Invalid stream name: {}\", streamName); resp = Response.status(Status.BAD_REQUEST).build(); } else { log.warn(\"createStream failed for : {}/{}\", scopeName, streamName); resp = Response.status(Status.INTERNAL_SERVER_ERROR).build(); } return resp; }).exceptionally(exception -> { log.warn(\"createStream for {}/{} failed: \", scopeName, streamName, exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"createStream\", traceId)); } ",
        "focal_src": "@Override public void createStream(final String scopeName, final CreateStreamRequest createStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"createStream\"); try { NameUtils.validateUserStreamName(createStreamRequest.getStreamName()); } catch(IllegalArgumentException | NullPointerException e) { log.warn(\"Create stream failed due to invalid stream name {}\", createStreamRequest.getStreamName()); asyncResponse.resume(Response.status(Status.BAD_REQUEST).build()); LoggerHelpers.traceLeave(log, \"createStream\", traceId); return; } try { authenticateAuthorize(scopeName + \"/\" + createStreamRequest.getStreamName(), READ_UPDATE); } catch(AuthException e) { log.warn(\"Create stream for {} failed due to authentication failure.\", createStreamRequest.getStreamName()); asyncResponse.resume(Response.status(Status.fromStatusCode(e.getResponseCode())).build()); LoggerHelpers.traceLeave(log, \"createStream\", traceId); return; } StreamConfiguration streamConfiguration = ModelHelper.getCreateStreamConfig(createStreamRequest, scopeName); controllerService.createStream(streamConfiguration, System.currentTimeMillis()).thenApply(streamStatus -> { Response resp = null; if(streamStatus.getStatus() == CreateStreamStatus.Status.SUCCESS) { log.info(\"Successfully created stream: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CREATED).entity(ModelHelper.encodeStreamResponse(streamConfiguration)).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.STREAM_EXISTS) { log.warn(\"Stream already exists: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CONFLICT).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Scope not found: {}\", scopeName); resp = Response.status(Status.NOT_FOUND).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.INVALID_STREAM_NAME) { log.warn(\"Invalid stream name: {}\", streamConfiguration.getStreamName()); resp = Response.status(Status.BAD_REQUEST).build(); } else { log.warn(\"createStream failed for : {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.INTERNAL_SERVER_ERROR).build(); } return resp; }).exceptionally(exception -> { log.warn(\"createStream for {}/{} failed {}: \", scopeName, streamConfiguration.getStreamName(), exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"createStream\", traceId)); } ",
        "test_tgt": "@Test public void testCreateStream()throws ExecutionException, InterruptedException { String streamResourceURI = getURI() + \"v1/scopes/\" + scope1 + \"/streams\"; when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus); Response response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); StreamProperty streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest4)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected2, streamResponseActual); response.close(); final CreateStreamRequest streamRequest = new CreateStreamRequest(); streamRequest.setStreamName(NameUtils.getInternalNameForStream(\"stream\")); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus2); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(streamRequest)).invoke(); assertEquals(\"Create Stream Status\", 400, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest5)).invoke(); assertEquals(\"Create Stream Status\", 201, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected3, streamResponseActual); response.close(); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus2); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Create Stream Status\", 409, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus3); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest2)).invoke(); assertEquals(\"Create Stream Status\", 500, response.getStatus()); response.close(); when(mockControllerService.createStream(any(), any(), any(), anyLong())).thenReturn(createStreamStatus4); response = addAuthHeaders(client.target(streamResourceURI).request()).buildPost(Entity.json(createStreamRequest3)).invoke(); assertEquals(\"Create Stream Status for non-existent scope\", 404, response.getStatus()); response.close(); } "
    },
    {
        "test_src": "@Test(expected = NullPointerException.class)public void testFormatDuration2333() { formatDuration(null, new Date()); } ",
        "focal_tgt": "public static String formatDuration(Date beginDate) { return formatDuration(beginDate, now()); } ",
        "focal_src": "public static String formatDuration(Date beginDate) { return formatDuration(beginDate, new Date()); } ",
        "test_tgt": "@Test(expected = NullPointerException.class)public void testFormatDuration2333() { formatDuration(null, now()); } "
    },
    {
        "test_src": "@Test public final void getResponseBodyAsString() { String templateFile = \"http://10.8.25.80:6666/template.csv?sign=123456\"; HttpURLConnectionParam httpURLConnectionParam = new HttpURLConnectionParam(); httpURLConnectionParam.setContentCharset(CharsetType.GBK); String responseBodyAsString = URLConnectionUtil.getResponseBodyAsString(templateFile, httpURLConnectionParam); LOGGER.info(responseBodyAsString); } ",
        "focal_tgt": "public static String getResponseBodyAsString(String urlString, ConnectionConfig connectionConfig) { if(null == connectionConfig) { connectionConfig = new ConnectionConfig(); } InputStream inputStream = getInputStream(urlString, connectionConfig); return InputStreamUtil.inputStream2String(inputStream, connectionConfig.getContentCharset()); } ",
        "focal_src": "public static String getResponseBodyAsString(String urlString, HttpURLConnectionParam httpURLConnectionParam) { if(null == httpURLConnectionParam) { httpURLConnectionParam = new HttpURLConnectionParam(); } InputStream inputStream = getInputStream(urlString, httpURLConnectionParam); String inputStream2String = InputStreamUtil.inputStream2String(inputStream, httpURLConnectionParam.getContentCharset()); return inputStream2String; } ",
        "test_tgt": "@Test public final void getResponseBodyAsString() { String templateFile = \"http://10.8.25.80:6666/template.csv?sign=123456\"; ConnectionConfig connectionConfig = new ConnectionConfig(); connectionConfig.setContentCharset(CharsetType.GBK); String responseBodyAsString = URLConnectionUtil.getResponseBodyAsString(templateFile, connectionConfig); LOGGER.info(responseBodyAsString); } "
    },
    {
        "test_src": "@Test public void testLloyd64() { System.out.println(\"Lloyd 64\"); KMeans kmeans = KMeans.lloyd(data, 64, 100); AdjustedRandIndex ari = new AdjustedRandIndex(); RandIndex rand = new RandIndex(); double r = rand.measure(label, kmeans.getClusterLabel()); double r2 = ari.measure(label, kmeans.getClusterLabel()); System.out.format(\"Training rand index = %.2f%%\\tadjusted rand index = %.2f%%%n\", 100.0 * r, 100.0 * r2); } ",
        "focal_tgt": "public static KMeans lloyd(double[][]data, int k) { return lloyd(data, k, 100, 1E-4); } ",
        "focal_src": "public static KMeans lloyd(double[][]data, int k) { return lloyd(data, k, 100); } ",
        "test_tgt": "@Test public void testLloyd64() { System.out.println(\"Lloyd 64\"); MathEx.setSeed(19650218); KMeans kmeans = KMeans.lloyd(data, 64); AdjustedRandIndex ari = new AdjustedRandIndex(); RandIndex rand = new RandIndex(); double r = rand.measure(label, kmeans.y); double r2 = ari.measure(label, kmeans.y); System.out.format(\"Training rand index = %.2f%%\\tadjusted rand index = %.2f%%%n\", 100.0 * r, 100.0 * r2); } "
    },
    {
        "test_src": "@Test public void testRepairSurvivors()throws InterruptedException, ExecutionException { System.out.println(\"Running testRepairSurvivors\"); InitiatorMailbox mailbox = mock(MpInitiatorMailbox.class); doReturn(4L).when(mailbox).getHSId(); ArrayList < Long > masters = new ArrayList < Long > (); masters.add(1L); masters.add(2L); masters.add(3L); MpPromoteAlgo algo = new MpPromoteAlgo(masters, mailbox, \"Test\"); long requestId = algo.getRequestId(); Future < RepairResult > result = algo.start(); verify(mailbox, times(1)).send(any(long[].class), any(Iv2RepairLogRequestMessage.class)); algo.deliver(makeRealAckResponse(requestId, 1L, 0, 2, txnEgo(1000L), m_hashinatorConfig)); algo.deliver(makeRealFragResponse(requestId, 1L, 1, 2, txnEgo(1000L))); algo.deliver(makeRealAckResponse(requestId, 2L, 0, 1, Long.MAX_VALUE, m_hashinatorConfig)); Pair < Long, byte[] > torv3 = Pair.of(m_hashinatorConfig.getFirst() + 1, m_hashinatorConfig.getSecond()); algo.deliver(makeRealAckResponse(requestId, 3L, 0, 3, txnEgo(1000L), torv3)); algo.deliver(makeRealFragResponse(requestId, 3L, 1, 3, txnEgo(1000L))); algo.deliver(makeRealCompleteResponse(requestId, 3L, 2, 3, txnEgo(1000L))); algo.deliver(makeRealAckResponse(requestId, 4L, 0, 2, txnEgo(1000L), m_hashinatorConfig)); algo.deliver(makeRealCompleteResponse(requestId, 4L, 1, 2, txnEgo(1000L))); List < Long > needsRepair = new ArrayList < Long > (); needsRepair.add(1L); needsRepair.add(2L); needsRepair.add(3L); verify(mailbox, times(1)).repairReplicasWith(eq(needsRepair), any(Iv2RepairLogResponseMessage.class)); assertEquals(txnEgo(1000L), result.get().m_txnId); assertEquals(torv3.getFirst(), TheHashinator.getCurrentVersionedConfig().getFirst()); } ",
        "focal_tgt": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"skipping repair message creation for cancelled Term.\"); return; } tmLog.debug(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { if( ! (li.getPayload()instanceof CompleteTransactionMessage) && ! m_forPromotion) { tmLog.debug(m_whoami + \"stop repairing: \" + m_survivors + \" with: \" + TxnEgo.txnIdToString(li.getTxnId())); break; } VoltMessage repairMsg = createRepairMessage(li); tmLog.debug(m_whoami + \"repairing: \" + m_survivors + \" with: \" + TxnEgo.txnIdToString(li.getTxnId())); if(tmLog.isTraceEnabled()) { tmLog.trace(m_whoami + \"repairing with message: \" + repairMsg); } m_mailbox.repairReplicasWith(m_survivors, repairMsg); } } ",
        "focal_src": "public void repairSurvivors() { if(this.m_promotionResult.isCancelled()) { tmLog.debug(m_whoami + \"skipping repair message creation for cancelled Term.\"); return; } tmLog.debug(m_whoami + \"received all repair logs and is repairing surviving replicas.\"); for(Iv2RepairLogResponseMessage li : m_repairLogUnion) { VoltMessage repairMsg = createRepairMessage(li); tmLog.debug(m_whoami + \"repairing: \" + m_survivors + \" with: \" + TxnEgo.txnIdToString(li.getTxnId())); if(tmLog.isTraceEnabled()) { tmLog.trace(m_whoami + \"repairing with message: \" + repairMsg); } m_mailbox.repairReplicasWith(m_survivors, repairMsg); } m_promotionResult.set(new RepairResult(m_maxSeenTxnId)); } ",
        "test_tgt": "@Test public void testRepairSurvivors()throws InterruptedException, ExecutionException { System.out.println(\"Running testRepairSurvivors\"); InitiatorMailbox mailbox = mock(MpInitiatorMailbox.class); doReturn(4L).when(mailbox).getHSId(); ArrayList < Long > masters = new ArrayList < Long > (); masters.add(1L); masters.add(2L); masters.add(3L); MpPromoteAlgo algo = new MpPromoteAlgo(masters, mailbox, \"Test\", true); long requestId = algo.getRequestId(); Future < RepairResult > result = algo.start(); verify(mailbox, times(1)).send(any(long[].class), any(Iv2RepairLogRequestMessage.class)); algo.deliver(makeRealAckResponse(requestId, 1L, 0, 2, txnEgo(1000L), m_hashinatorConfig)); algo.deliver(makeRealFragResponse(requestId, 1L, 1, 2, txnEgo(1000L))); algo.deliver(makeRealAckResponse(requestId, 2L, 0, 1, Long.MAX_VALUE, m_hashinatorConfig)); Pair < Long, byte[] > torv3 = Pair.of(m_hashinatorConfig.getFirst() + 1, m_hashinatorConfig.getSecond()); algo.deliver(makeRealAckResponse(requestId, 3L, 0, 3, txnEgo(1000L), torv3)); algo.deliver(makeRealFragResponse(requestId, 3L, 1, 3, txnEgo(1000L))); algo.deliver(makeRealCompleteResponse(requestId, 3L, 2, 3, txnEgo(1000L))); algo.deliver(makeRealAckResponse(requestId, 4L, 0, 2, txnEgo(1000L), m_hashinatorConfig)); algo.deliver(makeRealCompleteResponse(requestId, 4L, 1, 2, txnEgo(1000L))); List < Long > needsRepair = new ArrayList < Long > (); needsRepair.add(1L); needsRepair.add(2L); needsRepair.add(3L); verify(mailbox, times(1)).repairReplicasWith(eq(needsRepair), any(Iv2RepairLogResponseMessage.class)); assertEquals(txnEgo(1000L), result.get().m_txnId); assertEquals(torv3.getFirst(), TheHashinator.getCurrentVersionedConfig().getFirst()); } "
    },
    {
        "test_src": "@Test public void pathToNative()throws IOException { query(_FILE_WRITE.args(PATH1, \"()\")); assertEquals(Paths.get(PATH1).toRealPath().toString(), query(_FILE_PATH_TO_NATIVE.args(PATH1))); query(_FILE_PATH_TO_NATIVE.args(PATH + \"../\" + NAME + '/' + NAME), Paths.get(PATH + \"../\" + NAME + '/' + NAME).toRealPath().toString()); error(_FILE_PATH_TO_NATIVE.args(PATH1 + NAME), Err.FILE_NOT_FOUND); } ",
        "focal_tgt": "private Str pathToNative(final QueryContext qc)throws QueryException, IOException { final Path nat = toPath(0, qc).toRealPath(); return get(nat, Files.isDirectory(nat)); } ",
        "focal_src": "private Str pathToNative(final QueryContext qc)throws QueryException, IOException { final Path nat = checkPath(0, qc).toRealPath(); return get(nat, Files.isDirectory(nat)); } ",
        "test_tgt": "@Test public void pathToNative()throws IOException { query(_FILE_WRITE.args(PATH1, \"()\")); assertEquals(Paths.get(PATH1).toRealPath().toString(), query(_FILE_PATH_TO_NATIVE.args(PATH1))); query(_FILE_PATH_TO_NATIVE.args(PATH + \"../\" + NAME + '/' + NAME), Paths.get(PATH + \"../\" + NAME + '/' + NAME).toRealPath().toString()); error(_FILE_PATH_TO_NATIVE.args(PATH1 + NAME), Err.FILE_NOT_FOUND_X); } "
    },
    {
        "test_src": "@Test(expectedExceptions = NullPointerException.class)public void test_appendValueReduced_null()throws Exception { builder.appendValueReduced(null, 2, 2000); } ",
        "focal_tgt": "public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int maxWidth, int baseValue) { Objects.requireNonNull(field, \"field\"); ReducedPrinterParser pp = new ReducedPrinterParser(field, width, maxWidth, baseValue); if(width == maxWidth) { appendFixedWidth(width, pp); } else { appendInternal(pp); } return this; } ",
        "focal_src": "public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int baseValue) { Objects.requireNonNull(field, \"field\"); ReducedPrinterParser pp = new ReducedPrinterParser(field, width, baseValue); appendFixedWidth(width, pp); return this; } ",
        "test_tgt": "@Test(expectedExceptions = NullPointerException.class)public void test_appendValueReduced_null()throws Exception { builder.appendValueReduced(null, 2, 2, 2000); } "
    },
    {
        "test_src": "@Test public void move_downInUnmanagedMode() { RealmList < Dog > dogs = createUnmanagedDogList(); Dog dog1 = dogs.get(1); dogs.move(1, 0); assertEquals(0, dogs.indexOf(dog1)); } ",
        "focal_tgt": "public void move(int oldPos, int newPos) { if(isManaged()) { checkValidRealm(); osListOperator.move(oldPos, newPos); } else { final int listSize = unmanagedList.size(); if(oldPos < 0 || listSize <= oldPos) { throw new IndexOutOfBoundsException(\"Invalid index \" + oldPos + \", size is \" + listSize); } if(newPos < 0 || listSize <= newPos) { throw new IndexOutOfBoundsException(\"Invalid index \" + newPos + \", size is \" + listSize); } E object = unmanagedList.remove(oldPos); unmanagedList.add(newPos, object); } } ",
        "focal_src": "public void move(int oldPos, int newPos) { if(isManaged()) { checkValidRealm(); osListOperator.move(oldPos, newPos); } else { final int listSize = unmanagedList.size(); if(oldPos < 0 || listSize <= oldPos) { throw new IndexOutOfBoundsException(\"Invalid index \" + oldPos + \", size is \" + listSize); } if(newPos < 0 || listSize <= newPos) { throw new IndexOutOfBoundsException(\"Invalid index \" + newPos + \", size is \" + listSize); } E object = unmanagedList.remove(oldPos); if(newPos > oldPos) { unmanagedList.add(newPos - 1, object); } else { unmanagedList.add(newPos, object); } } } ",
        "test_tgt": "@Test public void move_downInUnmanagedMode() { RealmList < Dog > dogs = createUnmanagedDogList(); Dog dog1 = dogs.get(1); Dog dog2 = dogs.get(0); dogs.move(1, 0); assertEquals(TEST_SIZE, dogs.size()); assertEquals(0, dogs.indexOf(dog1)); assertEquals(1, dogs.indexOf(dog2)); } "
    },
    {
        "test_src": "@Test public void createUser() { User user = UserData.randomUser(); UserDTO userDTO = BeanMapper.map(user, UserDTO.class); IdResponse response = accountWebServiceClient.createUser(userDTO); assertNotNull(response.getId()); GetUserResponse response2 = accountWebServiceClient.getUser(response.getId()); assertEquals(user.getLoginName(), response2.getUser().getLoginName()); } ",
        "focal_tgt": "IdResult createUser(@WebParam(name = \"user\")UserDTO user); ",
        "focal_src": "IdResponse createUser(@WebParam(name = \"user\")UserDTO user); ",
        "test_tgt": "@Test public void createUser() { User user = UserData.randomUser(); UserDTO userDTO = BeanMapper.map(user, UserDTO.class); IdResult response = accountWebServiceClient.createUser(userDTO); assertNotNull(response.getId()); GetUserResult response2 = accountWebServiceClient.getUser(response.getId()); assertEquals(user.getLoginName(), response2.getUser().getLoginName()); } "
    },
    {
        "test_src": "@Test public void testGetSnapshottingSettings()throws Exception { ExecutionJobVertex jobVertex = mock(ExecutionJobVertex.class); when(jobVertex.getJobVertexId()).thenReturn(new JobVertexID()); when(jobVertex.getParallelism()).thenReturn(1); JobSnapshottingSettings snapshottingSettings = new JobSnapshottingSettings(Collections.singletonList(new JobVertexID()), Collections.singletonList(new JobVertexID()), Collections.singletonList(new JobVertexID()), 181238123L, 19191992L, 191929L, 123, ExternalizedCheckpointSettings.none(), null, false); CheckpointStatsTracker tracker = new CheckpointStatsTracker(0, Collections.singletonList(jobVertex), snapshottingSettings, new UnregisteredMetricsGroup()); assertEquals(snapshottingSettings, tracker.getSnapshottingSettings()); } ",
        "focal_tgt": "public JobCheckpointingSettings getSnapshottingSettings() { return jobCheckpointingSettings; } ",
        "focal_src": "public JobSnapshottingSettings getSnapshottingSettings() { return jobSnapshottingSettings; } ",
        "test_tgt": "@Test public void testGetSnapshottingSettings()throws Exception { ExecutionJobVertex jobVertex = mock(ExecutionJobVertex.class); when(jobVertex.getJobVertexId()).thenReturn(new JobVertexID()); when(jobVertex.getParallelism()).thenReturn(1); JobCheckpointingSettings snapshottingSettings = new JobCheckpointingSettings(Collections.singletonList(new JobVertexID()), Collections.singletonList(new JobVertexID()), Collections.singletonList(new JobVertexID()), 181238123L, 19191992L, 191929L, 123, ExternalizedCheckpointSettings.none(), null, false); CheckpointStatsTracker tracker = new CheckpointStatsTracker(0, Collections.singletonList(jobVertex), snapshottingSettings, new UnregisteredMetricsGroup()); assertEquals(snapshottingSettings, tracker.getSnapshottingSettings()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should fail if name is a duplicate\", method = \"validate(Object,Errors)\")public void validate_shouldFailIfNameIsADuplicate()throws Exception { OrderType orderType = new OrderType(); orderType.setName(\"Drug order\"); Errors errors = new BindException(orderType, \"orderType\"); new OrderTypeValidator().validate(orderType, errors); Assert.assertEquals(true, errors.hasFieldErrors(\"name\")); } ",
        "focal_tgt": "public void validate(Object obj, Errors errors) { if(obj == null || ! (obj instanceof OrderType)) { throw new IllegalArgumentException(\"The parameter obj should not be null and must be of type\" + OrderType.class); } else { OrderType orderType = (OrderType)obj; String name = orderType.getName(); if( ! StringUtils.hasText(name)) { errors.rejectValue(\"name\", \"error.name\"); return; } OrderType duplicate = Context.getOrderService().getOrderTypeByName(name); if(duplicate != null && ! orderType.equals(duplicate)) { errors.rejectValue(\"name\", \"OrderType.duplicate.name\", \"Duplicate order type name: \" + name); } for(OrderType ot : Context.getOrderService().getOrderTypes(true)) { if(ot != null) { if(orderType.equals(ot)) { continue; } if(OpenmrsUtil.nullSafeEquals(orderType.getJavaClassName(), ot.getJavaClassName())) { errors.rejectValue(\"javaClassName\", \"OrderType.duplicate\", new Object[] { orderType.getJavaClassName(), orderType.getName() }, ot.getJavaClassName() + \" is already associated to another order type:\" + orderType.getName()); } else { int index = 0; for(ConceptClass cc : ot.getConceptClasses()) { if(cc != null && orderType.getConceptClasses().contains(cc)) { errors.rejectValue(\"conceptClasses[\" + index + \"]\", \"OrderType.duplicate\", new Object[] { cc.getName(), orderType.getName() }, cc.getName() + \" is already associated to another order type:\" + orderType.getName()); } index ++ ; } } } } } } ",
        "focal_src": "public void validate(Object obj, Errors errors) { if(obj == null || ! (obj instanceof OrderType)) { throw new IllegalArgumentException(\"The parameter obj should not be null and must be of type\" + OrderType.class); } else { OrderType orderType = (OrderType)obj; String name = orderType.getName(); if( ! StringUtils.hasText(name)) { errors.rejectValue(\"name\", \"error.name\"); } OrderType duplicate = Context.getOrderService().getOrderTypeByName(name); if(duplicate != null && ! orderType.equals(duplicate)) { errors.rejectValue(\"name\", \"OrderType.duplicate.name\", \"Duplicate order type name: \" + name); } for(OrderType ot : Context.getOrderService().getOrderTypes(true)) { if(ot != null) { if(OpenmrsUtil.nullSafeEquals(orderType.getJavaClassName(), ot.getJavaClassName())) { errors.rejectValue(\"javaClassName\", \"OrderType.duplicate.javaClass\", \"Duplicate order type java class: \" + ot.getJavaClassName()); } else { for(ConceptClass cc : ot.getConceptClasses()) { if(cc != null && orderType.getConceptClasses().contains(cc)) { errors.rejectValue(\"conceptClasses\", \"OrderType.duplicate.conceptClass\", \"Duplicate order type concept class: \" + cc.getName()); } } } } } } } ",
        "test_tgt": "@Test@Verifies(value = \"should fail if name is a duplicate\", method = \"validate(Object,Errors)\")public void validate_shouldFailIfNameIsADuplicate()throws Exception { OrderType orderType = new OrderType(); orderType.setName(orderService.getOrderType(1).getName()); Errors errors = new BindException(orderType, \"orderType\"); new OrderTypeValidator().validate(orderType, errors); Assert.assertEquals(true, errors.hasFieldErrors(\"name\")); } "
    },
    {
        "test_src": "@Test public void createBlockPath()throws IOException { String absolutePath = PathUtils.concatPath(mTestFolder.getRoot(), \"tmp\", \"bar\"); File tempFile = new File(absolutePath); FileUtils.createBlockPath(tempFile.getAbsolutePath()); assertTrue(FileUtils.exists(tempFile.getParent())); } ",
        "focal_tgt": "public static void createBlockPath(String path, String workerDataFolderPermissions)throws IOException { try { createStorageDirPath(PathUtils.getParent(path), workerDataFolderPermissions); } catch(InvalidPathException e) { throw new IOException(\"Failed to create block path, get parent path of \" + path + \"failed\", e); } catch(IOException e) { throw new IOException(\"Failed to create block path \" + path, e); } } ",
        "focal_src": "public static void createBlockPath(String path)throws IOException { try { createStorageDirPath(PathUtils.getParent(path)); } catch(InvalidPathException e) { throw new IOException(\"Failed to create block path, get parent path of \" + path + \"failed\", e); } catch(IOException e) { throw new IOException(\"Failed to create block path \" + path, e); } } ",
        "test_tgt": "@Test public void createBlockPath()throws IOException { String absolutePath = PathUtils.concatPath(mTestFolder.getRoot(), \"tmp\", \"bar\"); File tempFile = new File(absolutePath); FileUtils.createBlockPath(tempFile.getAbsolutePath(), mWorkerDataFolderPerms); assertTrue(FileUtils.exists(tempFile.getParent())); } "
    },
    {
        "test_src": "@Test public void testStartRequest() { String requestId = sessionRequestService.startRequest(); assertNotNull(requestId); String cacheRID = (String)getRequestCache().get(CachingService.REQUEST_ID_KEY); assertNotNull(cacheRID); assertEquals(cacheRID, requestId); sessionRequestService.endRequest(null); } ",
        "focal_tgt": "public String startRequest() { return startRequest(new InternalRequestImpl()); } ",
        "focal_src": "public String startRequest() { Session session = makeSession(null); String requestId = makeRequestId(); List < RequestInterceptor > interceptors = getInterceptors(false); for(RequestInterceptor requestInterceptor : interceptors) { if(requestInterceptor != null) { try { requestInterceptor.onStart(requestId, session); } catch(RequestInterruptionException e) { String message = \"Request stopped from starting by exception from the interceptor (\" + requestInterceptor + \"): \" + e.getMessage(); log.warn(message); throw new RequestInterruptionException(message, e); } catch(Exception e) { log.warn(\"Request interceptor (\" + requestInterceptor + \") failed to execute on start (\" + requestId + \"): \" + e.getMessage()); } } } getRequestCache().put(CachingService.REQUEST_ID_KEY, requestId); return requestId; } ",
        "test_tgt": "@Test public void testStartRequest() { String requestId = sessionRequestService.startRequest(); assertNotNull(requestId); sessionRequestService.endRequest(null); } "
    },
    {
        "test_src": "@Test public void testGetDeadWorkerDirs()throws Exception { Map < String, Object > stormConf = Utils.readStormConfig(); stormConf.put(SUPERVISOR_WORKER_TIMEOUT_SECS, 5); LSWorkerHeartbeat hb = new LSWorkerHeartbeat(); hb.set_time_secs(1); Map < String, LSWorkerHeartbeat > idToHb = Collections.singletonMap(\"42\", hb); int nowSecs = 2; File unexpectedDir1 = new MockDirectoryBuilder().setDirName(\"dir1\").build(); File expectedDir2 = new MockDirectoryBuilder().setDirName(\"dir2\").build(); File expectedDir3 = new MockDirectoryBuilder().setDirName(\"dir3\").build(); Set < File > logDirs = Sets.newSet(unexpectedDir1, expectedDir2, expectedDir3); try { SupervisorUtils mockedSupervisorUtils = mock(SupervisorUtils.class); SupervisorUtils.setInstance(mockedSupervisorUtils); LogCleaner logCleaner = new LogCleaner(stormConf, new DirectoryCleaner()) { @Override Map < String, File > identifyWorkerLogDirs(Set < File > logDirs) { Map < String, File > ret = new HashMap < > (); ret.put(\"42\", unexpectedDir1); ret.put(\"007\", expectedDir2); ret.put(\"\", expectedDir3); return ret; } }; when(mockedSupervisorUtils.readWorkerHeartbeatsImpl(anyMapOf(String.class, Object.class))).thenReturn(idToHb); assertEquals(Sets.newSet(expectedDir2, expectedDir3), logCleaner.getDeadWorkerDirs(nowSecs, logDirs)); } finally { SupervisorUtils.resetInstance(); } } ",
        "focal_tgt": "@VisibleForTesting SortedSet < File > getDeadWorkerDirs(int nowSecs, Set < File > logDirs)throws Exception { if(logDirs.isEmpty()) { return new TreeSet < > (); } else { Set < String > aliveIds = workerLogs.getAliveIds(nowSecs); Map < String, File > idToDir = workerLogs.identifyWorkerLogDirs(logDirs); return idToDir.entrySet().stream().filter(entry -> ! aliveIds.contains(entry.getKey())).map(Map.Entry :: getValue).collect(toCollection(TreeSet :: new)); } } ",
        "focal_src": "@VisibleForTesting SortedSet < File > getDeadWorkerDirs(int nowSecs, Set < File > logDirs)throws Exception { if(logDirs.isEmpty()) { return new TreeSet < > (); } else { Set < String > aliveIds = getAliveIds(nowSecs); Map < String, File > idToDir = identifyWorkerLogDirs(logDirs); return idToDir.entrySet().stream().filter(entry -> ! aliveIds.contains(entry.getKey())).map(Map.Entry :: getValue).collect(toCollection(TreeSet :: new)); } } ",
        "test_tgt": "@Test public void testGetDeadWorkerDirs()throws Exception { Map < String, Object > stormConf = Utils.readStormConfig(); stormConf.put(SUPERVISOR_WORKER_TIMEOUT_SECS, 5); LSWorkerHeartbeat hb = new LSWorkerHeartbeat(); hb.set_time_secs(1); Map < String, LSWorkerHeartbeat > idToHb = Collections.singletonMap(\"42\", hb); int nowSecs = 2; File unexpectedDir1 = new MockDirectoryBuilder().setDirName(\"dir1\").build(); File expectedDir2 = new MockDirectoryBuilder().setDirName(\"dir2\").build(); File expectedDir3 = new MockDirectoryBuilder().setDirName(\"dir3\").build(); Set < File > logDirs = Sets.newSet(unexpectedDir1, expectedDir2, expectedDir3); try { SupervisorUtils mockedSupervisorUtils = mock(SupervisorUtils.class); SupervisorUtils.setInstance(mockedSupervisorUtils); Map < String, Object > conf = Utils.readStormConfig(); WorkerLogs stubbedWorkerLogs = new WorkerLogs(conf, null) { @Override public Map < String, File > identifyWorkerLogDirs(Set < File > logDirs) { Map < String, File > ret = new HashMap < > (); ret.put(\"42\", unexpectedDir1); ret.put(\"007\", expectedDir2); ret.put(\"\", expectedDir3); return ret; } }; LogCleaner logCleaner = new LogCleaner(conf, stubbedWorkerLogs, new DirectoryCleaner(), null); when(mockedSupervisorUtils.readWorkerHeartbeatsImpl(anyMapOf(String.class, Object.class))).thenReturn(idToHb); assertEquals(Sets.newSet(expectedDir2, expectedDir3), logCleaner.getDeadWorkerDirs(nowSecs, logDirs)); } finally { SupervisorUtils.resetInstance(); } } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); expectedException.expect(APIException.class); expectedException.expectMessage(\"Order.frequency.cannot.edit\"); orderService.saveOrderFrequency(orderFrequency); } ",
        "focal_tgt": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw CannotEditOrderPropertyInUseException.withProperty(\"frequency\"); } } return dao.saveOrderFrequency(orderFrequency); } ",
        "focal_src": "@Override public OrderFrequency saveOrderFrequency(OrderFrequency orderFrequency)throws APIException { if(orderFrequency.getOrderFrequencyId() != null) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw new APIException(\"Order.frequency.cannot.edit\"); } } return dao.saveOrderFrequency(orderFrequency); } ",
        "test_tgt": "@Test@Verifies(value = \"should not allow editing an existing order frequency that is in use\", method = \"saveOrderFrequency(OrderFrequency)\")public void saveOrderFrequency_shouldNotAllowEditingAnExistingOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); orderFrequency.setFrequencyPerDay(4d); expectedException.expect(CannotEditOrderPropertyInUseException.class); expectedException.expectMessage(\"Order.frequency.cannot.edit\"); orderService.saveOrderFrequency(orderFrequency); } "
    },
    {
        "test_src": "@Test public void testGetInputs() { final Operator input1 = new OpImpl(0); final Operator input2 = new OpImpl(1); final Operator fixture = new OpImpl(0).withInputs(input1, input2); final List < Operator.Output > result = fixture.getInputs(); assertNotNull(result); assertEquals(2, result.size()); assertEquals(Arrays.asList(input1.getOutput(0), input2.getOutput(0)), result); } ",
        "focal_tgt": "public List < Operator < ? > .Output > getInputs() { return new ArrayList < Operator < ? > .Output > (this.inputs); } ",
        "focal_src": "public List < Output > getInputs() { return new ArrayList < Output > (this.inputs); } ",
        "test_tgt": "@Test public void testGetInputs() { final Operator < ? > input1 = new OpImpl(0); final Operator < ? > input2 = new OpImpl(1); final Operator < ? > fixture = new OpImpl(0).withInputs(input1, input2); final List < Operator < ? > .Output > result = fixture.getInputs(); assertNotNull(result); assertEquals(2, result.size()); assertEquals(Arrays.asList(input1.getOutput(0), input2.getOutput(0)), result); } "
    },
    {
        "test_src": "@Test(description = \"GET /v${apiVersion}/{tenantId}/flavors\")public void testListFlavors()throws Exception { for(String zoneId : zones) { FlavorApi api = novaContext.getApi().getFlavorApiForZone(zoneId); Set < ? extends Resource > response = api.listFlavors(); assertNotNull(response); assertFalse(response.isEmpty()); for(Resource flavor : response) { assertNotNull(flavor.getId()); assertNotNull(flavor.getName()); assertNotNull(flavor.getLinks()); } } } ",
        "focal_tgt": "PagedIterable < ? extends Resource > list(); ",
        "focal_src": "Set < ? extends Resource > listFlavors(); ",
        "test_tgt": "@Test(description = \"GET /v${apiVersion}/{tenantId}/flavors\")public void testListFlavors()throws Exception { for(String zoneId : zones) { FlavorApi api = novaContext.getApi().getFlavorApiForZone(zoneId); Set < ? extends Resource > response = api.list().concat().toImmutableSet(); assertNotNull(response); assertFalse(response.isEmpty()); for(Resource flavor : response) { assertNotNull(flavor.getId()); assertNotNull(flavor.getName()); assertNotNull(flavor.getLinks()); } } } "
    },
    {
        "test_src": "@Test public void testClearAndPut() { for(int i = 0; i < CAPACITY; ++ i) { Assert.assertTrue(mailbox.tryPutMail(() -> { })); } mailbox.clearAndPut(POISON_LETTER); Assert.assertTrue(mailbox.hasMail()); Assert.assertEquals(POISON_LETTER, mailbox.tryTakeMail().get()); Assert.assertFalse(mailbox.hasMail()); } ",
        "focal_tgt": "@Nonnull List < Runnable > clearAndPut(@Nonnull Runnable priorityLetter)throws MailboxStateException; ",
        "focal_src": "void clearAndPut(@Nonnull Runnable priorityAction); ",
        "test_tgt": "@Test public void testClearAndPut()throws Exception { Runnable letterInstance = () -> { }; for(int i = 0; i < CAPACITY; ++ i) { Assert.assertTrue(mailbox.tryPutMail(letterInstance)); } List < Runnable > droppedLetters = mailbox.clearAndPut(POISON_LETTER); Assert.assertTrue(mailbox.hasMail()); Assert.assertEquals(POISON_LETTER, mailbox.tryTakeMail().get()); Assert.assertFalse(mailbox.hasMail()); Assert.assertEquals(CAPACITY, droppedLetters.size()); } "
    },
    {
        "test_src": "@Test public void create() { query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry level='9'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry \" + \"last-modified='2000-01-01T12:12:12'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { }\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { 'format':'zip', 'algorithm':'deflate' }\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\", \"<archive:options/>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='zip'/>\" + \"<archive:algorithm value='deflate'/></archive:options>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='zip'/></archive:options>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='gzip'/></archive:options>\")), \"1\"); error(_ARCHIVE_CREATE.args(\"X\", \"()\"), Err.ARCH_DIFF); error(_ARCHIVE_CREATE.args(\"<archive:entry/>\", \"\"), Err.ARCH_EMPTY); error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='x'>X</archive:entry>\", \"\"), Err.ARCH_LEVEL); error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='10'>X</archive:entry>\", \"\"), Err.ARCH_LEVEL); error(_ARCHIVE_CREATE.args(\"<archive:entry last-modified='2020'>X</archive:entry>\", \"\"), Err.ARCH_DATETIME); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \" 123\"), Err.STRBINTYPE); error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='x'>X</archive:entry>\", \"\"), Err.ARCH_ENCODING); error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X</archive:entry>\", \"\"), Err.ARCH_ENCODE); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { 'format':'rar' }\"), Err.ARCH_UNKNOWN); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='rar'/></archive:options>\"), Err.ARCH_UNKNOWN); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:algorithm value='unknown'/></archive:options>\"), Err.ARCH_SUPP); error(_ARCHIVE_CREATE.args(\"('x','y')\", \"('a','b')\", \"<archive:options><archive:format value='gzip'/></archive:options>\"), Err.ARCH_ONE); } ",
        "focal_tgt": "public static synchronized Data create(final IO source, final boolean single, final Context ctx)throws IOException { if( ! source.exists() || single && source.isDir())throw new BaseXException(RES_NOT_FOUND_X, source); if( ! ctx.options.get(MainOptions.FORCECREATE))return CreateDB.mainMem(source, ctx); final String nm = source.dbname(); final DirParser dp = new DirParser(source, ctx.options, ctx.globalopts.dbpath(nm)); return CreateDB.create(nm, dp, ctx); } ",
        "focal_src": "public static synchronized Data create(final IO source, final boolean single, final Context ctx)throws IOException { if( ! source.exists() || single && source.isDir())throw new BaseXException(RES_NOT_FOUND_X, source); if( ! ctx.options.bool(MainOptions.FORCECREATE))return CreateDB.mainMem(source, ctx); final String nm = source.dbname(); final DirParser dp = new DirParser(source, ctx.options, ctx.globalopts.dbpath(nm)); return CreateDB.create(nm, dp, ctx); } ",
        "test_tgt": "@Test public void create() { query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry level='9'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry \" + \"last-modified='2000-01-01T12:12:12'>X</archive:entry>\", \"\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { }\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { 'format':'zip', 'algorithm':'deflate' }\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"X\", \"\", \"<archive:options/>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='zip'/>\" + \"<archive:algorithm value='deflate'/></archive:options>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='zip'/></archive:options>\")), \"1\"); query(COUNT.args(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='gzip'/></archive:options>\")), \"1\"); error(_ARCHIVE_CREATE.args(\"X\", \"()\"), Err.ARCH_DIFF); error(_ARCHIVE_CREATE.args(\"<archive:entry/>\", \"\"), Err.ARCH_EMPTY); error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='x'>X</archive:entry>\", \"\"), Err.ARCH_LEVEL); error(_ARCHIVE_CREATE.args(\"<archive:entry compression-level='10'>X</archive:entry>\", \"\"), Err.ARCH_LEVEL); error(_ARCHIVE_CREATE.args(\"<archive:entry last-modified='2020'>X</archive:entry>\", \"\"), Err.ARCH_DATETIME); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \" 123\"), Err.STRBINTYPE); error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='x'>X</archive:entry>\", \"\"), Err.ARCH_ENCODING); error(_ARCHIVE_CREATE.args(\"<archive:entry encoding='US-ASCII'>X</archive:entry>\", \"\"), Err.ARCH_ENCODE); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { 'format':'rar' }\"), Err.ARCH_UNKNOWN); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \" { 'x':'y' }\"), Err.INVALIDOPT); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:format value='rar'/></archive:options>\"), Err.ARCH_UNKNOWN); error(_ARCHIVE_CREATE.args(\"<archive:entry>X</archive:entry>\", \"\", \"<archive:options><archive:algorithm value='unknown'/></archive:options>\"), Err.ARCH_SUPP); error(_ARCHIVE_CREATE.args(\"('x','y')\", \"('a','b')\", \"<archive:options><archive:format value='gzip'/></archive:options>\"), Err.ARCH_ONE); } "
    },
    {
        "test_src": "@Test public void extract_skipsSelfField()throws Exception { carrier.put(\"x-amzn-trace-id\", \"Robot=Hello;Self=1-582113d1-1e48b74b3603af8479078ed6; \" + \"Root=1-58211399-36d228ad5d99923122bbe354; \" + \"TotalTimeSoFar=112ms;CalledFrom=Foo\"); TraceContextOrSamplingFlags extracted = extractor.extract(carrier); assertThat(extracted.traceIdContext()).isEqualTo(TraceIdContext.newBuilder().traceIdHigh(lowerHexToUnsignedLong(\"5821139936d228ad\")).traceId(lowerHexToUnsignedLong(\"5d99923122bbe354\")).build()); assertThat(((AWSPropagation.Extra)extracted.extra().get(0)).fields).contains(new StringBuilder(\";Robot=Hello;TotalTimeSoFar=112ms;CalledFrom=Foo\")); } ",
        "focal_tgt": "public static TraceContextOrSamplingFlags extract(String amznTraceId) { if(amznTraceId == null)return EMPTY; return STRING_EXTRACTOR.extract(amznTraceId); } ",
        "focal_src": "public static TraceContextOrSamplingFlags extract(String amznTraceId) { if(amznTraceId == null)throw new NullPointerException(\"amznTraceId == null\"); return STRING_EXTRACTOR.extract(amznTraceId); } ",
        "test_tgt": "@Test public void extract_skipsSelfField()throws Exception { carrier.put(\"x-amzn-trace-id\", \"Robot=Hello;Self=1-582113d1-1e48b74b3603af8479078ed6; \" + \"Root=1-58211399-36d228ad5d99923122bbe354; \" + \"TotalTimeSoFar=112ms;CalledFrom=Foo\"); TraceContextOrSamplingFlags extracted = extractor.extract(carrier); assertThat(extracted.traceIdContext()).isEqualTo(TraceIdContext.newBuilder().traceIdHigh(lowerHexToUnsignedLong(\"5821139936d228ad\")).traceId(lowerHexToUnsignedLong(\"5d99923122bbe354\")).build()); assertThat(((AWSPropagation.Extra)extracted.extra().get(0)).fields).contains(new StringBuilder(\";Robot=Hello;TotalTimeSoFar=112ms;CalledFrom=Foo\")); } "
    },
    {
        "test_src": "@Test@SuppressWarnings(\"unchecked\")public void persistFileTest()throws Exception { long fileId = 1; List < Long > blockIds = Lists.newArrayList(1L, 2L); BlockWorker blockWorker = Mockito.mock(BlockWorker.class); FileInfo fileInfo = new FileInfo(); fileInfo.setPath(\"test\"); Mockito.when(blockWorker.getFileInfo(fileId)).thenReturn(fileInfo); BlockReader reader = Mockito.mock(BlockReader.class); for(long blockId : blockIds) { Mockito.when(blockWorker.lockBlock(Sessions.CHECKPOINT_SESSION_ID, blockId)).thenReturn(blockId); Mockito.when(blockWorker.readBlockRemote(Sessions.CHECKPOINT_SESSION_ID, blockId, blockId)).thenReturn(reader); } FileDataManager manager = new FileDataManager(blockWorker); UnderFileSystem ufs = Mockito.mock(UnderFileSystem.class); String ufsRoot = new Configuration().get(Constants.UNDERFS_ADDRESS); Mockito.when(ufs.exists(ufsRoot)).thenReturn(true); Whitebox.setInternalState(manager, \"mUfs\", ufs); OutputStream outputStream = Mockito.mock(OutputStream.class); PowerMockito.mockStatic(BufferUtils.class); String dstPath = PathUtils.concatPath(ufsRoot, fileInfo.getPath()); Mockito.when(ufs.create(dstPath)).thenReturn(outputStream); Mockito.when(ufs.create(Mockito.anyString(), Mockito.any(UnderFileSystemCreateOptions.class))).thenReturn(outputStream); manager.lockBlocks(fileId, blockIds); manager.persistFile(fileId, blockIds); Set < Long > persistedFiles = (Set < Long > )Whitebox.getInternalState(manager, \"mPersistedFiles\"); Assert.assertEquals(Sets.newHashSet(fileId), persistedFiles); PowerMockito.verifyStatic(Mockito.times(2)); BufferUtils.fastCopy(Mockito.any(ReadableByteChannel.class), Mockito.any(WritableByteChannel.class)); Assert.assertFalse(manager.needPersistence(fileId)); } ",
        "focal_tgt": "public static long persistFile(FileSystem fs, AlluxioURI uri, URIStatus status, Configuration conf)throws IOException, FileDoesNotExistException, AlluxioException { Closer closer = Closer.create(); long ret; try { OpenFileOptions options = OpenFileOptions.defaults().setReadType(ReadType.NO_CACHE); FileInStream in = closer.register(fs.openFile(uri, options)); AlluxioURI dstPath = new AlluxioURI(status.getUfsPath()); UnderFileSystem ufs = UnderFileSystem.get(dstPath.toString(), conf); String parentPath = dstPath.getParent().toString(); if( ! ufs.exists(parentPath) && ! ufs.mkdirs(parentPath, true)) { throw new IOException(\"Failed to create \" + parentPath); } URIStatus uriStatus = fs.getStatus(uri); PermissionStatus ps = new PermissionStatus(uriStatus.getUserName(), uriStatus.getGroupName(), (short)uriStatus.getPermission()); OutputStream out = closer.register(ufs.create(dstPath.getPath(), CreateOptions.defaults().setPermissionStatus(ps))); ret = IOUtils.copyLarge(in, out); } catch(Exception e) { throw closer.rethrow(e); } finally { closer.close(); } fs.setAttribute(uri, SetAttributeOptions.defaults().setPersisted(true)); return ret; } ",
        "focal_src": "public static long persistFile(FileSystem fs, AlluxioURI uri, URIStatus status, Configuration conf)throws IOException, FileDoesNotExistException, AlluxioException { Closer closer = Closer.create(); long ret; try { OpenFileOptions options = OpenFileOptions.defaults().setReadType(ReadType.NO_CACHE); FileInStream in = closer.register(fs.openFile(uri, options)); AlluxioURI dstPath = new AlluxioURI(status.getUfsPath()); UnderFileSystem ufs = UnderFileSystem.get(dstPath.toString(), conf); String parentPath = dstPath.getParent().toString(); if( ! ufs.exists(parentPath) && ! ufs.mkdirs(parentPath, true)) { throw new IOException(\"Failed to create \" + parentPath); } URIStatus uriStatus = fs.getStatus(uri); PermissionStatus ps = new PermissionStatus(uriStatus.getUserName(), uriStatus.getGroupName(), (short)uriStatus.getPermission()); OutputStream out = closer.register(ufs.create(dstPath.getPath(), UnderFileSystemCreateOptions.defaults().setPermissionStatus(ps))); ret = IOUtils.copyLarge(in, out); } catch(Exception e) { throw closer.rethrow(e); } finally { closer.close(); } fs.setAttribute(uri, SetAttributeOptions.defaults().setPersisted(true)); return ret; } ",
        "test_tgt": "@Test@SuppressWarnings(\"unchecked\")public void persistFileTest()throws Exception { long fileId = 1; List < Long > blockIds = Lists.newArrayList(1L, 2L); BlockWorker blockWorker = Mockito.mock(BlockWorker.class); FileInfo fileInfo = new FileInfo(); fileInfo.setPath(\"test\"); Mockito.when(blockWorker.getFileInfo(fileId)).thenReturn(fileInfo); BlockReader reader = Mockito.mock(BlockReader.class); for(long blockId : blockIds) { Mockito.when(blockWorker.lockBlock(Sessions.CHECKPOINT_SESSION_ID, blockId)).thenReturn(blockId); Mockito.when(blockWorker.readBlockRemote(Sessions.CHECKPOINT_SESSION_ID, blockId, blockId)).thenReturn(reader); } FileDataManager manager = new FileDataManager(blockWorker); UnderFileSystem ufs = Mockito.mock(UnderFileSystem.class); String ufsRoot = new Configuration().get(Constants.UNDERFS_ADDRESS); Mockito.when(ufs.exists(ufsRoot)).thenReturn(true); Whitebox.setInternalState(manager, \"mUfs\", ufs); OutputStream outputStream = Mockito.mock(OutputStream.class); PowerMockito.mockStatic(BufferUtils.class); String dstPath = PathUtils.concatPath(ufsRoot, fileInfo.getPath()); Mockito.when(ufs.create(dstPath)).thenReturn(outputStream); Mockito.when(ufs.create(Mockito.anyString(), Mockito.any(CreateOptions.class))).thenReturn(outputStream); manager.lockBlocks(fileId, blockIds); manager.persistFile(fileId, blockIds); Set < Long > persistedFiles = (Set < Long > )Whitebox.getInternalState(manager, \"mPersistedFiles\"); Assert.assertEquals(Sets.newHashSet(fileId), persistedFiles); PowerMockito.verifyStatic(Mockito.times(2)); BufferUtils.fastCopy(Mockito.any(ReadableByteChannel.class), Mockito.any(WritableByteChannel.class)); Assert.assertFalse(manager.needPersistence(fileId)); } "
    },
    {
        "test_src": "@Test public void recreateTokenFromBytes_InvalidTokenException()throws Exception { mock.checking(new Expectations() { { one(testTokenService).recreateTokenFromBytes(tokenBytes); will(throwException(new InvalidTokenException(\"Expected test exception\"))); } }); try { tokenManager.recreateTokenFromBytes(tokenBytes); fail(\"recreateTokenFromBytes should have throw an InvalidTokenException as per the mock setting\"); } catch(InvalidTokenException e) { String msg = \"CWWKS4001I: The security token cannot be validated.\"; assertTrue(\"Unable to find token expiration message\", outputMgr.checkForMessages(msg)); msg = \"1. The security token was generated on another server using different keys.\"; assertTrue(\"Unable to find token expiration message part 1\", outputMgr.checkForMessages(msg)); msg = \"2. The token configuration or the security keys of the token service which created the token has been changed.\"; assertTrue(\"Unable to find token expiration message part 2\", outputMgr.checkForMessages(msg)); msg = \"3. The token service which created the token is no longer available.\"; assertTrue(\"Unable to find token expiration message part 3\", outputMgr.checkForMessages(msg)); } } ",
        "focal_tgt": "@FFDCIgnore(InvalidTokenException.class)public abstract Token recreateTokenFromBytes(byte[]tokenBytes, String ... removeAttributes)throws InvalidTokenException, TokenExpiredException; ",
        "focal_src": "@FFDCIgnore(InvalidTokenException.class)public abstract Token recreateTokenFromBytes(byte[]tokenBytes)throws InvalidTokenException, TokenExpiredException; ",
        "test_tgt": "@Test public void recreateTokenFromBytes_InvalidTokenException()throws Exception { mock.checking(new Expectations() { { one(testTokenService).recreateTokenFromBytes(tokenBytes, removeAttrs); will(throwException(new InvalidTokenException(\"Expected test exception\"))); one(testTokenService).recreateTokenFromBytes(tokenBytes); will(throwException(new InvalidTokenException(\"Expected test exception\"))); } }); try { tokenManager.recreateTokenFromBytes(tokenBytes); fail(\"recreateTokenFromBytes should have throw an InvalidTokenException as per the mock setting\"); tokenManager.recreateTokenFromBytes(tokenBytes, removeAttrs); fail(\"recreateTokenFromBytes should have throw an InvalidTokenException as per the mock setting\"); } catch(InvalidTokenException e) { String msg = \"CWWKS4001I: The security token cannot be validated.\"; assertTrue(\"Unable to find token expiration message\", outputMgr.checkForMessages(msg)); msg = \"1. The security token was generated on another server using different keys.\"; assertTrue(\"Unable to find token expiration message part 1\", outputMgr.checkForMessages(msg)); msg = \"2. The token configuration or the security keys of the token service which created the token has been changed.\"; assertTrue(\"Unable to find token expiration message part 2\", outputMgr.checkForMessages(msg)); msg = \"3. The token service which created the token is no longer available.\"; assertTrue(\"Unable to find token expiration message part 3\", outputMgr.checkForMessages(msg)); } } "
    },
    {
        "test_src": "@Test public void hessian_F32() { ImageFloat32 original = new ImageFloat32(width, height); ImageFloat32 integral = new ImageFloat32(width, height); ImageFloat32 found = new ImageFloat32(width, height); ImageFloat32 expected = new ImageFloat32(width, height); GImageMiscOps.fillUniform(original, rand, 0, 50); IntegralImageOps.transform(original, integral); int size = 9; for(int skip = 1; skip <= 4; skip ++ ) { found.reshape(width / skip, height / skip); expected.reshape(width / skip, height / skip); ImplIntegralImageFeatureIntensity.hessianNaive(integral, skip, size, expected); IntegralImageFeatureIntensity.hessian(integral, skip, size, found); BoofTesting.assertEquals(expected, found, 1e-4f); } } ",
        "focal_tgt": "public static void hessian(GrayF32 integral, int skip, int size, GrayF32 intensity) { ImplIntegralImageFeatureIntensity.hessianBorder(integral, skip, size, intensity); ImplIntegralImageFeatureIntensity.hessianInner(integral, skip, size, intensity); } ",
        "focal_src": "public static void hessian(ImageFloat32 integral, int skip, int size, ImageFloat32 intensity) { ImplIntegralImageFeatureIntensity.hessianBorder(integral, skip, size, intensity); ImplIntegralImageFeatureIntensity.hessianInner(integral, skip, size, intensity); } ",
        "test_tgt": "@Test public void hessian_F32() { GrayF32 original = new GrayF32(width, height); GrayF32 integral = new GrayF32(width, height); GrayF32 found = new GrayF32(width, height); GrayF32 expected = new GrayF32(width, height); GImageMiscOps.fillUniform(original, rand, 0, 50); IntegralImageOps.transform(original, integral); int size = 9; for(int skip = 1; skip <= 4; skip ++ ) { found.reshape(width / skip, height / skip); expected.reshape(width / skip, height / skip); ImplIntegralImageFeatureIntensity.hessianNaive(integral, skip, size, expected); IntegralImageFeatureIntensity.hessian(integral, skip, size, found); BoofTesting.assertEquals(expected, found, 1e-4f); } } "
    },
    {
        "test_src": "@Test public void setBorderTop() { RegionUtil.setBorderTop(THIN, A1C3, sheet); } ",
        "focal_tgt": "@Removal(version = \"3.17\")public static void setBorderTop(int border, CellRangeAddress region, Sheet sheet, Workbook workbook) { setBorderTop(border, region, sheet); } ",
        "focal_src": "public static void setBorderTop(int border, CellRangeAddress region, Sheet sheet, Workbook workbook) { setBorderTop(border, region, sheet); } ",
        "test_tgt": "@Test public void setBorderTop() { assertEquals(NONE, getCellStyle(0, 0).getBorderTopEnum()); assertEquals(NONE, getCellStyle(0, 1).getBorderTopEnum()); assertEquals(NONE, getCellStyle(0, 2).getBorderTopEnum()); RegionUtil.setBorderTop(THIN, A1C3, sheet); assertEquals(THIN, getCellStyle(0, 0).getBorderTopEnum()); assertEquals(THIN, getCellStyle(0, 1).getBorderTopEnum()); assertEquals(THIN, getCellStyle(0, 2).getBorderTopEnum()); } "
    },
    {
        "test_src": "@Test public void testOnCreateOrUpdateCluster()throws GeniePreconditionException { this.c = new Cluster(NAME, USER, VERSION, ClusterStatus.UP, CLUSTER_TYPE); Assert.assertNull(this.c.getTags()); this.c.onCreateOrUpdateCluster(); Assert.assertEquals(2, this.c.getTags().size()); } ",
        "focal_tgt": "@PrePersist@PreUpdate protected void onCreateOrUpdateCluster()throws GeniePreconditionException { this.addAndValidateSystemTags(this.tags); } ",
        "focal_src": "@PrePersist@PreUpdate protected void onCreateOrUpdateCluster()throws GeniePreconditionException { if(this.tags == null) { this.tags = new HashSet < > (); } this.addAndValidateSystemTags(this.tags); } ",
        "test_tgt": "@Test public void testOnCreateOrUpdateCluster()throws GeniePreconditionException { this.c = new Cluster(NAME, USER, VERSION, ClusterStatus.UP, CLUSTER_TYPE); Assert.assertNotNull(this.c.getTags()); Assert.assertTrue(this.c.getTags().isEmpty()); this.c.onCreateOrUpdateCluster(); Assert.assertEquals(2, this.c.getTags().size()); } "
    },
    {
        "test_src": "@Test public void testContainsText() { assertTrue(instance.containsText(\"name\", \"a\").getQueryCriterions().contains(new ContainsTextCriterion(\"name\", \"a\"))); } ",
        "focal_tgt": "public CriteriaQuery containsText(String propName, String value) { criterion = criterion.and(criterionBuilder.containsText(propName, value)); return this; } ",
        "focal_src": "public CriteriaQuery containsText(String propName, String value) { addCriterion(criterionBuilder.containsText(propName, value)); return this; } ",
        "test_tgt": "@Test public void testContainsText() { assertEquals(new ContainsTextCriterion(\"name\", \"a\"), instance.containsText(\"name\", \"a\").getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void createUser() { User user = AccountData.getRandomUser(); UserDTO userDTO = new UserDTO(); userDTO.setLoginName(user.getLoginName()); userDTO.setName(user.getName()); userDTO.setEmail(user.getEmail()); IdResult result = accountWebServiceClient.createUser(userDTO); assertNotNull(result.getId()); } ",
        "focal_tgt": "@Override public IdResponse createUser(UserDTO user) { try { User userEntity = BeanMapper.map(user, User.class); Long userId = accountManager.saveUser(userEntity); return new IdResponse(userId); } catch(ConstraintViolationException e) { String message = StringUtils.join(BeanValidators.extractPropertyAndMessage(e), \"\\n\"); return new IdResponse().setError(WSResponse.PARAMETER_ERROR, message); } catch(DataIntegrityViolationException e) { String message = \"(:\" + user + \")\"; logger.error(message, e); return new IdResponse().setError(WSResponse.PARAMETER_ERROR, message); } catch(RuntimeException e) { logger.error(e.getMessage(), e); return new IdResponse().setDefaultError(); } } ",
        "focal_src": "@Override public IdResult createUser(UserDTO user) { try { User userEntity = BeanMapper.map(user, User.class); Long userId = accountManager.saveUser(userEntity); return new IdResult(userId); } catch(ConstraintViolationException e) { String message = StringUtils.join(BeanValidators.extractPropertyAndMessage(e), \"\\n\"); return new IdResult().setError(WSResult.PARAMETER_ERROR, message); } catch(DataIntegrityViolationException e) { String message = \"(:\" + user + \")\"; logger.error(message, e); return new IdResult().setError(WSResult.PARAMETER_ERROR, message); } catch(RuntimeException e) { logger.error(e.getMessage(), e); return new IdResult().setDefaultError(); } } ",
        "test_tgt": "@Test public void createUser() { User user = AccountData.getRandomUser(); UserDTO userDTO = new UserDTO(); userDTO.setLoginName(user.getLoginName()); userDTO.setName(user.getName()); userDTO.setEmail(user.getEmail()); IdResponse result = accountWebServiceClient.createUser(userDTO); assertNotNull(result.getId()); } "
    },
    {
        "test_src": "@Test public void saveOrder_shouldSaveARevisedOrder()throws Exception { Order originalOrder = orderService.getOrder(111); assertTrue(originalOrder.isCurrent()); final Patient patient = originalOrder.getPatient(); List < Order > originalActiveOrders = orderService.getActiveOrders(patient, null, null, null); final int originalOrderCount = originalActiveOrders.size(); assertTrue(originalActiveOrders.contains(originalOrder)); Order revisedOrder = originalOrder.cloneForRevision(); revisedOrder.setEncounter(encounterService.getEncounter(5)); revisedOrder.setInstructions(\"Take after a meal\"); revisedOrder.setStartDate(new Date()); revisedOrder.setOrderer(providerService.getProvider(1)); revisedOrder.setEncounter(encounterService.getEncounter(3)); orderService.saveOrder(revisedOrder, null); Thread.sleep(1); List < Order > activeOrders = orderService.getActiveOrders(patient, null, null, null); assertEquals(originalOrderCount, activeOrders.size()); assertFalse(originalOrder.isCurrent()); } ",
        "focal_tgt": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Cannot edit an existing order, you need to revise it instead\"); } if(order.getStartDate() == null) { order.setStartDate(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { concept = ((DrugOrder)order).getDrug().getConcept(); order.setConcept(concept); } if( ! isDiscontinueOrReviseOrder(order)) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order o : activeOrders) { if(o.getConcept().equals(concept)) { throw new APIException(\"Cannot have more than one active order for the same concept and care setting\"); } } } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Cannot determine the order type of the order, make sure the concept's class is mapped to an order type\"); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Cannot determine the care setting of the order\"); } order.setCareSetting(careSetting); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Previous Order is required for a revised order\"); } stopOrder(previousOrder, order.getStartDate()); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if( ! order.getOrderType().getJavaClass().isAssignableFrom(order.getClass())) { throw new APIException(\"Order type class \" + order.getOrderType().getJavaClass() + \" does not match the order class \" + order.getClass().getName()); } if(previousOrder != null) { String query = \"SELECT patient_id, care_setting, concept_id FROM orders WHERE order_id = \"; boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); if(isPreviousDrugOrder) { query = \"SELECT o.patient_id, o.care_setting, o.concept_id, d.drug_inventory_id \" + \"FROM orders o, drug_order d WHERE o.order_id = d.order_id AND o.order_id =\"; } List < List < Object > > rows = Context.getAdministrationService().executeSQL(query + previousOrder.getOrderId(), true); List < Object > rowData = rows.get(0); if( ! rowData.get(0).equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Cannot change the patient of an order\"); } else if( ! rowData.get(1).equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Cannot change the careSetting of an order\"); } else if( ! rowData.get(2).equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Cannot change the concept of an order\"); } else if(isPreviousDrugOrder && ! rowData.get(3).equals(((DrugOrder)previousOrder).getDrug().getDrugId())) { throw new APIException(\"Cannot change the drug of a drug order\"); } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"The concept of the previous order and the new one order don't match\"); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"The drug of the previous order and the new one order don't match\"); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"The order type does not match that of the previous order\"); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"The care setting does not match that of the previous order\"); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"The class does not match that of the previous order\"); } } return saveOrderInternal(order, orderContext); } ",
        "focal_src": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Cannot edit an existing order, you need to revise it instead\"); } if(order.getStartDate() == null) { order.setStartDate(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { concept = ((DrugOrder)order).getDrug().getConcept(); order.setConcept(concept); } if( ! isDiscontinueOrReviseOrder(order)) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order o : activeOrders) { if(o.getConcept().equals(concept)) { throw new APIException(\"Cannot have more than one active order for the same concept and care setting\"); } } } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Cannot determine the order type of the order, make sure the concept's class is mapped to an order type\"); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Cannot determine the care setting of the order\"); } order.setCareSetting(careSetting); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Previous Order is required for a revised order\"); } stopOrder(previousOrder, order.getStartDate()); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if(previousOrder != null) { String query = \"SELECT patient_id, care_setting, concept_id FROM orders WHERE order_id = \"; boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); if(isPreviousDrugOrder) { query = \"SELECT o.patient_id, o.care_setting, o.concept_id, d.drug_inventory_id \" + \"FROM orders o, drug_order d WHERE o.order_id = d.order_id AND o.order_id =\"; } List < List < Object > > rows = Context.getAdministrationService().executeSQL(query + previousOrder.getOrderId(), true); List < Object > rowData = rows.get(0); if( ! rowData.get(0).equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Cannot change the patient of an order\"); } else if( ! rowData.get(1).equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Cannot change the careSetting of an order\"); } else if( ! rowData.get(2).equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Cannot change the concept of an order\"); } else if(isPreviousDrugOrder && ! rowData.get(3).equals(((DrugOrder)previousOrder).getDrug().getDrugId())) { throw new APIException(\"Cannot change the drug of a drug order\"); } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"The concept of the previous order and the new one order don't match\"); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"The drug of the previous order and the new one order don't match\"); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"The order type does not match that of the previous order\"); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"The care setting does not match that of the previous order\"); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"The class does not match that of the previous order\"); } } return saveOrderInternal(order, orderContext); } ",
        "test_tgt": "@Test public void saveOrder_shouldSaveARevisedOrder()throws Exception { Order originalOrder = orderService.getOrder(111); assertTrue(originalOrder.isCurrent()); final Patient patient = originalOrder.getPatient(); List < Order > originalActiveOrders = orderService.getActiveOrders(patient, null, null, null); final int originalOrderCount = originalActiveOrders.size(); assertTrue(originalActiveOrders.contains(originalOrder)); Order revisedOrder = originalOrder.cloneForRevision(); revisedOrder.setEncounter(encounterService.getEncounter(5)); revisedOrder.setInstructions(\"Take after a meal\"); revisedOrder.setStartDate(new Date()); revisedOrder.setOrderer(providerService.getProvider(1)); revisedOrder.setEncounter(encounterService.getEncounter(3)); orderService.saveOrder(revisedOrder, null); Thread.sleep(1); List < Order > activeOrders = orderService.getActiveOrders(patient, null, null, null); assertEquals(originalOrderCount, activeOrders.size()); assertFalse(originalOrder.isCurrent()); } "
    },
    {
        "test_src": "@Test public void testGetNumBigrams() { System.out.println(\"getNumBigrams\"); assertEquals(17121, corpus.getNumBigrams()); } ",
        "focal_tgt": "long getNumBigrams(); ",
        "focal_src": "public long getNumBigrams(); ",
        "test_tgt": "@Test public void testGetNumBigrams() { System.out.println(\"getNumBigrams\"); assertEquals(18303, corpus.getNumBigrams()); } "
    },
    {
        "test_src": "@Test public void testWithDayOfMonth() { HijrahDate date = testDate.withDayOfMonth(4); assertEquals(date, HijrahDate.hijrahDate(testYear, testMonthOfYear, 4)); } ",
        "focal_tgt": "public HijrahDate withDayOfMonth(int dayOfMonth) { return HijrahDate.of(this.era, this.yearOfEra, this.monthOfYear, dayOfMonth); } ",
        "focal_src": "public HijrahDate withDayOfMonth(int dayOfMonth) { return HijrahDate.hijrahDate(this.era, this.yearOfEra, this.monthOfYear, dayOfMonth); } ",
        "test_tgt": "@Test public void testWithDayOfMonth() { HijrahDate date = testDate.withDayOfMonth(4); assertEquals(date, HijrahDate.of(testYear, testMonthOfYear, 4)); } "
    },
    {
        "test_src": "@Test public void testSetPollInterval()throws Exception { ospfInterface.setPollInterval(100); assertThat(ospfInterface.pollInterval(), is(100)); } ",
        "focal_tgt": "void interfaceUp()throws Exception; ",
        "focal_src": "void setPollInterval(int pollInterval); ",
        "test_tgt": "@Test public void testElectDR()throws Exception { ospfEligibleRouter = new OspfEligibleRouter(); ospfEligibleRouter.setIpAddress(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsDr(true); ospfEligibleRouter.setRouterPriority(10); ospfEligibleRouter.setRouterId(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsBdr(false); OspfEligibleRouter ospfEligibleRouter1 = new OspfEligibleRouter(); ospfEligibleRouter.setIpAddress(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsDr(true); ospfEligibleRouter.setRouterPriority(10); ospfEligibleRouter.setRouterId(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsBdr(false); OspfEligibleRouter ospfEligibleRouter2 = new OspfEligibleRouter(); ospfEligibleRouter.setIpAddress(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsDr(true); ospfEligibleRouter.setRouterPriority(10); ospfEligibleRouter.setRouterId(Ip4Address.valueOf(\"1.1.1.1\")); ospfEligibleRouter.setIsBdr(false); List < OspfEligibleRouter > ospfEligibleRouters = new ArrayList < > (); ospfEligibleRouters.add(ospfEligibleRouter); ospfEligibleRouters.add(ospfEligibleRouter1); ospfEligibleRouters.add(ospfEligibleRouter2); OspfEligibleRouter eligibleRouter = ospfInterface.electDr(ospfEligibleRouters, ospfEligibleRouter); assertThat(ospfEligibleRouters.size(), is(3)); assertThat(eligibleRouter, is(notNullValue())); } "
    },
    {
        "test_src": "@Test public void testCopy_String() { System.out.println(\"\\n+++ copy\"); RunTable instance = createHorizontalInstance(); RunTable expResult = createHorizontalInstance(); RunTable result = instance.copy(); if( ! expResult.isIdentical(result)) { fail(\"Copy not identical to original\"); } } ",
        "focal_tgt": "public RunTable copy() { RunTable clone = new RunTable(orientation, width, height); for(int i = 0; i < sequences.length; i ++ ) { RunSequence seq = sequences[i]; if(seq != null) { short[]rle = new short[seq.rle.length]; System.arraycopy(seq.rle, 0, rle, 0, seq.rle.length); clone.sequences[i] = new RunSequence(rle); } } return clone; } ",
        "focal_src": "public RunTable copy() { RunTable clone = new RunTable(orientation, width, height); for(int i = 0; i < sequences.length; i ++ ) { short[]seq = getSequence(i); if(seq != null) { short[]rle = new short[seq.length]; System.arraycopy(seq, 0, rle, 0, seq.length); clone.sequences[i] = rle; } } return clone; } ",
        "test_tgt": "@Test public void testCopy_String() { System.out.println(\"\\n+++ copy\"); RunTable instance = createHorizontalInstance(); RunTable expResult = createHorizontalInstance(); RunTable result = instance.copy(); if( ! expResult.equals(result)) { fail(\"Copy not identical to original\"); } } "
    },
    {
        "test_src": "@Test public void addPackageInfoTest()throws IOException { File dirPath = new File(CREATE_PATH); dirPath.mkdirs(); addPackageInfo(dirPath, CHECK1, CREATE_PATH, false); File filePath = new File(dirPath + File.separator + PKG_INFO); assertThat(filePath.isFile(), is(true)); } ",
        "focal_tgt": "public static void addPackageInfo(File path, String classInfo, String pack, boolean isChildNode, YangPluginConfig pluginConfig)throws IOException { pack = parsePkg(pack); try { File packageInfo = new File(path + SLASH + \"package-info.java\"); packageInfo.createNewFile(); FileWriter fileWriter = new FileWriter(packageInfo); BufferedWriter bufferedWriter = new BufferedWriter(fileWriter); bufferedWriter.write(CopyrightHeader.getCopyrightHeader()); bufferedWriter.write(getJavaDoc(PACKAGE_INFO, classInfo, isChildNode, pluginConfig)); String pkg = PACKAGE + SPACE + pack + SEMI_COLAN; if(pkg.length() > LINE_SIZE) { pkg = whenDelimiterIsPersent(pkg, LINE_SIZE); } bufferedWriter.write(pkg); bufferedWriter.close(); fileWriter.close(); } catch(IOException e) { throw new IOException(\"Exception occured while creating package info file.\"); } } ",
        "focal_src": "public static void addPackageInfo(File path, String classInfo, String pack, boolean isChildNode)throws IOException { if(pack.contains(ORG)) { String[]strArray = pack.split(ORG); pack = ORG + strArray[1]; } try { File packageInfo = new File(path + SLASH + \"package-info.java\"); packageInfo.createNewFile(); FileWriter fileWriter = new FileWriter(packageInfo); BufferedWriter bufferedWriter = new BufferedWriter(fileWriter); bufferedWriter.write(CopyrightHeader.getCopyrightHeader()); bufferedWriter.write(getJavaDoc(PACKAGE_INFO, classInfo, isChildNode)); bufferedWriter.write(PACKAGE + SPACE + pack + SEMI_COLAN); bufferedWriter.close(); fileWriter.close(); } catch(IOException e) { throw new IOException(\"Exception occured while creating package info file.\"); } } ",
        "test_tgt": "@Test public void addPackageInfoTest()throws IOException { File dirPath = new File(CREATE_PATH); dirPath.mkdirs(); addPackageInfo(dirPath, CHECK1, CREATE_PATH, false, getStubPluginConfig()); File filePath = new File(dirPath + File.separator + PKG_INFO); assertThat(filePath.isFile(), is(true)); } "
    },
    {
        "test_src": "@Test public void testAdd()throws Exception { int segmentCount = 10; int operationCountPerType = 5; MemoryOperationLog opLog = new MemoryOperationLog(); ArrayList < TestReadIndex.MethodInvocation > methodInvocations = new ArrayList < > (); TestReadIndex readIndex = new TestReadIndex(methodInvocations :: add); MemoryLogUpdater updater = new MemoryLogUpdater(opLog, new CacheUpdater(new InMemoryCache(\"0\"), readIndex)); ArrayList < Operation > operations = populate(updater, segmentCount, operationCountPerType); Assert.assertEquals(\"Unexpected size for MemoryOperationLog.\", operations.size(), opLog.getSize()); Assert.assertEquals(\"Unexpected number of items added to ReadIndex.\", operations.size() - segmentCount * operationCountPerType, methodInvocations.size()); Iterator < Operation > logIterator = opLog.read(op -> true, opLog.getSize()); int currentIndex = - 1; int currentReadIndex = - 1; while(logIterator.hasNext()) { currentIndex ++ ; Operation expected = operations.get(currentIndex); Assert.assertEquals(\"Unexpected operation queued to MemoryOperationLog at sequence \" + currentIndex, expected, logIterator.next()); if(expected instanceof StorageOperation) { currentReadIndex ++ ; TestReadIndex.MethodInvocation invokedMethod = methodInvocations.get(currentReadIndex); if(expected instanceof StreamSegmentAppendOperation) { StreamSegmentAppendOperation appendOp = (StreamSegmentAppendOperation)expected; CacheKey expectedKey = new CacheKey(appendOp.getStreamSegmentId(), appendOp.getStreamSegmentOffset()); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was not added to the ReadIndex.\", TestReadIndex.APPEND, invokedMethod.methodName); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", expectedKey, invokedMethod.args.get(\"key\")); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", appendOp.getData().length, invokedMethod.args.get(\"length\")); } else if(expected instanceof MergeBatchOperation) { MergeBatchOperation mergeOp = (MergeBatchOperation)expected; Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was not added to the ReadIndex.\", TestReadIndex.BEGIN_MERGE, invokedMethod.methodName); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getStreamSegmentId(), invokedMethod.args.get(\"targetStreamSegmentId\")); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getTargetStreamSegmentOffset(), invokedMethod.args.get(\"offset\")); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getBatchStreamSegmentId(), invokedMethod.args.get(\"sourceStreamSegmentId\")); } } } AssertExtensions.assertThrows(\"MemoryLogUpdater accepted an operation that was out of order.\", () -> updater.add(new MergeBatchOperation(1, 2)), ex -> ex instanceof DataCorruptionException); } ",
        "focal_tgt": "void process(Operation operation)throws DataCorruptionException { CacheKey cacheKey = addToCache(operation); try { operation = addToMemoryOperationLog(operation, cacheKey); if(operation instanceof StorageOperation) { this.cacheUpdater.addToReadIndex((StorageOperation)operation); } } catch(Exception | Error ex) { if(cacheKey != null) { this.cacheUpdater.removeFromCache(cacheKey); } throw ex; } } ",
        "focal_src": "void add(Operation operation)throws DataCorruptionException { CacheKey cacheKey = addToCache(operation); try { if( ! addToMemoryOperationLog(operation, cacheKey)) { throw new DataCorruptionException(\"About to have added a Log Operation to InMemoryOperationLog that was out of order.\"); } if(operation instanceof StorageOperation) { this.cacheUpdater.addToReadIndex((StorageOperation)operation, cacheKey); } } catch(Exception | Error ex) { if(cacheKey != null) { this.cacheUpdater.removeFromCache(cacheKey); } throw ex; } } ",
        "test_tgt": "@Test public void testProcess()throws Exception { int segmentCount = 10; int operationCountPerType = 5; MemoryOperationLog opLog = new MemoryOperationLog(); ArrayList < TestReadIndex.MethodInvocation > methodInvocations = new ArrayList < > (); TestReadIndex readIndex = new TestReadIndex(methodInvocations :: add); @Cleanup InMemoryCache cache = new InMemoryCache(\"0\"); MemoryLogUpdater updater = new MemoryLogUpdater(opLog, new CacheUpdater(cache, readIndex)); ArrayList < Operation > operations = populate(updater, segmentCount, operationCountPerType); Assert.assertEquals(\"Unexpected size for MemoryOperationLog.\", operations.size(), opLog.getSize()); Assert.assertEquals(\"Unexpected number of items added to ReadIndex.\", operations.size() - segmentCount * operationCountPerType, methodInvocations.size()); Iterator < Operation > logIterator = opLog.read(op -> true, opLog.getSize()); int currentIndex = - 1; int currentReadIndex = - 1; OperationComparer comparer = new OperationComparer(true, cache); while(logIterator.hasNext()) { currentIndex ++ ; Operation expected = operations.get(currentIndex); Operation actual = logIterator.next(); comparer.assertEquals(expected, actual); if(expected instanceof StorageOperation) { currentReadIndex ++ ; TestReadIndex.MethodInvocation invokedMethod = methodInvocations.get(currentReadIndex); if(expected instanceof StreamSegmentAppendOperation) { Assert.assertTrue(\"StreamSegmentAppendOperation was not added as a CachedStreamSegmentAppendOperation to the Memory Log.\", actual instanceof CachedStreamSegmentAppendOperation); StreamSegmentAppendOperation appendOp = (StreamSegmentAppendOperation)expected; CacheKey expectedKey = new CacheKey(appendOp.getStreamSegmentId(), appendOp.getStreamSegmentOffset()); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was not added to the ReadIndex.\", TestReadIndex.APPEND, invokedMethod.methodName); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", expectedKey, invokedMethod.args.get(\"key\")); Assert.assertEquals(\"Append with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", appendOp.getData().length, invokedMethod.args.get(\"length\")); } else if(expected instanceof MergeBatchOperation) { MergeBatchOperation mergeOp = (MergeBatchOperation)expected; Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was not added to the ReadIndex.\", TestReadIndex.BEGIN_MERGE, invokedMethod.methodName); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getStreamSegmentId(), invokedMethod.args.get(\"targetStreamSegmentId\")); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getTargetStreamSegmentOffset(), invokedMethod.args.get(\"offset\")); Assert.assertEquals(\"Merge with SeqNo \" + expected.getSequenceNumber() + \" was added to the ReadIndex with wrong arguments.\", mergeOp.getBatchStreamSegmentId(), invokedMethod.args.get(\"sourceStreamSegmentId\")); } } } AssertExtensions.assertThrows(\"MemoryLogUpdater accepted an operation that was out of order.\", () -> updater.process(new MergeBatchOperation(1, 2)), ex -> ex instanceof DataCorruptionException); } "
    },
    {
        "test_src": "@Test public void create()throws BaseXException { new Close().execute(context); query(_DB_CREATE.args(NAME)); query(_DB_EXISTS.args(NAME), true); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(NAME) + ',' + _DB_CREATE.args(NAME), BXDB_ONCE_X_X); query(_DB_CREATE.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(NAME, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(NAME, \"()\", \"1.xml\"), BXDB_CREATEARGS_X_X); error(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"1.xml\"), BXDB_CREATEARGS_X_X); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + NAME + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + NAME + \"' || $i\")); error(_DB_CREATE.args(\"\"), BXDB_NAME_X); query(_DB_DROP.args(NAME)); error(_DB_CREATE.args(NAME) + ',' + _DB_DROP.args(NAME), BXDB_WHICH_X); query(_DB_CREATE.args(NAME, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(NAME)); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(NAME) + ',' + _DB_DROP.args(NAME)); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(NAME)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(NAME) + \"//updindex/text()\", b); } assertEquals(context.options.get(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':'' }\")); } query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':true() }\")); query(_DB_OPEN.args(NAME), \"<a/>\"); query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':false() }\")); query(_DB_OPEN.args(NAME), \"<a> </a>\"); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'xyz':'abc' }\"), BASX_OPTIONS_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':-1 }\"), BASX_VALUE_X_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':'a' }\"), BASX_VALUE_X_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'textindex':'nope' }\"), BASX_VALUE_X_X); } ",
        "focal_tgt": "private static void create(final int ... db) { for(final int d : db) { final String[]doc = DOCS[d - 1]; execute(new CreateDB(doc[0], doc[1])); } } ",
        "focal_src": "private static void create(final int ... db)throws BaseXException { for(final int d : db) { final String[]doc = DOCS[d - 1]; new CreateDB(doc[0], doc[1]).execute(context); } } ",
        "test_tgt": "@Test public void create() { execute(new Close()); query(_DB_CREATE.args(NAME)); query(_DB_EXISTS.args(NAME), true); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \" document { <dummy/> }\", \"t2.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"\\\"<dummy/>\\\"\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\")); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); error(_DB_CREATE.args(NAME) + ',' + _DB_CREATE.args(NAME), BXDB_ONCE_X_X); query(_DB_CREATE.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_CREATE.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"('1.xml','2.xml')\")); query(_DB_CREATE.args(NAME, \"(<a/>,'\" + FILE + \"')\", \"('1.xml','2.xml')\")); error(_DB_CREATE.args(NAME, \"()\", \"1.xml\"), BXDB_CREATEARGS_X_X); error(_DB_CREATE.args(NAME, \"(<a/>,<b/>)\", \"1.xml\"), BXDB_CREATEARGS_X_X); query(\"for $i in 1 to 5 return \" + _DB_CREATE.args(\" '\" + NAME + \"' || $i\")); query(\"for $i in 1 to 5 return \" + _DB_DROP.args(\" '\" + NAME + \"' || $i\")); error(_DB_CREATE.args(\"\"), BXDB_NAME_X); query(_DB_DROP.args(NAME)); error(_DB_CREATE.args(NAME) + ',' + _DB_DROP.args(NAME), BXDB_WHICH_X); query(_DB_CREATE.args(NAME, \"<a/>\", \"a.xml\")); query(\"insert node <dummy/> into \" + _DB_OPEN.args(NAME)); query(_DB_CREATE.args(NAME, \"<dummy/>\", \"t1.xml\") + \", insert node <dummy/> into \" + _DB_OPEN.args(NAME) + ',' + _DB_DROP.args(NAME)); query(_DB_OPEN.args(NAME) + \"/root()\", \"<dummy/>\"); query(_DB_DROP.args(NAME)); for(final boolean b : new boolean[] { false, true }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'updindex':\" + b + \"() }\")); query(_DB_INFO.args(NAME) + \"//updindex/text()\", b); } assertEquals(context.options.get(MainOptions.UPDINDEX), false); final String[]nopt = { \"maxcats\", \"maxlen\", \"indexsplitsize\", \"ftindexsplitsize\" }; for(final String k : nopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':1 }\")); } final String[]bopt = { \"textindex\", \"attrindex\", \"ftindex\", \"stemming\", \"casesens\", \"diacritics\" }; for(final String k : bopt) { for(final boolean v : new boolean[] { true, false }) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':\" + v + \"() }\")); } } final String[]sopt = { \"language\", \"stopwords\" }; for(final String k : sopt) { query(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { '\" + k + \"':'' }\")); } query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':true() }\")); query(_DB_OPEN.args(NAME), \"<a/>\"); query(_DB_CREATE.args(NAME, \" '<a> </a>'\", \"a.xml\", \" map { 'chop':false() }\")); query(_DB_OPEN.args(NAME), \"<a> </a>\"); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'xyz':'abc' }\"), BASX_OPTIONS_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':-1 }\"), BASX_VALUE_X_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'maxlen':'a' }\"), BASX_VALUE_X_X); error(_DB_CREATE.args(NAME, \"()\", \"()\", \" map { 'textindex':'nope' }\"), BASX_VALUE_X_X); } "
    },
    {
        "test_src": "@Test public void testDelete()throws QueryException, BaseXException { final String fun = check(Function.DBDELETE); new Add(\"etc/test/dir\", \"docs\", \"test\").execute(CONTEXT); query(fun + \"('db', 'test')\", \"\"); query(\"count(collection('db/test')) eq 0\", \"true\"); } ",
        "focal_tgt": "public final void delete(final int pre) { meta.update(); int k = kind(pre); int s = size(pre, k); final boolean empty = pre == 0 && s == meta.size; docindex.delete(this, pre, s); ns.delete(pre, s); int par = pre; if(k == ATTR) { par = parent(par, ATTR); attSize(par, ELEM, attSize(par, ELEM) - 1); size(par, ELEM, size(par, ELEM) - 1); k = kind(par); } while(par > 0 && k != DOC) { par = parent(par, k); k = kind(par); size(par, k, size(par, k) - s); } int p = pre; if(empty) { ++ p; -- s; } else if(kind(p) == DOC) { -- meta.ndocs; } table.delete(pre, s); updateDist(p, - s); ns.update(pre, s, false, null); if(empty) { doc(0, 1, EMPTY); table.set(0, buffer()); } } ",
        "focal_src": "public final void delete(final int pre) { meta.update(true); int k = kind(pre); int s = size(pre, k); ns.delete(pre, s); int par = pre; if(k == ATTR) { par = parent(par, ATTR); attSize(par, ELEM, attSize(par, ELEM) - 1); size(par, ELEM, size(par, ELEM) - 1); k = kind(par); } while(par > 0 && k != DOC) { par = parent(par, k); k = kind(par); size(par, k, size(par, k) - s); } int p = pre; final boolean empty = p == 0 && s == meta.size; if(empty) { ++ p; -- s; } else { if(kind(p) == DOC) -- meta.ndocs; } table.delete(pre, s); updateDist(p, - s); ns.update(pre, s, false, null); if(empty) { doc(0, 1, EMPTY); table.set(0, buffer()); } } ",
        "test_tgt": "@Test public void testDelete()throws QueryException, BaseXException { final String fun = check(Function.DBDELETE); new Add(FLDR, \"docs\", \"test\").execute(CONTEXT); query(fun + \"('db', 'test')\", \"\"); query(\"count(collection('db/test')) eq 0\", \"true\"); } "
    },
    {
        "test_src": "@Test public void writeStream() { WriteCallback callback = new WriteCallback() { @Override public void writeData(Attributes attributes) { } }; ByteArrayResponse response = new ByteArrayResponse(); Attributes attributes = new Attributes(new MockWebRequest(new Url()), response); byte[]srcData = new byte[5000]; for(int i = 0; i < srcData.length; i ++ ) { srcData[i] = (byte)i; } InputStream in = new ByteArrayInputStream(srcData); callback.writeStream(attributes, in); assertTrue(\"Content not equal\", Arrays.equals(response.getBytes(), srcData)); } ",
        "focal_tgt": "protected final void writeStream(Attributes attributes, InputStream stream)throws IOException { final Response response = attributes.getResponse(); Streams.copy(stream, response.getOutputStream()); } ",
        "focal_src": "protected final void writeStream(Attributes attributes, InputStream stream) { final Response response = attributes.getResponse(); try { Streams.copy(stream, response.getOutputStream()); } catch(IOException e) { throw new WicketRuntimeException(e); } } ",
        "test_tgt": "@Test public void writeStream()throws IOException { WriteCallback callback = new WriteCallback() { @Override public void writeData(Attributes attributes) { } }; ByteArrayResponse response = new ByteArrayResponse(); Attributes attributes = new Attributes(new MockWebRequest(new Url()), response); byte[]srcData = new byte[5000]; for(int i = 0; i < srcData.length; i ++ ) { srcData[i] = (byte)i; } InputStream in = new ByteArrayInputStream(srcData); callback.writeStream(attributes, in); assertTrue(\"Content not equal\", Arrays.equals(response.getBytes(), srcData)); } "
    },
    {
        "test_src": "@Test public void connectNodes_oneCluster() { List < Polygon2D_F64 > squares = new ArrayList < Polygon2D_F64 > (); double width = 1; for(int i = 0; i < 3; i ++ ) { for(int j = 0; j < 4; j ++ ) { squares.add(createSquare(i * 2 * width, j * 2 * width, 0, width)); } } SquaresIntoClusters alg = new SquaresIntoClusters(1.0, 6); alg.computeNodeInfo(squares); alg.connectNodes(); assertEquals(2 * 4 + (2 + 4) * 3 + (1 * 2 * 4), countConnections(alg.nodes.toList())); } ",
        "focal_tgt": "void connectNodes() { setupSearch(); for(int i = 0; i < nodes.size(); i ++ ) { SquareNode n = nodes.get(i); double[]point = searchPoints.get(i); double neighborDistance = n.largestSide * (1.0 + spaceToSquareRatio) * maxNeighborDistanceRatio; searchResults.reset(); search.findNearest(point, neighborDistance * neighborDistance, maxNeighbors + 1, searchResults); for(int j = 0; j < searchResults.size(); j ++ ) { NnData < SquareNode > neighbor = searchResults.get(j); if(neighbor.data != n)considerConnect(n, neighbor.data); } } } ",
        "focal_src": "void connectNodes() { setupSearch(); for(int i = 0; i < nodes.size(); i ++ ) { SquareNode n = nodes.get(i); double[]point = searchPoints.get(i); double neighborDistance = n.largestSide * (1.0 + spaceToSquareRatio) * 1.2; searchResults.reset(); search.findNearest(point, neighborDistance * neighborDistance, maxNeighbors + 1, searchResults); for(int j = 0; j < searchResults.size(); j ++ ) { NnData < SquareNode > neighbor = searchResults.get(j); if(neighbor.data != n)considerConnect(n, neighbor.data); } } } ",
        "test_tgt": "@Test public void connectNodes_oneCluster() { List < Polygon2D_F64 > squares = new ArrayList < Polygon2D_F64 > (); double width = 1; for(int i = 0; i < 3; i ++ ) { for(int j = 0; j < 4; j ++ ) { squares.add(createSquare(i * 2 * width, j * 2 * width, 0, width)); } } SquaresIntoClusters alg = new SquaresIntoClusters(1.0, 6, 1.35); alg.computeNodeInfo(squares); alg.connectNodes(); assertEquals(2 * 4 + (2 + 4) * 3 + (1 * 2 * 4), countConnections(alg.nodes.toList())); } "
    },
    {
        "test_src": "@Test public void saveOrder_shouldNotAllowChangingTheDrugOfThePreviousDrugOrderWhenRevisingAnOrder()throws Exception { DrugOrder order = (DrugOrder)orderService.getOrder(111).cloneForRevision(); order.setDateActivated(new Date()); order.setEncounter(encounterService.getEncounter(3)); order.setOrderer(providerService.getProvider(1)); Drug newDrug = conceptService.getDrug(2); DrugOrder previousOrder = (DrugOrder)order.getPreviousOrder(); assertFalse(previousOrder.getDrug().equals(newDrug)); previousOrder.setDrug(newDrug); expectedException.expect(APIException.class); expectedException.expectMessage(\"Cannot change the drug of a drug order\"); orderService.saveOrder(order, null); } ",
        "focal_tgt": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Order.cannot.edit.existing\", (Object[])null); } if(order.getDateActivated() == null) { order.setDateActivated(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { DrugOrder drugOrder = (DrugOrder)order; if(drugOrder.getDrug() != null) { concept = drugOrder.getDrug().getConcept(); drugOrder.setConcept(concept); } } if(isDrugOrder) { ((DrugOrder)order).setAutoExpireDateBasedOnDuration(); } if(concept == null) { throw new APIException(\"Order.concept.required\", (Object[])null); } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Order.type.cannot.determine\", (Object[])null); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Order.care.cannot.determine\", (Object[])null); } order.setCareSetting(careSetting); } if( ! order.getOrderType().getJavaClass().isAssignableFrom(order.getClass())) { throw new APIException(\"Order.type.class.does.not.match\", new Object[] { order.getOrderType().getJavaClass(), order.getClass().getName() }); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Order.previous.required\", (Object[])null); } stopOrder(previousOrder, order.getDateActivated()); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if(previousOrder != null) { boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); List < List < Object > > rows = dao.getOrderFromDatabase(previousOrder, isPreviousDrugOrder); List < Object > rowData = rows.get(0); if( ! rowData.get(0).equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Order.cannot.change.patient\", (Object[])null); } else if( ! rowData.get(1).equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Order.cannot.change.careSetting\", (Object[])null); } else if( ! rowData.get(2).equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Order.cannot.change.concept\", (Object[])null); } else if(isPreviousDrugOrder) { Drug previousDrug = ((DrugOrder)previousOrder).getDrug(); if(previousDrug == null && rowData.get(3) != null) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } else if(previousDrug != null && ! OpenmrsUtil.nullSafeEquals(rowData.get(3), previousDrug.getDrugId())) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"Order.previous.concept\", (Object[])null); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"Order.previous.drug\", (Object[])null); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"Order.type.does.not.match\", (Object[])null); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"Order.care.setting.does.not.match\", (Object[])null); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"Order.class.does.not.match\", (Object[])null); } } if(DISCONTINUE != order.getAction()) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order activeOrder : activeOrders) { if(order.hasSameOrderableAs(activeOrder) && ! OpenmrsUtil.nullSafeEquals(order.getPreviousOrder(), activeOrder) && OrderUtil.checkScheduleOverlap(order, activeOrder)) { throw new APIException(\"Order.cannot.have.more.than.one\", (Object[])null); } } } return saveOrderInternal(order, orderContext); } ",
        "focal_src": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Cannot edit an existing order, you need to revise it instead\"); } if(order.getDateActivated() == null) { order.setDateActivated(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { DrugOrder drugOrder = (DrugOrder)order; if(drugOrder.getDrug() != null) { concept = drugOrder.getDrug().getConcept(); drugOrder.setConcept(concept); } } if(isDrugOrder) { ((DrugOrder)order).setAutoExpireDateBasedOnDuration(); } if(concept == null) { throw new APIException(\"concept is required for an order\"); } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Cannot determine the order type of the order, make sure the concept's class is mapped to an order type\"); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Cannot determine the care setting of the order\"); } order.setCareSetting(careSetting); } if( ! order.getOrderType().getJavaClass().isAssignableFrom(order.getClass())) { throw new APIException(\"Order type class \" + order.getOrderType().getJavaClass() + \" does not match the order class \" + order.getClass().getName()); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Previous Order is required for a revised order\"); } stopOrder(previousOrder, order.getDateActivated()); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if(previousOrder != null) { boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); List < List < Object > > rows = dao.getOrderFromDatabase(previousOrder, isPreviousDrugOrder); List < Object > rowData = rows.get(0); if( ! rowData.get(0).equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Cannot change the patient of an order\"); } else if( ! rowData.get(1).equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Cannot change the careSetting of an order\"); } else if( ! rowData.get(2).equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Cannot change the concept of an order\"); } else if(isPreviousDrugOrder) { Drug previousDrug = ((DrugOrder)previousOrder).getDrug(); if(previousDrug == null && rowData.get(3) != null) { throw new APIException(\"Cannot change the drug of a drug order\"); } else if(previousDrug != null && ! OpenmrsUtil.nullSafeEquals(rowData.get(3), previousDrug.getDrugId())) { throw new APIException(\"Cannot change the drug of a drug order\"); } } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"The concept of the previous order and the new one order don't match\"); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"The drug of the previous order and the new one order don't match\"); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"The order type does not match that of the previous order\"); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"The care setting does not match that of the previous order\"); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"The class does not match that of the previous order\"); } } if(DISCONTINUE != order.getAction()) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order activeOrder : activeOrders) { if(order.hasSameOrderableAs(activeOrder) && ! OpenmrsUtil.nullSafeEquals(order.getPreviousOrder(), activeOrder) && OrderUtil.checkScheduleOverlap(order, activeOrder)) { throw new APIException(\"Cannot have more than one active order for the same orderable and care setting at same time\"); } } } return saveOrderInternal(order, orderContext); } ",
        "test_tgt": "@Test public void saveOrder_shouldNotAllowChangingTheDrugOfThePreviousDrugOrderWhenRevisingAnOrder()throws Exception { DrugOrder order = (DrugOrder)orderService.getOrder(111).cloneForRevision(); order.setDateActivated(new Date()); order.setEncounter(encounterService.getEncounter(3)); order.setOrderer(providerService.getProvider(1)); Drug newDrug = conceptService.getDrug(2); DrugOrder previousOrder = (DrugOrder)order.getPreviousOrder(); assertFalse(previousOrder.getDrug().equals(newDrug)); previousOrder.setDrug(newDrug); expectedException.expect(APIException.class); expectedException.expectMessage(\"Order.cannot.change.drug\"); orderService.saveOrder(order, null); } "
    },
    {
        "test_src": "@Test(expected = IllegalArgumentException.class)public void test_getDocAction_NonDocument() { final Properties ctx = Env.getCtx(); final INonDocumentWithDocumentNo record = InterfaceWrapperHelper.create(ctx, INonDocumentWithDocumentNo.class, ITrx.TRXNAME_None); record.setDocumentNo(\"SomeDocumentNo\"); InterfaceWrapperHelper.save(record); docActionBL.getDocAction(record); } ",
        "focal_tgt": "IDocument getDocument(Object document); ",
        "focal_src": "IDocument getDocAction(Object document); ",
        "test_tgt": "@Test(expected = IllegalArgumentException.class)public void test_getDocAction_NonDocument() { final Properties ctx = Env.getCtx(); final INonDocumentWithDocumentNo record = InterfaceWrapperHelper.create(ctx, INonDocumentWithDocumentNo.class, ITrx.TRXNAME_None); record.setDocumentNo(\"SomeDocumentNo\"); InterfaceWrapperHelper.save(record); docActionBL.getDocument(record); } "
    },
    {
        "test_src": "@Test public void compareToNaive() { ImageUInt8 img = new ImageUInt8(width, height); ImageTestingOps.randomize(img, new Random(0xfeed), 0, 100); ImageSInt16 derivX = new ImageSInt16(img.getWidth(), img.getHeight()); ImageSInt16 derivY = new ImageSInt16(img.getWidth(), img.getHeight()); GradientSobel.process(img, derivX, derivY, new ImageBorder1D_I32(BorderIndex1D_Extend.class)); BoofTesting.checkSubImage(this, \"compareToNaive\", true, derivX, derivY); } ",
        "focal_tgt": "public void compareToNaive() { ImageFloat32 inten = new ImageFloat32(30, 40); QueueCorner naiveCorners = new QueueCorner(inten.getWidth() * inten.getHeight()); for(int useSubImage = 0; useSubImage <= 1; useSubImage ++ ) { if(useSubImage == 1) { ImageFloat32 larger = new ImageFloat32(inten.width + 10, inten.height + 8); inten = larger.subimage(5, 5, inten.width + 5, inten.height + 5); } for(int nonMaxWidth = 3; nonMaxWidth <= 9; nonMaxWidth += 2) { int radius = nonMaxWidth / 2; NonMaxExtractorNaive reg = new NonMaxExtractorNaive(strict); reg.setSearchRadius(radius); reg.setThreshold(0.6f); for(int i = 0; i < 10; i ++ ) { ImageMiscOps.fillUniform(inten, rand, 0, 10); findLocalMaximums(inten, 0.6f, radius, 0); naiveCorners.reset(); reg.process(inten, naiveCorners); assertTrue(found.size() > 0); assertEquals(naiveCorners.size(), found.size()); for(int j = 0; j < naiveCorners.size(); j ++ ) { Point2D_I16 b = naiveCorners.get(j); boolean foundMatch = false; for(int k = 0; k < found.size(); k ++ ) { Point2D_I16 a = found.get(k); if(a.x == b.x && a.y == b.y) { foundMatch = true; break; } } assertTrue(foundMatch); } } } } } ",
        "focal_src": "public void compareToNaive() { ImageFloat32 inten = new ImageFloat32(30, 40); QueueCorner naiveCorners = new QueueCorner(inten.getWidth() * inten.getHeight()); for(int useSubImage = 0; useSubImage <= 1; useSubImage ++ ) { if(useSubImage == 1) { ImageFloat32 larger = new ImageFloat32(inten.width + 10, inten.height + 8); inten = larger.subimage(5, 5, inten.width + 5, inten.height + 5); } for(int nonMaxWidth = 3; nonMaxWidth <= 9; nonMaxWidth += 2) { int radius = nonMaxWidth / 2; NonMaxExtractorNaive reg = new NonMaxExtractorNaive(strict); reg.setSearchRadius(radius); reg.setThreshold(0.6f); for(int i = 0; i < 10; i ++ ) { ImageTestingOps.randomize(inten, rand, 0, 10); findLocalMaximums(inten, 0.6f, radius, 0); naiveCorners.reset(); reg.process(inten, naiveCorners); assertTrue(found.size() > 0); assertEquals(naiveCorners.size(), found.size()); for(int j = 0; j < naiveCorners.size(); j ++ ) { Point2D_I16 b = naiveCorners.get(j); boolean foundMatch = false; for(int k = 0; k < found.size(); k ++ ) { Point2D_I16 a = found.get(k); if(a.x == b.x && a.y == b.y) { foundMatch = true; break; } } assertTrue(foundMatch); } } } } } ",
        "test_tgt": "@Test public void compareToNaive() { ImageUInt8 img = new ImageUInt8(width, height); ImageMiscOps.fillUniform(img, new Random(0xfeed), 0, 100); ImageSInt16 derivX = new ImageSInt16(img.getWidth(), img.getHeight()); ImageSInt16 derivY = new ImageSInt16(img.getWidth(), img.getHeight()); GradientSobel.process(img, derivX, derivY, new ImageBorder1D_I32(BorderIndex1D_Extend.class)); BoofTesting.checkSubImage(this, \"compareToNaive\", true, derivX, derivY); } "
    },
    {
        "test_src": "@Test public void byteArrayToHexStringTest() { Assert.assertEquals(\"\", FormatUtils.byteArrayToHexString(new byte[0])); Assert.assertEquals(\"0x01\", FormatUtils.byteArrayToHexString(new byte[] { 1 })); Assert.assertEquals(\"0x01 0xAC\", FormatUtils.byteArrayToHexString(new byte[] { 1, (byte)0xAC })); } ",
        "focal_tgt": "public static String byteArrayToHexString(byte[]bytes) { return byteArrayToHexString(bytes, \"0x\", \" \"); } ",
        "focal_src": "public static String byteArrayToHexString(byte[]bytes) { StringBuilder sb = new StringBuilder(); for(int i = 0; i < bytes.length; i ++ ) { sb.append(String.format(\"0x%02X\", bytes[i])); if(i != bytes.length - 1) { sb.append(\" \"); } } return sb.toString(); } ",
        "test_tgt": "@Test public void byteArrayToHexStringTest() { Assert.assertEquals(\"\", FormatUtils.byteArrayToHexString(new byte[0])); Assert.assertEquals(\"0x01\", FormatUtils.byteArrayToHexString(new byte[] { 1 })); Assert.assertEquals(\"0x01 0xac\", FormatUtils.byteArrayToHexString(new byte[] { 1, (byte)0xac })); Assert.assertEquals(\"01ac\", FormatUtils.byteArrayToHexString(new byte[] { 1, (byte)0xac }, \"\", \"\")); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should return all unvoided visits if includeEnded is set to true\", method = \"getVisits(Collection<VisitType>,Collection<Patient>,Collection<Location>,Collection<Concept>,Date,Date,Date,Date,boolean,boolean)\")public void getVisits_shouldReturnAllUnvoidedVisitsIfIncludeEndedIsSetToTrue()throws Exception { executeDataSet(VISITS_WITH_DATES_XML); Assert.assertEquals(13, dao.getVisits(null, null, null, null, null, null, null, null, true, false).size()); } ",
        "focal_tgt": "@Transactional(readOnly = true)@Authorized(PrivilegeConstants.VIEW_VISITS)public List < Visit > getVisits(Collection < VisitType > visitTypes, Collection < Patient > patients, Collection < Location > locations, Collection < Concept > indications, Date minStartDatetime, Date maxStartDatetime, Date minEndDatetime, Date maxEndDatetime, Map < VisitAttributeType, Object > attributeValues, boolean includeVoided)throws APIException; ",
        "focal_src": "@Transactional(readOnly = true)@Authorized(PrivilegeConstants.VIEW_VISITS)public List < Visit > getVisits(Collection < VisitType > visitTypes, Collection < Patient > patients, Collection < Location > locations, Collection < Concept > indications, Date minStartDatetime, Date maxStartDatetime, Date minEndDatetime, Date maxEndDatetime, boolean includeVoided)throws APIException; ",
        "test_tgt": "@Test@Verifies(value = \"should return all unvoided visits if includeEnded is set to true\", method = \"getVisits(Collection<VisitType>,Collection<Patient>,Collection<Location>,Collection<Concept>,Date,Date,Date,Date,boolean,boolean)\")public void getVisits_shouldReturnAllUnvoidedVisitsIfIncludeEndedIsSetToTrue()throws Exception { executeDataSet(VISITS_WITH_DATES_XML); Assert.assertEquals(13, dao.getVisits(null, null, null, null, null, null, null, null, null, true, false).size()); } "
    },
    {
        "test_src": "@Test public void testCreateStream()throws ExecutionException, InterruptedException { when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest4)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected2, streamResponseActual); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest5)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected3, streamResponseActual); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus2); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest)); assertEquals(\"Create Stream Status\", 409, response.get().getStatus()); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus3); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest2)); assertEquals(\"Create Stream Status\", 500, response.get().getStatus()); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus4); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest3)); assertEquals(\"Create Stream Status for non-existent scope\", 404, response.get().getStatus()); } ",
        "focal_tgt": "@Override public void createStream(final String scopeName, final CreateStreamRequest createStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"createStream\"); try { NameUtils.validateUserStreamName(createStreamRequest.getStreamName()); } catch(IllegalArgumentException | NullPointerException e) { log.warn(\"Create stream failed due to invalid stream name {}\", createStreamRequest.getStreamName()); asyncResponse.resume(Response.status(Status.BAD_REQUEST).build()); LoggerHelpers.traceLeave(log, \"createStream\", traceId); return; } StreamConfiguration streamConfiguration = ModelHelper.getCreateStreamConfig(createStreamRequest, scopeName); controllerService.createStream(streamConfiguration, System.currentTimeMillis()).thenApply(streamStatus -> { Response resp = null; if(streamStatus.getStatus() == CreateStreamStatus.Status.SUCCESS) { log.info(\"Successfully created stream: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CREATED).entity(ModelHelper.encodeStreamResponse(streamConfiguration)).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.STREAM_EXISTS) { log.warn(\"Stream already exists: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CONFLICT).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Scope not found: {}\", scopeName); resp = Response.status(Status.NOT_FOUND).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.INVALID_STREAM_NAME) { log.warn(\"Invalid stream name: {}\", streamConfiguration.getStreamName()); resp = Response.status(Status.BAD_REQUEST).build(); } else { log.warn(\"createStream failed for : {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.INTERNAL_SERVER_ERROR).build(); } return resp; }).exceptionally(exception -> { log.warn(\"createStream for {}/{} failed {}: \", scopeName, streamConfiguration.getStreamName(), exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"createStream\", traceId)); } ",
        "focal_src": "@Override public void createStream(final String scopeName, final CreateStreamRequest createStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"createStream\"); StreamConfiguration streamConfiguration = ModelHelper.getCreateStreamConfig(createStreamRequest, scopeName); controllerService.createStream(streamConfiguration, System.currentTimeMillis()).thenApply(streamStatus -> { Response resp = null; if(streamStatus.getStatus() == CreateStreamStatus.Status.SUCCESS) { log.info(\"Successfully created stream: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CREATED).entity(ModelHelper.encodeStreamResponse(streamConfiguration)).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.STREAM_EXISTS) { log.warn(\"Stream already exists: {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.CONFLICT).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Scope not found: {}\", scopeName); resp = Response.status(Status.NOT_FOUND).build(); } else if(streamStatus.getStatus() == CreateStreamStatus.Status.INVALID_STREAM_NAME) { log.warn(\"Invalid stream name: {}\", streamConfiguration.getStreamName()); resp = Response.status(Status.BAD_REQUEST).build(); } else { log.warn(\"createStream failed for : {}/{}\", scopeName, streamConfiguration.getStreamName()); resp = Response.status(Status.INTERNAL_SERVER_ERROR).build(); } return resp; }).exceptionally(exception -> { log.warn(\"createStream for {}/{} failed {}: \", scopeName, streamConfiguration.getStreamName(), exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"createStream\", traceId)); } ",
        "test_tgt": "@Test public void testCreateStream()throws ExecutionException, InterruptedException { when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest4)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected2, streamResponseActual); final CreateStreamRequest streamRequest = new CreateStreamRequest(); streamRequest.setStreamName(NameUtils.getInternalNameForStream(\"stream\")); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus2); response = target(streamResourceURI).request().async().post(Entity.json(streamRequest)); assertEquals(\"Create Stream Status\", 400, response.get().getStatus()); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest5)); assertEquals(\"Create Stream Status\", 201, response.get().getStatus()); streamResponseActual = response.get().readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected3, streamResponseActual); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus2); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest)); assertEquals(\"Create Stream Status\", 409, response.get().getStatus()); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus3); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest2)); assertEquals(\"Create Stream Status\", 500, response.get().getStatus()); when(mockControllerService.createStream(any(), anyLong())).thenReturn(createStreamStatus4); response = target(streamResourceURI).request().async().post(Entity.json(createStreamRequest3)); assertEquals(\"Create Stream Status for non-existent scope\", 404, response.get().getStatus()); } "
    },
    {
        "test_src": "@Test public void testAssign() { executor.assign(\"foo\", \"2\", message); Object var = executor.getState().get(\"foo\"); assertThat(var, instanceOf(Integer.class)); assertThat(var, equalTo(2)); } ",
        "focal_tgt": "@Override public void assign(String variable, String expression, JSONObject message, Context stellarContext) { Object result = execute(expression, message, stellarContext); state.put(variable, result); } ",
        "focal_src": "@Override public void assign(String variable, String expression, JSONObject message) { Object result = execute(expression, message); state.put(variable, result); } ",
        "test_tgt": "@Test public void testAssign() { executor.assign(\"foo\", \"2\", message, Context.EMPTY_CONTEXT()); Object var = executor.getState().get(\"foo\"); assertThat(var, instanceOf(Integer.class)); assertThat(var, equalTo(2)); } "
    },
    {
        "test_src": "@Test public void persistFile()throws Exception { long fileId = 1; List < Long > blockIds = Lists.newArrayList(1L, 2L); writeFileWithBlocks(fileId, blockIds); FileDataManager.PersistedFilesInfo info = mManager.getPersistedFilesInfo(); assertEquals(Arrays.asList(fileId), info.idList()); PowerMockito.verifyStatic(Mockito.times(2)); BufferUtils.fastCopy(Mockito.any(ReadableByteChannel.class), Mockito.any(WritableByteChannel.class)); assertFalse(mManager.needPersistence(fileId)); } ",
        "focal_tgt": "public void persistFile(long fileId, List < Long > blockIds)throws AlluxioException, IOException { Map < Long, Long > blockIdToLockId; synchronized(mLock) { blockIdToLockId = mPersistingInProgressFiles.get(fileId); if(blockIdToLockId == null || ! blockIdToLockId.keySet().equals(new HashSet < > (blockIds))) { throw new IOException(\"Not all the blocks of file \" + fileId + \" are locked\"); } } String dstPath = prepareUfsFilePath(fileId); FileInfo fileInfo = mBlockWorker.getFileInfo(fileId); UnderFileSystem ufs = mUfsManager.get(fileInfo.getMountId()).getUfs(); OutputStream outputStream = ufs.create(dstPath, CreateOptions.defaults().setOwner(fileInfo.getOwner()).setGroup(fileInfo.getGroup()).setMode(new Mode((short)fileInfo.getMode()))); final WritableByteChannel outputChannel = Channels.newChannel(outputStream); List < Throwable > errors = new ArrayList < > (); try { for(long blockId : blockIds) { long lockId = blockIdToLockId.get(blockId); if(Configuration.getBoolean(PropertyKey.WORKER_FILE_PERSIST_RATE_LIMIT_ENABLED)) { BlockMeta blockMeta = mBlockWorker.getBlockMeta(Sessions.CHECKPOINT_SESSION_ID, blockId, lockId); mPersistenceRateLimiter.acquire((int)blockMeta.getBlockSize()); } BlockReader reader = mBlockWorker.readBlockRemote(Sessions.CHECKPOINT_SESSION_ID, blockId, lockId); ReadableByteChannel inputChannel = reader.getChannel(); BufferUtils.fastCopy(inputChannel, outputChannel); reader.close(); } } catch(BlockDoesNotExistException | InvalidWorkerStateException e) { errors.add(e); } finally { for(long lockId : blockIdToLockId.values()) { try { mBlockWorker.unlockBlock(lockId); } catch(BlockDoesNotExistException e) { errors.add(e); } } if( ! errors.isEmpty()) { StringBuilder errorStr = new StringBuilder(); errorStr.append(\"the blocks of file\").append(fileId).append(\" are failed to persist\\n\"); for(Throwable e : errors) { errorStr.append(e).append('\\n'); } throw new IOException(errorStr.toString()); } } outputStream.flush(); outputChannel.close(); outputStream.close(); String ufsFingerprint = ufs.getFingerprint(dstPath); synchronized(mLock) { mPersistingInProgressFiles.remove(fileId); mPersistedUfsFingerprints.put(fileId, ufsFingerprint); } } ",
        "focal_src": "public void persistFile(long fileId, List < Long > blockIds)throws AlluxioException, IOException { Map < Long, Long > blockIdToLockId; synchronized(mLock) { blockIdToLockId = mPersistingInProgressFiles.get(fileId); if(blockIdToLockId == null || ! blockIdToLockId.keySet().equals(new HashSet < > (blockIds))) { throw new IOException(\"Not all the blocks of file \" + fileId + \" are locked\"); } } String dstPath = prepareUfsFilePath(fileId); FileInfo fileInfo = mBlockWorker.getFileInfo(fileId); UnderFileSystem ufs = mUfsManager.get(fileInfo.getMountId()).getUfs(); OutputStream outputStream = ufs.create(dstPath, CreateOptions.defaults().setOwner(fileInfo.getOwner()).setGroup(fileInfo.getGroup()).setMode(new Mode((short)fileInfo.getMode()))); final WritableByteChannel outputChannel = Channels.newChannel(outputStream); List < Throwable > errors = new ArrayList < > (); try { for(long blockId : blockIds) { long lockId = blockIdToLockId.get(blockId); if(Configuration.getBoolean(PropertyKey.WORKER_FILE_PERSIST_RATE_LIMIT_ENABLED)) { BlockMeta blockMeta = mBlockWorker.getBlockMeta(Sessions.CHECKPOINT_SESSION_ID, blockId, lockId); mPersistenceRateLimiter.acquire((int)blockMeta.getBlockSize()); } BlockReader reader = mBlockWorker.readBlockRemote(Sessions.CHECKPOINT_SESSION_ID, blockId, lockId); ReadableByteChannel inputChannel = reader.getChannel(); BufferUtils.fastCopy(inputChannel, outputChannel); reader.close(); } } catch(BlockDoesNotExistException | InvalidWorkerStateException e) { errors.add(e); } finally { for(long lockId : blockIdToLockId.values()) { try { mBlockWorker.unlockBlock(lockId); } catch(BlockDoesNotExistException e) { errors.add(e); } } if( ! errors.isEmpty()) { StringBuilder errorStr = new StringBuilder(); errorStr.append(\"the blocks of file\").append(fileId).append(\" are failed to persist\\n\"); for(Throwable e : errors) { errorStr.append(e).append('\\n'); } throw new IOException(errorStr.toString()); } } outputStream.flush(); outputChannel.close(); outputStream.close(); UfsFileStatus ufsFileStatus = ufs.getFileStatus(dstPath); synchronized(mLock) { mPersistingInProgressFiles.remove(fileId); mPersistedFilesInfo.put(fileId, ufsFileStatus); } } ",
        "test_tgt": "@Test public void persistFile()throws Exception { long fileId = 1; List < Long > blockIds = Lists.newArrayList(1L, 2L); writeFileWithBlocks(fileId, blockIds); FileDataManager.PersistedFilesInfo info = mManager.getPersistedUfsFingerprints(); assertEquals(Arrays.asList(fileId), info.idList()); PowerMockito.verifyStatic(Mockito.times(2)); BufferUtils.fastCopy(Mockito.any(ReadableByteChannel.class), Mockito.any(WritableByteChannel.class)); assertFalse(mManager.needPersistence(fileId)); } "
    },
    {
        "test_src": "@Test public void zipFile()throws IOException { check(_ZIP_ZIP_FILE); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='one'/>\"))); checkZipEntry(\"one\", new byte[0]); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='two'>!</entry>\"))); checkZipEntry(\"two\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='three' encoding='UTF-16'>!</entry>\"))); checkZipEntry(\"three\", new byte[] { '\\0', '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='four' src='\" + TMPFILE + \"'/>\"))); checkZipEntry(\"four\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry src='\" + TMPFILE + \"'/>\"))); checkZipEntry(NAME + \".tmp\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<dir name='a'><entry name='b' src='\" + TMPFILE + \"'/></dir>\"))); checkZipEntry(\"a/b\", new byte[] { '!' }); error(_ZIP_ZIP_FILE.args(zipParams(\"\")), Err.ZIP_FAIL); error(_ZIP_ZIP_FILE.args(zipParams(\"<entry src='\" + TMPFILE + \"'/>\" + \"<entry src='\" + TMPFILE + \"'/>\")), Err.ZIP_FAIL); } ",
        "focal_tgt": "private Item zipFile(final QueryContext ctx)throws QueryException { final ANode elm = (ANode)checkType(expr[0].item(ctx, info), NodeType.ELM); if( ! elm.qname().eq(E_FILE))ZIP_UNKNOWN.thrw(info, elm.qname()); final String file = attribute(elm, A_HREF, true); FileOutputStream fos = null; boolean ok = true; try { fos = new FileOutputStream(file); final ZipOutputStream zos = new ZipOutputStream(new BufferedOutputStream(fos)); create(zos, elm.children(), \"\", null, ctx); zos.close(); } catch(final IOException ex) { ok = false; ZIP_FAIL.thrw(info, ex); } finally { if(fos != null) { try { fos.close(); } catch(final IOException ex) { } if( ! ok)new IOFile(file).delete(); } } return null; } ",
        "focal_src": "private Item zipFile(final QueryContext ctx)throws QueryException { final ANode elm = (ANode)checkType(expr[0].item(ctx, info), NodeType.ELM); if( ! elm.qname().eq(E_FILE))ZIP_UNKNOWN.thrw(info, elm.qname()); final String file = attribute(elm, A_HREF, true); FileOutputStream fos = null; boolean ok = true; try { fos = new FileOutputStream(file); final ZipOutputStream zos = new ZipOutputStream(new BufferedOutputStream(fos)); create(zos, elm.children(), \"\", null, ctx); zos.close(); } catch(final IOException ex) { ok = false; ZIP_FAIL.thrw(info, ex.getMessage()); } finally { if(fos != null) { try { fos.close(); } catch(final IOException ex) { } if( ! ok)new IOFile(file).delete(); } } return null; } ",
        "test_tgt": "@Test public void zipZipFile()throws IOException { check(_ZIP_ZIP_FILE); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='one'/>\"))); checkZipEntry(\"one\", new byte[0]); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='two'>!</entry>\"))); checkZipEntry(\"two\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='three' encoding='UTF-16'>!</entry>\"))); checkZipEntry(\"three\", new byte[] { '\\0', '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry name='four' src='\" + TMPFILE + \"'/>\"))); checkZipEntry(\"four\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<entry src='\" + TMPFILE + \"'/>\"))); checkZipEntry(NAME + \".tmp\", new byte[] { '!' }); query(_ZIP_ZIP_FILE.args(zipParams(\"<dir name='a'><entry name='b' src='\" + TMPFILE + \"'/></dir>\"))); checkZipEntry(\"a/b\", new byte[] { '!' }); error(_ZIP_ZIP_FILE.args(zipParams(\"\")), Err.ZIP_FAIL); error(_ZIP_ZIP_FILE.args(zipParams(\"<entry src='\" + TMPFILE + \"'/>\" + \"<entry src='\" + TMPFILE + \"'/>\")), Err.ZIP_FAIL); } "
    },
    {
        "test_src": "@Test public void add() { query(COUNT.args(COLLECTION.args(NAME)), \"1\"); query(_DB_ADD.args(NAME, FILE)); query(COUNT.args(COLLECTION.args(NAME)), \"2\"); query(_DB_ADD.args(NAME, \"\\\"<root/>\\\"\", \"t1.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/t1.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, \" document { <root/> }\", \"t2.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/t2.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, \" <root/>\", \"test/t3.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/t3.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_ADD.args(NAME, FILE, \"test/t4.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/t4.xml\") + \"/html\"), \"1\"); query(_DB_ADD.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(\"for $f in \" + _FILE_LIST.args(FLDR, \"true()\", \"*.xml\") + \" return \" + _DB_ADD.args(NAME, \" '\" + FLDR + \"' || $f\", \"dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/dir\")), NFLDR); query(\"for $i in 1 to 3 return \" + _DB_ADD.args(NAME, \"\\\"<root/>\\\"\", \"\\\"doc\\\" || $i\")); query(COUNT.args(\" for $i in 1 to 3 return \" + COLLECTION.args('\"' + NAME + \"/doc\\\" || $i\")), 3); } ",
        "focal_tgt": "private Item add(final QueryContext ctx)throws QueryException { final Data data = checkData(ctx); final byte[]path = expr.length < 3 ? Token.EMPTY : token(path(2, ctx)); final NewInput input = checkInput(checkItem(expr[1], ctx), path); final Options opts = checkOptions(3, Q_OPTIONS, new Options(), ctx); ctx.updates.add(new DBAdd(data, input, opts, ctx, info), ctx); return null; } ",
        "focal_src": "private Item add(final QueryContext ctx)throws QueryException { final Data data = checkData(ctx); final byte[]path = expr.length < 3 ? Token.EMPTY : token(path(2, ctx)); final NewInput input = checkInput(checkItem(expr[1], ctx), path); ctx.updates.add(new DBAdd(data, input, ctx, info), ctx); return null; } ",
        "test_tgt": "@Test public void add() { query(COUNT.args(COLLECTION.args(NAME)), \"1\"); query(_DB_ADD.args(NAME, FILE)); query(COUNT.args(COLLECTION.args(NAME)), \"2\"); query(_DB_ADD.args(NAME, \"\\\"<root/>\\\"\", \"t1.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/t1.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, \" document { <root/> }\", \"t2.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/t2.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, \" <root/>\", \"test/t3.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/t3.xml\") + \"/root\"), \"1\"); query(_DB_ADD.args(NAME, FILE, \"in/\")); query(COUNT.args(COLLECTION.args(NAME + \"/in/input.xml\") + \"/html\"), \"1\"); query(_DB_ADD.args(NAME, FILE, \"test/t4.xml\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/t4.xml\") + \"/html\"), \"1\"); query(_DB_ADD.args(NAME, FLDR, \"test/dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/test/dir\")), NFLDR); query(\"for $f in \" + _FILE_LIST.args(FLDR, \"true()\", \"*.xml\") + \" return \" + _DB_ADD.args(NAME, \" '\" + FLDR + \"' || $f\", \"dir\")); query(COUNT.args(COLLECTION.args(NAME + \"/dir\")), NFLDR); query(\"for $i in 1 to 3 return \" + _DB_ADD.args(NAME, \"\\\"<root/>\\\"\", \"\\\"doc\\\" || $i\")); query(COUNT.args(\" for $i in 1 to 3 return \" + COLLECTION.args('\"' + NAME + \"/doc\\\" || $i\")), 3); query(_DB_ADD.args(NAME, \" '<a> </a>'\", \"chop.xml\", \" map { 'chop':true() }\")); query(_DB_OPEN.args(NAME, \"chop.xml\"), \"<a/>\"); query(_DB_ADD.args(NAME, \" '<a> </a>'\", \"nochop.xml\", \" map { 'chop':false() }\")); query(_DB_OPEN.args(NAME, \"nochop.xml\"), \"<a> </a>\"); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_plusHours_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.toLocalDate(); for(int i = 0; i < 50; i ++ ) { t = t.plusHours(1); if((i + 1) % 24 == 0) { d = d.plusDays(1); } assertEquals(t.toLocalDate(), d); assertEquals(t.getHour(), (i + 1) % 24); } } ",
        "focal_tgt": "ChronoZonedDateTime < C > plusHours(long hours) { ChronoDateTime newDT = dateTime.getDateTime().plusHours(hours); return(newDT == dateTime.getDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "focal_src": "ChronoZonedDateTime < C > plusHours(long hours) { ChronoDateTime newDT = dateTime.toDateTime().plusHours(hours); return(newDT == dateTime.toDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_plusHours_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.getDate(); for(int i = 0; i < 50; i ++ ) { t = t.plusHours(1); if((i + 1) % 24 == 0) { d = d.plusDays(1); } assertEquals(t.getDate(), d); assertEquals(t.getHour(), (i + 1) % 24); } } "
    },
    {
        "test_src": "@Test public void testGetDriverConfig() { when(resourceRequests.readDriverConfig()).thenReturn(driverConfigBean(driverConfig())); client.getDriverConfig(); client.getDriverConfigBundle(); verify(resourceRequests, times(1)).readDriverConfig(); } ",
        "focal_tgt": "public MDriverConfig getDriverConfig() { if(mDriver != null) { return mDriver.clone(false).getDriverConfig(); } retrieveAndCacheDriver(); return mDriver.clone(false).getDriverConfig(); } ",
        "focal_src": "public MDriverConfig getDriverConfig() { if(driverConfig != null) { return driverConfig.clone(false); } retrieveAndCacheDriverConfig(); return driverConfig.clone(false); } ",
        "test_tgt": "@Test public void testGetDriverConfig() { when(resourceRequests.readDriver()).thenReturn(driverBean(driver())); client.getDriverConfig(); client.getDriverConfigBundle(); verify(resourceRequests, times(1)).readDriver(); } "
    },
    {
        "test_src": "@Test public void createSSOToken_TokenCreationFailedException()throws Exception { mock.checking(new Expectations() { { one(testTokenService).createToken(testTokenData); will(throwException(new TokenCreationFailedException(\"Expected test exception\"))); } }); try { tokenManager.createToken(TEST_TOKEN_TYPE, testTokenData); fail(\"createToken should have throw an TokenCreationFailedException as per the mock setting\"); } catch(TokenCreationFailedException e) { } } ",
        "focal_tgt": "@Override public SingleSignonToken createSSOToken(Token token)throws TokenCreationFailedException { try { TokenService tokenService = getTokenServiceForType(ssoTokenType); SingleSignonTokenImpl ssoToken = new SingleSignonTokenImpl(tokenService); ssoToken.initializeToken(token); return ssoToken; } catch(IllegalArgumentException e) { throw new TokenCreationFailedException(e.getMessage(), e); } } ",
        "focal_src": "public SingleSignonToken createSSOToken(Token token)throws TokenCreationFailedException { try { TokenService tokenService = getTokenServiceForType(ssoTokenType); SingleSignonTokenImpl ssoToken = new SingleSignonTokenImpl(tokenService); ssoToken.initializeToken(token); return ssoToken; } catch(IllegalArgumentException e) { throw new TokenCreationFailedException(e.getMessage(), e); } } ",
        "test_tgt": "@Test public void createSSOToken_TokenCreationFailedException()throws Exception { mock.checking(new Expectations() { { one(testTokenService).createToken(testTokenData); will(throwException(new TokenCreationFailedException(\"Expected test exception\"))); } }); try { tokenManager.createToken(TEST_TOKEN_TYPE, testTokenData); fail(\"createToken should have throw an TokenCreationFailedException as per the mock setting\"); } catch(TokenCreationFailedException e) { } } "
    },
    {
        "test_src": "@Ignore@Test public void testProcessImportedGrades() { final List < Assignment > assignments = mockAssignments(); final List < GbStudentGradeInfo > existingGrades = mockExistingStudentGrades(); final ImportedSpreadsheetWrapper importedSpreadsheetWrapper = mockImportedSpreadsheetData(); final List < ProcessedGradeItem > processedGradeItems = ImportGradesHelper.processImportedGrades(importedSpreadsheetWrapper, assignments, existingGrades); Assert.assertNotNull(processedGradeItems); Assert.assertEquals(\"Wrong number of columns\", 4, processedGradeItems.size()); final ProcessedGradeItem item1 = processedGradeItems.get(0); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 1\", item1.getItemTitle()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_NA, item1.getStatus().getStatusCode()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_NA, item1.getCommentStatus().getStatusCode()); final ProcessedGradeItem item2 = processedGradeItems.get(1); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 2\", item2.getItemTitle()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_MODIFIED, item2.getStatus().getStatusCode()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_UPDATE, item2.getCommentStatus().getStatusCode()); final ProcessedGradeItem item3 = processedGradeItems.get(2); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 3\", item3.getItemTitle()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_NEW, item3.getStatus().getStatusCode()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_NEW, item3.getCommentStatus().getStatusCode()); final ProcessedGradeItem item4 = processedGradeItems.get(3); Assert.assertEquals(\"Incorrect title: \" + \"Assignment Ext\", item4.getItemTitle()); Assert.assertEquals(\"wrong status\", ProcessedGradeItemStatus.STATUS_EXTERNAL, item4.getStatus().getStatusCode()); Assert.assertEquals(\"wrong status name\", \"From a test\", item4.getStatus().getStatusValue()); } ",
        "focal_tgt": "public static List < ProcessedGradeItem > processImportedGrades(final ImportedSpreadsheetWrapper spreadsheetWrapper, final List < Assignment > assignments, final List < GbStudentGradeInfo > currentGrades) { final List < ProcessedGradeItem > processedGradeItems = new ArrayList < > (); final Map < Long, AssignmentStudentGradeInfo > transformedGradeMap = transformCurrentGrades(currentGrades); final Map < String, Assignment > assignmentMap = assignments.stream().collect(Collectors.toMap(Assignment :: getName, Function.identity())); final List < String > commentColumns = new ArrayList < > (); for(final ImportedColumn column : spreadsheetWrapper.getColumns()) { if(column.isIgnorable()) { continue; } final String columnTitle = StringUtils.trim(column.getColumnTitle()); final ProcessedGradeItem processedGradeItem = new ProcessedGradeItem(); processedGradeItem.setType(ProcessedGradeItem.Type.GB_ITEM); final Assignment assignment = assignmentMap.get(columnTitle); if(assignment != null) { processedGradeItem.setItemId(assignment.getId()); } final Status status = determineStatus(column, assignment, spreadsheetWrapper, transformedGradeMap); processedGradeItem.setStatus(status); processedGradeItem.setItemTitle(columnTitle); log.debug(\"Column name: \" + columnTitle + \", type: \" + column.getType() + \", status: \" + status); if(column.getType() == ImportedColumn.Type.GB_ITEM_WITH_POINTS) { processedGradeItem.setItemPointValue(column.getPoints()); } else if(column.getType() == ImportedColumn.Type.COMMENTS) { processedGradeItem.setType(ProcessedGradeItem.Type.COMMENT); commentColumns.add(columnTitle); } else if(column.getType() == ImportedColumn.Type.GB_ITEM_WITHOUT_POINTS) { } else { log.warn(\"Bad column. Type: \" + column.getType() + \", header: \" + columnTitle + \". Skipping.\"); continue; } final List < ProcessedGradeItemDetail > processedGradeItemDetails = new ArrayList < > (); for(final ImportedRow row : spreadsheetWrapper.getRows()) { final ImportedCell cell = row.getCellMap().get(columnTitle); if(cell != null) { final ProcessedGradeItemDetail processedGradeItemDetail = new ProcessedGradeItemDetail(); processedGradeItemDetail.setStudentEid(row.getStudentEid()); processedGradeItemDetail.setStudentUuid(row.getStudentUuid()); processedGradeItemDetail.setGrade(cell.getScore()); processedGradeItemDetail.setComment(cell.getComment()); processedGradeItemDetails.add(processedGradeItemDetail); } } processedGradeItem.setProcessedGradeItemDetails(processedGradeItemDetails); processedGradeItems.add(processedGradeItem); } commentColumns.forEach(c -> { final boolean matchingItemExists = processedGradeItems.stream().filter(p -> StringUtils.equals(c, p.getItemTitle())).findFirst().isPresent(); if( ! matchingItemExists) { throw new GbImportCommentMissingItemException(\"The comment column '\" + c + \"' does not have a corresponding gradebook item.\"); } }); return processedGradeItems; } ",
        "focal_src": "public static List < ProcessedGradeItem > processImportedGrades(final ImportedSpreadsheetWrapper spreadsheetWrapper, final List < Assignment > assignments, final List < GbStudentGradeInfo > currentGrades) { final Map < String, ProcessedGradeItem > assignmentProcessedGradeItemMap = new LinkedHashMap < > (); final Map < Long, AssignmentStudentGradeInfo > transformedGradeMap = transformCurrentGrades(currentGrades); final Map < String, Assignment > assignmentNameMap = assignments.stream().collect(Collectors.toMap(Assignment :: getName, a -> a)); final List < String > commentColumns = new ArrayList < > (); for(final ImportedColumn column : spreadsheetWrapper.getColumns()) { boolean needsToBeAdded = false; if(column.isIgnorable()) { continue; } final String columnTitle = StringUtils.trim(column.getColumnTitle()); ProcessedGradeItem processedGradeItem = assignmentProcessedGradeItemMap.get(columnTitle); if(processedGradeItem == null) { processedGradeItem = new ProcessedGradeItem(); needsToBeAdded = true; processedGradeItem.setType(ProcessedGradeItem.Type.GB_ITEM); } final Assignment assignment = assignmentNameMap.get(columnTitle); final ProcessedGradeItemStatus status = determineStatus(column, assignment, spreadsheetWrapper, transformedGradeMap); if(column.getType() == ImportedColumn.Type.GB_ITEM_WITH_POINTS) { log.debug(\"GB Item: \" + columnTitle + \", status: \" + status.getStatusCode()); processedGradeItem.setItemTitle(columnTitle); processedGradeItem.setItemPointValue(column.getPoints()); processedGradeItem.setStatus(status); } else if(column.getType() == ImportedColumn.Type.COMMENTS) { log.debug(\"Comments: \" + columnTitle + \", status: \" + status.getStatusCode()); processedGradeItem.setType(ProcessedGradeItem.Type.COMMENT); processedGradeItem.setCommentStatus(status); commentColumns.add(columnTitle); } else if(column.getType() == ImportedColumn.Type.GB_ITEM_WITHOUT_POINTS) { log.debug(\"Regular: \" + columnTitle + \", status: \" + status.getStatusCode()); processedGradeItem.setItemTitle(columnTitle); processedGradeItem.setStatus(status); } else { log.warn(\"Bad column. Type: \" + column.getType() + \", header: \" + columnTitle + \". Skipping.\"); continue; } if(assignment != null) { processedGradeItem.setItemId(assignment.getId()); } final List < ProcessedGradeItemDetail > processedGradeItemDetails = new ArrayList < > (); for(final ImportedRow row : spreadsheetWrapper.getRows()) { final ImportedCell cell = row.getCellMap().get(columnTitle); if(cell != null) { final ProcessedGradeItemDetail processedGradeItemDetail = new ProcessedGradeItemDetail(); processedGradeItemDetail.setStudentEid(row.getStudentEid()); processedGradeItemDetail.setStudentUuid(row.getStudentUuid()); processedGradeItemDetail.setGrade(cell.getScore()); processedGradeItemDetail.setComment(cell.getComment()); processedGradeItemDetails.add(processedGradeItemDetail); } } processedGradeItem.setProcessedGradeItemDetails(processedGradeItemDetails); if(needsToBeAdded) { assignmentProcessedGradeItemMap.put(columnTitle, processedGradeItem); } } final List < ProcessedGradeItem > processedGradeItems = new ArrayList < > (assignmentProcessedGradeItemMap.values()); commentColumns.forEach(c -> { final boolean matchingItemExists = processedGradeItems.stream().filter(p -> StringUtils.equals(c, p.getItemTitle())).findFirst().isPresent(); if( ! matchingItemExists) { throw new GbImportCommentMissingItemException(\"The comment column '\" + c + \"' does not have a corresponding gradebook item.\"); } }); return processedGradeItems; } ",
        "test_tgt": "@Ignore@Test public void testProcessImportedGrades() { final List < Assignment > assignments = mockAssignments(); final List < GbStudentGradeInfo > existingGrades = mockExistingStudentGrades(); final ImportedSpreadsheetWrapper importedSpreadsheetWrapper = mockImportedSpreadsheetData(); final List < ProcessedGradeItem > processedGradeItems = ImportGradesHelper.processImportedGrades(importedSpreadsheetWrapper, assignments, existingGrades); Assert.assertNotNull(processedGradeItems); Assert.assertEquals(\"Wrong number of columns\", 4, processedGradeItems.size()); final ProcessedGradeItem item1 = processedGradeItems.get(0); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 1\", item1.getItemTitle()); Assert.assertEquals(\"wrong status\", Status.SKIP, item1.getStatus()); final ProcessedGradeItem item2 = processedGradeItems.get(1); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 2\", item2.getItemTitle()); Assert.assertEquals(\"wrong status\", Status.MODIFIED, item2.getStatus()); final ProcessedGradeItem item3 = processedGradeItems.get(2); Assert.assertEquals(\"Incorrect title: \" + \"Assignment 3\", item3.getItemTitle()); Assert.assertEquals(\"wrong status\", Status.NEW, item3.getStatus()); final ProcessedGradeItem item4 = processedGradeItems.get(3); Assert.assertEquals(\"Incorrect title: \" + \"Assignment Ext\", item4.getItemTitle()); Assert.assertEquals(\"wrong status\", Status.EXTERNAL, item4.getStatus()); } "
    },
    {
        "test_src": "@Test public void testRequest()throws TwilioRestException { TwilioRestClient client = new TwilioRestClient(\"ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"); TwilioRestResponse response = client.request(\"/2010-04-01/Accounts.json\", \"GET\", null); assertEquals(401, response.getHttpStatus()); response = client.request(\"/2010-04-01\", \"GET\", null); assertEquals(200, response.getHttpStatus()); response = client.request(\"/asfhrhewhwejrkasyrey\", \"GET\", null); assertEquals(404, response.getHttpStatus()); } ",
        "focal_tgt": "public TwilioRestResponse request(String path, String method, Map < String, String > paramMap)throws TwilioRestException { List < NameValuePair > paramList = generateParameters(paramMap); return request(path, method, paramList); } ",
        "focal_src": "public TwilioRestResponse request(String path, String method, Map < String, String > vars)throws TwilioRestException { HttpUriRequest request = setupRequest(path, method, vars); HttpResponse response; try { response = httpclient.execute(request); HttpEntity entity = response.getEntity(); Header[]contentTypeHeaders = response.getHeaders(\"Content-Type\"); String responseBody = \"\"; if(entity != null) { responseBody = EntityUtils.toString(entity); } StatusLine status = response.getStatusLine(); int statusCode = status.getStatusCode(); TwilioRestResponse restResponse = new TwilioRestResponse(request.getURI().toString(), responseBody, statusCode); for(Header h : contentTypeHeaders) { restResponse.setContentType(h.getValue()); break; } return restResponse; } catch(ClientProtocolException e1) { throw new RuntimeException(e1); } catch(IOException e1) { throw new RuntimeException(e1); } } ",
        "test_tgt": "@Test public void testRequest()throws TwilioRestException { TwilioRestClient client = new TwilioRestClient(\"ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"); TwilioRestResponse response = client.request(\"/2010-04-01/Accounts.json\", \"GET\", (Map)null); assertEquals(401, response.getHttpStatus()); response = client.request(\"/2010-04-01\", \"GET\", (Map)null); assertEquals(200, response.getHttpStatus()); response = client.request(\"/asfhrhewhwejrkasyrey\", \"GET\", (Map)null); assertEquals(404, response.getHttpStatus()); } "
    },
    {
        "test_src": "@Test public void delete() { try { new RepoManager(context).delete(\"xyz\"); fail(\"Not installed package not detected.\"); } catch(final QueryException ex) { check(null, ex, BXRE_WHICH_X); } execute(new RepoInstall(REPO + \"pkg3.xar\", null)); assertTrue(context.repo.pkgDict().contains(token(PKG3ID))); final String pkg3Dir = normalize(PKG3ID); assertTrue(isDir(pkg3Dir)); assertTrue(isFile(pkg3Dir + \"/expath-pkg.xml\")); assertTrue(isDir(pkg3Dir + \"/pkg3\")); assertTrue(isDir(pkg3Dir + \"/pkg3/mod\")); assertTrue(isFile(pkg3Dir + \"/pkg3/mod/pkg3mod1.xql\")); execute(new RepoInstall(REPO + \"pkg4.xar\", null)); assertTrue(context.repo.pkgDict().contains(token(PKG4ID))); final String pkg4Dir = normalize(PKG4ID); assertTrue(isDir(pkg4Dir)); assertTrue(isFile(pkg4Dir + \"/expath-pkg.xml\")); assertTrue(isDir(pkg4Dir + \"/pkg4\")); assertTrue(isDir(pkg4Dir + \"/pkg4/mod\")); assertTrue(isFile(pkg4Dir + \"/pkg4/mod/pkg4mod1.xql\")); try { new RepoManager(context).delete(PKG3ID); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(null, ex, BXRE_DEP_X_X); } execute(new RepoDelete(PKG4, null)); assertFalse(context.repo.pkgDict().contains(token(PKG4ID))); assertFalse(isDir(pkg4Dir)); execute(new RepoDelete(PKG3ID, null)); assertFalse(context.repo.pkgDict().contains(token(PKG3ID))); assertFalse(isDir(pkg3Dir)); } ",
        "focal_tgt": "public void delete(final String name)throws QueryException { final EXPathRepo repo = context.repo; final ArrayList < Pkg > delete = new ArrayList < > (); for(final Pkg pkg : repo.pkgDict().values()) { if(pkg.name().equals(name) || pkg.id().equals(name)) { final String dep = primary(pkg); if(dep != null)throw BXRE_DEP_X_X.get(info, dep, name); delete.add(pkg); } } for(final Pkg pkg : delete) { repo.delete(pkg); final IOFile dir = repo.path(pkg.dir()); if( ! dir.delete())throw BXRE_DELETE_X.get(info, dir); } final IOFile file = find(name); if(file != null) { if( ! file.delete())throw BXRE_DELETE_X.get(info, file); return; } if(delete.isEmpty())throw BXRE_WHICH_X.get(info, name); } ",
        "focal_src": "public void delete(final String pkg)throws QueryException { boolean found = false; final Repo repo = context.repo; final TokenMap dict = repo.pkgDict(); final byte[]pp = token(pkg); for(final byte[]nextPkg : dict) { if(nextPkg == null)continue; if(eq(nextPkg, pp) || eq(Package.name(nextPkg), pp)) { final byte[]primPkg = primary(nextPkg); if(primPkg != null)throw BXRE_DEP_X_X.get(info, string(primPkg), pkg); final IOFile f = repo.path(string(dict.get(nextPkg))); repo.delete(new PkgParser(info).parse(new IOFile(f, DESCRIPTOR))); if( ! f.delete())throw BXRE_DELETE_X.get(info, f); found = true; } } final IOFile file = file(pkg, repo); if(file != null) { if( ! file.delete())throw BXRE_DELETE_X.get(info, file); return; } if( ! found)throw BXRE_WHICH_X.get(info, pkg); } ",
        "test_tgt": "@Test public void delete() { try { new RepoManager(context).delete(\"xyz\"); fail(\"Not installed package not detected.\"); } catch(final QueryException ex) { check(null, ex, BXRE_WHICH_X); } execute(new RepoInstall(REPO + \"pkg3.xar\", null)); assertTrue(context.repo.pkgDict().containsKey(PKG3ID)); final String pkg3Dir = normalize(PKG3ID); assertTrue(isDir(pkg3Dir)); assertTrue(isFile(pkg3Dir + \"/expath-pkg.xml\")); assertTrue(isDir(pkg3Dir + \"/pkg3\")); assertTrue(isDir(pkg3Dir + \"/pkg3/mod\")); assertTrue(isFile(pkg3Dir + \"/pkg3/mod/pkg3mod1.xql\")); execute(new RepoInstall(REPO + \"pkg4.xar\", null)); assertTrue(context.repo.pkgDict().containsKey(PKG4ID)); final String pkg4Dir = normalize(PKG4ID); assertTrue(isDir(pkg4Dir)); assertTrue(isFile(pkg4Dir + \"/expath-pkg.xml\")); assertTrue(isDir(pkg4Dir + \"/pkg4\")); assertTrue(isDir(pkg4Dir + \"/pkg4/mod\")); assertTrue(isFile(pkg4Dir + \"/pkg4/mod/pkg4mod1.xql\")); try { new RepoManager(context).delete(PKG3ID); fail(\"Package involved in a dependency was deleted.\"); } catch(final QueryException ex) { check(null, ex, BXRE_DEP_X_X); } execute(new RepoDelete(PKG4, null)); assertFalse(context.repo.pkgDict().containsKey(PKG4ID)); assertFalse(isDir(pkg4Dir)); execute(new RepoDelete(PKG3ID, null)); assertFalse(context.repo.pkgDict().containsKey(PKG3ID)); assertFalse(isDir(pkg3Dir)); } "
    },
    {
        "test_src": "@Test public void testGetSupportedExtensions() { ArchiveAnalyzer instance = new ArchiveAnalyzer(); Set < String > expResult = new HashSet < String > (); expResult.add(\"zip\"); expResult.add(\"war\"); expResult.add(\"ear\"); expResult.add(\"jar\"); expResult.add(\"sar\"); expResult.add(\"apk\"); expResult.add(\"nupkg\"); expResult.add(\"tar\"); expResult.add(\"gz\"); expResult.add(\"tgz\"); Set result = instance.getSupportedExtensions(); assertEquals(expResult, result); } ",
        "focal_tgt": "protected abstract FileFilter getFileFilter(); ",
        "focal_src": "protected abstract Set < String > getSupportedExtensions(); ",
        "test_tgt": "@Test public void testSupportsExtensions() { ArchiveAnalyzer instance = new ArchiveAnalyzer(); Set < String > expResult = new HashSet < String > (); expResult.add(\"zip\"); expResult.add(\"war\"); expResult.add(\"ear\"); expResult.add(\"jar\"); expResult.add(\"sar\"); expResult.add(\"apk\"); expResult.add(\"nupkg\"); expResult.add(\"tar\"); expResult.add(\"gz\"); expResult.add(\"tgz\"); for(String ext : expResult) { assertTrue(ext, instance.accept(new File(\"test.\" + ext))); } } "
    },
    {
        "test_src": "@Test public void testCapitalize() { assert \"Bob\".equals(StringUtils.capitalize(\"bob\")); assert \"Bob\".equals(StringUtils.capitalize(\"BOB\")); assert \"Bob\".equals(StringUtils.capitalize(\"bOB\")); assert \"Bob\".equals(StringUtils.capitalize(\"bOB\")); assert \"Bob servant\".equals(StringUtils.capitalize(\"Bob Servant\")); assert \"B\".equals(StringUtils.capitalize(\"b\")); assert \"\".equals(StringUtils.capitalize(\"\")); assert \"\".equals(StringUtils.capitalize(null)); assert \"7\".equals(StringUtils.capitalize(\"7\")); } ",
        "focal_tgt": "public static String capitalize(String s) { if(s == null || s.isEmpty())return \"\"; StringBuilder out; out = new StringBuilder(s.length()); out.append(Character.toUpperCase(s.charAt(0))); if(s.length() > 1)out.append(s.substring(1).toLowerCase()); return out.toString(); } ",
        "focal_src": "public static String capitalize(String s) { if(s == null || s.equals(\"\"))return \"\"; String capedS = \"\" + Character.toUpperCase(s.charAt(0)); int len = s.length(); if(len > 1)capedS += s.substring(1, len).toLowerCase(); return capedS; } ",
        "test_tgt": "@Test(dataProvider = \"capitalize\")public void testCapitalize(String input, String expected) { assert expected.equals(StringUtils.capitalize(input)); } "
    },
    {
        "test_src": "@Test public void matchUdpSrcTest() { Criterion criterion = Criteria.matchUdpSrc(40000); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result, matchesCriterion(criterion)); } ",
        "focal_tgt": "@Deprecated Builder matchUdpSrc(short udpPort); ",
        "focal_src": "Builder matchUdpSrc(short udpPort); ",
        "test_tgt": "@Test public void matchUdpSrcTest() { Criterion criterion = Criteria.matchUdpSrc(tpPort); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result, matchesCriterion(criterion)); } "
    },
    {
        "test_src": "@Test public void testGet() { BytesRef ref = new BytesRef(); BytesRef scratch = new BytesRef(); int num = atLeast(2); for(int j = 0; j < num; j ++ ) { Map < String, Integer > strings = new HashMap < > (); int uniqueCount = 0; for(int i = 0; i < 797; i ++ ) { String str; do { str = TestUtil.randomRealisticUnicodeString(random(), 1000); } while(str.length() == 0); ref.copyChars(str); int count = hash.size(); int key = hash.add(ref); if(key >= 0) { assertNull(strings.put(str, Integer.valueOf(key))); assertEquals(uniqueCount, key); uniqueCount ++ ; assertEquals(hash.size(), count + 1); } else { assertTrue(( - key) - 1 < count); assertEquals(hash.size(), count); } } for(Entry < String, Integer > entry : strings.entrySet()) { ref.copyChars(entry.getKey()); assertEquals(ref, hash.get(entry.getValue().intValue(), scratch)); } hash.clear(); assertEquals(0, hash.size()); hash.reinit(); } } ",
        "focal_tgt": "public BytesRef get(BytesRefBuilder spare, int index) { if(lastElement > index) { int offset = offsets[index]; int length = index == lastElement - 1 ? currentOffset - offset : offsets[index + 1] - offset; spare.grow(length); spare.setLength(length); pool.readBytes(offset, spare.bytes(), 0, spare.length()); return spare.get(); } throw new IndexOutOfBoundsException(\"index \" + index + \" must be less than the size: \" + lastElement); } ",
        "focal_src": "public BytesRef get(BytesRef spare, int index) { if(lastElement > index) { int offset = offsets[index]; int length = index == lastElement - 1 ? currentOffset - offset : offsets[index + 1] - offset; assert spare.offset == 0; spare.grow(length); spare.length = length; pool.readBytes(offset, spare.bytes, spare.offset, spare.length); return spare; } throw new IndexOutOfBoundsException(\"index \" + index + \" must be less than the size: \" + lastElement); } ",
        "test_tgt": "@Test public void testGet() { BytesRefBuilder ref = new BytesRefBuilder(); BytesRef scratch = new BytesRef(); int num = atLeast(2); for(int j = 0; j < num; j ++ ) { Map < String, Integer > strings = new HashMap < > (); int uniqueCount = 0; for(int i = 0; i < 797; i ++ ) { String str; do { str = TestUtil.randomRealisticUnicodeString(random(), 1000); } while(str.length() == 0); ref.copyChars(str); int count = hash.size(); int key = hash.add(ref.get()); if(key >= 0) { assertNull(strings.put(str, Integer.valueOf(key))); assertEquals(uniqueCount, key); uniqueCount ++ ; assertEquals(hash.size(), count + 1); } else { assertTrue(( - key) - 1 < count); assertEquals(hash.size(), count); } } for(Entry < String, Integer > entry : strings.entrySet()) { ref.copyChars(entry.getKey()); assertEquals(ref.get(), hash.get(entry.getValue().intValue(), scratch)); } hash.clear(); assertEquals(0, hash.size()); hash.reinit(); } } "
    },
    {
        "test_src": "@Test public void writeTextLines() { error(_FILE_WRITE_TEXT_LINES.args(PATH, \"x\"), Err.FILE_DIR); error(_FILE_WRITE_TEXT_LINES.args(PATH1, \" 123\"), Err.INVCAST); query(_FILE_WRITE_TEXT_LINES.args(PATH1, \"x\")); query(_FILE_SIZE.args(PATH1), 1 + Prop.NL.length()); query(_FILE_WRITE_TEXT_LINES.args(PATH1, \"\", \"US-ASCII\")); query(_FILE_READ_TEXT_LINES.args(PATH1), \"?\"); query(_FILE_DELETE.args(PATH1)); } ",
        "focal_tgt": "private synchronized Item writeTextLines(final boolean append, final QueryContext ctx)throws QueryException, IOException { final File path = check(checkFile(0, ctx)); final Iter ir = expr[1].iter(ctx); final String enc = encoding(2, FILE_UE, ctx); final Charset cs = enc == null || enc == UTF8 ? null : Charset.forName(enc); final PrintOutput out = PrintOutput.get(new FileOutputStream(path, append)); try { for(Item it; (it = ir.next()) != null; ) { if( ! it.type.isStringOrUntyped())throw Err.typeError(this, AtomType.STR, it); final byte[]s = it.string(info); out.write(cs == null ? s : string(s).getBytes(cs)); out.write(cs == null ? NL : Prop.NL.getBytes(cs)); } } finally { out.close(); } return null; } ",
        "focal_src": "private synchronized Item writeTextLines(final boolean append, final QueryContext ctx)throws QueryException, IOException { final File path = check(checkFile(0, ctx)); final Iter ir = expr[1].iter(ctx); final String enc = encoding(2, FILE_ENCODING, ctx); final Charset cs = enc == null || enc == UTF8 ? null : Charset.forName(enc); final PrintOutput out = PrintOutput.get(new FileOutputStream(path, append)); try { for(Item it; (it = ir.next()) != null; ) { if( ! it.type.isStringOrUntyped())throw Err.typeError(this, AtomType.STR, it); final byte[]s = it.string(info); out.write(cs == null ? s : string(s).getBytes(cs)); out.write(cs == null ? NL : Prop.NL.getBytes(cs)); } } finally { out.close(); } return null; } ",
        "test_tgt": "@Test public void writeTextLines() { error(_FILE_WRITE_TEXT_LINES.args(PATH, \"x\"), Err.FILE_ID); error(_FILE_WRITE_TEXT_LINES.args(PATH1, \" 123\"), Err.INVCAST); query(_FILE_WRITE_TEXT_LINES.args(PATH1, \"x\")); query(_FILE_SIZE.args(PATH1), 1 + Prop.NL.length()); query(_FILE_WRITE_TEXT_LINES.args(PATH1, \"\", \"US-ASCII\")); query(_FILE_READ_TEXT_LINES.args(PATH1), \"?\"); query(_FILE_DELETE.args(PATH1)); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should unvoid the orders and encounters associated with the patient\", method = \"handle(Patient,User,Date,String)\")public void handle_shouldUnvoidTheOrdersAndEncountersAssociatedWithThePatient()throws Exception { Patient patient = Context.getPatientService().getPatient(7); patient = Context.getPatientService().voidPatient(patient, \"Void Reason\"); Assert.assertTrue(patient.isVoided()); EncounterService es = Context.getEncounterService(); List < Encounter > encounters = es.getEncounters(patient, null, null, null, null, null, null, true); Assert.assertTrue(CollectionUtils.isNotEmpty(encounters)); for(Encounter encounter : encounters) { Assert.assertTrue(encounter.isVoided()); Assert.assertNotNull(encounter.getDateVoided()); Assert.assertNotNull(encounter.getVoidedBy()); Assert.assertNotNull(encounter.getVoidReason()); } OrderService os = Context.getOrderService(); List < Patient > patients = new ArrayList < Patient > (); patients.add(patient); List < Order > orders = os.getOrders(Order.class, patients, null, null, null); Assert.assertTrue(CollectionUtils.isNotEmpty(orders)); for(Order order : orders) { Assert.assertTrue(order.isVoided()); Assert.assertNotNull(order.getDateVoided()); Assert.assertNotNull(order.getVoidedBy()); Assert.assertNotNull(order.getVoidReason()); } User user = Context.getUserService().getUser(1); new PatientDataUnvoidHandler().handle(patient, user, patient.getDateVoided(), null); for(Encounter encounter : encounters) { Assert.assertFalse(encounter.isVoided()); Assert.assertNull(encounter.getDateVoided()); Assert.assertNull(encounter.getVoidedBy()); Assert.assertNull(encounter.getVoidReason()); } for(Order order : orders) { Assert.assertFalse(order.isVoided()); Assert.assertNull(order.getDateVoided()); Assert.assertNull(order.getVoidedBy()); Assert.assertNull(order.getVoidReason()); } } ",
        "focal_tgt": "@Override public void handle(Patient patient, User voidingUser, Date voidedDate, String voidReason) { EncounterService es = Context.getEncounterService(); List < Encounter > encounters = es.getEncountersByPatient(patient); if(CollectionUtils.isNotEmpty(encounters)) { for(Encounter encounter : encounters) { if( ! encounter.isVoided()) { encounter.setDateVoided(patient.getDateVoided()); es.voidEncounter(encounter, voidReason); } } } OrderService os = Context.getOrderService(); List < Patient > patients = new ArrayList < Patient > (); patients.add(patient); List < Order > orders = os.getOrders(null, patients, null, null, null); if(CollectionUtils.isNotEmpty(orders)) { for(Order order : orders) { if( ! order.isVoided()) { order.setDateVoided(patient.getDateVoided()); os.voidOrder(order, voidReason); } } } } ",
        "focal_src": "@Override public void handle(Patient patient, User voidingUser, Date voidedDate, String voidReason) { EncounterService es = Context.getEncounterService(); List < Encounter > encounters = es.getEncountersByPatient(patient); if(CollectionUtils.isNotEmpty(encounters)) { for(Encounter encounter : encounters) { if( ! encounter.isVoided()) { encounter.setDateVoided(patient.getDateVoided()); es.voidEncounter(encounter, voidReason); } } } OrderService os = Context.getOrderService(); List < Patient > patients = new ArrayList < Patient > (); patients.add(patient); List < Order > orders = os.getOrders(Order.class, patients, null, null, null); if(CollectionUtils.isNotEmpty(orders)) { for(Order order : orders) { if( ! order.isVoided()) { order.setDateVoided(patient.getDateVoided()); os.voidOrder(order, voidReason); } } } } ",
        "test_tgt": "@Test@Verifies(value = \"should unvoid the orders and encounters associated with the patient\", method = \"handle(Patient,User,Date,String)\")public void handle_shouldUnvoidTheOrdersAndEncountersAssociatedWithThePatient()throws Exception { Patient patient = Context.getPatientService().getPatient(7); patient = Context.getPatientService().voidPatient(patient, \"Void Reason\"); Assert.assertTrue(patient.isVoided()); EncounterService es = Context.getEncounterService(); List < Encounter > encounters = es.getEncounters(patient, null, null, null, null, null, null, true); Assert.assertTrue(CollectionUtils.isNotEmpty(encounters)); for(Encounter encounter : encounters) { Assert.assertTrue(encounter.isVoided()); Assert.assertNotNull(encounter.getDateVoided()); Assert.assertNotNull(encounter.getVoidedBy()); Assert.assertNotNull(encounter.getVoidReason()); } OrderService os = Context.getOrderService(); List < Patient > patients = new ArrayList < Patient > (); patients.add(patient); List < Order > orders = os.getOrders(null, patients, null, null, null); Assert.assertTrue(CollectionUtils.isNotEmpty(orders)); for(Order order : orders) { Assert.assertTrue(order.isVoided()); Assert.assertNotNull(order.getDateVoided()); Assert.assertNotNull(order.getVoidedBy()); Assert.assertNotNull(order.getVoidReason()); } User user = Context.getUserService().getUser(1); new PatientDataUnvoidHandler().handle(patient, user, patient.getDateVoided(), null); for(Encounter encounter : encounters) { Assert.assertFalse(encounter.isVoided()); Assert.assertNull(encounter.getDateVoided()); Assert.assertNull(encounter.getVoidedBy()); Assert.assertNull(encounter.getVoidReason()); } for(Order order : orders) { Assert.assertFalse(order.isVoided()); Assert.assertNull(order.getDateVoided()); Assert.assertNull(order.getVoidedBy()); Assert.assertNull(order.getVoidReason()); } } "
    },
    {
        "test_src": "@Test public void testDeriveSecret() { String macAlgorithm = HKDFAlgorithm.TLS_HKDF_SHA256.getMacAlgorithm().getJavaName(); byte[]prk = ArrayConverter.hexStringToByteArray(\"31168cad69862a80c6f6bfd42897d0fe23c406a12e652a8d3ae4217694f49844\"); byte[]hashValue = ArrayConverter.hexStringToByteArray(\"52c04472bdfe929772c98b91cf425f78f47659be9d4a7d68b9e29d162935e9b9\"); String labelIn = \"client handshake traffic secret\"; byte[]result = HKDFunction.deriveSecret(macAlgorithm, prk, labelIn, hashValue); byte[]resultCorrect = ArrayConverter.hexStringToByteArray(\"6c6f274b1eae09b8bbd2039b7eb56147201a5e19288a3fd504fa52b1178a6e93\"); assertArrayEquals(result, resultCorrect); } ",
        "focal_tgt": "public static byte[]deriveSecret(String macAlgorithm, String hashAlgorithm, byte[]prk, String labelIn, byte[]toHash) { try { MessageDigest hashFunction = MessageDigest.getInstance(hashAlgorithm); hashFunction.update(toHash); byte[]hashValue = hashFunction.digest(); int outLen = Mac.getInstance(macAlgorithm).getMacLength(); return expandLabel(macAlgorithm, prk, labelIn, hashValue, outLen); } catch(NoSuchAlgorithmException ex) { throw new CryptoException(\"Could not initialize HKDF\", ex); } } ",
        "focal_src": "public static byte[]deriveSecret(String macAlgorithm, byte[]prk, String labelIn, byte[]hashValue) { try { int outLen = Mac.getInstance(macAlgorithm).getMacLength(); byte[]info = labelEncoder(hashValue, labelIn, outLen); byte[]result = expand(macAlgorithm, prk, info, outLen); return result; } catch(NoSuchAlgorithmException ex) { throw new CryptoException(\"Could not initialize HKDF\", ex); } } ",
        "test_tgt": "@Test public void testDeriveSecret() { String macAlgorithm = HKDFAlgorithm.TLS_HKDF_SHA256.getMacAlgorithm().getJavaName(); String hashAlgorithm = DigestAlgorithm.SHA256.getJavaName(); byte[]prk = ArrayConverter.hexStringToByteArray(\"33AD0A1C607EC03B09E6CD9893680CE210ADF300AA1F2660E1B22E10F170F92A\"); byte[]toHash = ArrayConverter.hexStringToByteArray(\"\"); String labelIn = HKDFunction.DERIVED; byte[]result = HKDFunction.deriveSecret(macAlgorithm, hashAlgorithm, prk, labelIn, toHash); byte[]resultCorrect = ArrayConverter.hexStringToByteArray(\"6F2615A108C702C5678F54FC9DBAB69716C076189C48250CEBEAC3576C3611BA\"); assertArrayEquals(result, resultCorrect); } "
    },
    {
        "test_src": "@Test(enabled = false, testName = \"PUT /vApp/{id}/media/action/insertMedia\", dependsOnMethods = { \"testGetVApp\" })public void testInsertMedia() { MediaInsertOrEjectParams params = MediaInsertOrEjectParams.builder().build(); Task insertMedia = vAppClient.insertMedia(vApp.getHref(), params); assertTrue(retryTaskSuccess.apply(insertMedia), String.format(TASK_COMPLETE_TIMELY, \"insertMedia\")); } ",
        "focal_tgt": "@POST@Path(\"/media/action/insertMedia\")@Produces(MEDIA_PARAMS)@Consumes(TASK)@JAXBResponseParser@ExceptionParser(ThrowVCloudErrorOn4xx.class)ListenableFuture < Task > insertMedia(@EndpointParam URI vAppURI, @BinderParam(BindToXMLPayload.class)MediaInsertOrEjectParams mediaParams); ",
        "focal_src": "@POST@Path(\"/media/action/insertMedia\")@Consumes(VCloudDirectorMediaType.TASK)@JAXBResponseParser@ExceptionParser(ThrowVCloudErrorOn4xx.class)ListenableFuture < Task > insertMedia(@EndpointParam URI vAppURI, @BinderParam(BindToXMLPayload.class)MediaInsertOrEjectParams mediaParams); ",
        "test_tgt": "@Test(enabled = false, testName = \"PUT /vApp/{id}/media/action/insertMedia\", dependsOnMethods = { \"testGetVApp\" })public void testInsertMedia() { MediaInsertOrEjectParams params = MediaInsertOrEjectParams.builder().media(Reference.builder().href(mediaURI).type(MEDIA).build()).build(); Task insertMedia = vAppClient.insertMedia(vApp.getHref(), params); assertTrue(retryTaskSuccess.apply(insertMedia), String.format(TASK_COMPLETE_TIMELY, \"insertMedia\")); } "
    },
    {
        "test_src": "@Test public void installJar()throws Exception { execute(new RepoInstall(REPO + \"testJar.xar\", null)); final String dir = normalize(\"jarPkg-1.0.0\"); assertTrue(isDir(dir)); assertTrue(isFile(dir + \"/expath-pkg.xml\")); assertTrue(isFile(dir + \"/basex.xml\")); assertTrue(isDir(dir + \"/jar\")); assertTrue(isFile(dir + \"/jar/test.jar\")); assertTrue(isFile(dir + \"/jar/wrapper.xq\")); try(QueryProcessor qp = new QueryProcessor(\"import module namespace j='jar'; j:print('test')\", context)) { assertEquals(qp.value().serialize().toString(), \"test\"); } assertTrue(\"Repo directory could not be deleted.\", new IOFile(REPO, dir).delete()); assertFalse(new IOFile(REPO, dir).exists()); } ",
        "focal_tgt": "private boolean installJAR(final byte[]content, final String path)throws QueryException, IOException { final IOContent manifest = new IOContent(new Zip(new IOContent(content)).read(MANIFEST_MF)); final NewlineInput nli = new NewlineInput(manifest); for(String s; (s = nli.readLine()) != null; ) { final Matcher main = MAIN_CLASS.matcher(s); if(main.find())return write(main.group(1).replace('.', '/') + IO.JARSUFFIX, content); } throw BXRE_MAIN_X.get(info, path); } ",
        "focal_src": "private boolean installJAR(final byte[]content, final String path)throws QueryException, IOException { final IOContent mf = new IOContent(new Zip(new IOContent(content)).read(MANIFEST_MF)); final NewlineInput nli = new NewlineInput(mf); for(String s; (s = nli.readLine()) != null; ) { final Matcher m = MAIN_CLASS.matcher(s); if(m.find())return write(m.group(1).replace('.', '/') + IO.JARSUFFIX, content); } throw BXRE_MAIN_X.get(info, path); } ",
        "test_tgt": "@Test public void installJar() { execute(new RepoInstall(REPO + \"Hello.jar\", null)); final IOFile jar = new IOFile(REPO, \"org/basex/modules/Hello.jar\"); final IOFile xqm = new IOFile(REPO, \"org/basex/modules/Hello.xqm\"); assertTrue(\"File not found: \" + jar, jar.exists()); assertTrue(\"File not found: \" + xqm, xqm.exists()); String query = \"import module namespace h='http://basex.org/modules/Hello';h:hello('Universe')\"; assertEquals(\"Hello Universe\", execute(new XQuery(query))); query = \"import module namespace h='http://basex.org/modules/Hello';h:hello(123)\"; try(QueryProcessor qp = new QueryProcessor(query, context)) { qp.value(); } catch(final QueryException ex) { assertEquals(QueryError.INVPROMOTE_X, ex.error()); } execute(new RepoDelete(\"org.basex.modules.Hello\", null)); assertFalse(\"File was not deleted:\" + jar, jar.exists()); assertFalse(\"File was not deleted:\" + xqm, xqm.exists()); try { new RepoDelete(\"org.basex.modules.Hello\", null).execute(context); } catch(final BaseXException ex) { assertTrue(ex.toString().contains(BXRE_WHICH_X.code)); } } "
    },
    {
        "test_src": "@Test public void testRemoveProperty() { String key = \"SomeKey\"; String value = \"value\"; String dfault = \"default\"; Settings.setString(key, value); String ret = Settings.getString(key); Assert.assertEquals(value, ret); Settings.removeProperty(key); ret = Settings.getString(key, dfault); Assert.assertEquals(dfault, ret); } ",
        "focal_tgt": "public void removeProperty(String key) { props.remove(key); } ",
        "focal_src": "public static void removeProperty(String key) { LOCAL_SETTINGS.get().props.remove(key); } ",
        "test_tgt": "@Test public void testRemoveProperty() { String key = \"SomeKey\"; String value = \"value\"; String dfault = \"default\"; getSettings().setString(key, value); String ret = getSettings().getString(key); Assert.assertEquals(value, ret); getSettings().removeProperty(key); ret = getSettings().getString(key, dfault); Assert.assertEquals(dfault, ret); } "
    },
    {
        "test_src": "@Test public void testReplenishConnections() { connectionTracker = new ConnectionTracker(routerConfig.routerScalingUnitMaxConnectionsPerPortPlainText, routerConfig.routerScalingUnitMaxConnectionsPerPortSsl); int minActiveConnectionsCount = 0; int totalConnectionsCount = 0; int availableCount = 0; MockDataNodeId dataNodeId1 = new MockDataNodeId(\"host1\", Collections.singletonList(plainTextPort), Collections.emptyList(), \"DC1\"); MockDataNodeId dataNodeId2 = new MockDataNodeId(\"host2\", Arrays.asList(plainTextPort, sslPort), Collections.emptyList(), \"DC1\"); dataNodeId2.setSslEnabledDataCenters(Collections.singletonList(\"DC1\")); connectionTracker.setMinimumActiveConnectionsPercentage(dataNodeId1, 50); minActiveConnectionsCount += 50 * routerConfig.routerScalingUnitMaxConnectionsPerPortPlainText / 100; connectionTracker.setMinimumActiveConnectionsPercentage(dataNodeId2, 200); minActiveConnectionsCount += routerConfig.routerScalingUnitMaxConnectionsPerPortSsl; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection); totalConnectionsCount += minActiveConnectionsCount; assertCounts(totalConnectionsCount, availableCount); List < String > newConnections = getNewlyEstablishedConnections(); newConnections.forEach(connectionTracker :: checkInConnection); availableCount += minActiveConnectionsCount; assertCounts(totalConnectionsCount, availableCount); Assert.assertTrue(connectionTracker.mayCreateNewConnection(\"host1\", plainTextPort, dataNodeId1)); Assert.assertFalse(connectionTracker.mayCreateNewConnection(\"host2\", sslPort, dataNodeId2)); newConnections.stream().limit(2).forEach(connectionTracker :: removeConnection); totalConnectionsCount -= 2; availableCount -= 2; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection); totalConnectionsCount += 2; assertCounts(totalConnectionsCount, availableCount); newConnections = getNewlyEstablishedConnections(); newConnections.forEach(connectionTracker :: checkInConnection); availableCount += 2; assertCounts(totalConnectionsCount, availableCount); String conn1 = connectionTracker.checkOutConnection(\"host1\", plainTextPort, dataNodeId1); Assert.assertNotNull(conn1); String conn2 = connectionTracker.checkOutConnection(\"host2\", sslPort, dataNodeId2); Assert.assertNotNull(conn2); availableCount -= 2; assertCounts(totalConnectionsCount, availableCount); connectionTracker.removeConnection(conn1); connectionTracker.checkInConnection(conn2); totalConnectionsCount -= 1; availableCount += 1; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection); totalConnectionsCount += 1; assertCounts(totalConnectionsCount, availableCount); } ",
        "focal_tgt": "int replenishConnections(ConnectionFactory connectionFactory, int maxNewConnectionsPerHost) { int newConnections = 0; Iterator < HostPortPoolManager > iter = poolManagersBelowMinActiveConnections.iterator(); while(iter.hasNext()) { HostPortPoolManager poolManager = iter.next(); try { if(poolManager.dataNodeId.getState() == HardwareState.AVAILABLE) { int newConnectionsToHost = 0; while(newConnectionsToHost < maxNewConnectionsPerHost && ! poolManager.hasMinActiveConnections()) { String connId = connectionFactory.connect(poolManager.host, poolManager.port); poolManager.incrementPoolCount(); connectionIdToPoolManager.put(connId, poolManager); totalManagedConnectionsCount ++ ; newConnections ++ ; newConnectionsToHost ++ ; } if(poolManager.hasMinActiveConnections()) { iter.remove(); } } } catch(IOException e) { LOGGER.warn(\"Encountered exception while replenishing connections to {}:{}.\", poolManager.host, poolManager.port.getPort(), e); } } return newConnections; } ",
        "focal_src": "int replenishConnections(ConnectionFactory connectionFactory) { int connectionsInitiated = 0; Iterator < HostPortPoolManager > iter = poolManagersBelowMinActiveConnections.iterator(); while(iter.hasNext()) { HostPortPoolManager poolManager = iter.next(); try { if(poolManager.dataNodeId.getState() == HardwareState.AVAILABLE) { while( ! poolManager.hasMinActiveConnections()) { String connId = connectionFactory.connect(poolManager.host, poolManager.port); poolManager.incrementPoolCount(); connectionIdToPoolManager.put(connId, poolManager); totalManagedConnectionsCount ++ ; connectionsInitiated ++ ; } iter.remove(); } } catch(IOException e) { LOGGER.warn(\"Encountered exception while replenishing connections to {}:{}.\", poolManager.host, poolManager.port.getPort(), e); } } return connectionsInitiated; } ",
        "test_tgt": "@Test public void testReplenishConnections() { connectionTracker = new ConnectionTracker(routerConfig.routerScalingUnitMaxConnectionsPerPortPlainText, routerConfig.routerScalingUnitMaxConnectionsPerPortSsl); int minActiveConnectionsCount = 0; int totalConnectionsCount = 0; int availableCount = 0; MockDataNodeId dataNodeId1 = new MockDataNodeId(\"host1\", Collections.singletonList(plainTextPort), Collections.emptyList(), \"DC1\"); MockDataNodeId dataNodeId2 = new MockDataNodeId(\"host2\", Arrays.asList(plainTextPort, sslPort), Collections.emptyList(), \"DC1\"); dataNodeId2.setSslEnabledDataCenters(Collections.singletonList(\"DC1\")); connectionTracker.setMinimumActiveConnectionsPercentage(dataNodeId1, 50); minActiveConnectionsCount += 50 * routerConfig.routerScalingUnitMaxConnectionsPerPortPlainText / 100; connectionTracker.setMinimumActiveConnectionsPercentage(dataNodeId2, 200); minActiveConnectionsCount += routerConfig.routerScalingUnitMaxConnectionsPerPortSsl; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection, Integer.MAX_VALUE); totalConnectionsCount += minActiveConnectionsCount; assertCounts(totalConnectionsCount, availableCount); List < String > newConnections = getNewlyEstablishedConnections(); newConnections.forEach(connectionTracker :: checkInConnection); availableCount += minActiveConnectionsCount; assertCounts(totalConnectionsCount, availableCount); Assert.assertTrue(connectionTracker.mayCreateNewConnection(\"host1\", plainTextPort, dataNodeId1)); Assert.assertFalse(connectionTracker.mayCreateNewConnection(\"host2\", sslPort, dataNodeId2)); newConnections.stream().limit(2).forEach(connectionTracker :: removeConnection); totalConnectionsCount -= 2; availableCount -= 2; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection, Integer.MAX_VALUE); totalConnectionsCount += 2; assertCounts(totalConnectionsCount, availableCount); newConnections = getNewlyEstablishedConnections(); newConnections.forEach(connectionTracker :: checkInConnection); availableCount += 2; assertCounts(totalConnectionsCount, availableCount); String conn1 = connectionTracker.checkOutConnection(\"host1\", plainTextPort, dataNodeId1); Assert.assertNotNull(conn1); String conn2 = connectionTracker.checkOutConnection(\"host2\", sslPort, dataNodeId2); Assert.assertNotNull(conn2); availableCount -= 2; assertCounts(totalConnectionsCount, availableCount); connectionTracker.removeConnection(conn1); connectionTracker.checkInConnection(conn2); totalConnectionsCount -= 1; availableCount += 1; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection, Integer.MAX_VALUE); totalConnectionsCount += 1; assertCounts(totalConnectionsCount, availableCount); String connId; while((connId = connectionTracker.checkOutConnection(\"host2\", sslPort, dataNodeId2)) != null) { connectionTracker.removeConnection(connId); } totalConnectionsCount -= 2; availableCount -= 2; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection, 1); totalConnectionsCount += 1; assertCounts(totalConnectionsCount, availableCount); connectionTracker.replenishConnections(this :: mockNewConnection, 1); totalConnectionsCount += 1; assertCounts(totalConnectionsCount, availableCount); } "
    },
    {
        "test_src": "@Test public void test_buildAddressString_0080_EscapeBrackets() { final I_C_Location location = prepareLocation(\"addr1\", \"addr2\", null, null, \"City1\", \"Region1\", \"121212\", \"\", prepareCountry(\"Country1\", \"@A1@ @A2@ @P@ @C@ \\\\(Region @R@\\\\) @CO@\")); boolean isLocalAddress = false; final String bPartnerBlock = null; final String userBlock = null; Assert.assertEquals(\"addr1\\naddr2\\n121212 City1\\n(Region Region1) Country1\", builder.setLanguage(\"de_CH\").buildAddressString(location, isLocalAddress, bPartnerBlock, userBlock)); isLocalAddress = true; Assert.assertEquals(\"LOCAL: addr1\\naddr2\\n121212 City1\\n(Region Region1) Country1\", builder.setLanguage(\"de_CH\").buildAddressString(location, isLocalAddress, bPartnerBlock, userBlock)); } ",
        "focal_tgt": "public String buildAddressString(final I_C_Location location, final boolean isLocalAddress, final String bPartnerBlock, final String userBlock) { final CountryId countryId = CountryId.ofRepoId(location.getC_Country_ID()); final I_C_Country country = countriesRepo.getById(countryId); final String displaySequence = getDisplaySequence(country, isLocalAddress); String inStr = displaySequence; final StringBuilder outStr = new StringBuilder(); final List < String > bracketsTxt = extractBracketsString(inStr); for(final String s : bracketsTxt) { Check.assume(s.startsWith(\"(\") || s.startsWith(\"\\\\(\"), \"Expected brackets or escaped brackets!\"); Check.assume(s.endsWith(\")\") || s.endsWith(\"\\\\)\"), \"Expected brackets or escaped brackets!\"); String in = new String(s); final StringBuilder out = new StringBuilder(); if(s.startsWith(\"(\")) { in = in.substring(1, s.length() - 1); replaceAddrToken(location, isLocalAddress, in, out, bPartnerBlock, userBlock, true); } else if(s.startsWith(\"\\\\(\")) { in = in.substring(1, in.length() - 2).concat(\")\"); replaceAddrToken(location, isLocalAddress, in, out, bPartnerBlock, userBlock, false); } if(out.length() == 0) { inStr = inStr.replace(s.concat(\" \"), out.toString()); } else { if(out.lastIndexOf(\"\\n\") == out.length() - 1) { inStr = inStr.replace(s + \" \", out.toString()); } else { inStr = inStr.replace(s, out.toString()); } } } replaceAddrToken(location, isLocalAddress, inStr, outStr, bPartnerBlock, userBlock, false); final String retValue = StringUtils.replace(outStr.toString().trim(), \"\\\\n\", \"\\n\"); return retValue; } ",
        "focal_src": "public String buildAddressString(final I_C_Location location, boolean isLocalAddress, String bPartnerBlock, String userBlock) { final String displaySequence = getDisplaySequence(location.getC_Country(), isLocalAddress); String inStr = displaySequence; final StringBuilder outStr = new StringBuilder(); final List < String > bracketsTxt = extractBracketsString(inStr); for(final String s : bracketsTxt) { Check.assume(s.startsWith(\"(\") || s.startsWith(\"\\\\(\"), \"Expected brackets or escaped brackets!\"); Check.assume(s.endsWith(\")\") || s.endsWith(\"\\\\)\"), \"Expected brackets or escaped brackets!\"); String in = new String(s); final StringBuilder out = new StringBuilder(); if(s.startsWith(\"(\")) { in = in.substring(1, s.length() - 1); replaceAddrToken(location, isLocalAddress, in, out, bPartnerBlock, userBlock, true); } else if(s.startsWith(\"\\\\(\")) { in = in.substring(1, in.length() - 2).concat(\")\"); replaceAddrToken(location, isLocalAddress, in, out, bPartnerBlock, userBlock, false); } if(out.length() == 0) { inStr = inStr.replace(s.concat(\" \"), out.toString()); } else { if(out.lastIndexOf(\"\\n\") == out.length() - 1) { inStr = inStr.replace(s + \" \", out.toString()); } else { inStr = inStr.replace(s, out.toString()); } } } replaceAddrToken(location, isLocalAddress, inStr, outStr, bPartnerBlock, userBlock, false); final String retValue = StringUtils.replace(outStr.toString().trim(), \"\\\\n\", \"\\n\"); return retValue; } ",
        "test_tgt": "@Test public void test_buildAddressString_0080_EscapeBrackets() { final I_C_Location location = prepareLocation(\"addr1\", \"addr2\", null, null, \"City1\", \"Region1\", \"121212\", \"\", prepareCountry(\"Country1\", \"@A1@ @A2@ @P@ @C@ \\\\(Region @R@\\\\) @CO@\")); boolean isLocalAddress = false; final String bPartnerBlock = null; final String userBlock = null; Assert.assertEquals(\"addr1\\naddr2\\n121212 City1\\n(Region Region1) Country1\", builder(\"de_CH\").buildAddressString(location, isLocalAddress, bPartnerBlock, userBlock)); isLocalAddress = true; Assert.assertEquals(\"LOCAL: addr1\\naddr2\\n121212 City1\\n(Region Region1) Country1\", builder(\"de_CH\").buildAddressString(location, isLocalAddress, bPartnerBlock, userBlock)); } "
    },
    {
        "test_src": "@Test public void add_nonManagedObjectToManagedList() { testRealm.beginTransaction(); CyclicType parent = testRealm.createObject(CyclicType.class); RealmList < CyclicType > children = parent.getObjects(); children.add(new CyclicType()); testRealm.commitTransaction(); assertEquals(1, testRealm.where(CyclicType.class).findFirst().getObjects().size()); } ",
        "focal_tgt": "@Override public void add(int location, E object) { checkValidObject(object); if(managedMode) { checkValidView(); if(location < 0 || location > size()) { throw new IndexOutOfBoundsException(\"Invalid index \" + location + \", size is \" + size()); } object = copyToRealmIfNeeded(object); view.insert(location, object.row.getIndex()); } else { nonManagedList.add(location, object); } } ",
        "focal_src": "@Override public void add(int location, E object) { checkValidObject(object); if(managedMode) { checkValidView(); object = copyToRealmIfNeeded(object); view.insert(location, object.row.getIndex()); } else { nonManagedList.add(location, object); } } ",
        "test_tgt": "@Test public void add_nonManagedObjectToManagedList() { realm.beginTransaction(); CyclicType parent = realm.createObject(CyclicType.class); RealmList < CyclicType > children = parent.getObjects(); children.add(new CyclicType()); realm.commitTransaction(); assertEquals(1, realm.where(CyclicType.class).findFirst().getObjects().size()); } "
    },
    {
        "test_src": "@Test public void testSizeGt() { assertEquals(new SizeGtCriterion(\"id\", 3), instance.sizeGt(\"id\", 3).getQueryCriterion()); } ",
        "focal_tgt": "public CriteriaQuery sizeGt(String propName, int size) { criterion = criterion.and(Criteria.sizeGt(propName, size)); return this; } ",
        "focal_src": "public CriteriaQuery sizeGt(String propName, int size) { criterion = criterion.and(criterionBuilder.sizeGt(propName, size)); return this; } ",
        "test_tgt": "@Test public void testSizeGt() { assertEquals(Criteria.sizeGt(\"id\", 3), instance.sizeGt(\"id\", 3).getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void testRetractObject()throws Exception { StatefulKnowledgeSessionImpl ksession = (StatefulKnowledgeSessionImpl)kBase.newStatefulKnowledgeSession(); final Rete rete = kBase.getRete(); final ObjectTypeNode objectTypeNode = new ObjectTypeNode(1, this.entryPoint, new ClassObjectType(List.class), buildContext); objectTypeNode.attach(buildContext); final MockObjectSink sink1 = new MockObjectSink(); objectTypeNode.addObjectSink(sink1); final String string = \"String\"; final DefaultFactHandle h1 = new DefaultFactHandle(1, string); rete.assertObject(h1, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); assertLength(0, sink1.getAsserted()); assertLength(0, sink1.getRetracted()); final List list = new ArrayList(); final DefaultFactHandle h2 = new DefaultFactHandle(1, list); rete.assertObject(h2, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); rete.retractObject(h2, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); final List retracted = sink1.getRetracted(); assertLength(1, retracted); final Object[]results = (Object[])retracted.get(0); assertSame(list, ((DefaultFactHandle)results[0]).getObject()); } ",
        "focal_tgt": "public void retractObject(final InternalFactHandle handle, final PropagationContext context, final ObjectTypeConf objectTypeConf, final InternalWorkingMemory workingMemory) { if(log.isTraceEnabled()) { log.trace(\"Delete {}\", handle.toString()); } if(workingMemory.getSessionConfiguration().isThreadSafe()) { workingMemory.addPropagation(new PropagationEntry.Delete(this, handle, context, objectTypeConf)); } else { propagateRetract(handle, context, objectTypeConf, workingMemory); } } ",
        "focal_src": "public void retractObject(final InternalFactHandle handle, final PropagationContext context, final ObjectTypeConf objectTypeConf, final InternalWorkingMemory workingMemory) { if(log.isTraceEnabled()) { log.trace(\"Delete {}\", handle.toString()); } ObjectTypeNode[]cachedNodes = objectTypeConf.getObjectTypeNodes(); if(cachedNodes == null) { return; } for(int i = 0; i < cachedNodes.length; i ++ ) { cachedNodes[i].retractObject(handle, context, workingMemory); } if(handle instanceof EventFactHandle) { ((EventFactHandle)handle).unscheduleAllJobs(workingMemory); } } ",
        "test_tgt": "@Test public void testRetractObject()throws Exception { StatefulKnowledgeSessionImpl ksession = (StatefulKnowledgeSessionImpl)kBase.newStatefulKnowledgeSession(); final Rete rete = kBase.getRete(); final ObjectTypeNode objectTypeNode = new ObjectTypeNode(1, this.entryPoint, new ClassObjectType(List.class), buildContext); objectTypeNode.attach(buildContext); final MockObjectSink sink1 = new MockObjectSink(); objectTypeNode.addObjectSink(sink1); final String string = \"String\"; final DefaultFactHandle h1 = new DefaultFactHandle(1, string); rete.assertObject(h1, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); assertLength(0, sink1.getAsserted()); assertLength(0, sink1.getRetracted()); final List list = new ArrayList(); final DefaultFactHandle h2 = new DefaultFactHandle(1, list); rete.assertObject(h2, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); rete.retractObject(h2, pctxFactory.createPropagationContext(0, PropagationContext.INSERTION, null, null, null), ksession); ksession.fireAllRules(); final List retracted = sink1.getRetracted(); assertLength(1, retracted); final Object[]results = (Object[])retracted.get(0); assertSame(list, ((DefaultFactHandle)results[0]).getObject()); } "
    },
    {
        "test_src": "@TestOnly private DistributedMetaStorageHistoryItem[]localFullData()throws IgniteCheckedException { return bridge.localFullData(); } ",
        "focal_tgt": "DistributedMetaStorageKeyValuePair[]localFullData()throws IgniteCheckedException; ",
        "focal_src": "DistributedMetaStorageHistoryItem[]localFullData()throws IgniteCheckedException; ",
        "test_tgt": "@TestOnly private DistributedMetaStorageKeyValuePair[]localFullData()throws IgniteCheckedException { return bridge.localFullData(); } "
    },
    {
        "test_src": "@Test public void addPackageInfoTest()throws IOException { File dirPath = new File(CREATE_PATH); dirPath.mkdirs(); addPackageInfo(dirPath, \"check1\", CREATE_PATH); File filePath = new File(dirPath + File.separator + \"package-info.java\"); assertThat(filePath.isFile(), is(true)); } ",
        "focal_tgt": "public static void addPackageInfo(File path, String classInfo, String pack, boolean isChildNode)throws IOException { if(pack.contains(ORG)) { String[]strArray = pack.split(ORG); pack = ORG + strArray[1]; } try { File packageInfo = new File(path + SLASH + \"package-info.java\"); packageInfo.createNewFile(); FileWriter fileWriter = new FileWriter(packageInfo); BufferedWriter bufferedWriter = new BufferedWriter(fileWriter); bufferedWriter.write(CopyrightHeader.getCopyrightHeader()); bufferedWriter.write(getJavaDoc(PACKAGE_INFO, classInfo, isChildNode)); bufferedWriter.write(PACKAGE + SPACE + pack + SEMI_COLAN); bufferedWriter.close(); fileWriter.close(); } catch(IOException e) { throw new IOException(\"Exception occured while creating package info file.\"); } } ",
        "focal_src": "public static void addPackageInfo(File path, String classInfo, String pack)throws IOException { if(pack.contains(ORG)) { String[]strArray = pack.split(ORG); pack = ORG + strArray[1]; } try { File packageInfo = new File(path + SLASH + \"package-info.java\"); packageInfo.createNewFile(); FileWriter fileWriter = new FileWriter(packageInfo); BufferedWriter bufferedWriter = new BufferedWriter(fileWriter); bufferedWriter.write(CopyrightHeader.getCopyrightHeader()); bufferedWriter.write(getJavaDoc(PACKAGE_INFO, classInfo, false)); bufferedWriter.write(PACKAGE + SPACE + pack + SEMI_COLAN); bufferedWriter.close(); fileWriter.close(); } catch(IOException e) { throw new IOException(\"Exception occured while creating package info file.\"); } } ",
        "test_tgt": "@Test public void addPackageInfoTest()throws IOException { File dirPath = new File(CREATE_PATH); dirPath.mkdirs(); addPackageInfo(dirPath, CHECK1, CREATE_PATH, false); File filePath = new File(dirPath + File.separator + PKG_INFO); assertThat(filePath.isFile(), is(true)); } "
    },
    {
        "test_src": "@Test public void testGetColumns() { TestUtils.log(this.getClass(), \"getColumns\"); RandomSingleton.getInstance().setSeed(TestConfiguration.RANDOM_SEED); DatabaseConfiguration dbConf = TestUtils.getDBConfig(); Dataset instance = new Dataset(dbConf); AssociativeArray xData1 = new AssociativeArray(); xData1.put(\"1\", true); instance.add(new Record(xData1, null)); AssociativeArray xData2 = new AssociativeArray(); xData2.put(\"2\", 1.0); instance.add(new Record(xData2, null)); AssociativeArray xData3 = new AssociativeArray(); xData3.put(\"3\", (short)1); instance.add(new Record(xData3, null)); AssociativeArray xData4 = new AssociativeArray(); xData4.put(\"4\", \"s\"); instance.add(new Record(xData4, null)); Map < Object, Dataset.ColumnType > expResult = new LinkedHashMap < > (); expResult.put(\"1\", Dataset.ColumnType.DUMMYVAR); expResult.put(\"2\", Dataset.ColumnType.NUMERICAL); expResult.put(\"3\", Dataset.ColumnType.ORDINAL); expResult.put(\"4\", Dataset.ColumnType.CATEGORICAL); Map < Object, Dataset.ColumnType > result = instance.getColumns(); assertEquals(expResult, result); } ",
        "focal_tgt": "public Map < Object, TypeInference.DataType > getXDataTypes() { return Collections.unmodifiableMap(xDataTypes); } ",
        "focal_src": "public Map < Object, ColumnType > getColumns() { return Collections.unmodifiableMap(columns); } ",
        "test_tgt": "@Test public void testGetColumns() { TestUtils.log(this.getClass(), \"getColumns\"); RandomSingleton.getInstance().setSeed(TestConfiguration.RANDOM_SEED); DatabaseConfiguration dbConf = TestUtils.getDBConfig(); Dataset instance = new Dataset(dbConf); AssociativeArray xData1 = new AssociativeArray(); xData1.put(\"1\", true); instance.add(new Record(xData1, null)); AssociativeArray xData2 = new AssociativeArray(); xData2.put(\"2\", 1.0); instance.add(new Record(xData2, null)); AssociativeArray xData3 = new AssociativeArray(); xData3.put(\"3\", (short)1); instance.add(new Record(xData3, null)); AssociativeArray xData4 = new AssociativeArray(); xData4.put(\"4\", \"s\"); instance.add(new Record(xData4, null)); Map < Object, TypeInference.DataType > expResult = new LinkedHashMap < > (); expResult.put(\"1\", TypeInference.DataType.BOOLEAN); expResult.put(\"2\", TypeInference.DataType.NUMERICAL); expResult.put(\"3\", TypeInference.DataType.ORDINAL); expResult.put(\"4\", TypeInference.DataType.CATEGORICAL); Map < Object, TypeInference.DataType > result = instance.getXDataTypes(); assertEquals(expResult, result); } "
    },
    {
        "test_src": "@Test public void testCurrentlyPreparedTxs() { txPrepare(1); txKeyWrite(1, 10); txKeyWrite(1, 11); txPrepare(2); txKeyWrite(2, 20); txKeyWrite(2, 21); txKeyWrite(2, 22); txPrepare(3); txKeyWrite(3, 30); txCommit(2); tracker.writeLockState(); try { Map < GridCacheVersion, WALPointer > currentlyPreparedTxs = tracker.currentlyPreparedTxs(); assertEquals(2, currentlyPreparedTxs.size()); assertTrue(currentlyPreparedTxs.containsKey(nearXidVersion(1))); assertTrue(currentlyPreparedTxs.containsKey(nearXidVersion(3))); } finally { tracker.writeUnlockState(); } txKeyWrite(3, 31); txCommit(3); tracker.writeLockState(); try { Map < GridCacheVersion, WALPointer > currentlyPreparedTxs = tracker.currentlyPreparedTxs(); assertEquals(1, currentlyPreparedTxs.size()); assertTrue(currentlyPreparedTxs.containsKey(nearXidVersion(1))); } finally { tracker.writeUnlockState(); } } ",
        "focal_tgt": "public Set < GridCacheVersion > currentlyPreparedTxs() { assert stateLock.writeLock().isHeldByCurrentThread(); return U.sealSet(preparedCommittedTxsCounters.keySet()); } ",
        "focal_src": "public Map < GridCacheVersion, WALPointer > currentlyPreparedTxs() { assert stateLock.writeLock().isHeldByCurrentThread(); return U.sealMap(currentlyPreparedTxs); } ",
        "test_tgt": "@Test public void testCurrentlyPreparedTxs() { txPrepare(1); txKeyWrite(1, 10); txKeyWrite(1, 11); txPrepare(2); txKeyWrite(2, 20); txKeyWrite(2, 21); txKeyWrite(2, 22); txPrepare(3); txKeyWrite(3, 30); txCommit(2); tracker.writeLockState(); try { Set < GridCacheVersion > currentlyPreparedTxs = tracker.currentlyPreparedTxs(); assertEquals(2, currentlyPreparedTxs.size()); assertTrue(currentlyPreparedTxs.contains(nearXidVersion(1))); assertTrue(currentlyPreparedTxs.contains(nearXidVersion(3))); } finally { tracker.writeUnlockState(); } txKeyWrite(3, 31); txCommit(3); tracker.writeLockState(); try { Set < GridCacheVersion > currentlyPreparedTxs = tracker.currentlyPreparedTxs(); assertEquals(1, currentlyPreparedTxs.size()); assertTrue(currentlyPreparedTxs.contains(nearXidVersion(1))); } finally { tracker.writeUnlockState(); } } "
    },
    {
        "test_src": "@Test@Verifies(value = \"set this care setting to new order\", method = \"cloneForDiscontinuing(Order)\")public void cloneForDiscontinuing_shouldSetThisCareSettingToNewOrder() { Order anOrder = new Order(); CareSetting careSetting = new CareSetting(); anOrder.setCareSetting(careSetting); Order orderThatCanDiscontinueTheOrder = anOrder.cloneForDiscontinuing(); assertEquals(anOrder.getCareSetting(), orderThatCanDiscontinueTheOrder.getCareSetting()); } ",
        "focal_tgt": "public Order cloneForDiscontinuing()throws IllegalAccessException, InstantiationException { Order newOrder = this.getClass().newInstance(); newOrder.setCareSetting(this.getCareSetting()); newOrder.setConcept(this.getConcept()); newOrder.setAction(Action.DISCONTINUE); newOrder.setPreviousOrder(this); return newOrder; } ",
        "focal_src": "public Order cloneForDiscontinuing() { Order newOrder = new Order(); newOrder.setCareSetting(this.getCareSetting()); newOrder.setConcept(this.getConcept()); newOrder.setAction(Action.DISCONTINUE); newOrder.setPreviousOrder(this); return newOrder; } ",
        "test_tgt": "@Test@Verifies(value = \"set this care setting to new order\", method = \"cloneForDiscontinuing(Order)\")public void cloneForDiscontinuing_shouldSetThisCareSettingToNewOrder()throws Exception { Order anOrder = new Order(); CareSetting careSetting = new CareSetting(); anOrder.setCareSetting(careSetting); Order orderThatCanDiscontinueTheOrder = anOrder.cloneForDiscontinuing(); assertEquals(anOrder.getCareSetting(), orderThatCanDiscontinueTheOrder.getCareSetting()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should not allow deleting an order frequency that is in use\", method = \"purgeOrderFrequency(OrderFrequency)\")public void purgeOrderFrequency_shouldNotAllowDeletingAnOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); expectedException.expect(CannotDeleteOrderPropertyInUseException.class); expectedException.expectMessage(\"Order.frequency.cannot.delete\"); orderService.purgeOrderFrequency(orderFrequency); } ",
        "focal_tgt": "@Override public void purgeOrderFrequency(OrderFrequency orderFrequency) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw new CannotDeleteObjectInUseException(\"Order.frequency.cannot.delete\", (Object[])null); } dao.purgeOrderFrequency(orderFrequency); } ",
        "focal_src": "@Override public void purgeOrderFrequency(OrderFrequency orderFrequency) { if(dao.isOrderFrequencyInUse(orderFrequency)) { throw CannotDeleteOrderPropertyInUseException.withProperty(\"frequency\"); } dao.purgeOrderFrequency(orderFrequency); } ",
        "test_tgt": "@Test@Verifies(value = \"should not allow deleting an order frequency that is in use\", method = \"purgeOrderFrequency(OrderFrequency)\")public void purgeOrderFrequency_shouldNotAllowDeletingAnOrderFrequencyThatIsInUse()throws Exception { OrderFrequency orderFrequency = orderService.getOrderFrequency(1); assertNotNull(orderFrequency); expectedException.expect(CannotDeleteObjectInUseException.class); expectedException.expectMessage(mss.getMessage(\"Order.frequency.cannot.delete\")); orderService.purgeOrderFrequency(orderFrequency); } "
    },
    {
        "test_src": "@Test public void testSetExcludePorts()throws Exception { ImmutableSet.Builder < String > builder = ImmutableSet.builder(); builder.add(PORT_NAME_3); config.setExcludePorts(builder.build()); Set < String > excludePorts = config.excludePorts(); assertThat(excludePorts.size(), is(1)); assertTrue(excludePorts.contains(PORT_NAME_3)); } ",
        "focal_tgt": "public SegmentRoutingAppConfig setSuppressHost(Set < ConnectPoint > suppressHost) { if(suppressHost == null) { object.remove(SUPPRESS_HOST); } else { ArrayNode arrayNode = mapper.createArrayNode(); suppressHost.forEach(connectPoint -> { arrayNode.add(connectPoint.deviceId() + \"/\" + connectPoint.port()); }); object.set(SUPPRESS_HOST, arrayNode); } return this; } ",
        "focal_src": "public SegmentRoutingAppConfig setExcludePorts(Set < String > excludePorts) { if(excludePorts == null) { object.remove(EXCLUDE_PORTS); } else { ArrayNode arrayNode = mapper.createArrayNode(); excludePorts.forEach(portName -> { arrayNode.add(portName); }); object.set(EXCLUDE_PORTS, arrayNode); } return this; } ",
        "test_tgt": "@Test public void testSetSuppressHost()throws Exception { ImmutableSet.Builder < ConnectPoint > builder = ImmutableSet.builder(); builder.add(PORT_3); config.setSuppressHost(builder.build()); Set < ConnectPoint > suppressHost = config.suppressHost(); assertNotNull(\"suppressHost should not be null\", suppressHost); assertThat(suppressHost.size(), is(1)); assertTrue(suppressHost.contains(PORT_3)); } "
    },
    {
        "test_src": "@Test public void getConfiguration()throws Exception { Configuration.set(PropertyKey.METRICS_CONF_FILE, \"abc\"); String result = new TestCase(mHostname, mPort, getEndpoint(AlluxioWorkerRestServiceHandler.GET_CONFIGURATION), NO_PARAMS, HttpMethod.GET, null).call(); @SuppressWarnings(\"unchecked\")Map < String, String > config = (Map < String, String > )new ObjectMapper().readValue(result, Map.class); Assert.assertEquals(\"abc\", Configuration.get(PropertyKey.METRICS_CONF_FILE)); } ",
        "focal_tgt": "private Map < String, String > getConfiguration() { Set < Map.Entry < String, String > > properties = Configuration.toMap().entrySet(); SortedMap < String, String > configuration = new TreeMap < > (); for(Map.Entry < String, String > entry : properties) { String key = entry.getKey(); if(PropertyKey.isValid(key)) { configuration.put(key, entry.getValue()); } } return configuration; } ",
        "focal_src": "@GET@Path(GET_CONFIGURATION)@ReturnType(\"java.util.SortedMap<java.lang.String, java.lang.String>\")public Response getConfiguration() { return RestUtils.call(new RestUtils.RestCallable < Map < String, String > > () { @Override public Map < String, String > call()throws Exception { Set < Map.Entry < String, String > > properties = Configuration.toMap().entrySet(); SortedMap < String, String > configuration = new TreeMap < > (); for(Map.Entry < String, String > entry : properties) { String key = entry.getKey(); if(PropertyKey.isValid(key)) { configuration.put(key, entry.getValue()); } } return configuration; } }); } ",
        "test_tgt": "@Test public void getConfiguration()throws Exception { Configuration.set(PropertyKey.METRICS_CONF_FILE, \"abc\"); Assert.assertEquals(\"abc\", getInfo().getConfiguration().get(PropertyKey.METRICS_CONF_FILE.toString())); } "
    },
    {
        "test_src": "@Test public void testSetCommandInfoForJob()throws GenieException { final String id = UUID.randomUUID().toString(); final String name = UUID.randomUUID().toString(); this.service.setCommandInfoForJob(JOB_1_ID, id, name); final Job job = this.service.getJob(JOB_1_ID); Assert.assertEquals(id, job.getCommandId()); Assert.assertEquals(name, job.getCommandName()); } ",
        "focal_tgt": "@Override@Transactional(rollbackFor = { GenieException.class, ConstraintViolationException.class })public void setCommandInfoForJob(@NotBlank(message = \"No job id entered. Unable to set command info for job.\")final String id, @NotBlank(message = \"No command id entered. Unable to set command info for job.\")final String commandId, @NotBlank(message = \"No command name entered. Unable to set command info for job.\")final String commandName)throws GenieException { if(LOG.isDebugEnabled()) { LOG.debug(\"Setting the command info for job with id \" + id); } final Job job = this.jobRepo.findOne(id); if(job != null) { job.setCommandId(commandId); job.setCommandName(commandName); } else { throw new GenieNotFoundException(\"No job with id \" + id + \" exists\"); } } ",
        "focal_src": "@Override@Transactional(rollbackFor = { GenieException.class, ConstraintViolationException.class })public void setCommandInfoForJob(@NotBlank(message = \"No job id entered. Unable to set command info for job.\")final String id, @NotBlank(message = \"No command id entered. Unable to set command info for job.\")final String commandId, @NotBlank(message = \"No command name entered. Unable to set command info for job.\")final String commandName)throws GenieException { LOG.debug(\"Setting the command info for job with id \" + id); final Job job = this.jobRepo.findOne(id); if(job != null) { job.setCommandId(commandId); job.setCommandName(commandName); } else { throw new GenieNotFoundException(\"No job with id \" + id + \" exists\"); } } ",
        "test_tgt": "@Test@Ignore public void testSetCommandInfoForJob()throws GenieException { } "
    },
    {
        "test_src": "@Test@Category(IntegrationTests.class)public void testParseRecords() { Random r = RandomHelper.getRandom(); for(int i = 0; i < 1000; i ++ ) { byte[]data = new byte[r.nextInt(1000)]; r.nextBytes(data); layer.parseRecords(data); } } ",
        "focal_tgt": "public abstract List < AbstractRecord > parseRecords(byte[]rawBytes)throws ParserException; ",
        "focal_src": "public abstract List < AbstractRecord > parseRecords(byte[]rawBytes); ",
        "test_tgt": "@Test@Category(IntegrationTests.class)public void testParseRecords() { Random r = RandomHelper.getRandom(); for(int i = 0; i < 1000; i ++ ) { byte[]data = new byte[r.nextInt(1000)]; r.nextBytes(data); layer.parseRecordsSoftly(data); } } "
    },
    {
        "test_src": "@Test public void numberTest()throws QueryIOException { parse(\"0\", ECMA_262); parse(\"1\", ECMA_262); parse(\"-1\", ECMA_262); parse(\"10\", ECMA_262); parse(\"1234567890123456789012345678901234567890\", ECMA_262); parse(\"0.5\", ECMA_262); parse(\"0.01\", ECMA_262); parse(\"-0.01\", ECMA_262); parse(\"1234567890123456789012345678901234567890\" + \".1234567890123456789012345678901234567890\", ECMA_262); parse(\"0E1\", ECMA_262); parse(\"0E-1\", ECMA_262); parse(\"0E+1\", ECMA_262); parse(\"-0E+1\", ECMA_262); parse(\"0E00\", ECMA_262); parse(\"1234567890123456789012345678901234567890\" + \"e1234567890123456789012345678901234567890\", ECMA_262); parse(\"123e-123\", ECMA_262); parse(\"123.4e-123\", ECMA_262); parse(\"123.456E0001\", ECMA_262); parse(\"-123.456E0001\", ECMA_262); parse(\"[ -123.456E0001, 0 ]\", ECMA_262); error(\"01\", ECMA_262); error(\"-\", ECMA_262); error(\"-\", ECMA_262); error(\"0.\", ECMA_262); error(\"0.\", ECMA_262); error(\"1e\", ECMA_262); error(\"1e+\", ECMA_262); error(\"1e+\", ECMA_262); error(\"1e+0\", ECMA_262); } ",
        "focal_tgt": "private byte[]number()throws QueryIOException { tb.reset(); int ch = consume(); add(ch); if(ch == '-') { ch = consume(); if(ch < '0' || ch > '9')throw error(\"Number expected after '-'\"); add(ch); } final boolean zero = ch == '0'; ch = curr(); if(zero && ch >= '0' && ch <= '9')throw error(\"No digit allowed after '0'\"); loop : while(true) { switch(ch) { case '0' : case '1' : case '2' : case '3' : case '4' : case '5' : case '6' : case '7' : case '8' : case '9' : add(ch); pos ++ ; ch = curr(); break; case '.' : case 'e' : case 'E' : break loop; default : skipWs(); return tb.toArray(); } } if(consume('.')) { add('.'); ch = curr(); if(ch < '0' || ch > '9')throw error(\"Number expected after '.'\"); do { add(ch); pos ++ ; ch = curr(); } while(ch >= '0' && ch <= '9'); if(ch != 'e' && ch != 'E') { skipWs(); return tb.toArray(); } } add(consume()); ch = curr(); if(ch == '-' || ch == '+') { add(consume()); ch = curr(); } if(ch < '0' || ch > '9')throw error(\"Exponent expected\"); do add(consume()); while((ch = curr()) >= '0' && ch <= '9'); skipWs(); return tb.toArray(); } ",
        "focal_src": "private byte[]number()throws QueryIOException { tb.reset(); int ch = consume(); tb.addByte((byte)ch); if(ch == '-') { ch = consume(); if(ch < '0' || ch > '9')throw error(\"Number expected after '-'\"); tb.addByte((byte)ch); } final boolean zero = ch == '0'; ch = curr(); if(zero && ch >= '0' && ch <= '9')throw error(\"No digit allowed after '0'\"); loop : while(true) { switch(ch) { case '0' : case '1' : case '2' : case '3' : case '4' : case '5' : case '6' : case '7' : case '8' : case '9' : tb.addByte((byte)ch); pos ++ ; ch = curr(); break; case '.' : case 'e' : case 'E' : break loop; default : skipWs(); return tb.toArray(); } } if(consume('.')) { tb.addByte((byte)'.'); ch = curr(); if(ch < '0' || ch > '9')throw error(\"Number expected after '.'\"); do { tb.addByte((byte)ch); pos ++ ; ch = curr(); } while(ch >= '0' && ch <= '9'); if(ch != 'e' && ch != 'E') { skipWs(); return tb.toArray(); } } tb.addByte((byte)consume()); ch = curr(); if(ch == '-' || ch == '+') { tb.addByte((byte)consume()); ch = curr(); } if(ch < '0' || ch > '9')throw error(\"Exponent expected\"); do tb.addByte((byte)consume()); while((ch = curr()) >= '0' && ch <= '9'); skipWs(); return tb.toArray(); } ",
        "test_tgt": "@Test public void numberTest()throws QueryIOException { parse(\"0\", false); parse(\"1\", false); parse(\"-1\", false); parse(\"10\", false); parse(\"1234567890123456789012345678901234567890\", false); parse(\"0.5\", false); parse(\"0.01\", false); parse(\"-0.01\", false); parse(\"1234567890123456789012345678901234567890\" + \".1234567890123456789012345678901234567890\", false); parse(\"0E1\", false); parse(\"0E-1\", false); parse(\"0E+1\", false); parse(\"-0E+1\", false); parse(\"0E00\", false); parse(\"1234567890123456789012345678901234567890\" + \"e1234567890123456789012345678901234567890\", false); parse(\"123e-123\", false); parse(\"123.4e-123\", false); parse(\"123.456E0001\", false); parse(\"-123.456E0001\", false); parse(\"[ -123.456E0001, 0 ]\", false); error(\"01\", false); error(\"-\", false); error(\"-\", false); error(\"0.\", false); error(\"0.\", false); error(\"1e\", false); error(\"1e+\", false); error(\"1e+\", false); error(\"1e+0\", false); } "
    },
    {
        "test_src": "@Test public void testStreamCommands() { System.out.println(\"streamCommands\"); MockConnection mc = new MockConnection(mg.in, mg.out); GrblCommunicator instance = new GrblCommunicator(cb, asl, mc); String thirtyNineCharString = \"thirty-nine character command here.....\"; boolean result; boolean expResult; LinkedList < GcodeCommand > l = new LinkedList < > (); l.add(new GcodeCommand(\"12characters\")); assertEquals(13, CommUtils.getSizeOfBuffer(l)); assertEquals(123, GrblUtils.GRBL_RX_BUFFER_SIZE); instance.queueStringForComm(thirtyNineCharString); instance.queueStringForComm(thirtyNineCharString); instance.queueStringForComm(thirtyNineCharString); instance.streamCommands(); expResult = true; result = instance.areActiveCommands(); assertEquals(expResult, result); instance.queueStringForComm(thirtyNineCharString); instance.streamCommands(); expResult = true; result = instance.areActiveCommands(); assertEquals(expResult, result); String output = mg.readStringFromGrblBuffer(); assertEquals(thirtyNineCharString + \"\\n\" + thirtyNineCharString + \"\\n\" + thirtyNineCharString + \"\\n\", output); mc.sendResponse(\"ok\"); instance.streamCommands(); output = mg.readStringFromGrblBuffer(); assertEquals(thirtyNineCharString + \"\\n\", output); mc.sendResponse(\"ok\"); mc.sendResponse(\"ok\"); mc.sendResponse(\"ok\"); expResult = false; result = instance.areActiveCommands(); assertEquals(expResult, result); } ",
        "focal_tgt": "@Override public void streamCommands() { if( ! this.getNextCommand().isPresent()) { return; } if(this.sendPaused) { return; } while(this.getNextCommand().isPresent() && CommUtils.checkRoomInBuffer(this.sentBufferSize, this.getNextCommand().get().getCommandString(), this.getBufferSize()) && allowMoreCommands()) { GcodeCommand command = this.getNextCommand().get(); if(command.getCommandString().isEmpty()) { dispatchListenerEvents(COMMAND_SKIPPED, command); synchronized(nextCommandLock) { nextCommand = null; } continue; } String commandString = command.getCommandString().trim(); this.activeCommandList.add(command); this.sentBufferSize += commandString.length() + 1; this.sendMessageToConsoleListener(\">>> \" + commandString + \"\\n\"); try { this.sendingCommand(commandString); conn.sendStringToComm(commandString + this.getLineTerminator()); synchronized(nextCommandLock) { nextCommand = null; } dispatchListenerEvents(SerialCommunicatorEvent.COMMAND_SENT, command); } catch(Exception e) { e.printStackTrace(); System.exit( - 1); } } } ",
        "focal_src": "@Override public void streamCommands() { if( ! this.getNextCommand().isPresent()) { return; } if(this.sendPaused) { return; } while(this.getNextCommand().isPresent() && CommUtils.checkRoomInBuffer(this.sentBufferSize, this.getNextCommand().get(), this.getBufferSize()) && allowMoreCommands()) { String commandString = this.getNextCommand().get(); this.activeStringList.add(commandString); this.sentBufferSize += commandString.length(); this.sendMessageToConsoleListener(\">>> \" + commandString); try { this.sendingCommand(commandString); conn.sendStringToComm(commandString); synchronized(nextCommandLock) { nextCommand = null; } dispatchListenerEvents(COMMAND_SENT, this.commandSentListeners, commandString.trim()); } catch(Exception e) { e.printStackTrace(); System.exit( - 1); } } } ",
        "test_tgt": "@Test public void testStreamCommands() { System.out.println(\"streamCommands\"); MockConnection mc = new MockConnection(mg.in, mg.out); GrblCommunicator instance = new GrblCommunicator(cb, asl, mc); String term = instance.getLineTerminator(); String thirtyNineCharString = \"thirty-nine character command here.....\"; boolean result; boolean expResult; LinkedList < GcodeCommand > l = new LinkedList < > (); l.add(new GcodeCommand(\"12characters\")); assertEquals(13, CommUtils.getSizeOfBuffer(l)); assertEquals(123, GrblUtils.GRBL_RX_BUFFER_SIZE); instance.queueStringForComm(thirtyNineCharString); instance.queueStringForComm(thirtyNineCharString); instance.queueStringForComm(thirtyNineCharString); instance.streamCommands(); expResult = true; result = instance.areActiveCommands(); assertEquals(expResult, result); instance.queueStringForComm(thirtyNineCharString); instance.streamCommands(); expResult = true; result = instance.areActiveCommands(); assertEquals(expResult, result); String output = mg.readStringFromGrblBuffer(); String goal = thirtyNineCharString + term + thirtyNineCharString + term + thirtyNineCharString + term; assertEquals(goal, output); mc.sendResponse(\"ok\"); instance.streamCommands(); output = mg.readStringFromGrblBuffer(); assertEquals(thirtyNineCharString + term, output); mc.sendResponse(\"ok\"); mc.sendResponse(\"ok\"); mc.sendResponse(\"ok\"); expResult = false; result = instance.areActiveCommands(); assertEquals(expResult, result); } "
    },
    {
        "test_src": "@Test public void parse() { parse(\"[]\", \"\", \"<json type=\\\"array\\\"/>\"); parse(\"{}\", \"\", \"<json type=\\\"object\\\"/>\"); parse(\"{ } \", \"\", \"<json type=\\\"object\\\"/>\"); parse(\"{ \\\"\\\\t\\\" : 0 }\", \"\", \"<json type=\\\"object\\\"><_0009 type=\\\"number\\\">0</_0009></json>\"); parse(\"{ \\\"a\\\" :0 }\", \"\", \"<json type=\\\"object\\\"><a type=\\\"number\\\">0</a></json>\"); parse(\"{ \\\"\\\" : 0 }\", \"\", \"<json type=\\\"object\\\"><_ type=\\\"number\\\">0</_></json>\"); parse(\"{ \\\"\\\" : 0.0e0 }\", \"\", \"...<_ type=\\\"number\\\">0.0e0</_>\"); parse(\"{ \\\"\\\" : null }\", \"\", \"...<_ type=\\\"null\\\"/>\"); parse(\"{ \\\"\\\" : true }\", \"\", \"...<_ type=\\\"boolean\\\">true</_>\"); parse(\"{ \\\"\\\" : {} }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"object\\\"/>\"); parse(\"{ \\\"\\\" : [] }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"array\\\"/>\"); parse(\"{ \\\"\\\" : 0, \\\"\\\": 1 }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"number\\\">0</_><_ type=\\\"number\\\">1</_>\"); parse(\"{ \\\"O\\\" : [ 1 ] }\", \"\", \"...<O type=\\\"array\\\"><_ type=\\\"number\\\">1</_></O>\"); parse(\"{ \\\"A\\\" : [ 0,1 ] }\", \"\", \"...<A type=\\\"array\\\"><_ type=\\\"number\\\">0</_><_ type=\\\"number\\\">1</_>\"); parse(\"{ \\\"\\\" : 0.0 }\", \"\", \"...0.0\"); parse(\"[]\", \"'merge':true()\", \"<json arrays=\\\"json\\\"/>\"); parse(\"{}\", \"'merge':true()\", \"<json objects=\\\"json\\\"/>\"); parse(\"{ } \", \"'merge':true()\", \"<json objects=\\\"json\\\"/>\"); parse(\"{ \\\"\\\\t\\\" : 0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"_0009\\\"><_0009>0</_0009></json>\"); parse(\"{ \\\"a\\\" :0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"a\\\"><a>0</a></json>\"); parse(\"{ \\\"\\\" : 0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"_\\\"><_>0</_></json>\"); parse(\"{ \\\"\\\" : 0.0e0 }\", \"'merge':true()\", \"...<_>0.0e0</_>\"); parse(\"{ \\\"\\\" : null }\", \"'merge':true()\", \"...<_/>\"); parse(\"{ \\\"\\\" : true }\", \"'merge':true()\", \"...<_>true</_>\"); parse(\"{ \\\"\\\" : {} }\", \"'merge':true()\", \"... objects=\\\"json _\\\"><_/>\"); parse(\"{ \\\"\\\" : [] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"_\\\"><_/>\"); parse(\"{ \\\"\\\" : 0, \\\"\\\": 1 }\", \"'merge':true()\", \"... objects=\\\"json\\\" numbers=\\\"_\\\"><_>0</_><_>1</_>\"); parse(\"{ \\\"O\\\" : [ 1 ] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"O\\\" numbers=\\\"_\\\"><O><_>1</_></O>\"); parse(\"{ \\\"A\\\" : [ 0,1 ] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"A\\\" numbers=\\\"_\\\"><A><_>0</_><_>1</_>\"); parseError(\"\", \"\"); parseError(\"{\", \"\"); parseError(\"{ \\\"\", \"\"); parseError(\"{ \\\"\\\" : 00 }\", \"\"); parseError(\"{ \\\"\\\" : 0. }\", \"\"); parseError(\"{ \\\"\\\\c\\\" : 0 }\", \"\"); parseError(\"{ \\\"\\\" : 0e }\", \"\"); parseError(\"{ \\\"\\\" : 0.1. }\", \"\"); parseError(\"{ \\\"\\\" : 0.1e }\", \"\"); parseError(\"{ \\\"a\\\" : 0 }}\", \"\"); parseError(\"{ \\\"a\\\" : 0, }\", \"'format':'RFC4627'\"); } ",
        "focal_tgt": "private void parse()throws QueryIOException { skipWs(); value(); if(more())throw error(\"Unexpected trailing content: %\", rest()); } ",
        "focal_src": "private void parse()throws QueryIOException { skipWs(); if(spec == JsonSpec.RFC4627 && ! (curr() == '{' || curr() == '['))throw error(\"Expected '{' or '[', found %\", rest()); value(); if(more())throw error(\"Unexpected trailing content: %\", rest()); } ",
        "test_tgt": "@Test public void parseXml() { parse(\"[]\", \"\", \"<json type=\\\"array\\\"/>\"); parse(\"{}\", \"\", \"<json type=\\\"object\\\"/>\"); parse(\"{ } \", \"\", \"<json type=\\\"object\\\"/>\"); parse(\"{ \\\"\\\\t\\\" : 0 }\", \"\", \"<json type=\\\"object\\\"><_0009 type=\\\"number\\\">0</_0009></json>\"); parse(\"{ \\\"a\\\" :0 }\", \"\", \"<json type=\\\"object\\\"><a type=\\\"number\\\">0</a></json>\"); parse(\"{ \\\"\\\" : 0 }\", \"\", \"<json type=\\\"object\\\"><_ type=\\\"number\\\">0</_></json>\"); parse(\"{ \\\"\\\" : 0.0e0 }\", \"\", \"...<_ type=\\\"number\\\">0.0e0</_>\"); parse(\"{ \\\"\\\" : null }\", \"\", \"...<_ type=\\\"null\\\"/>\"); parse(\"{ \\\"\\\" : true }\", \"\", \"...<_ type=\\\"boolean\\\">true</_>\"); parse(\"{ \\\"\\\" : {} }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"object\\\"/>\"); parse(\"{ \\\"\\\" : [] }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"array\\\"/>\"); parse(\"{ \\\"\\\" : 0, \\\"\\\": 1 }\", \"\", \"... type=\\\"object\\\"><_ type=\\\"number\\\">0</_><_ type=\\\"number\\\">1</_>\"); parse(\"{ \\\"O\\\" : [ 1 ] }\", \"\", \"...<O type=\\\"array\\\"><_ type=\\\"number\\\">1</_></O>\"); parse(\"{ \\\"A\\\" : [ 0,1 ] }\", \"\", \"...<A type=\\\"array\\\"><_ type=\\\"number\\\">0</_><_ type=\\\"number\\\">1</_>\"); parse(\"{ \\\"\\\" : 0.0 }\", \"\", \"...0.0\"); parse(\"[]\", \"'merge':true()\", \"<json arrays=\\\"json\\\"/>\"); parse(\"{}\", \"'merge':true()\", \"<json objects=\\\"json\\\"/>\"); parse(\"{ } \", \"'merge':true()\", \"<json objects=\\\"json\\\"/>\"); parse(\"{ \\\"\\\\t\\\" : 0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"_0009\\\"><_0009>0</_0009></json>\"); parse(\"{ \\\"a\\\" :0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"a\\\"><a>0</a></json>\"); parse(\"{ \\\"\\\" : 0 }\", \"'merge':true()\", \"<json objects=\\\"json\\\" numbers=\\\"_\\\"><_>0</_></json>\"); parse(\"{ \\\"\\\" : 0.0e0 }\", \"'merge':true()\", \"...<_>0.0e0</_>\"); parse(\"{ \\\"\\\" : null }\", \"'merge':true()\", \"...<_/>\"); parse(\"{ \\\"\\\" : true }\", \"'merge':true()\", \"...<_>true</_>\"); parse(\"{ \\\"\\\" : {} }\", \"'merge':true()\", \"... objects=\\\"json _\\\"><_/>\"); parse(\"{ \\\"\\\" : [] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"_\\\"><_/>\"); parse(\"{ \\\"\\\" : 0, \\\"\\\": 1 }\", \"'merge':true()\", \"... objects=\\\"json\\\" numbers=\\\"_\\\"><_>0</_><_>1</_>\"); parse(\"{ \\\"O\\\" : [ 1 ] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"O\\\" numbers=\\\"_\\\"><O><_>1</_></O>\"); parse(\"{ \\\"A\\\" : [ 0,1 ] }\", \"'merge':true()\", \"... objects=\\\"json\\\" arrays=\\\"A\\\" numbers=\\\"_\\\"><A><_>0</_><_>1</_>\"); parseError(\"\", \"\"); parseError(\"{\", \"\"); parseError(\"{ \\\"\", \"\"); parseError(\"{ \\\"\\\" : 00 }\", \"\"); parseError(\"{ \\\"\\\" : 0. }\", \"\"); parseError(\"{ \\\"\\\\c\\\" : 0 }\", \"\"); parseError(\"{ \\\"\\\" : 0e }\", \"\"); parseError(\"{ \\\"\\\" : 0.1. }\", \"\"); parseError(\"{ \\\"\\\" : 0.1e }\", \"\"); parseError(\"{ \\\"a\\\" : 0 }}\", \"\"); parseError(\"{ \\\"a\\\" : 0, }\", \"'liberal':false()\"); } "
    },
    {
        "test_src": "@Test public void parsePersonName_shouldNotFailWhenEndingWithWhitespace()throws Exception { Context.getPersonService().parsePersonName(\"John \"); } ",
        "focal_tgt": "public PersonName parsePersonName(String name)throws APIException { name = name.trim(); while(name.endsWith(\",\"))name = name.substring(0, name.length() - 1); String firstName = name; String middleName = \"\"; String lastName = \"\"; String lastName2 = null; if(name.contains(\",\")) { String[]names = name.split(\",\"); for(int x = 0; x < names.length; x ++ ) { names[x] = names[x].trim(); } String[]firstNames = names[1].split(\" \"); if(firstNames.length == 2) { lastName = names[0]; firstName = firstNames[0]; middleName = firstNames[1]; } else { firstName = names[1]; lastName = names[0]; } } else if(name.contains(\" \")) { String[]names = name.split(\" \"); if(names.length == 4) { firstName = names[0]; middleName = names[1]; lastName = names[2]; lastName2 = names[3]; } else if(names.length == 3) { firstName = names[0]; middleName = names[1]; lastName = names[2]; } else { firstName = names[0]; lastName = names[1]; } } PersonName pn = new PersonName(firstName, middleName, lastName); pn.setFamilyName2(lastName2); return pn; } ",
        "focal_src": "public PersonName parsePersonName(String name)throws APIException { name = name.trim(); while(name.endsWith(\",\"))name = name.substring(0, name.length() - 1); String firstName = name; String middleName = \"\"; String lastName = \"\"; if(name.contains(\",\")) { String[]names = name.split(\",\"); for(int x = 0; x < names.length; x ++ ) { names[x] = names[x].trim(); } String[]firstNames = names[1].split(\" \"); if(firstNames.length == 2) { lastName = names[0]; firstName = firstNames[0]; middleName = firstNames[1]; } else { firstName = names[1]; lastName = names[0]; } } else if(name.contains(\" \")) { String[]names = name.split(\" \"); if(names.length == 3) { firstName = names[0]; middleName = names[1]; lastName = names[2]; } else { firstName = names[0]; lastName = names[1]; } } return new PersonName(firstName, middleName, lastName); } ",
        "test_tgt": "@Test public void parsePersonName_shouldNotFailWhenEndingWithWhitespace()throws Exception { PersonName pname = Context.getPersonService().parsePersonName(\"John \"); assertEquals(\"John\", pname.getGivenName()); } "
    },
    {
        "test_src": "@Test public void removeGroupMember_shouldReturnTrueWhenAnObsIsRemoved()throws Exception { Obs obs = new Obs(); Obs member = new Obs(); obs.addGroupMember(member); assertTrue(obs.isDirty()); resetObs(obs); obs.removeGroupMember(member); assertTrue(obs.isDirty()); } ",
        "focal_tgt": "public void removeGroupMember(Obs member) { if(member == null || getGroupMembers() == null) { return; } if(groupMembers.remove(member)) { member.setObsGroup(null); setDirty(true); } } ",
        "focal_src": "public void removeGroupMember(Obs member) { if(member == null || getGroupMembers() == null) { return; } if(groupMembers.remove(member)) { member.setObsGroup(null); dirty = true; } } ",
        "test_tgt": "@Test public void removeGroupMember_shouldReturnTrueWhenAnObsIsRemoved()throws Exception { Obs obs = new Obs(2); Obs member = new Obs(); obs.addGroupMember(member); assertTrue(obs.isDirty()); resetObs(obs); obs.removeGroupMember(member); assertTrue(obs.isDirty()); } "
    },
    {
        "test_src": "@Test public void testGetMetadata_String() { String mdString = \"dc.contributor.author\"; DCValue[]dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 0\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 1\", dc.length == 0); mdString = \"dc.contributor.*\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 2\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 3\", dc.length == 0); mdString = \"dc.contributor\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 4\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 5\", dc.length == 0); } ",
        "focal_tgt": "public Metadatum[]getMetadata(String schema, String element, String qualifier, String lang) { try { BrowseItemDAO dao = BrowseDAOFactory.getItemInstance(ourContext); if(Item.ANY.equals(qualifier)) { try { return dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } } if( ! metadata.isEmpty()) { List < Metadatum > values = new ArrayList < Metadatum > (); Iterator < Metadatum > i = metadata.iterator(); while(i.hasNext()) { Metadatum dcv = i.next(); if(match(schema, element, qualifier, lang, dcv)) { values.add(dcv); } } if(values.isEmpty()) { Metadatum[]dcvs = new Metadatum[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } Metadatum[]valueArray = new Metadatum[values.size()]; valueArray = (Metadatum[])values.toArray(valueArray); return valueArray; } else { Metadatum[]dcvs = new Metadatum[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } } catch(BrowseException be) { log.error(\"caught exception: \", be); return null; } } ",
        "focal_src": "public DCValue[]getMetadata(String schema, String element, String qualifier, String lang) { try { BrowseItemDAO dao = BrowseDAOFactory.getItemInstance(ourContext); if(Item.ANY.equals(qualifier)) { try { return dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } } if( ! metadata.isEmpty()) { List < DCValue > values = new ArrayList < DCValue > (); Iterator < DCValue > i = metadata.iterator(); while(i.hasNext()) { DCValue dcv = i.next(); if(match(schema, element, qualifier, lang, dcv)) { values.add(dcv); } } if(values.isEmpty()) { DCValue[]dcvs = new DCValue[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } DCValue[]valueArray = new DCValue[values.size()]; valueArray = (DCValue[])values.toArray(valueArray); return valueArray; } else { DCValue[]dcvs = new DCValue[0]; try { dcvs = dao.queryMetadata(id, schema, element, qualifier, lang); } catch(SQLException e) { log.error(\"caught exception: \", e); } if(dcvs != null) { Collections.addAll(metadata, dcvs); } return dcvs; } } catch(BrowseException be) { log.error(\"caught exception: \", be); return null; } } ",
        "test_tgt": "@Test public void testGetMetadata_String() { String mdString = \"dc.contributor.author\"; Metadatum[]dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 0\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 1\", dc.length == 0); mdString = \"dc.contributor.*\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 2\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 3\", dc.length == 0); mdString = \"dc.contributor\"; dc = it.getMetadataByMetadataString(mdString); assertThat(\"testGetMetadata_String 4\", dc, notNullValue()); assertTrue(\"testGetMetadata_String 5\", dc.length == 0); } "
    },
    {
        "test_src": "@Test public void testIsSavepoint()throws Exception { { CheckpointProperties props = CheckpointProperties.forStandardCheckpoint(); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forExternalizedCheckpoint(true); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forExternalizedCheckpoint(false); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forStandardSavepoint(); assertTrue(props.isSavepoint()); } } ",
        "focal_tgt": "public boolean isSavepoint() { return savepoint; } ",
        "focal_src": "public boolean isSavepoint() { return this == STANDARD_SAVEPOINT; } ",
        "test_tgt": "@Test public void testIsSavepoint()throws Exception { { CheckpointProperties props = CheckpointProperties.forStandardCheckpoint(); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forExternalizedCheckpoint(true); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forExternalizedCheckpoint(false); assertFalse(props.isSavepoint()); } { CheckpointProperties props = CheckpointProperties.forStandardSavepoint(); assertTrue(props.isSavepoint()); CheckpointProperties deserializedCheckpointProperties = InstantiationUtil.deserializeObject(InstantiationUtil.serializeObject(props), getClass().getClassLoader()); assertTrue(deserializedCheckpointProperties.isSavepoint()); } } "
    },
    {
        "test_src": "@Test public void testGetConnection()throws SQLException, InterruptedException, IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException { expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(true).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockPartition.getAvailableConnections()).andReturn(1).anyTimes(); expect(mockConnectionHandles.poll()).andReturn(mockConnection).once(); mockConnection.renewConnection(); expectLastCall().once(); replay(mockPartition, mockConnectionHandles, mockConnection); assertEquals(mockConnection, testClass.getConnection()); verify(mockPartition, mockConnectionHandles, mockConnection); } ",
        "focal_tgt": "public Connection getConnection()throws SQLException { ConnectionHandle result; long statsObtainTime = 0; if(this.poolShuttingDown) { throw new SQLException(this.shutdownStackTrace); } int partition = (int)(Thread.currentThread().getId() % this.partitionCount); ConnectionPartition connectionPartition = this.partitions[partition]; if(this.statisticsEnabled) { statsObtainTime = System.nanoTime(); this.statistics.incrementConnectionsRequested(); } result = connectionPartition.getFreeConnections().poll(); if(result == null) { for(int i = 0; i < this.partitionCount; i ++ ) { if(i == partition) { continue; } result = this.partitions[i].getFreeConnections().poll(); connectionPartition = this.partitions[i]; if(result != null) { break; } } } if( ! connectionPartition.isUnableToCreateMoreTransactions()) { maybeSignalForMoreConnections(connectionPartition); } if(result == null) { try { result = connectionPartition.getFreeConnections().poll(this.connectionTimeoutInMs, TimeUnit.MILLISECONDS); if(result == null) { throw new SQLException(\"Timed out waiting for a free available connection.\", \"08001\"); } } catch(InterruptedException e) { throw new SQLException(e.getMessage()); } } result.renewConnection(); if(result.getConnectionHook() != null) { result.getConnectionHook().onCheckOut(result); } if(this.closeConnectionWatch) { watchConnection(result); } if(this.statisticsEnabled) { this.statistics.addCumulativeConnectionWaitTime(System.nanoTime() - statsObtainTime); } return result; } ",
        "focal_src": "public Connection getConnection()throws SQLException { ConnectionHandle result; long statsObtainTime = 0; if(this.poolShuttingDown) { throw new SQLException(this.shutdownStackTrace); } int partition = (int)(Thread.currentThread().getId() % this.partitionCount); ConnectionPartition connectionPartition = this.partitions[partition]; if(this.statisticsEnabled) { statsObtainTime = System.nanoTime(); this.statistics.incrementConnectionsRequested(); } result = connectionPartition.getFreeConnections().poll(); if(result == null) { for(int i = 0; i < this.partitionCount; i ++ ) { if(i == partition) { continue; } result = this.partitions[i].getFreeConnections().poll(); connectionPartition = this.partitions[i]; if(result != null) { break; } } } if( ! connectionPartition.isUnableToCreateMoreTransactions()) { maybeSignalForMoreConnections(connectionPartition); } if(result == null) { try { result = connectionPartition.getFreeConnections().poll(this.connectionTimeout, TimeUnit.MILLISECONDS); if(result == null) { throw new SQLException(\"Timed out waiting for a free available connection.\", \"08001\"); } } catch(InterruptedException e) { throw new SQLException(e.getMessage()); } } result.renewConnection(); if(result.getConnectionHook() != null) { result.getConnectionHook().onCheckOut(result); } if(this.closeConnectionWatch) { watchConnection(result); } if(this.statisticsEnabled) { this.statistics.addCumulativeConnectionWaitTime(System.nanoTime() - statsObtainTime); } return result; } ",
        "test_tgt": "@Test public void testGetConnection()throws SQLException, InterruptedException, IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException { expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(true).once(); expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes(); expect(mockPartition.getAvailableConnections()).andReturn(1).anyTimes(); expect(mockConnectionHandles.poll()).andReturn(mockConnection).once(); mockConnection.renewConnection(); expectLastCall().once(); replay(mockPartition, mockConnectionHandles, mockConnection); assertEquals(mockConnection, testClass.getConnection()); verify(mockPartition, mockConnectionHandles, mockConnection); } "
    },
    {
        "test_src": "@Test public void testGetCommandsForCluster()throws GenieException { final List < Command > commands = this.service.getCommandsForCluster(CLUSTER_1_ID); Assert.assertEquals(3, commands.size()); Assert.assertEquals(COMMAND_1_ID, commands.get(0).getId()); Assert.assertEquals(COMMAND_3_ID, commands.get(1).getId()); Assert.assertEquals(COMMAND_2_ID, commands.get(2).getId()); } ",
        "focal_tgt": "@GET@Path(\"/{id}/commands\")@ApiOperation(value = \"Get the commands for a cluster\", notes = \"Get the commands for the cluster with the supplied id.\", response = Command.class, responseContainer = \"List\")@ApiResponses(value = { @ApiResponse(code = HttpURLConnection.HTTP_NOT_FOUND, message = \"Cluster not found\"), @ApiResponse(code = HttpURLConnection.HTTP_PRECON_FAILED, message = \"Invalid required parameter supplied\"), @ApiResponse(code = HttpURLConnection.HTTP_INTERNAL_ERROR, message = \"Genie Server Error due to Unknown Exception\") })public List < Command > getCommandsForCluster(@ApiParam(value = \"Id of the cluster to get commands for.\", required = true)@PathParam(\"id\")final String id, @QueryParam(\"status\")final Set < String > statuses)throws GenieException { LOG.info(\"Called with id \" + id + \" status \" + statuses); Set < CommandStatus > enumStatuses = null; if( ! statuses.isEmpty()) { enumStatuses = EnumSet.noneOf(CommandStatus.class); for(final String status : statuses) { if(StringUtils.isNotBlank(status)) { enumStatuses.add(CommandStatus.parse(status)); } } } return this.clusterConfigService.getCommandsForCluster(id, enumStatuses); } ",
        "focal_src": "@GET@Path(\"/{id}/commands\")@ApiOperation(value = \"Get the commands for a cluster\", notes = \"Get the commands for the cluster with the supplied id.\", response = Command.class, responseContainer = \"List\")@ApiResponses(value = { @ApiResponse(code = HttpURLConnection.HTTP_NOT_FOUND, message = \"Cluster not found\"), @ApiResponse(code = HttpURLConnection.HTTP_PRECON_FAILED, message = \"Invalid required parameter supplied\"), @ApiResponse(code = HttpURLConnection.HTTP_INTERNAL_ERROR, message = \"Genie Server Error due to Unknown Exception\") })public List < Command > getCommandsForCluster(@ApiParam(value = \"Id of the cluster to get commands for.\", required = true)@PathParam(\"id\")final String id)throws GenieException { LOG.info(\"Called with id \" + id); return this.clusterConfigService.getCommandsForCluster(id); } ",
        "test_tgt": "@Test public void testGetCommandsForCluster()throws GenieException { final List < Command > commands = this.service.getCommandsForCluster(CLUSTER_1_ID, null); Assert.assertEquals(3, commands.size()); Assert.assertEquals(COMMAND_1_ID, commands.get(0).getId()); Assert.assertEquals(COMMAND_3_ID, commands.get(1).getId()); Assert.assertEquals(COMMAND_2_ID, commands.get(2).getId()); } "
    },
    {
        "test_src": "@Test public void testGetValueId() { assertThat(\"testGetValueId 0\", mv.getValueId(), notNullValue()); } ",
        "focal_tgt": "public Integer getID() { return id; } ",
        "focal_src": "public int getValueId() { return valueId; } ",
        "test_tgt": "@Test public void testGetValueId() { assertThat(\"testGetValueId 0\", mv.getID(), notNullValue()); } "
    },
    {
        "test_src": "@Test public void testClear() { val q = new WriteQueue(MAX_PARALLELISM); val expectedWrites = new ArrayList < Write > (); for(int i = 0; i < ITEM_COUNT; i ++ ) { val w = new Write(new ByteArraySegment(new byte[i]), new TestWriteLedger(i), CompletableFuture.completedFuture(null)); q.add(w); expectedWrites.add(w); } val removedWrites = q.clear(); AssertExtensions.assertListEquals(\"Unexpected writes removed.\", expectedWrites, removedWrites, Object :: equals); val clearStats = q.getStatistics(); Assert.assertEquals(\"Unexpected getSize after clear.\", 0, clearStats.getSize()); Assert.assertEquals(\"Unexpected getAverageFillRate after clear.\", 0, clearStats.getAverageItemFillRate(), 0); Assert.assertEquals(\"Unexpected getExpectedProcessingTimeMillis after clear.\", 0, clearStats.getExpectedProcessingTimeMillis()); Assert.assertEquals(\"Unexpected getMaxParallelism after clear.\", MAX_PARALLELISM, clearStats.getMaxParallelism()); q.add(new Write(new ByteArraySegment(new byte[BookKeeperConfig.MAX_APPEND_LENGTH]), new TestWriteLedger(0), CompletableFuture.completedFuture(null))); val addStats = q.getStatistics(); Assert.assertEquals(\"Unexpected getSize after clear+add.\", 1, addStats.getSize()); Assert.assertEquals(\"Unexpected getAverageFillRate after clear+add.\", 1, addStats.getAverageItemFillRate(), 0); } ",
        "focal_tgt": "synchronized List < Write > close() { List < Write > items = new ArrayList < > (this.writes); this.writes.clear(); this.totalLength = 0; this.closed = true; return items; } ",
        "focal_src": "synchronized List < Write > clear() { List < Write > items = new ArrayList < > (this.writes); this.writes.clear(); this.totalLength = 0; return items; } ",
        "test_tgt": "@Test public void testClose() { val q = new WriteQueue(MAX_PARALLELISM); val expectedWrites = new ArrayList < Write > (); for(int i = 0; i < ITEM_COUNT; i ++ ) { val w = new Write(new ByteArraySegment(new byte[i]), new TestWriteLedger(i), CompletableFuture.completedFuture(null)); q.add(w); expectedWrites.add(w); } val removedWrites = q.close(); AssertExtensions.assertListEquals(\"Unexpected writes removed.\", expectedWrites, removedWrites, Object :: equals); val clearStats = q.getStatistics(); Assert.assertEquals(\"Unexpected getSize after clear.\", 0, clearStats.getSize()); Assert.assertEquals(\"Unexpected getAverageFillRate after clear.\", 0, clearStats.getAverageItemFillRate(), 0); Assert.assertEquals(\"Unexpected getExpectedProcessingTimeMillis after clear.\", 0, clearStats.getExpectedProcessingTimeMillis()); Assert.assertEquals(\"Unexpected getMaxParallelism after clear.\", MAX_PARALLELISM, clearStats.getMaxParallelism()); AssertExtensions.assertThrows(\"add() worked after close().\", () -> q.add(new Write(new ByteArraySegment(new byte[1]), new TestWriteLedger(0), CompletableFuture.completedFuture(null))), ex -> ex instanceof ObjectClosedException); AssertExtensions.assertThrows(\"getWritesToExecute() worked after close().\", () -> q.getWritesToExecute(1), ex -> ex instanceof ObjectClosedException); AssertExtensions.assertThrows(\"removeFinishedWrites() worked after close().\", q :: removeFinishedWrites, ex -> ex instanceof ObjectClosedException); } "
    },
    {
        "test_src": "@Test public void testCsv() { String text = null; EscapeTool instance = new EscapeTool(); String expResult = null; String result = instance.csv(text); assertEquals(expResult, result); text = \"\"; expResult = \"\"; result = instance.csv(text); assertEquals(expResult, result); text = \"one, two\"; expResult = \"\\\"one, two\\\"\"; result = instance.csv(text); assertEquals(expResult, result); } ",
        "focal_tgt": "public String csv(String text) { if(text == null || text.isEmpty()) { return \"\\\"\\\"\"; } return StringEscapeUtils.escapeCsv(text.trim().replace(\"\\n\", \" \")); } ",
        "focal_src": "public String csv(String text) { if(text == null || text.isEmpty()) { return text; } return StringEscapeUtils.escapeCsv(text.trim().replace(\"\\n\", \" \")); } ",
        "test_tgt": "@Test public void testCsv() { String text = null; EscapeTool instance = new EscapeTool(); String expResult = null; String result = instance.csv(text); assertEquals(expResult, result); text = \"\"; expResult = \"\\\"\\\"\"; result = instance.csv(text); assertEquals(expResult, result); text = \"one, two\"; expResult = \"\\\"one, two\\\"\"; result = instance.csv(text); assertEquals(expResult, result); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"reset\", args = { })public void test_reset() { InputStream is = new ByteArrayInputStream(new byte[10]); InflaterInputStream iis = new InflaterInputStream(is); try { iis.reset(); fail(\"Should throw IOException\"); } catch(IOException e) { } } ",
        "focal_tgt": "public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { breakBarrier(); nextGeneration(); } finally { lock.unlock(); } } ",
        "focal_src": "public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { generation -= 4; broken = false; trip.signalAll(); } finally { lock.unlock(); } } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"reset\", args = { })public void test_reset() { InputStream is = new ByteArrayInputStream(new byte[10]); InflaterInputStream iis = new InflaterInputStream(is); try { iis.reset(); fail(\"Should throw IOException\"); } catch(IOException e) { } } "
    },
    {
        "test_src": "@Test public void close() { query(conn() + \" ! \" + _CLIENT_CLOSE.args(\" .\")); error(_CLIENT_CLOSE.args(\"xs:anyURI('unknown')\"), Err.BXCL_NOTAVL); error(conn() + \" ! (\" + _CLIENT_CLOSE.args(\" .\") + \", \" + _CLIENT_CLOSE.args(\" .\") + \")\", Err.BXCL_NOTAVL); } ",
        "focal_tgt": "public void close() { for(int i = 0; i < conns.size(); i ++ ) { final int key = conns.key(i); final Object obj = conns.get(key); if(obj == null)continue; try { if(obj instanceof Connection)((Connection)obj).close(); else((Statement)obj).close(); } catch(final SQLException ex) { Util.debug(ex); } } } ",
        "focal_src": "public void close() { for(int i = 0; i < conns.size(); i ++ ) { final int key = conns.key(i); final Object obj = conns.get(key); if(obj == null)continue; try { if(obj instanceof Connection)((Connection)obj).close(); else((PreparedStatement)obj).close(); } catch(final SQLException ex) { Util.debug(ex); } } } ",
        "test_tgt": "@Test public void close() { query(conn() + \" ! \" + _CLIENT_CLOSE.args(\" .\")); error(_CLIENT_CLOSE.args(\"xs:anyURI('unknown')\"), Err.BXCL_NOTAVL); error(conn() + \" ! (\" + _CLIENT_CLOSE.args(\" .\") + \", \" + _CLIENT_CLOSE.args(\" .\") + ')', Err.BXCL_NOTAVL); } "
    },
    {
        "test_src": "@Test public void list()throws IOException { String testDirNonEmpty = PathUtils.concatPath(mUnderfsAddress, \"testDirNonEmpty1\"); String testDirNonEmptyChildDir = PathUtils.concatPath(testDirNonEmpty, \"testDirNonEmpty2\"); String testDirNonEmptyChildFile = PathUtils.concatPath(testDirNonEmpty, \"testDirNonEmptyF\"); String testDirNonEmptyChildDirFile = PathUtils.concatPath(testDirNonEmptyChildDir, \"testDirNonEmptyChildDirF\"); mUfs.mkdirs(testDirNonEmpty, MkdirsOptions.defaults().setCreateParent(false)); mUfs.mkdirs(testDirNonEmptyChildDir, MkdirsOptions.defaults().setCreateParent(false)); createEmptyFile(testDirNonEmptyChildFile); createEmptyFile(testDirNonEmptyChildDirFile); String[]expectedResTopDir = new String[] { \"testDirNonEmpty2\", \"testDirNonEmptyF\" }; String[]expectedResTopDir2 = new String[] { \"/testDirNonEmpty2\", \"/testDirNonEmptyF\" }; Arrays.sort(expectedResTopDir); Arrays.sort(expectedResTopDir2); UnderFileStatus[]resTopDir = mUfs.list(testDirNonEmpty); Arrays.sort(resTopDir); Assert.assertTrue(Arrays.equals(expectedResTopDir, resTopDir) || Arrays.equals(expectedResTopDir2, resTopDir)); Assert.assertTrue(mUfs.list(testDirNonEmptyChildDir)[0].equals(\"testDirNonEmptyChildDirF\") || mUfs.list(testDirNonEmptyChildDir)[0].equals(\"/testDirNonEmptyChildDirF\")); } ",
        "focal_tgt": "UnderFileStatus[]listStatus(String path)throws IOException; ",
        "focal_src": "UnderFileStatus[]list(String path)throws IOException; ",
        "test_tgt": "@Test public void list()throws IOException { String testDirNonEmpty = PathUtils.concatPath(mUnderfsAddress, \"testDirNonEmpty1\"); String testDirNonEmptyChildDir = PathUtils.concatPath(testDirNonEmpty, \"testDirNonEmpty2\"); String testDirNonEmptyChildFile = PathUtils.concatPath(testDirNonEmpty, \"testDirNonEmptyF\"); String testDirNonEmptyChildDirFile = PathUtils.concatPath(testDirNonEmptyChildDir, \"testDirNonEmptyChildDirF\"); mUfs.mkdirs(testDirNonEmpty, MkdirsOptions.defaults().setCreateParent(false)); mUfs.mkdirs(testDirNonEmptyChildDir, MkdirsOptions.defaults().setCreateParent(false)); createEmptyFile(testDirNonEmptyChildFile); createEmptyFile(testDirNonEmptyChildDirFile); String[]expectedResTopDir = new String[] { \"testDirNonEmpty2\", \"testDirNonEmptyF\" }; String[]expectedResTopDir2 = new String[] { \"/testDirNonEmpty2\", \"/testDirNonEmptyF\" }; Arrays.sort(expectedResTopDir); Arrays.sort(expectedResTopDir2); UnderFileStatus[]resTopDir = mUfs.listStatus(testDirNonEmpty); Arrays.sort(resTopDir); Assert.assertTrue(Arrays.equals(expectedResTopDir, resTopDir) || Arrays.equals(expectedResTopDir2, resTopDir)); Assert.assertTrue(mUfs.listStatus(testDirNonEmptyChildDir)[0].equals(\"testDirNonEmptyChildDirF\") || mUfs.listStatus(testDirNonEmptyChildDir)[0].equals(\"/testDirNonEmptyChildDirF\")); } "
    },
    {
        "test_src": "@Test public void getStatus()throws Exception { AlluxioURI file = new AlluxioURI(\"/file\"); URIStatus status = new URIStatus(new FileInfo()); Mockito.when(mFileSystemMasterClient.getStatus(file)).thenReturn(status); GetStatusOptions getStatusOptions = GetStatusOptions.defaults(); Assert.assertSame(status, mFileSystem.getStatus(file, getStatusOptions)); Mockito.verify(mFileSystemMasterClient).getStatus(file); } ",
        "focal_tgt": "public FileInfo getStatus(String path, GetStatusTOptions options)throws alluxio.thrift.AlluxioTException, org.apache.thrift.TException; ",
        "focal_src": "public FileInfo getStatus(String path)throws alluxio.thrift.AlluxioTException, org.apache.thrift.TException; ",
        "test_tgt": "@Test public void getStatus()throws Exception { AlluxioURI file = new AlluxioURI(\"/file\"); URIStatus status = new URIStatus(new FileInfo()); GetStatusOptions getStatusOptions = GetStatusOptions.defaults(); Mockito.when(mFileSystemMasterClient.getStatus(file, getStatusOptions)).thenReturn(status); Assert.assertSame(status, mFileSystem.getStatus(file, getStatusOptions)); Mockito.verify(mFileSystemMasterClient).getStatus(file, getStatusOptions); } "
    },
    {
        "test_src": "@Test public void testGetOAuthQueryString()throws Exception { final TreeMap < String, Set < CharSequence > > params = new TreeMap < String, Set < CharSequence > > (); CoreOAuthConsumerSupport support = new CoreOAuthConsumerSupport() { @Override protected Map < String, Set < CharSequence > > loadOAuthParameters(ProtectedResourceDetails details, URL requestURL, OAuthConsumerToken requestToken, String httpMethod, Map < String, String > additionalParameters) { return params; } }; URL url = new URL(\"https://myhost.com/somepath?with=some&query=params&too\"); OAuthConsumerToken token = new OAuthConsumerToken(); when(details.isAcceptsAuthorizationHeader()).thenReturn(true); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); params.put(\"query\", Collections.singleton((CharSequence)\"params\")); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"query=params&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); when(details.isAcceptsAuthorizationHeader()).thenReturn(false); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); params.put(\"query\", Collections.singleton((CharSequence)\"params\")); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"oauth_consumer_key=mykey&oauth_nonce=mynonce&oauth_timestamp=myts&query=params&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); when(details.isAcceptsAuthorizationHeader()).thenReturn(false); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); String encoded_space = URLEncoder.encode(\" \", \"utf-8\"); params.put(\"query\", Collections.singleton((CharSequence)(\"params\" + encoded_space + \"spaced\"))); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"oauth_consumer_key=mykey&oauth_nonce=mynonce&oauth_timestamp=myts&query=params\" + encoded_space + \"spaced&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); } ",
        "focal_tgt": "public String getOAuthQueryString(ProtectedResourceDetails details, OAuthConsumerToken accessToken, URL url, String httpMethod, Map < String, String > additionalParameters) { Map < String, Set < CharSequence > > oauthParams = loadOAuthParameters(details, url, accessToken, httpMethod, additionalParameters); StringBuilder queryString = new StringBuilder(); if(details.isAcceptsAuthorizationHeader()) { for(OAuthConsumerParameter oauthParam : OAuthConsumerParameter.values()) { oauthParams.remove(oauthParam.toString()); } if(additionalParameters != null) { for(String additionalParam : additionalParameters.keySet()) { oauthParams.remove(additionalParam); } } } Iterator < String > parametersIt = oauthParams.keySet().iterator(); while(parametersIt.hasNext()) { String parameter = parametersIt.next(); queryString.append(parameter); Set < CharSequence > values = oauthParams.get(parameter); if(values != null) { Iterator < CharSequence > valuesIt = values.iterator(); while(valuesIt.hasNext()) { CharSequence parameterValue = valuesIt.next(); if(parameterValue != null) { queryString.append('=').append(urlEncode(parameterValue.toString())); } if(valuesIt.hasNext()) { queryString.append('&').append(parameter); } } } if(parametersIt.hasNext()) { queryString.append('&'); } } return queryString.toString(); } ",
        "focal_src": "public String getOAuthQueryString(ProtectedResourceDetails details, OAuthConsumerToken accessToken, URL url, String httpMethod, Map < String, String > additionalParameters) { Map < String, Set < CharSequence > > oauthParams = loadOAuthParameters(details, url, accessToken, httpMethod, additionalParameters); StringBuilder queryString = new StringBuilder(); if(details.isAcceptsAuthorizationHeader()) { for(OAuthConsumerParameter oauthParam : OAuthConsumerParameter.values()) { oauthParams.remove(oauthParam.toString()); } if(additionalParameters != null) { for(String additionalParam : additionalParameters.keySet()) { oauthParams.remove(additionalParam); } } } Iterator < String > parametersIt = oauthParams.keySet().iterator(); while(parametersIt.hasNext()) { String parameter = parametersIt.next(); queryString.append(parameter); Set < CharSequence > values = oauthParams.get(parameter); if(values != null) { Iterator < CharSequence > valuesIt = values.iterator(); while(valuesIt.hasNext()) { CharSequence parameterValue = valuesIt.next(); if(parameterValue != null) { queryString.append('=').append(parameterValue); } if(valuesIt.hasNext()) { queryString.append('&').append(parameter); } } } if(parametersIt.hasNext()) { queryString.append('&'); } } return queryString.toString(); } ",
        "test_tgt": "@Test public void testGetOAuthQueryString()throws Exception { final TreeMap < String, Set < CharSequence > > params = new TreeMap < String, Set < CharSequence > > (); CoreOAuthConsumerSupport support = new CoreOAuthConsumerSupport() { @Override protected Map < String, Set < CharSequence > > loadOAuthParameters(ProtectedResourceDetails details, URL requestURL, OAuthConsumerToken requestToken, String httpMethod, Map < String, String > additionalParameters) { return params; } }; URL url = new URL(\"https://myhost.com/somepath?with=some&query=params&too\"); OAuthConsumerToken token = new OAuthConsumerToken(); when(details.isAcceptsAuthorizationHeader()).thenReturn(true); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); params.put(\"query\", Collections.singleton((CharSequence)\"params\")); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"query=params&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); when(details.isAcceptsAuthorizationHeader()).thenReturn(false); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); params.put(\"query\", Collections.singleton((CharSequence)\"params\")); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"oauth_consumer_key=mykey&oauth_nonce=mynonce&oauth_timestamp=myts&query=params&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); when(details.isAcceptsAuthorizationHeader()).thenReturn(false); params.put(\"with\", Collections.singleton((CharSequence)\"some\")); String encoded_space = URLEncoder.encode(\" \", \"utf-8\"); params.put(\"query\", Collections.singleton((CharSequence)(\"params spaced\"))); params.put(\"too\", null); params.put(OAuthConsumerParameter.oauth_consumer_key.toString(), Collections.singleton((CharSequence)\"mykey\")); params.put(OAuthConsumerParameter.oauth_nonce.toString(), Collections.singleton((CharSequence)\"mynonce\")); params.put(OAuthConsumerParameter.oauth_timestamp.toString(), Collections.singleton((CharSequence)\"myts\")); assertEquals(\"oauth_consumer_key=mykey&oauth_nonce=mynonce&oauth_timestamp=myts&query=params\" + encoded_space + \"spaced&too&with=some\", support.getOAuthQueryString(details, token, url, \"POST\", null)); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"receive\", args = { int.class })public void test_receive()throws IOException { pis = new PipedInputStream(); pos = new PipedOutputStream(); pis.connect(pos); class WriteRunnable implements Runnable { boolean pass = false; boolean readerAlive = true; public void run() { try { pos.write(1); while(readerAlive) { Thread.sleep(100); } try { pos.write(1); } catch(IOException e) { pass = true; } } catch(IOException e) { } catch(InterruptedException e) { } } } WriteRunnable writeRunnable = new WriteRunnable(); Thread writeThread = new Thread(writeRunnable); class ReadRunnable implements Runnable { boolean pass; public void run() { try { pis.read(); pass = true; } catch(IOException e) { } } }; ReadRunnable readRunnable = new ReadRunnable(); Thread readThread = new Thread(readRunnable); writeThread.start(); readThread.start(); while(readThread.isAlive()); writeRunnable.readerAlive = false; assertTrue(\"reader thread failed to read\", readRunnable.pass); while(writeThread.isAlive()); assertTrue(\"writer thread failed to recognize dead reader\", writeRunnable.pass); pis = new PipedInputStream(); pos = new PipedOutputStream(); pis.connect(pos); class MyRunnable implements Runnable { boolean pass; public void run() { try { pos.write(1); } catch(IOException e) { pass = true; } } } MyRunnable myRun = new MyRunnable(); synchronized(pis) { t = new Thread(myRun); t.start(); try { Thread.sleep(100); } catch(InterruptedException e) { } pos.close(); } while(t.isAlive()) { ; } assertTrue(\"write failed to throw IOException on closed PipedOutputStream\", myRun.pass); } ",
        "focal_tgt": "public synchronized void receive(DatagramPacket pack)throws IOException { checkClosedAndBind(true); InetAddress senderAddr; int senderPort; DatagramPacket tempPack = new DatagramPacket(new byte[1], 1); boolean copy = false; SecurityManager security = System.getSecurityManager(); if(address != null || security != null) { if(pack == null) { throw new NullPointerException(); } while(true) { copy = false; try { senderPort = impl.peekData(tempPack); senderAddr = tempPack.getAddress(); } catch(SocketException e) { if(e.getMessage().equals(\"The socket does not support the operation\")) { tempPack = new DatagramPacket(new byte[pack.capacity], pack.capacity); impl.receive(tempPack); senderAddr = tempPack.getAddress(); senderPort = tempPack.getPort(); copy = true; } else { throw e; } } if(address == null) { try { security.checkAccept(senderAddr.getHostName(), senderPort); break; } catch(SecurityException e) { if( ! copy) { impl.receive(tempPack); } } } else if(port == senderPort && address.equals(senderAddr)) { break; } else if( ! copy) { impl.receive(tempPack); } } } if(copy) { System.arraycopy(tempPack.getData(), 0, pack.getData(), pack.getOffset(), tempPack.getLength()); pack.length = tempPack.length; pack.setAddress(tempPack.getAddress()); pack.setPort(tempPack.getPort()); } else { pack.setLength(pack.capacity); impl.receive(pack); } } ",
        "focal_src": "public synchronized void receive(DatagramPacket pack)throws IOException { checkClosedAndBind(true); boolean secure = true; InetAddress senderAddr = null; int senderPort = 0; DatagramPacket tempPack = new DatagramPacket(new byte[1], 1); boolean copy = false; SecurityManager security = System.getSecurityManager(); if(address != null || security != null) { if(pack == null) { throw new NullPointerException(); } secure = false; while( ! secure) { copy = false; try { senderPort = impl.peekData(tempPack); senderAddr = tempPack.getAddress(); } catch(SocketException e) { if(e.getMessage().equals(\"The socket does not support the operation\")) { tempPack = new DatagramPacket(new byte[pack.length], pack.getLength()); impl.receive(tempPack); senderAddr = tempPack.getAddress(); senderPort = tempPack.getPort(); copy = true; } else { throw e; } } if(address == null) { try { security.checkAccept(senderAddr.getHostName(), senderPort); if( ! copy) { secure = true; } break; } catch(SecurityException e) { if( ! copy) { if(tempPack == null) { tempPack = new DatagramPacket(new byte[pack.length], pack.length); } impl.receive(tempPack); } } } else if(port == senderPort && address.equals(senderAddr)) { if( ! copy) { secure = true; } break; } else if( ! copy) { if(tempPack == null) { tempPack = new DatagramPacket(new byte[pack.length], pack.length); } impl.receive(tempPack); } } } if(copy) { System.arraycopy(tempPack.getData(), 0, pack.getData(), pack.getOffset(), tempPack.getLength()); pack.setLength(tempPack.getLength()); pack.setAddress(tempPack.getAddress()); pack.setPort(tempPack.getPort()); } if(secure) { impl.receive(pack); } } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"receive\", args = { int.class })@BrokenTest(value = \"bug 2002061\")public void test_receive()throws IOException { pis = new PipedInputStream(); pos = new PipedOutputStream(); pis.connect(pos); class WriteRunnable implements Runnable { boolean pass = false; boolean readerAlive = true; public void run() { try { pos.write(1); while(readerAlive) { Thread.sleep(100); } try { pos.write(1); } catch(IOException e) { pass = true; } } catch(IOException e) { } catch(InterruptedException e) { } } } WriteRunnable writeRunnable = new WriteRunnable(); Thread writeThread = new Thread(writeRunnable); class ReadRunnable implements Runnable { boolean pass; public void run() { try { pis.read(); pass = true; } catch(IOException e) { } } }; ReadRunnable readRunnable = new ReadRunnable(); Thread readThread = new Thread(readRunnable); writeThread.start(); readThread.start(); while(readThread.isAlive()); writeRunnable.readerAlive = false; assertTrue(\"reader thread failed to read\", readRunnable.pass); while(writeThread.isAlive()); assertTrue(\"writer thread failed to recognize dead reader\", writeRunnable.pass); pis = new PipedInputStream(); pos = new PipedOutputStream(); pis.connect(pos); class MyRunnable implements Runnable { boolean pass; public void run() { try { pos.write(1); } catch(IOException e) { pass = true; } } } MyRunnable myRun = new MyRunnable(); synchronized(pis) { t = new Thread(myRun); t.start(); try { Thread.sleep(100); } catch(InterruptedException e) { } pos.close(); } while(t.isAlive()) { ; } assertTrue(\"write failed to throw IOException on closed PipedOutputStream\", myRun.pass); } "
    },
    {
        "test_src": "@Test public void testReadPatterns() { } ",
        "focal_tgt": "public static Set < String > readPatterns(File patternFile)throws IOException { Set < String > patterns = new HashSet < > (); if( ! patternFile.exists() || ! patternFile.isFile()) { return patterns; } try(BufferedReader in = new BufferedReader(new FileReader(patternFile))) { String line; while((line = in.readLine()) != null) { if( ! line.startsWith(\"#\")) { line = line.trim(); if( ! line.equals(\"\")) { patterns.add(line); } } else { } } } return patterns; } ",
        "focal_src": "public static Set < String > readPatterns(File patternFile)throws IOException { Set < String > patterns = new HashSet < String > (); if( ! patternFile.exists() || ! patternFile.isFile()) { return patterns; } BufferedReader in = new BufferedReader(new FileReader(patternFile)); String line; while((line = in.readLine()) != null) { if( ! line.startsWith(\"#\")) { line = line.trim(); if( ! line.equals(\"\")) { patterns.add(line); } } else { } } in.close(); return patterns; } ",
        "test_tgt": "@Test public void testReadPatterns() { } "
    },
    {
        "test_src": "@Test public final void singleElementArrayToGetInstance() { final Predicate < T > predicate = createMockPredicate(null); final Predicate < T > allPredicate = getPredicateInstance(predicate); assertSame(\"expected argument to be returned by getInstance()\", predicate, allPredicate); } ",
        "focal_tgt": "@SuppressWarnings(\"unchecked\")public void singleElementArrayToGetInstance() { final Predicate < T > predicate = createMockPredicate(null); final Predicate < T > allPredicate = getPredicateInstance(predicate); Assert.assertSame(\"expected argument to be returned by getInstance()\", predicate, allPredicate); } ",
        "focal_src": "public void singleElementArrayToGetInstance() { final Predicate < T > predicate = createMockPredicate(null); final Predicate < T > allPredicate = getPredicateInstance(predicate); Assert.assertSame(\"expected argument to be returned by getInstance()\", predicate, allPredicate); } ",
        "test_tgt": "@SuppressWarnings(\"unchecked\")@Test public final void singleElementArrayToGetInstance() { final Predicate < T > predicate = createMockPredicate(null); final Predicate < T > allPredicate = getPredicateInstance(predicate); assertSame(\"expected argument to be returned by getInstance()\", predicate, allPredicate); } "
    },
    {
        "test_src": "@Test public void testPutAll_MultiMap_Simple() { MultiMap < String > mm = new MultiMap < String > (); assertMapSize(mm, 0); MultiMap < String > input = new MultiMap < String > (); input.put(\"food\", \"apple\"); input.put(\"color\", \"red\"); input.put(\"amount\", \"bushel\"); mm.putAll(input); assertMapSize(mm, 3); assertValues(mm, \"food\", \"apple\"); assertValues(mm, \"color\", \"red\"); assertValues(mm, \"amount\", \"bushel\"); } ",
        "focal_tgt": "@Override public void putAll(Map < ? extends String, ? extends Object > m) { boolean multi = (m instanceof MultiMap); if(multi) { for(Map.Entry < ? extends String, ? extends Object > entry : m.entrySet()) { _map.put(entry.getKey(), LazyList.clone(entry.getValue())); } } else { _map.putAll(m); } } ",
        "focal_src": "public void putAll(Map < ? extends K, ? extends Object > m) { boolean multi = (m instanceof MultiMap); if(multi) { for(Map.Entry < ? extends K, ? extends Object > entry : m.entrySet()) { _map.put(entry.getKey(), LazyList.clone(entry.getValue())); } } else { _map.putAll(m); } } ",
        "test_tgt": "@Test public void testPutAll_MultiMap_Simple() { MultiMap mm = new MultiMap(); assertMapSize(mm, 0); MultiMap input = new MultiMap(); input.put(\"food\", \"apple\"); input.put(\"color\", \"red\"); input.put(\"amount\", \"bushel\"); mm.putAll(input); assertMapSize(mm, 3); assertValues(mm, \"food\", \"apple\"); assertValues(mm, \"color\", \"red\"); assertValues(mm, \"amount\", \"bushel\"); } "
    },
    {
        "test_src": "@Test public void findErrorLocatorBM() { GrowQueue_I8 message = GrowQueue_I8.parseHex(\"[ 0x40, 0xd2, 0x75, 0x47, 0x76, 0x17, 0x32, 0x06, 0x27, 0x26, 0x96, 0xc6, 0xc6, 0x96, 0x70, 0xec ]\"); GrowQueue_I8 ecc = new GrowQueue_I8(); int nsyn = 10; int syndromes[] = new int[nsyn]; ReidSolomonCodes alg = new ReidSolomonCodes(8, primitive8); alg.generator(nsyn); alg.computeECC(message, ecc); message.data[0] = 0; alg.computeSyndromes(message, ecc, syndromes); GrowQueue_I8 errorLocator = new GrowQueue_I8(); alg.findErrorLocatorBM(syndromes, nsyn, errorLocator); assertEquals(2, errorLocator.size); assertEquals(3, errorLocator.get(0)); assertEquals(1, errorLocator.get(1)); message.data[6] = 10; alg.computeSyndromes(message, ecc, syndromes); alg.findErrorLocatorBM(syndromes, nsyn, errorLocator); assertEquals(3, errorLocator.size); assertEquals(238, errorLocator.get(0) & 0xFF); assertEquals(89, errorLocator.get(1)); assertEquals(1, errorLocator.get(2)); } ",
        "focal_tgt": "void findErrorLocatorPolynomialBM(int syndromes[], int length, GrowQueue_I8 errorLocator) { GrowQueue_I8 C = errorLocator; GrowQueue_I8 B = new GrowQueue_I8(); initToOne(C, length + 1); initToOne(B, length + 1); GrowQueue_I8 tmp = new GrowQueue_I8(length); int b = 1; for(int n = 0; n < length; n ++ ) { int delta = syndromes[n]; for(int j = 1; j < C.size; j ++ ) { delta ^= math.multiply(C.data[C.size - j - 1] & 0xFF, syndromes[n - j]); } B.data[B.size ++ ] = 0; if(delta != 0) { int scale = math.multiply(delta, math.inverse(b)); math.polyAddScaleB(C, B, scale, tmp); if(2 * C.size > length) { } else { B.setTo(C); b = delta; } C.setTo(tmp); } } removeLeadingZeros(C); } ",
        "focal_src": "void findErrorLocatorBM(int syndromes[], int length, GrowQueue_I8 errorLocator) { GrowQueue_I8 C = errorLocator; GrowQueue_I8 B = new GrowQueue_I8(); initToOne(C, length + 1); initToOne(B, length + 1); GrowQueue_I8 tmp = new GrowQueue_I8(length); int b = 1; for(int n = 0; n < length; n ++ ) { int delta = syndromes[n]; for(int j = 1; j < C.size; j ++ ) { delta ^= math.multiply(C.data[C.size - j - 1] & 0xFF, syndromes[n - j]); } B.data[B.size ++ ] = 0; if(delta != 0) { int scale = math.multiply(delta, math.inverse(b)); math.polyAddScaleB(C, B, scale, tmp); if(2 * C.size > length) { } else { B.setTo(C); b = delta; } C.setTo(tmp); } } removeLeadingZeros(C); } ",
        "test_tgt": "@Test public void findErrorLocatorPolynomialBM() { GrowQueue_I8 message = GrowQueue_I8.parseHex(\"[ 0x40, 0xd2, 0x75, 0x47, 0x76, 0x17, 0x32, 0x06, 0x27, 0x26, 0x96, 0xc6, 0xc6, 0x96, 0x70, 0xec ]\"); GrowQueue_I8 ecc = new GrowQueue_I8(); int nsyn = 10; int syndromes[] = new int[nsyn]; ReidSolomonCodes alg = new ReidSolomonCodes(8, primitive8); alg.generator(nsyn); alg.computeECC(message, ecc); message.data[0] = 0; alg.computeSyndromes(message, ecc, syndromes); GrowQueue_I8 errorLocator = new GrowQueue_I8(); alg.findErrorLocatorPolynomialBM(syndromes, nsyn, errorLocator); assertEquals(2, errorLocator.size); assertEquals(3, errorLocator.get(0)); assertEquals(1, errorLocator.get(1)); message.data[6] = 10; alg.computeSyndromes(message, ecc, syndromes); alg.findErrorLocatorPolynomialBM(syndromes, nsyn, errorLocator); assertEquals(3, errorLocator.size); assertEquals(238, errorLocator.get(0) & 0xFF); assertEquals(89, errorLocator.get(1)); assertEquals(1, errorLocator.get(2)); } "
    },
    {
        "test_src": "@Test public void testAddWords()throws InterruptedException, FileNotFoundException { String id = \"foo\"; Word newWord = loadFixture(\"src/test/resources/speech_to_text/word.json\", Word.class); Map < String, Object > wordsAsMap = new HashMap < String, Object > (); wordsAsMap.put(\"words\", new Word[] { newWord }); server.enqueue(new MockResponse().addHeader(CONTENT_TYPE, HttpMediaType.APPLICATION_JSON).setBody(\"{}\")); AddWordsOptions addOptions = new AddWordsOptions.Builder().customizationId(id).customWords(new CustomWords.Builder().addWords(new CustomWord.Builder().word(newWord.getWord()).displayAs(newWord.getDisplayAs()).soundsLike(newWord.getSoundsLike()).build()).build()).build(); service.addWords(addOptions).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(\"POST\", request.getMethod()); assertEquals(String.format(PATH_WORDS, id), request.getPath()); assertEquals(GSON.toJson(wordsAsMap), request.getBody().readUtf8()); } ",
        "focal_tgt": "public ServiceCall < Void > addWords(AddWordsOptions addWordsOptions) { Validator.notNull(addWordsOptions, \"addWordsOptions cannot be null\"); RequestBuilder builder = RequestBuilder.post(String.format(\"/v1/customizations/%s/words\", addWordsOptions.customizationId())); final JsonObject contentJson = new JsonObject(); contentJson.add(\"words\", GsonSingleton.getGson().toJsonTree(addWordsOptions.words())); builder.bodyJson(contentJson); return createServiceCall(builder.build(), ResponseConverterUtils.getVoid()); } ",
        "focal_src": "public ServiceCall < Void > addWords(AddWordsOptions addWordsOptions) { Validator.notNull(addWordsOptions, \"addWordsOptions cannot be null\"); RequestBuilder builder = RequestBuilder.post(String.format(\"/v1/customizations/%s/words\", addWordsOptions.customizationId())); builder.header(\"Content-Type\", addWordsOptions.contentType()); if(addWordsOptions.contentType().equalsIgnoreCase(AddWordsOptions.ContentType.APPLICATION_JSON)) { builder.bodyJson(GsonSingleton.getGson().toJsonTree(addWordsOptions.customWords()).getAsJsonObject()); } return createServiceCall(builder.build(), ResponseConverterUtils.getVoid()); } ",
        "test_tgt": "@Test public void testAddWords()throws InterruptedException, FileNotFoundException { String id = \"foo\"; Word newWord = loadFixture(\"src/test/resources/speech_to_text/word.json\", Word.class); Map < String, Object > wordsAsMap = new HashMap < String, Object > (); wordsAsMap.put(\"words\", new Word[] { newWord }); server.enqueue(new MockResponse().addHeader(CONTENT_TYPE, HttpMediaType.APPLICATION_JSON).setBody(\"{}\")); CustomWord word = new CustomWord(); word.setWord(newWord.getWord()); word.setDisplayAs(newWord.getDisplayAs()); word.setSoundsLike(newWord.getSoundsLike()); AddWordsOptions addOptions = new AddWordsOptions.Builder().customizationId(id).addWords(word).build(); service.addWords(addOptions).execute(); final RecordedRequest request = server.takeRequest(); assertEquals(\"POST\", request.getMethod()); assertEquals(String.format(PATH_WORDS, id), request.getPath()); assertEquals(GSON.toJson(wordsAsMap), request.getBody().readUtf8()); } "
    },
    {
        "test_src": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration configuration = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(configuration); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String storageName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters(); trainingParameters.setDataTransformerTrainingParameters(dtParams); trainingParameters.setFeatureSelectorTrainingParameters(null); Modeler instance = MLBuilder.create(trainingParameters, configuration); instance.fit(trainingData); instance.save(storageName); instance.close(); instance = MLBuilder.load(Modeler.class, storageName, configuration); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); trainingData.close(); instance.close(); instance = MLBuilder.load(Modeler.class, storageName, configuration); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); validationData.close(); } ",
        "focal_tgt": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(ML.AbstractTrainingParameters modelerTrainingParameters, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score, int testId) { Configuration configuration = Configuration.getConfiguration(); String storageName = this.getClass().getSimpleName() + testId; Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setNumericalScalerTrainingParameters(null); trainingParameters.setCategoricalEncoderTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = MLBuilder.create(trainingParameters, configuration); instance.fit(dataset); instance.save(storageName); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(TextClassifier.class, storageName, configuration); Dataframe validationData; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.close(); } ",
        "focal_src": "private < ML extends AbstractClassifier, FS extends AbstractFeatureSelector > void trainAndValidate(ML.AbstractTrainingParameters modelerTrainingParameters, FS.AbstractTrainingParameters featureSelectorTrainingParameters, double expectedF1score, int testId) { Configuration configuration = Configuration.getConfiguration(); String storageName = this.getClass().getSimpleName() + testId; Map < Object, URI > dataset = new HashMap < > (); try { dataset.put(\"negative\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.neg.txt\").toURI()); dataset.put(\"positive\", this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.pos.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters(); trainingParameters.setModelerTrainingParameters(modelerTrainingParameters); trainingParameters.setDataTransformerTrainingParameters(null); trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters); NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters(); exParams.setMaxDistanceBetweenKwds(2); exParams.setExaminationWindowLength(6); trainingParameters.setTextExtractorParameters(exParams); TextClassifier instance = MLBuilder.create(trainingParameters, configuration); instance.fit(dataset); instance.save(storageName); ClassificationMetrics vm = instance.validate(dataset); assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); instance.close(); instance = MLBuilder.load(TextClassifier.class, storageName, configuration); Dataframe validationData; try { validationData = instance.predict(this.getClass().getClassLoader().getResource(\"datasets/sentimentAnalysis.unlabelled.txt\").toURI()); } catch(UncheckedIOException | URISyntaxException ex) { logger.warn(\"Unable to download datasets, skipping test.\"); throw new RuntimeException(ex); } List < Object > expResult = Arrays.asList(\"negative\", \"positive\"); int i = 0; for(Record r : validationData.values()) { assertEquals(expResult.get(i), r.getYPredicted()); ++ i; } instance.delete(); validationData.close(); } ",
        "test_tgt": "@Test public void testTrainAndValidate() { logger.info(\"testTrainAndValidate\"); Configuration configuration = Configuration.getConfiguration(); Dataframe[]data = Datasets.carsNumeric(configuration); Dataframe trainingData = data[0]; Dataframe validationData = data[1]; String storageName = this.getClass().getSimpleName(); Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters(); MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters(); trainingParameters.setNumericalScalerTrainingParameters(nsParams); CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters(); trainingParameters.setCategoricalEncoderTrainingParameters(ceParams); trainingParameters.setFeatureSelectorTrainingParameters(null); MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters(); modelTrainingParameters.setMultiProbabilityWeighted(true); trainingParameters.setModelerTrainingParameters(modelTrainingParameters); Modeler instance = MLBuilder.create(trainingParameters, configuration); instance.fit(trainingData); instance.save(storageName); instance.close(); instance = MLBuilder.load(Modeler.class, storageName, configuration); instance.predict(trainingData); ClassificationMetrics vm = new ClassificationMetrics(trainingData); double expResult2 = 0.8; assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH); trainingData.close(); instance.close(); instance = MLBuilder.load(Modeler.class, storageName, configuration); instance.predict(validationData); Map < Integer, Object > expResult = new HashMap < > (); Map < Integer, Object > result = new HashMap < > (); for(Map.Entry < Integer, Record > e : validationData.entries()) { Integer rId = e.getKey(); Record r = e.getValue(); expResult.put(rId, r.getY()); result.put(rId, r.getYPredicted()); } assertEquals(expResult, result); instance.delete(); validationData.close(); } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"stop\", args = { })@AndroidOnly(\"Android throws UnsupportedOperationException for Thread.stop()\")@SuppressWarnings(\"deprecation\")public void test_stop() { try { Runnable r = new ResSupThread(null); synchronized(r) { st = new Thread(r, \"Interupt Test5\"); st.start(); r.wait(); } } catch(InterruptedException e) { fail(\"Unexpected interrupt received\"); } try { st.stop(); fail(\"Expected UnsupportedOperationException because\" + \"Thread.stop is not supported.\"); } catch(UnsupportedOperationException e) { } SecurityManager sm = new SecurityManager() { public void checkPermission(Permission perm) { if(perm.getName().equals(\"stopThread\")) { throw new SecurityException(); } } }; st = new Thread(); SecurityManager oldSm = System.getSecurityManager(); System.setSecurityManager(sm); try { st.stop(); fail(\"Should throw SecurityException\"); } catch(SecurityException e) { } finally { System.setSecurityManager(oldSm); } } ",
        "focal_tgt": "@SuppressWarnings(\"ThrowableInstanceNeverThrown\")void stop(Throwable throwable) { Logger.global.log(Level.SEVERE, UNSUPPORTED_THREAD_METHOD, new UnsupportedOperationException()); } ",
        "focal_src": "void stop(Throwable throwable) { throw new UnsupportedOperationException(\"Deprecated Thread methods are not supported.\"); } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"stop\", args = { })@AndroidOnly(\"Android throws UnsupportedOperationException for Thread.stop()\")@SuppressWarnings(\"deprecation\")public void test_stop() { try { Runnable r = new ResSupThread(null); synchronized(r) { st = new Thread(r, \"Interupt Test5\"); st.start(); r.wait(); } } catch(InterruptedException e) { fail(\"Unexpected interrupt received\"); } try { st.stop(); fail(\"Expected UnsupportedOperationException because\" + \"Thread.stop is not supported.\"); } catch(UnsupportedOperationException e) { } SecurityManager sm = new SecurityManager() { public void checkPermission(Permission perm) { if(perm.getName().equals(\"stopThread\")) { throw new SecurityException(); } } }; st = new Thread(); SecurityManager oldSm = System.getSecurityManager(); System.setSecurityManager(sm); try { st.stop(); fail(\"Should throw SecurityException\"); } catch(SecurityException e) { } finally { System.setSecurityManager(oldSm); } } "
    },
    {
        "test_src": "@Test public void testCreateEngine()throws InterruptedException, ExecutionException { DefaultEngineFactory factory = new DefaultEngineFactory() { @Override protected IConnectorFactory createConnectorFactory(IPluginRegistry pluginRegistry) { return new IConnectorFactory() { @Override public IServiceConnector createConnector(ServiceRequest request, Service service, RequiredAuthType requiredAuthType) { Assert.assertEquals(\"test\", service.getEndpointType()); Assert.assertEquals(\"test:endpoint\", service.getEndpoint()); IServiceConnector connector = new IServiceConnector() { @Override public IServiceConnection connect(ServiceRequest request, IAsyncResultHandler < IServiceConnectionResponse > handler)throws ConnectorException { final ServiceResponse response = new ServiceResponse(); response.setCode(200); response.setMessage(\"OK\"); mockServiceConnectionResponse = new MockServiceConnectionResponse() { @Override public void write(IApimanBuffer chunk) { handleBody(chunk); }@Override protected void handleHead(ServiceResponse head) { return; }@Override public ServiceResponse getHead() { return response; }@Override public void end() { handleEnd(); }@Override public void transmit() { transmitHandler.handle((Void)null); }@Override public void abort() { } }; IAsyncResult < IServiceConnectionResponse > mockResponseResultHandler = mock(IAsyncResult.class); given(mockResponseResultHandler.isSuccess()).willReturn(true); given(mockResponseResultHandler.isError()).willReturn(false); given(mockResponseResultHandler.getResult()).willReturn(mockServiceConnectionResponse); mockServiceConnection = mock(MockServiceConnection.class); given(mockServiceConnection.getHead()).willReturn(request); handler.handle(mockResponseResultHandler); return mockServiceConnection; } }; return connector; } }; } }; IEngine engine = factory.createEngine(); Assert.assertNotNull(engine); Service service = new Service(); service.setEndpointType(\"test\"); service.setEndpoint(\"test:endpoint\"); service.setOrganizationId(\"TestOrg\"); service.setServiceId(\"TestService\"); service.setVersion(\"1.0\"); Application app = new Application(); app.setApplicationId(\"TestApp\"); app.setOrganizationId(\"TestOrg\"); app.setVersion(\"1.0\"); Contract contract = new Contract(); contract.setApiKey(\"12345\"); contract.setPlan(\"Gold\"); contract.setServiceId(\"TestService\"); contract.setServiceOrgId(\"TestOrg\"); contract.setServiceVersion(\"1.0\"); contract.setPolicies(policyList); app.addContract(contract); engine.getRegistry().publishService(service, new IAsyncResultHandler < Void > () { @Override public void handle(IAsyncResult < Void > result) { } }); engine.getRegistry().registerApplication(app, new IAsyncResultHandler < Void > () { @Override public void handle(IAsyncResult < Void > result) { } }); ServiceRequest request = new ServiceRequest(); request.setApiKey(\"12345\"); request.setDestination(\"/\"); request.setType(\"TEST\"); IServiceRequestExecutor prExecutor = engine.executor(request, new IAsyncResultHandler < IEngineResult > () { @Override public void handle(IAsyncResult < IEngineResult > result) { IEngineResult er = result.getResult(); Assert.assertTrue(result.isSuccess()); Assert.assertNotNull(er); Assert.assertTrue( ! er.isFailure()); Assert.assertNotNull(er.getServiceResponse()); Assert.assertEquals(\"OK\", er.getServiceResponse().getMessage()); er.bodyHandler(mockBodyHandler); er.endHandler(mockEndHandler); } }); prExecutor.streamHandler(new IAsyncHandler < ISignalWriteStream > () { @Override public void handle(ISignalWriteStream streamWriter) { streamWriter.write(mockBufferInbound); streamWriter.end(); } }); transmitHandler = new IAsyncHandler < Void > () { @Override public void handle(Void result) { mockServiceConnectionResponse.write(mockBufferOutbound); mockServiceConnectionResponse.end(); } }; prExecutor.execute(); verify(mockServiceConnection, times(1)).write(mockBufferInbound); InOrder order = inOrder(mockBodyHandler, mockEndHandler); order.verify(mockBodyHandler).handle(mockBufferOutbound); order.verify(mockEndHandler).handle((Void)null); } ",
        "focal_tgt": "private IEngine createEngine() { DefaultEngineFactory factory = new DefaultEngineFactory() { @Override protected IConnectorFactory createConnectorFactory(IPluginRegistry pluginRegistry) { return new PolicyTesterConnectorFactory(); }@Override protected IComponentRegistry createComponentRegistry(IPluginRegistry pluginRegistry) { return new DefaultComponentRegistry() { @Override protected void registerBufferFactoryComponent() { addComponent(IBufferFactoryComponent.class, new ByteBufferFactoryComponent()); } }; }@Override protected IPluginRegistry createPluginRegistry() { return new IPluginRegistry() { @Override public Future < IAsyncResult < Plugin > > loadPlugin(PluginCoordinates coordinates, IAsyncResultHandler < Plugin > handler) { throw new RuntimeException(\"Plugins not supported.\"); } }; } }; return factory.createEngine(); } ",
        "focal_src": "private IEngine createEngine() { DefaultEngineFactory factory = new DefaultEngineFactory() { @Override protected IConnectorFactory createConnectorFactory(IPluginRegistry pluginRegistry) { return new PolicyTesterConnectorFactory(); }@Override protected IComponentRegistry createComponentRegistry(IPluginRegistry pluginRegistry) { return new DefaultComponentRegistry() { @Override protected void registerBufferFactoryComponent() { addComponent(IBufferFactoryComponent.class, new PolicyTesterBufferFactoryComponent()); } }; }@Override protected IPluginRegistry createPluginRegistry() { return new IPluginRegistry() { @Override public Future < IAsyncResult < Plugin > > loadPlugin(PluginCoordinates coordinates, IAsyncResultHandler < Plugin > handler) { throw new RuntimeException(\"Plugins not supported.\"); } }; } }; return factory.createEngine(); } ",
        "test_tgt": "@Test public void testCreateEngine()throws InterruptedException, ExecutionException { DefaultEngineFactory factory = new DefaultEngineFactory() { @Override protected IComponentRegistry createComponentRegistry(IPluginRegistry pluginRegistry) { return new DefaultComponentRegistry() { @Override protected void registerBufferFactoryComponent() { addComponent(IBufferFactoryComponent.class, new ByteBufferFactoryComponent()); } }; }@Override protected IConnectorFactory createConnectorFactory(IPluginRegistry pluginRegistry) { return new IConnectorFactory() { @Override public IServiceConnector createConnector(ServiceRequest request, Service service, RequiredAuthType requiredAuthType) { Assert.assertEquals(\"test\", service.getEndpointType()); Assert.assertEquals(\"test:endpoint\", service.getEndpoint()); IServiceConnector connector = new IServiceConnector() { @Override public IServiceConnection connect(ServiceRequest request, IAsyncResultHandler < IServiceConnectionResponse > handler)throws ConnectorException { final ServiceResponse response = new ServiceResponse(); response.setCode(200); response.setMessage(\"OK\"); mockServiceConnectionResponse = new MockServiceConnectionResponse() { @Override public void write(IApimanBuffer chunk) { handleBody(chunk); }@Override protected void handleHead(ServiceResponse head) { return; }@Override public ServiceResponse getHead() { return response; }@Override public void end() { handleEnd(); }@Override public void transmit() { transmitHandler.handle((Void)null); }@Override public void abort() { } }; IAsyncResult < IServiceConnectionResponse > mockResponseResultHandler = mock(IAsyncResult.class); given(mockResponseResultHandler.isSuccess()).willReturn(true); given(mockResponseResultHandler.isError()).willReturn(false); given(mockResponseResultHandler.getResult()).willReturn(mockServiceConnectionResponse); mockServiceConnection = mock(MockServiceConnection.class); given(mockServiceConnection.getHead()).willReturn(request); handler.handle(mockResponseResultHandler); return mockServiceConnection; } }; return connector; } }; } }; IEngine engine = factory.createEngine(); Assert.assertNotNull(engine); Service service = new Service(); service.setEndpointType(\"test\"); service.setEndpoint(\"test:endpoint\"); service.setOrganizationId(\"TestOrg\"); service.setServiceId(\"TestService\"); service.setVersion(\"1.0\"); Application app = new Application(); app.setApplicationId(\"TestApp\"); app.setOrganizationId(\"TestOrg\"); app.setVersion(\"1.0\"); Contract contract = new Contract(); contract.setApiKey(\"12345\"); contract.setPlan(\"Gold\"); contract.setServiceId(\"TestService\"); contract.setServiceOrgId(\"TestOrg\"); contract.setServiceVersion(\"1.0\"); contract.setPolicies(policyList); app.addContract(contract); engine.getRegistry().publishService(service, new IAsyncResultHandler < Void > () { @Override public void handle(IAsyncResult < Void > result) { } }); engine.getRegistry().registerApplication(app, new IAsyncResultHandler < Void > () { @Override public void handle(IAsyncResult < Void > result) { } }); ServiceRequest request = new ServiceRequest(); request.setApiKey(\"12345\"); request.setDestination(\"/\"); request.setType(\"TEST\"); IServiceRequestExecutor prExecutor = engine.executor(request, new IAsyncResultHandler < IEngineResult > () { @Override public void handle(IAsyncResult < IEngineResult > result) { IEngineResult er = result.getResult(); Assert.assertTrue(result.isSuccess()); Assert.assertNotNull(er); Assert.assertTrue( ! er.isFailure()); Assert.assertNotNull(er.getServiceResponse()); Assert.assertEquals(\"OK\", er.getServiceResponse().getMessage()); er.bodyHandler(mockBodyHandler); er.endHandler(mockEndHandler); } }); prExecutor.streamHandler(new IAsyncHandler < ISignalWriteStream > () { @Override public void handle(ISignalWriteStream streamWriter) { streamWriter.write(mockBufferInbound); streamWriter.end(); } }); transmitHandler = new IAsyncHandler < Void > () { @Override public void handle(Void result) { mockServiceConnectionResponse.write(mockBufferOutbound); mockServiceConnectionResponse.end(); } }; prExecutor.execute(); verify(mockServiceConnection, times(1)).write(mockBufferInbound); InOrder order = inOrder(mockBodyHandler, mockEndHandler); order.verify(mockBodyHandler).handle(mockBufferOutbound); order.verify(mockEndHandler).handle((Void)null); } "
    },
    {
        "test_src": "@Test public void testToString() { System.out.println(\"\\n+++ toString\"); RunTable instance = createHorizontalInstance(); String expResult = \"{RunTable hori HORIZONTAL 10x5 runs:9}\"; String result = instance.toString(); assertEquals(expResult, result); } ",
        "focal_tgt": "@Override public String toString() { StringBuilder sb = new StringBuilder(getClass().getSimpleName()); sb.append(\"{\"); if(name != null) { sb.append(\" name:\").append(name); } if(interline != null) { sb.append(\" interline:\").append(interline); } if(pitchPosition != null) { sb.append(\" pitch-position:\").append(pitchPosition); } sb.append(\"}\"); return sb.toString(); } ",
        "focal_src": "@Override public String toString() { StringBuilder sb = new StringBuilder(getClass().getSimpleName()); sb.append(\"{\"); if(name != null) { sb.append(\" name:\").append(name); } if(interline != null) { sb.append(\" interline:\").append(interline); } if(stemNumber != null) { sb.append(\" stem-number:\").append(stemNumber); } if(withLedger != null) { sb.append(\" with-ledger:\").append(withLedger); } if(pitchPosition != null) { sb.append(\" pitch-position:\").append(pitchPosition); } sb.append(\"}\"); return sb.toString(); } ",
        "test_tgt": "@Test public void testToString() { System.out.println(\"\\n+++ toString\"); RunTable instance = createHorizontalInstance(); String expResult = \"RunTable{hori HORIZONTAL 10x5}\"; String result = instance.toString(); assertEquals(expResult, result); } "
    },
    {
        "test_src": "@Test public void testCollect1() { List < Long > list = new ArrayList < Long > (); list.add(1L); list.add(100L); List < String > collect1 = CollectionsUtil.collect(list, TransformerUtils.stringValueTransformer()); LOGGER.info(\"list:{}\", JsonUtil.format(collect1, 0, 0)); } ",
        "focal_tgt": "public static < O, T > List < T > collect(final Iterable < O > inputIterable, final Transformer < ? super O, ? extends T > transformer) { return null == inputIterable ? Collections. < T > emptyList() : (List < T > )CollectionUtils.collect(inputIterable, transformer); } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public static < O, T > List < T > collect(final Iterable < O > inputIterable, final Transformer < ? super O, ? extends T > transformer) { return null == inputIterable ? (List < T > )Collections.emptyList() : (List < T > )CollectionUtils.collect(inputIterable, transformer); } ",
        "test_tgt": "@Test public void testCollect1() { List < Long > list = null; List < String > collect1 = CollectionsUtil.collect(list, TransformerUtils.stringValueTransformer()); LOGGER.info(\"list:{}\", JsonUtil.format(collect1, 0, 0)); } "
    },
    {
        "test_src": "@Test public final void replace() { no(new Replace(FILE, \"xxx\")); ok(new CreateDB(NAME, FILE)); ok(new Replace(FN, \"<a/>\")); ok(new Replace(FN, \"<a/>\")); no(new Replace(FN, \"\")); ok(new XQuery(\"db:store('\" + NAME + \"', 'a', 'a')\")); ok(new Replace(\"a\", \"<b/>\")); assertTrue( ! ok(new XQuery(\"db:open('\" + NAME + \"')\")).isEmpty()); ok(new XQuery(\"db:retrieve('\" + NAME + \"', 'a')\")); no(new Replace(FN, \"<a>\")); assertTrue( ! ok(new XQuery(\"doc('\" + NAME + \"')\")).isEmpty()); } ",
        "focal_tgt": "private void replace()throws IOException { execute(new Replace(in.readString())); } ",
        "focal_src": "private void replace()throws IOException { final Performance perf = new Performance(); final String path = in.readString(); final StringBuilder sb = new StringBuilder(REPLACE + \" \"); if( ! path.isEmpty())sb.append(TO + ' ' + path + ' '); log.write(this, sb.append(\"[...]\")); final DecodingInput di = new DecodingInput(in); try { final InputSource is = new InputSource(di); final String info = Replace.replace(path, is, context, true); info(true, info, perf); } catch(final BaseXException ex) { di.flush(); info(false, ex.getMessage(), perf); } out.flush(); } ",
        "test_tgt": "@Test public final void replace() { final String count = \"count(db:open('\" + NAME + \"'))\"; no(new Replace(FILE, \"xxx\")); ok(new CreateDB(NAME, FILE)); assertEquals(\"1\", ok(new XQuery(count))); ok(new Replace(FN, \"<a/>\")); assertEquals(\"1\", ok(new XQuery(count))); ok(new Replace(FN, \"<a/>\")); assertEquals(\"1\", ok(new XQuery(count))); no(new Replace(FN, \"\")); assertEquals(\"1\", ok(new XQuery(count))); ok(new XQuery(\"db:store('\" + NAME + \"', 'a', 'a')\")); ok(new Replace(\"a\", \"<b/>\")); assertTrue(ok(new XQuery(\"db:open('\" + NAME + \"')\")).length() != 0); ok(new XQuery(\"db:retrieve('\" + NAME + \"', 'a')\")); no(new Replace(FN, \"<a>\")); assertEquals(\"1\", ok(new XQuery(count))); } "
    },
    {
        "test_src": "@Test public void testCreateSSLClientContext()throws Exception { Configuration clientConfig = new Configuration(); clientConfig.setBoolean(ConfigConstants.SECURITY_SSL_ENABLED, true); clientConfig.setString(ConfigConstants.SECURITY_SSL_TRUSTSTORE, \"src/test/resources/local127.truststore\"); clientConfig.setString(ConfigConstants.SECURITY_SSL_TRUSTSTORE_PASSWORD, \"password\"); SSLContext clientContext = SSLUtils.createSSLClientContext(clientConfig); Assert.assertNotNull(clientContext); } ",
        "focal_tgt": "public static SSLContext createSSLClientContext(Configuration sslConfig)throws Exception { Preconditions.checkNotNull(sslConfig); SSLContext clientSSLContext = null; if(getSSLEnabled(sslConfig)) { LOG.debug(\"Creating client SSL context from configuration\"); String trustStoreFilePath = sslConfig.getString(SecurityOptions.SSL_TRUSTSTORE); String trustStorePassword = sslConfig.getString(SecurityOptions.SSL_TRUSTSTORE_PASSWORD); String sslProtocolVersion = sslConfig.getString(SecurityOptions.SSL_PROTOCOL); Preconditions.checkNotNull(trustStoreFilePath, SecurityOptions.SSL_TRUSTSTORE.key() + \" was not configured.\"); Preconditions.checkNotNull(trustStorePassword, SecurityOptions.SSL_TRUSTSTORE_PASSWORD.key() + \" was not configured.\"); KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); FileInputStream trustStoreFile = null; try { trustStoreFile = new FileInputStream(new File(trustStoreFilePath)); trustStore.load(trustStoreFile, trustStorePassword.toCharArray()); } finally { if(trustStoreFile != null) { trustStoreFile.close(); } } TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); trustManagerFactory.init(trustStore); clientSSLContext = SSLContext.getInstance(sslProtocolVersion); clientSSLContext.init(null, trustManagerFactory.getTrustManagers(), null); } return clientSSLContext; } ",
        "focal_src": "public static SSLContext createSSLClientContext(Configuration sslConfig)throws Exception { Preconditions.checkNotNull(sslConfig); SSLContext clientSSLContext = null; if(getSSLEnabled(sslConfig)) { LOG.debug(\"Creating client SSL context from configuration\"); String trustStoreFilePath = sslConfig.getString(ConfigConstants.SECURITY_SSL_TRUSTSTORE, null); String trustStorePassword = sslConfig.getString(ConfigConstants.SECURITY_SSL_TRUSTSTORE_PASSWORD, null); String sslProtocolVersion = sslConfig.getString(ConfigConstants.SECURITY_SSL_PROTOCOL, ConfigConstants.DEFAULT_SECURITY_SSL_PROTOCOL); Preconditions.checkNotNull(trustStoreFilePath, ConfigConstants.SECURITY_SSL_TRUSTSTORE + \" was not configured.\"); Preconditions.checkNotNull(trustStorePassword, ConfigConstants.SECURITY_SSL_TRUSTSTORE_PASSWORD + \" was not configured.\"); KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); FileInputStream trustStoreFile = null; try { trustStoreFile = new FileInputStream(new File(trustStoreFilePath)); trustStore.load(trustStoreFile, trustStorePassword.toCharArray()); } finally { if(trustStoreFile != null) { trustStoreFile.close(); } } TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); trustManagerFactory.init(trustStore); clientSSLContext = SSLContext.getInstance(sslProtocolVersion); clientSSLContext.init(null, trustManagerFactory.getTrustManagers(), null); } return clientSSLContext; } ",
        "test_tgt": "@Test public void testCreateSSLClientContext()throws Exception { Configuration clientConfig = new Configuration(); clientConfig.setBoolean(SecurityOptions.SSL_ENABLED, true); clientConfig.setString(SecurityOptions.SSL_TRUSTSTORE, \"src/test/resources/local127.truststore\"); clientConfig.setString(SecurityOptions.SSL_TRUSTSTORE_PASSWORD, \"password\"); SSLContext clientContext = SSLUtils.createSSLClientContext(clientConfig); Assert.assertNotNull(clientContext); } "
    },
    {
        "test_src": "@Test public void testNextLong()throws Exception { long result = RandomUtils.nextLong(33L, 42L); assertTrue(result >= 33L && result < 42L); } ",
        "focal_tgt": "public static long nextLong(final long startInclusive, final long endExclusive) { Validate.isTrue(endExclusive >= startInclusive, \"Start value must be smaller or equal to end value.\"); Validate.isTrue(startInclusive >= 0, \"Both range values must be non-negative.\"); if(startInclusive == endExclusive) { return startInclusive; } return(long)nextDouble(startInclusive, endExclusive); } ",
        "focal_src": "public static long nextLong(long startInclusive, long endExclusive) { Validate.isTrue(endExclusive >= startInclusive, \"Start value must be smaller or equal to end value.\"); Validate.isTrue(startInclusive >= 0, \"Both range values must be non-negative.\"); if(startInclusive == endExclusive) { return startInclusive; } return(long)nextDouble(startInclusive, endExclusive); } ",
        "test_tgt": "@Test public void testNextLong()throws Exception { final long result = RandomUtils.nextLong(33L, 42L); assertTrue(result >= 33L && result < 42L); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_withLaterOffsetAtOverlap() { OffsetDateTime odt = OffsetDateTime.of(2008, 10, 26, 2, 30, OFFSET_0200); ZonedDateTime base = ZonedDateTime.of(odt, ZONE_PARIS); ZonedDateTime test = base.withLaterOffsetAtOverlap(); assertEquals(test.getOffset(), OFFSET_0100); } ",
        "focal_tgt": "@Override public ChronoZonedDateTime < C > withLaterOffsetAtOverlap() { ZoneOffsetTransition trans = getZone().getRules().getTransition(LocalDateTime.from(this)); if(trans != null) { ZoneOffset offset = trans.getOffsetAfter(); if(offset.equals(getOffset()) == false) { return new ChronoZonedDateTimeImpl < C > (dateTime, offset, zoneId); } } return this; } ",
        "focal_src": "public ChronoZonedDateTime < C > withLaterOffsetAtOverlap() { ZoneOffsetTransition trans = getZone().getRules().getTransition(LocalDateTime.from(this)); if(trans != null) { ZoneOffset offset = trans.getOffsetAfter(); if(offset.equals(getOffset()) == false) { ChronoOffsetDateTimeImpl < C > newDT = dateTime.withOffsetSameLocal(offset); return new ChronoZonedDateTimeImpl < C > (newDT, zone); } } return this; } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_withLaterOffsetAtOverlap() { ZonedDateTime base = ZonedDateTime.ofStrict(TEST_PARIS_OVERLAP_2008_10_26_02_30, OFFSET_0200, ZONE_PARIS); ZonedDateTime test = base.withLaterOffsetAtOverlap(); assertEquals(test.getOffset(), OFFSET_0100); assertEquals(test.getDateTime(), base.getDateTime()); } "
    },
    {
        "test_src": "@Test public void testWillBlockSchedules() { fail(\"Not yet implemented\"); } ",
        "focal_tgt": "@Override public List < Trigger > willBlockSchedules(IBlockoutTrigger blockOut)throws SchedulerException { List < Trigger > blockedSchedules = new ArrayList < Trigger > (); for(String groupName : this.scheduler.getTriggerGroupNames()) { if(BLOCK_GROUP.equals(groupName)) { continue; } for(String jobName : this.scheduler.getJobNames(groupName)) { Trigger schedule = this.scheduler.getTrigger(jobName, groupName); if(willBlockSchedule(schedule, blockOut)) { blockedSchedules.add(schedule); } } } return blockedSchedules; } ",
        "focal_src": "@Override public boolean willBlockSchedules(IBlockoutTrigger testBlockout) { return false; } ",
        "test_tgt": "@Test public void testWillBlockSchedules() { try { Calendar trueBlockOutStartDate = new GregorianCalendar(2013, Calendar.JANUARY, 7); SimpleBlockoutTrigger trueBlockOutTrigger = new SimpleBlockoutTrigger(\"blockOut\", trueBlockOutStartDate.getTime(), null, - 1, TIME.WEEK.time * 2, TIME.HOUR.time * 2); Calendar falseBlockOutStartDate = new GregorianCalendar(2013, Calendar.JANUARY, 8); SimpleBlockoutTrigger falseBlockOutTrigger = new SimpleBlockoutTrigger(\"blockOut\", falseBlockOutStartDate.getTime(), null, - 1, TIME.WEEK.time * 2, TIME.HOUR.time * 2); Calendar scheduleStartDate = new GregorianCalendar(2013, Calendar.JANUARY, 7, 1, 0, 0); SimpleTrigger scheduleTrigger = new SimpleTrigger(\"trueSchedule\", \"SCHEDULES\", scheduleStartDate.getTime(), null, - 1, TIME.WEEK.time); scheduleJob(scheduleTrigger); assertEquals(1, this.blockOutManager.willBlockSchedules(trueBlockOutTrigger).size()); assertEquals(0, this.blockOutManager.willBlockSchedules(falseBlockOutTrigger).size()); deleteJob(scheduleTrigger); } catch(SchedulerException e) { throw new RuntimeException(e); } } "
    },
    {
        "test_src": "@Test@LocalAlluxioClusterResource.Config(confParams = { Constants.SECURITY_AUTHORIZATION_PERMISSION_ENABLED, \"true\", Constants.SECURITY_AUTHENTICATION_TYPE, \"SIMPLE\", Constants.SECURITY_GROUP_MAPPING, \"alluxio.security.group.provider.IdentityUserGroupsMapping\", Constants.SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP, \"test_user_ls\" })public void lsTest()throws IOException, AlluxioException { String testUser = \"test_user_ls\"; clearAndLogin(testUser); URIStatus[]files = createFiles(); mFsShell.run(\"ls\", \"/testRoot\"); String expected = \"\"; expected += getLsResultStr(\"/testRoot/testFileA\", files[0].getCreationTimeMs(), 10, LsCommand.STATE_FILE_IN_MEMORY, testUser, testUser, files[0].getPermission(), files[0].isFolder()); expected += getLsResultStr(\"/testRoot/testDir\", files[1].getCreationTimeMs(), 1, LsCommand.STATE_FOLDER, testUser, testUser, files[1].getPermission(), files[1].isFolder()); expected += getLsResultStr(\"/testRoot/testFileC\", files[3].getCreationTimeMs(), 30, LsCommand.STATE_FILE_NOT_IN_MEMORY, testUser, testUser, files[3].getPermission(), files[3].isFolder()); Assert.assertEquals(expected, mOutput.toString()); } ",
        "focal_tgt": "private void ls(AlluxioURI path, boolean recursive)throws AlluxioException, IOException { List < URIStatus > statuses = listStatusSortedByIncreasingCreationTime(path); for(URIStatus status : statuses) { System.out.format(formatLsString(SecurityUtils.isSecurityEnabled(mConfiguration), status.isFolder(), FormatUtils.formatMode((short)status.getMode(), status.isFolder()), status.getOwner(), status.getGroup(), status.getLength(), status.getCreationTimeMs(), 100 == status.getInMemoryPercentage(), status.getPath())); if(recursive && status.isFolder()) { ls(new AlluxioURI(path.getScheme(), path.getAuthority(), status.getPath()), true); } } } ",
        "focal_src": "private void ls(AlluxioURI path, boolean recursive)throws AlluxioException, IOException { List < URIStatus > statuses = listStatusSortedByIncreasingCreationTime(path); for(URIStatus status : statuses) { System.out.format(formatLsString(SecurityUtils.isSecurityEnabled(mConfiguration), status.isFolder(), FormatUtils.formatMode((short)status.getPermission(), status.isFolder()), status.getUserName(), status.getGroupName(), status.getLength(), status.getCreationTimeMs(), 100 == status.getInMemoryPercentage(), status.getPath())); if(recursive && status.isFolder()) { ls(new AlluxioURI(path.getScheme(), path.getAuthority(), status.getPath()), true); } } } ",
        "test_tgt": "@Test@LocalAlluxioClusterResource.Config(confParams = { Constants.SECURITY_AUTHORIZATION_PERMISSION_ENABLED, \"true\", Constants.SECURITY_AUTHENTICATION_TYPE, \"SIMPLE\", Constants.SECURITY_GROUP_MAPPING, \"alluxio.security.group.provider.IdentityUserGroupsMapping\", Constants.SECURITY_AUTHORIZATION_PERMISSION_SUPERGROUP, \"test_user_ls\" })public void lsTest()throws IOException, AlluxioException { String testUser = \"test_user_ls\"; clearAndLogin(testUser); URIStatus[]files = createFiles(); mFsShell.run(\"ls\", \"/testRoot\"); String expected = \"\"; expected += getLsResultStr(\"/testRoot/testFileA\", files[0].getCreationTimeMs(), 10, LsCommand.STATE_FILE_IN_MEMORY, testUser, testUser, files[0].getMode(), files[0].isFolder()); expected += getLsResultStr(\"/testRoot/testDir\", files[1].getCreationTimeMs(), 1, LsCommand.STATE_FOLDER, testUser, testUser, files[1].getMode(), files[1].isFolder()); expected += getLsResultStr(\"/testRoot/testFileC\", files[3].getCreationTimeMs(), 30, LsCommand.STATE_FILE_NOT_IN_MEMORY, testUser, testUser, files[3].getMode(), files[3].isFolder()); Assert.assertEquals(expected, mOutput.toString()); } "
    },
    {
        "test_src": "@Test public void considerConnect_nominal() { List < Polygon2D_F64 > squares = new ArrayList < Polygon2D_F64 > (); squares.add(new Polygon2D_F64( - 1, 1, 1, 1, 1, - 1, - 1, - 1)); squares.add(new Polygon2D_F64(2, 1, 4, 1, 4, - 1, 2, - 1)); SquaresIntoClusters alg = new SquaresIntoClusters(2, 6); alg.computeNodeInfo(squares); SquareNode a = alg.nodes.get(0); SquareNode b = alg.nodes.get(1); alg.considerConnect(a, b); assertConnected(a, 1, b, 3, 3); } ",
        "focal_tgt": "void considerConnect(SquareNode node0, SquareNode node1) { lineA.a = node0.center; lineA.b = node1.center; int intersection0 = findSideIntersect(node0, lineA, lineB); int intersection1 = findSideIntersect(node1, lineA, lineB); if(intersection1 < 0 || intersection0 < 0) { return; } double sideSideRatio0 = node0.largestSide / node0.smallestSideLength(); double sideSideRatio1 = node1.largestSide / node1.smallestSideLength(); if(Math.abs(sideSideRatio0 - sideSideRatio1) > 1.2) { return; } double closeSide0 = node0.sideLengths[intersection0]; double closeSide1 = node1.sideLengths[intersection1]; double ratio = closeSide0 > closeSide1 ? closeSide1 / closeSide0 : closeSide0 / closeSide1; if(ratio < 0.5) { return; } double distanceApart = lineA.getLength(); if( ! mostParallel(node0, intersection0, node1, intersection1)) { return; } if( ! areMiddlePointsClose(node0.corners.get(add(intersection0, - 1)), node0.corners.get(intersection0), node1.corners.get(add(intersection1, 1)), node1.corners.get(add(intersection1, 2)))) { return; } if( ! areMiddlePointsClose(node0.corners.get(add(intersection0, 2)), node0.corners.get(add(intersection0, 1)), node1.corners.get(intersection1), node1.corners.get(add(intersection1, - 1)))) { return; } checkConnect(node0, intersection0, node1, intersection1, distanceApart); } ",
        "focal_src": "void considerConnect(SquareNode node0, SquareNode node1) { lineA.a = node0.center; lineA.b = node1.center; int intersection0 = findSideIntersect(node0, lineA, lineB); int intersection1 = findSideIntersect(node1, lineA, lineB); if(intersection1 < 0 || intersection0 < 0) { return; } double closeSide0 = node0.sideLengths[intersection0]; double closeSide1 = node1.sideLengths[intersection1]; double ratio = closeSide0 > closeSide1 ? closeSide1 / closeSide0 : closeSide0 / closeSide1; if(ratio < 0.5) { return; } double distanceApart = lineA.getLength(); if( ! mostParallel(node0, intersection0, node1, intersection1)) { return; } if( ! areMiddlePointsClose(node0.corners.get(add(intersection0, - 1)), node0.corners.get(intersection0), node1.corners.get(add(intersection1, 1)), node1.corners.get(add(intersection1, 2)))) { return; } if( ! areMiddlePointsClose(node0.corners.get(add(intersection0, 2)), node0.corners.get(add(intersection0, 1)), node1.corners.get(intersection1), node1.corners.get(add(intersection1, - 1)))) { return; } checkConnect(node0, intersection0, node1, intersection1, distanceApart); } ",
        "test_tgt": "@Test public void considerConnect_nominal() { List < Polygon2D_F64 > squares = new ArrayList < Polygon2D_F64 > (); squares.add(new Polygon2D_F64( - 1, 1, 1, 1, 1, - 1, - 1, - 1)); squares.add(new Polygon2D_F64(2, 1, 4, 1, 4, - 1, 2, - 1)); SquaresIntoClusters alg = new SquaresIntoClusters(2, 6, 1.35); alg.computeNodeInfo(squares); SquareNode a = alg.nodes.get(0); SquareNode b = alg.nodes.get(1); alg.considerConnect(a, b); assertConnected(a, 1, b, 3, 3); } "
    },
    {
        "test_src": "@Test public void testJoinValues() { String value = \"create_salesorder\"; String value2 = \"unionpay_mobile\"; Map < String, String > map = new HashMap < String, String > (); map.put(\"service\", value); map.put(\"paymentType\", value2); assertEquals(StringUtils.EMPTY, ParamUtil.joinValues(map, \"a\", \"b\")); assertEquals(value, ParamUtil.joinValues(map, \"service\")); assertEquals(value + value2, ParamUtil.joinValues(map, \"service\", \"paymentType\")); assertEquals(value2 + value, ParamUtil.joinValues(map, \"paymentType\", \"service\")); } ",
        "focal_tgt": "public static String joinValuesOrderByIncludeKeys(Map < String, String > singleValueMap, String ... includeKeys) { Validate.notNull(singleValueMap, \"singleValueMap can't be null!\"); if(Validator.isNullOrEmpty(includeKeys)) { return StringUtils.EMPTY; } StringBuilder sb = new StringBuilder(); for(String key : includeKeys) { String value = singleValueMap.get(key); sb.append(StringUtils.defaultString(value)); } return sb.toString(); } ",
        "focal_src": "public static String joinValues(Map < String, String > singleValueMap, String ... includeKeys) { Validate.notNull(singleValueMap, \"singleValueMap can't be null!\"); if(Validator.isNullOrEmpty(includeKeys)) { return StringUtils.EMPTY; } StringBuilder sb = new StringBuilder(); for(String key : includeKeys) { String value = singleValueMap.get(key); sb.append(StringUtils.defaultString(value)); } return sb.toString(); } ",
        "test_tgt": "@Test public void testJoinValues() { String value = \"create_salesorder\"; String value2 = \"unionpay_mobile\"; Map < String, String > map = new HashMap < String, String > (); map.put(\"service\", value); map.put(\"paymentType\", value2); assertEquals(StringUtils.EMPTY, ParamUtil.joinValuesOrderByIncludeKeys(map, \"a\", \"b\")); assertEquals(value, ParamUtil.joinValuesOrderByIncludeKeys(map, \"service\")); assertEquals(value + value2, ParamUtil.joinValuesOrderByIncludeKeys(map, \"service\", \"paymentType\")); assertEquals(value2 + value, ParamUtil.joinValuesOrderByIncludeKeys(map, \"paymentType\", \"service\")); } "
    },
    {
        "test_src": "@Test public void testUniformCdf() { logger.info(\"UniformCdf\"); double x = 3.0; double a = 2.0; double b = 10.0; double expResult = 0.125; double result = ContinuousDistributions.UniformCdf(x, a, b); assertEquals(expResult, result, TestConfiguration.DOUBLE_ACCURACY_HIGH); } ",
        "focal_tgt": "public static double uniformCdf(int k, int n) { if(k < 0 || n < 1) { throw new IllegalArgumentException(\"All the parameters must be positive and n larger than 1.\"); } k = Math.min(k, n); double probabilitySum = k * uniform(n); return probabilitySum; } ",
        "focal_src": "public static double UniformCdf(int k, int n) { if(k < 0 || n < 1) { throw new IllegalArgumentException(\"All the parameters must be positive and n larger than 1.\"); } k = Math.min(k, n); double probabilitySum = k * Uniform(n); return probabilitySum; } ",
        "test_tgt": "@Test public void testUniformCdf() { logger.info(\"UniformCdf\"); double x = 3.0; double a = 2.0; double b = 10.0; double expResult = 0.125; double result = ContinuousDistributions.uniformCdf(x, a, b); assertEquals(expResult, result, TestConfiguration.DOUBLE_ACCURACY_HIGH); } "
    },
    {
        "test_src": "@Test public void backup()throws BaseXException { query(COUNT.args(_DB_BACKUPS.args(NAME)), \"0\"); query(_DB_BACKUP.args(NAME)); query(COUNT.args(_DB_BACKUPS.args(NAME)), \"1\"); error(_DB_BACKUP.args(NAME + new Object().hashCode()), Err.BXDB_OPEN); new DropBackup(NAME).execute(context); query(COUNT.args(_DB_BACKUPS.args(NAME)), \"0\"); } ",
        "focal_tgt": "private Item backup(final QueryContext ctx)throws QueryException { checkCreate(ctx); final String name = string(checkStr(expr[0], ctx)); if( ! Databases.validName(name))throw BXDB_NAME.get(info, name); if( ! ctx.context.globalopts.dbexists(name))throw BXDB_WHICH.get(info, name); ctx.updates.add(new DBBackup(name, info, ctx), ctx); return null; } ",
        "focal_src": "private Item backup(final QueryContext ctx)throws QueryException { checkCreate(ctx); final Data data = checkData(ctx); ctx.updates.add(new DBBackup(data, info, ctx), ctx); return null; } ",
        "test_tgt": "@Test public void backup()throws BaseXException { query(COUNT.args(_DB_BACKUPS.args(NAME)), \"0\"); query(_DB_BACKUP.args(NAME)); query(COUNT.args(_DB_BACKUPS.args(NAME)), \"1\"); error(_DB_BACKUP.args(NAME + 'x'), Err.BXDB_WHICH); new DropBackup(NAME).execute(context); query(COUNT.args(_DB_BACKUPS.args(NAME)), \"0\"); } "
    },
    {
        "test_src": "@Test public void getPeople_shouldGetOnePersonByRandomCaseAttribute()throws Exception { Assert.assertTrue(personAttributeHelper.personAttributeExists(\"Story teller\")); List < Person > people = hibernatePersonDAO.getPeople(\"sToRy TeLlEr\", false); logPeople(people); Assert.assertEquals(1, people.size()); Assert.assertEquals(\"Bilbo Odilon\", people.get(0).getGivenName()); } ",
        "focal_tgt": "@SuppressWarnings(\"unchecked\")public List < Person > getPeople(String searchString, Boolean dead, Boolean voided) { if(searchString == null) { return new ArrayList < Person > (); } PersonSearchCriteria personSearchCriteria = new PersonSearchCriteria(); searchString = searchString.replace(\", \", \" \"); String[]values = searchString.split(\" \"); Criteria criteria = sessionFactory.getCurrentSession().createCriteria(Person.class); personSearchCriteria.addAliasForName(criteria); personSearchCriteria.addAliasForAttribute(criteria); if(voided == null || voided == false)criteria.add(Restrictions.eq(\"personVoided\", false)); if(dead != null) { criteria.add(Restrictions.eq(\"dead\", dead)); } Disjunction disjunction = Restrictions.disjunction(); MatchMode matchMode = personSearchCriteria.getAttributeMatchMode(); for(String value : values) { if(value != null && value.length() > 0) { disjunction.add(personSearchCriteria.prepareCriterionForName(value, voided)).add(personSearchCriteria.prepareCriterionForAttribute(value, voided, matchMode)); } } criteria.add(disjunction); criteria.addOrder(Order.asc(\"personId\")); criteria.setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY); criteria.setMaxResults(getMaximumSearchResults()); log.debug(criteria.toString()); return criteria.list(); } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public List < Person > getPeople(String searchString, Boolean dead, Boolean voided) { if(searchString == null) { return new ArrayList < Person > (); } PersonSearchCriteria personSearchCriteria = new PersonSearchCriteria(); searchString = searchString.replace(\", \", \" \"); String[]values = searchString.split(\" \"); Criteria criteria = sessionFactory.getCurrentSession().createCriteria(Person.class); personSearchCriteria.addAliasForName(criteria); personSearchCriteria.addAliasForAttribute(criteria); if(voided == null || voided == false)criteria.add(Restrictions.eq(\"personVoided\", false)); if(dead != null) { criteria.add(Restrictions.eq(\"dead\", dead)); } Disjunction disjunction = Restrictions.disjunction(); for(String value : values) { if(value != null && value.length() > 0) { disjunction.add(personSearchCriteria.prepareCriterionForName(value, voided)).add(personSearchCriteria.prepareCriterionForAttribute(value, voided)); } } criteria.add(disjunction); criteria.addOrder(Order.asc(\"personId\")); criteria.setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY); criteria.setMaxResults(getMaximumSearchResults()); log.debug(criteria.toString()); return criteria.list(); } ",
        "test_tgt": "@Test public void getPeople_shouldGetOnePersonByRandomCaseAttribute()throws Exception { globalPropertiesTestHelper.setGlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_PERSON_ATTRIBUTE_SEARCH_MATCH_MODE, OpenmrsConstants.GLOBAL_PROPERTY_PERSON_ATTRIBUTE_SEARCH_MATCH_ANYWHERE); Assert.assertTrue(personAttributeHelper.personAttributeExists(\"Story teller\")); List < Person > people = hibernatePersonDAO.getPeople(\"sToRy TeLlEr\", false); logPeople(people); Assert.assertEquals(1, people.size()); Assert.assertEquals(\"Bilbo Odilon\", people.get(0).getGivenName()); } "
    },
    {
        "test_src": "@Test public void testReplace_StringStringArrayStringArrayBoolean() { assertNull(StringUtils.replaceEachRepeatedly(null, new String[] { \"a\" }, new String[] { \"b\" })); assertEquals(StringUtils.replaceEachRepeatedly(\"\", new String[] { \"a\" }, new String[] { \"b\" }), \"\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", null, null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[0], null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", null, new String[0]), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[0], null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[] { \"a\" }, new String[] { \"\" }), \"b\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[] { null }, new String[] { \"a\" }), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"w\", \"t\" }), \"wcte\"); assertEquals(StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"d\", \"t\" }), \"tcte\"); try { StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"d\", \"ab\" }); fail(\"Should be a circular reference\"); } catch(IllegalStateException e) { } } ",
        "focal_tgt": "public StrBuilder replace(final int startIndex, int endIndex, final String replaceStr) { endIndex = validateRange(startIndex, endIndex); final int insertLen = (replaceStr == null ? 0 : replaceStr.length()); replaceImpl(startIndex, endIndex, endIndex - startIndex, replaceStr, insertLen); return this; } ",
        "focal_src": "public StrBuilder replace(final int startIndex, int endIndex, final String replaceStr) { endIndex = validateRange(startIndex, endIndex); int insertLen = (replaceStr == null ? 0 : replaceStr.length()); replaceImpl(startIndex, endIndex, endIndex - startIndex, replaceStr, insertLen); return this; } ",
        "test_tgt": "@Test public void testReplace_StringStringArrayStringArrayBoolean() { assertNull(StringUtils.replaceEachRepeatedly(null, new String[] { \"a\" }, new String[] { \"b\" })); assertEquals(StringUtils.replaceEachRepeatedly(\"\", new String[] { \"a\" }, new String[] { \"b\" }), \"\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", null, null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[0], null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", null, new String[0]), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[0], null), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[] { \"a\" }, new String[] { \"\" }), \"b\"); assertEquals(StringUtils.replaceEachRepeatedly(\"aba\", new String[] { null }, new String[] { \"a\" }), \"aba\"); assertEquals(StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"w\", \"t\" }), \"wcte\"); assertEquals(StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"d\", \"t\" }), \"tcte\"); try { StringUtils.replaceEachRepeatedly(\"abcde\", new String[] { \"ab\", \"d\" }, new String[] { \"d\", \"ab\" }); fail(\"Should be a circular reference\"); } catch(final IllegalStateException e) { } } "
    },
    {
        "test_src": "@Test public void response_tagsNothingOnError() { parser.response(response, new RuntimeException(\"drat\"), customizer); verifyNoMoreInteractions(response, customizer); } ",
        "focal_tgt": "public void response(Resp response, @Nullable Throwable error, SpanCustomizer customizer) { String errorMessage = response.errorMessage(); if(errorMessage != null)customizer.tag(\"rpc.error_message\", errorMessage); if(errorMessage != null || error != null)error(errorMessage, error, customizer); } ",
        "focal_src": "public void response(Resp response, @Nullable Throwable error, SpanCustomizer customizer) { } ",
        "test_tgt": "@Test public void response_missingErrorMessage_tagsNothing() { parser.response(response, new RuntimeException(\"drat\"), customizer); verify(response).errorMessage(); verifyNoMoreInteractions(response, customizer); } "
    },
    {
        "test_src": "@Test(expectedExceptions = NullPointerException.class)public void test_appendValueReduced_null()throws Exception { builder.appendValueReduced(null, 2, 2000); } ",
        "focal_tgt": "public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int maxWidth, int baseValue) { Objects.requireNonNull(field, \"field\"); ReducedPrinterParser pp = new ReducedPrinterParser(field, width, maxWidth, baseValue, null); appendValue(pp); return this; } ",
        "focal_src": "public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int maxWidth, int baseValue) { Objects.requireNonNull(field, \"field\"); ReducedPrinterParser pp = new ReducedPrinterParser(field, width, maxWidth, baseValue); appendValue(pp); return this; } ",
        "test_tgt": "@Test(expectedExceptions = NullPointerException.class)public void test_appendValueReduced_int_nullField()throws Exception { builder.appendValueReduced(null, 2, 2, 2000); } "
    },
    {
        "test_src": "@Test public void stringTest()throws QueryIOException { parse(\"\\\"\\\"\", false); parse(\"\\\"test\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\\n\\\"\", false); parse(\"\\\"\\\\\\\"\\\\\\\\\\\"\", false); parse(\"\\\"\\\\u000a\\\"\", \"\\\"\\\\n\\\"\", false); parse(\"\\\"\\\\u000A\\\"\", \"\\\"\\\\n\\\"\", false); parse(\"\\\"\\n\\\"\", \"\\\"\\\\n\\\"\", true); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"a\\\"\", \"\\\"a\\\"\", false); parse(\"\\\"\\\\b\\\\f\\\\t\\\\r\\\\n\\\"\", \"\\\"\\\\t\\\\r\\\\n\\\"\", false); parse(\"\\\"\\\\u0000\\\\u001F\\\"\", \"\\\"\\\"\", false); unescape(\"\\\"\\\\b\\\\f\\\\t\\\\r\\\\n\\\"\", \"\\\"\\\\\\\\b\\\\\\\\f\\\\\\\\t\\\\\\\\r\\\\\\\\n\\\"\"); unescape(\"\\\"\\\\uD853\\\\uDF5C\\\"\", \"\\\"\\\\\\\\uD853\\\\\\\\uDF5C\\\"\"); unescape(\"\\\"\\\\uD853asdf\\\"\", \"\\\"\\\\\\\\uD853asdf\\\"\"); unescape(\"\\\"\\\\uD853\\\"\", \"\\\"\\\\\\\\uD853\\\"\"); unescape(\"\\\"\\\\t\\\"\", \"\\\"\\\\\\\\t\\\"\"); unescape(\"\\\"\\\\u00E4\\\\t\\\"\", \"\\\"\\\\\\\\u00E4\\\\\\\\t\\\"\"); error(\"\\\"\\\\u0A\", false); error(\"\\\"\\\\uXX0A\\\"\", false); error(\"\\\"\\\\u0 00\\\"\", false); error(\"\\\"\\\\u0:00\\\"\", false); error(\"\\\"\\\\u0_00\\\"\", false); error(\"\\\"\\\\u0~00\\\"\", false); error(\"\\\"test\", false); error(\"\\\"\", false); error(\"\\\"\\n\\\"\", false); } ",
        "focal_tgt": "private byte[]string()throws QueryIOException { if( ! consume('\"'))throw error(\"Expected string, found '%'\", curr()); tb.reset(); char high = 0; while(pos < length) { final int p = pos; int ch = consume(); if(ch == '\"') { if(high != 0)add(high, pos - 7, p); skipWs(); return tb.toArray(); } if(ch == '\\\\') { if(escape) { if(high != 0) { tb.add(high); high = 0; } tb.add('\\\\'); } final int n = consume(); switch(n) { case '/' : case '\\\\' : case '\"' : ch = n; break; case 'b' : ch = escape ? 'b' : '\\b'; break; case 'f' : ch = escape ? 'f' : '\\f'; break; case 't' : ch = escape ? 't' : '\\t'; break; case 'r' : ch = escape ? 'r' : '\\r'; break; case 'n' : ch = escape ? 'n' : '\\n'; break; case 'u' : if(pos + 4 >= length)throw eof(\", expected four-digit hex value\"); if(escape) { tb.add('u'); for(int i = 0; i < 4; i ++ ) { final char x = consume(); if(x >= '0' && x <= '9' || x >= 'a' && x <= 'f' || x >= 'A' && x <= 'F') { tb.add(x); } else throw error(\"Illegal hexadecimal digit: '%'\", x); } continue; } ch = 0; for(int i = 0; i < 4; i ++ ) { final char x = consume(); if(x >= '0' && x <= '9')ch = 16 * ch + x - '0'; else if(x >= 'a' && x <= 'f')ch = 16 * ch + x + 10 - 'a'; else if(x >= 'A' && x <= 'F')ch = 16 * ch + x + 10 - 'A'; else throw error(\"Illegal hexadecimal digit: '%'\", x); } break; default : throw error(\"Unknown character escape: '\\\\%'\", n); } } else if( ! liberal && ch <= 0x1F) { throw error(\"Non-escaped control character: '\\\\%'\", CTRL[ch]); } if(high != 0) { if(ch >= 0xDC00 && ch <= 0xDFFF)ch = (high - 0xD800 << 10) + ch - 0xDC00 + 0x10000; else add(high, p, pos); high = 0; } if(ch >= 0xD800 && ch <= 0xDBFF) { high = (char)ch; } else { add(ch, p, pos); } } throw eof(\" in string literal\"); } ",
        "focal_src": "private byte[]string()throws QueryIOException { if( ! consume('\"'))throw error(\"Expected string, found '%'\", curr()); tb.reset(); char high = 0; while(pos < length) { final int p = pos; int ch = consume(); if(ch == '\"') { if(high != 0)add(high, pos - 7, p); skipWs(); return tb.toArray(); } if(ch == '\\\\') { if( ! unescape) { if(high != 0) { tb.add(high); high = 0; } tb.add('\\\\'); } final int n = consume(); switch(n) { case '/' : case '\\\\' : case '\"' : ch = n; break; case 'b' : ch = unescape ? '\\b' : 'b'; break; case 'f' : ch = unescape ? '\\f' : 'f'; break; case 't' : ch = unescape ? '\\t' : 't'; break; case 'r' : ch = unescape ? '\\r' : 'r'; break; case 'n' : ch = unescape ? '\\n' : 'n'; break; case 'u' : if(pos + 4 >= length)throw eof(\", expected four-digit hex value\"); if(unescape) { ch = 0; for(int i = 0; i < 4; i ++ ) { final char x = consume(); if(x >= '0' && x <= '9')ch = 16 * ch + x - '0'; else if(x >= 'a' && x <= 'f')ch = 16 * ch + x + 10 - 'a'; else if(x >= 'A' && x <= 'F')ch = 16 * ch + x + 10 - 'A'; else throw error(\"Illegal hexadecimal digit: '%'\", x); } } else { tb.add('u'); for(int i = 0; i < 4; i ++ ) { final char x = consume(); if(x >= '0' && x <= '9' || x >= 'a' && x <= 'f' || x >= 'A' && x <= 'F') { tb.add(x); } else throw error(\"Illegal hexadecimal digit: '%'\", x); } continue; } break; default : throw error(\"Unknown character escape: '\\\\%'\", n); } } else if( ! liberal && ch <= 0x1F) { throw error(\"Non-escaped control character: '\\\\%'\", CTRL[ch]); } if(high != 0) { if(ch >= 0xDC00 && ch <= 0xDFFF)ch = (high - 0xD800 << 10) + ch - 0xDC00 + 0x10000; else add(high, p, pos); high = 0; } if(ch >= 0xD800 && ch <= 0xDBFF) { high = (char)ch; } else { add(ch, p, pos); } } throw eof(\" in string literal\"); } ",
        "test_tgt": "@Test public void stringTest()throws QueryIOException { parse(\"\\\"\\\"\", false); parse(\"\\\"test\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\"\", false); parse(\"\\\"\\\\n\\\"\", false); parse(\"\\\"\\\\\\\"\\\\\\\\\\\"\", false); parse(\"\\\"\\\\u000a\\\"\", \"\\\"\\\\n\\\"\", false); parse(\"\\\"\\\\u000A\\\"\", \"\\\"\\\\n\\\"\", false); parse(\"\\\"\\n\\\"\", \"\\\"\\\\n\\\"\", true); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"\\\"\", \"\\\"\\\"\", false); parse(\"\\\"a\\\"\", \"\\\"a\\\"\", false); parse(\"\\\"\\\\b\\\\f\\\\t\\\\r\\\\n\\\"\", \"\\\"\\\\t\\\\r\\\\n\\\"\", false); parse(\"\\\"\\\\u0000\\\\u001F\\\"\", \"\\\"\\\"\", false); escape(\"\\\"\\\\b\\\\f\\\\t\\\\r\\\\n\\\"\", \"\\\"\\\\\\\\b\\\\\\\\f\\\\\\\\t\\\\\\\\r\\\\\\\\n\\\"\"); escape(\"\\\"\\\\uD853\\\\uDF5C\\\"\", \"\\\"\\\\\\\\uD853\\\\\\\\uDF5C\\\"\"); escape(\"\\\"\\\\uD853asdf\\\"\", \"\\\"\\\\\\\\uD853asdf\\\"\"); escape(\"\\\"\\\\uD853\\\"\", \"\\\"\\\\\\\\uD853\\\"\"); escape(\"\\\"\\\\t\\\"\", \"\\\"\\\\\\\\t\\\"\"); escape(\"\\\"\\\\u00E4\\\\t\\\"\", \"\\\"\\\\\\\\u00E4\\\\\\\\t\\\"\"); error(\"\\\"\\\\u0A\", false); error(\"\\\"\\\\uXX0A\\\"\", false); error(\"\\\"\\\\u0 00\\\"\", false); error(\"\\\"\\\\u0:00\\\"\", false); error(\"\\\"\\\\u0_00\\\"\", false); error(\"\\\"\\\\u0~00\\\"\", false); error(\"\\\"test\", false); error(\"\\\"\", false); error(\"\\\"\\n\\\"\", false); } "
    },
    {
        "test_src": "@Test public void testGetOrAssignStreamSegmentId() { final int segmentCount = 10; final int transactionsPerSegment = 5; @Cleanup TestContext context = new TestContext(); HashSet < String > storageSegments = new HashSet < > (); for(int i = 0; i < segmentCount; i ++ ) { String segmentName = getName(i); storageSegments.add(segmentName); setAttributes(segmentName, storageSegments.size() % ATTRIBUTE_COUNT, context); for(int j = 0; j < transactionsPerSegment; j ++ ) { String transactionName = StreamSegmentNameUtils.getTransactionNameFromId(segmentName, UUID.randomUUID()); storageSegments.add(transactionName); setAttributes(transactionName, storageSegments.size() % ATTRIBUTE_COUNT, context); } } setupOperationLog(context); Predicate < String > isSealed = segmentName -> segmentName.hashCode() % 2 == 0; Function < String, Long > getInitialLength = segmentName -> (long)Math.abs(segmentName.hashCode()); setupStorageGetHandler(context, storageSegments, segmentName -> new StreamSegmentInformation(segmentName, getInitialLength.apply(segmentName), isSealed.test(segmentName), false, new ImmutableDate())); for(String name : storageSegments) { if(StreamSegmentNameUtils.getParentStreamSegmentName(name) == null) { long id = context.mapper.getOrAssignStreamSegmentId(name, TIMEOUT).join(); Assert.assertNotEquals(\"No id was assigned for StreamSegment \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, id); SegmentMetadata sm = context.metadata.getStreamSegmentMetadata(id); Assert.assertNotNull(\"No metadata was created for StreamSegment \" + name, sm); long expectedLength = getInitialLength.apply(name); boolean expectedSeal = isSealed.test(name); Assert.assertEquals(\"Metadata does not have the expected length for StreamSegment \" + name, expectedLength, sm.getDurableLogLength()); Assert.assertEquals(\"Metadata does not have the expected value for isSealed for StreamSegment \" + name, expectedSeal, sm.isSealed()); val segmentState = context.stateStore.get(name, TIMEOUT).join(); Map < UUID, Long > expectedAttributes = segmentState == null ? null : segmentState.getAttributes(); SegmentMetadataComparer.assertSameAttributes(\"Unexpected attributes in metadata for StreamSegment \" + name, expectedAttributes, sm); } } for(String name : storageSegments) { String parentName = StreamSegmentNameUtils.getParentStreamSegmentName(name); if(parentName != null) { long id = context.mapper.getOrAssignStreamSegmentId(name, TIMEOUT).join(); Assert.assertNotEquals(\"No id was assigned for Transaction \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, id); SegmentMetadata sm = context.metadata.getStreamSegmentMetadata(id); Assert.assertNotNull(\"No metadata was created for Transaction \" + name, sm); long expectedLength = getInitialLength.apply(name); boolean expectedSeal = isSealed.test(name); Assert.assertEquals(\"Metadata does not have the expected length for Transaction \" + name, expectedLength, sm.getDurableLogLength()); Assert.assertEquals(\"Metadata does not have the expected value for isSealed for Transaction \" + name, expectedSeal, sm.isSealed()); val segmentState = context.stateStore.get(name, TIMEOUT).join(); Map < UUID, Long > expectedAttributes = segmentState == null ? null : segmentState.getAttributes(); SegmentMetadataComparer.assertSameAttributes(\"Unexpected attributes in metadata for Transaction \" + name, expectedAttributes, sm); Assert.assertNotEquals(\"No parent defined in metadata for Transaction \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, sm.getParentId()); long parentId = context.metadata.getStreamSegmentId(parentName); Assert.assertEquals(\"Unexpected parent defined in metadata for Transaction \" + name, parentId, sm.getParentId()); } } } ",
        "focal_tgt": "public CompletableFuture < Long > getOrAssignStreamSegmentId(String streamSegmentName, Duration timeout) { long streamSegmentId = this.containerMetadata.getStreamSegmentId(streamSegmentName, true); if(isValidStreamSegmentId(streamSegmentId)) { if(this.containerMetadata.getStreamSegmentMetadata(streamSegmentId).isDeleted()) { return FutureHelpers.failedFuture(new StreamSegmentNotExistsException(streamSegmentName)); } else { return CompletableFuture.completedFuture(streamSegmentId); } } CompletableFuture < Long > result; boolean needsAssignment = false; synchronized(assignmentLock) { result = this.pendingRequests.getOrDefault(streamSegmentName, null); if(result == null) { needsAssignment = true; result = new CompletableFuture < > (); this.pendingRequests.put(streamSegmentName, result); } } if(needsAssignment) { String parentStreamSegmentName = StreamSegmentNameUtils.getParentStreamSegmentName(streamSegmentName); if(parentStreamSegmentName == null) { this.executor.execute(() -> assignStreamSegmentId(streamSegmentName, timeout)); } else { this.executor.execute(() -> assignTransactionStreamSegmentId(streamSegmentName, parentStreamSegmentName, timeout)); } } return result; } ",
        "focal_src": "public CompletableFuture < Long > getOrAssignStreamSegmentId(String streamSegmentName, Duration timeout) { long streamSegmentId = this.containerMetadata.getStreamSegmentId(streamSegmentName); if(isValidStreamSegmentId(streamSegmentId)) { if(this.containerMetadata.getStreamSegmentMetadata(streamSegmentId).isDeleted()) { return FutureHelpers.failedFuture(new StreamSegmentNotExistsException(streamSegmentName)); } else { return CompletableFuture.completedFuture(streamSegmentId); } } CompletableFuture < Long > result; boolean needsAssignment = false; synchronized(assignmentLock) { result = this.pendingRequests.getOrDefault(streamSegmentName, null); if(result == null) { needsAssignment = true; result = new CompletableFuture < > (); this.pendingRequests.put(streamSegmentName, result); } } if(needsAssignment) { String parentStreamSegmentName = StreamSegmentNameUtils.getParentStreamSegmentName(streamSegmentName); if(parentStreamSegmentName == null) { this.executor.execute(() -> assignStreamSegmentId(streamSegmentName, timeout)); } else { this.executor.execute(() -> assignTransactionStreamSegmentId(streamSegmentName, parentStreamSegmentName, timeout)); } } return result; } ",
        "test_tgt": "@Test public void testGetOrAssignStreamSegmentId() { final int segmentCount = 10; final int transactionsPerSegment = 5; @Cleanup TestContext context = new TestContext(); HashSet < String > storageSegments = new HashSet < > (); for(int i = 0; i < segmentCount; i ++ ) { String segmentName = getName(i); storageSegments.add(segmentName); setAttributes(segmentName, storageSegments.size() % ATTRIBUTE_COUNT, context); for(int j = 0; j < transactionsPerSegment; j ++ ) { String transactionName = StreamSegmentNameUtils.getTransactionNameFromId(segmentName, UUID.randomUUID()); storageSegments.add(transactionName); setAttributes(transactionName, storageSegments.size() % ATTRIBUTE_COUNT, context); } } setupOperationLog(context); Predicate < String > isSealed = segmentName -> segmentName.hashCode() % 2 == 0; Function < String, Long > getInitialLength = segmentName -> (long)Math.abs(segmentName.hashCode()); setupStorageGetHandler(context, storageSegments, segmentName -> new StreamSegmentInformation(segmentName, getInitialLength.apply(segmentName), isSealed.test(segmentName), false, new ImmutableDate())); for(String name : storageSegments) { if(StreamSegmentNameUtils.getParentStreamSegmentName(name) == null) { long id = context.mapper.getOrAssignStreamSegmentId(name, TIMEOUT).join(); Assert.assertNotEquals(\"No id was assigned for StreamSegment \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, id); SegmentMetadata sm = context.metadata.getStreamSegmentMetadata(id); Assert.assertNotNull(\"No metadata was created for StreamSegment \" + name, sm); long expectedLength = getInitialLength.apply(name); boolean expectedSeal = isSealed.test(name); Assert.assertEquals(\"Metadata does not have the expected length for StreamSegment \" + name, expectedLength, sm.getDurableLogLength()); Assert.assertEquals(\"Metadata does not have the expected value for isSealed for StreamSegment \" + name, expectedSeal, sm.isSealed()); val segmentState = context.stateStore.get(name, TIMEOUT).join(); Map < UUID, Long > expectedAttributes = segmentState == null ? null : segmentState.getAttributes(); SegmentMetadataComparer.assertSameAttributes(\"Unexpected attributes in metadata for StreamSegment \" + name, expectedAttributes, sm); } } for(String name : storageSegments) { String parentName = StreamSegmentNameUtils.getParentStreamSegmentName(name); if(parentName != null) { long id = context.mapper.getOrAssignStreamSegmentId(name, TIMEOUT).join(); Assert.assertNotEquals(\"No id was assigned for Transaction \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, id); SegmentMetadata sm = context.metadata.getStreamSegmentMetadata(id); Assert.assertNotNull(\"No metadata was created for Transaction \" + name, sm); long expectedLength = getInitialLength.apply(name); boolean expectedSeal = isSealed.test(name); Assert.assertEquals(\"Metadata does not have the expected length for Transaction \" + name, expectedLength, sm.getDurableLogLength()); Assert.assertEquals(\"Metadata does not have the expected value for isSealed for Transaction \" + name, expectedSeal, sm.isSealed()); val segmentState = context.stateStore.get(name, TIMEOUT).join(); Map < UUID, Long > expectedAttributes = segmentState == null ? null : segmentState.getAttributes(); SegmentMetadataComparer.assertSameAttributes(\"Unexpected attributes in metadata for Transaction \" + name, expectedAttributes, sm); Assert.assertNotEquals(\"No parent defined in metadata for Transaction \" + name, ContainerMetadata.NO_STREAM_SEGMENT_ID, sm.getParentId()); long parentId = context.metadata.getStreamSegmentId(parentName, false); Assert.assertEquals(\"Unexpected parent defined in metadata for Transaction \" + name, parentId, sm.getParentId()); } } } "
    },
    {
        "test_src": "@Test public void updateEntries()throws IOException { check(_ZIP_UPDATE_ENTRIES); String list = query(_ZIP_ENTRIES.args(ZIP)); query(_ZIP_UPDATE_ENTRIES.args(list, TMPZIP)); final String list2 = query(_ZIP_ENTRIES.args(TMPZIP)); assertEquals(list.replaceAll(\" href=\\\".*?\\\"\", \"\"), list2.replaceAll(\" href=\\\".*?\\\"\", \"\")); list = list.replaceAll(\"<zip:dir name=.test.>.*</zip:dir>\", \"\"); query(_ZIP_UPDATE_ENTRIES.args(list, TMPZIP)); list = list.replaceAll(\"<zip:dir.*</zip:dir>\", \"\"); error(_ZIP_UPDATE_ENTRIES.args(list, new File(TMPZIP).getCanonicalPath()), Err.ZIP_FAIL); } ",
        "focal_tgt": "private Item updateEntries(final QueryContext ctx)throws QueryException { final ANode elm = (ANode)checkType(expr[0].item(ctx, info), NodeType.ELM); if( ! elm.qname().eq(E_FILE))ZIP_UNKNOWN.thrw(info, elm.qname()); final String in = attribute(elm, A_HREF, true); final IOFile target = new IOFile(string(checkStr(expr[1], ctx))); IOFile out; do { out = new IOFile(target.path() + new Random().nextInt(0x7FFFFFFF)); } while(out.exists()); if( ! new IOFile(in).exists())ZIP_NOTFOUND.thrw(info, in); ZipFile zf = null; boolean ok = true; try { zf = new ZipFile(in); FileOutputStream fos = null; try { fos = new FileOutputStream(out.path()); final ZipOutputStream zos = new ZipOutputStream(new BufferedOutputStream(fos)); create(zos, elm.children(), \"\", zf, ctx); zos.close(); } catch(final IOException ex) { ok = false; ZIP_FAIL.thrw(info, ex); } finally { if(fos != null)try { fos.close(); } catch(final IOException ex) { } } } catch(final IOException ex) { throw ZIP_FAIL.thrw(info, ex); } finally { if(zf != null)try { zf.close(); } catch(final IOException e) { } if(ok) { target.delete(); out.rename(target); } else { out.delete(); } } return null; } ",
        "focal_src": "private Item updateEntries(final QueryContext ctx)throws QueryException { final ANode elm = (ANode)checkType(expr[0].item(ctx, info), NodeType.ELM); if( ! elm.qname().eq(E_FILE))ZIP_UNKNOWN.thrw(info, elm.qname()); final String in = attribute(elm, A_HREF, true); final IOFile target = new IOFile(string(checkStr(expr[1], ctx))); IOFile out; do { out = new IOFile(target.path() + new Random().nextInt(0x7FFFFFFF)); } while(out.exists()); if( ! new IOFile(in).exists())ZIP_NOTFOUND.thrw(info, in); ZipFile zf = null; boolean ok = true; try { zf = new ZipFile(in); FileOutputStream fos = null; try { fos = new FileOutputStream(out.path()); final ZipOutputStream zos = new ZipOutputStream(new BufferedOutputStream(fos)); create(zos, elm.children(), \"\", zf, ctx); zos.close(); } catch(final IOException ex) { ok = false; ZIP_FAIL.thrw(info, ex.getMessage()); } finally { if(fos != null)try { fos.close(); } catch(final IOException ex) { } } } catch(final IOException ex) { throw ZIP_FAIL.thrw(info, ex.getMessage()); } finally { if(zf != null)try { zf.close(); } catch(final IOException e) { } if(ok) { target.delete(); out.rename(target); } else { out.delete(); } } return null; } ",
        "test_tgt": "@Test public void zipUpdateEntries()throws IOException { check(_ZIP_UPDATE_ENTRIES); String list = query(_ZIP_ENTRIES.args(ZIP)); query(_ZIP_UPDATE_ENTRIES.args(list, TMPZIP)); final String list2 = query(_ZIP_ENTRIES.args(TMPZIP)); assertEquals(list.replaceAll(\" href=\\\".*?\\\"\", \"\"), list2.replaceAll(\" href=\\\".*?\\\"\", \"\")); list = list.replaceAll(\"<zip:dir name=.test.>.*</zip:dir>\", \"\"); query(_ZIP_UPDATE_ENTRIES.args(list, TMPZIP)); list = list.replaceAll(\"<zip:dir.*</zip:dir>\", \"\"); error(_ZIP_UPDATE_ENTRIES.args(list, new File(TMPZIP).getCanonicalPath()), Err.ZIP_FAIL); } "
    },
    {
        "test_src": "@Test public void scaleSpace() { double ss[] = new double[] { 1, 2, 4, 6, 8, 10 }; PyramidFloat < ImageFloat32 > pyramid = FactoryPyramid.scaleSpacePyramid(ss, ImageFloat32.class); for(int i = 0; i < ss.length; i ++ ) { assertEquals(ss[i], pyramid.getSigma(i), 1e-8); assertEquals(ss[i], pyramid.getScale(i), 1e-8); if(i > 1)assertTrue(Math.abs(ss[i] - ((PyramidFloatGaussianScale)pyramid).getSigmaLayers()[i]) > 0.1); } } ",
        "focal_tgt": "public static < T extends ImageGray > PyramidFloat < T > scaleSpace(double scaleSpace[], Class < T > imageType) { double[]scaleFactors = new double[scaleSpace.length]; for(int i = 0; i < scaleSpace.length; i ++ ) { scaleFactors[i] = 1; } double[]sigmas = new double[scaleSpace.length]; sigmas[0] = scaleSpace[0]; for(int i = 1; i < scaleSpace.length; i ++ ) { double c = scaleSpace[i]; double b = scaleSpace[i - 1]; sigmas[i] = Math.sqrt(c * c - b * b); } return floatGaussian(scaleFactors, sigmas, imageType); } ",
        "focal_src": "public static < T extends ImageSingleBand > PyramidFloat < T > scaleSpace(double scaleSpace[], Class < T > imageType) { double[]scaleFactors = new double[scaleSpace.length]; for(int i = 0; i < scaleSpace.length; i ++ ) { scaleFactors[i] = 1; } double[]sigmas = new double[scaleSpace.length]; sigmas[0] = scaleSpace[0]; for(int i = 1; i < scaleSpace.length; i ++ ) { double c = scaleSpace[i]; double b = scaleSpace[i - 1]; sigmas[i] = Math.sqrt(c * c - b * b); } return floatGaussian(scaleFactors, sigmas, imageType); } ",
        "test_tgt": "@Test public void scaleSpace() { double ss[] = new double[] { 1, 2, 4, 6, 8, 10 }; PyramidFloat < GrayF32 > pyramid = FactoryPyramid.scaleSpacePyramid(ss, GrayF32.class); for(int i = 0; i < ss.length; i ++ ) { assertEquals(ss[i], pyramid.getSigma(i), 1e-8); assertEquals(ss[i], pyramid.getScale(i), 1e-8); if(i > 1)assertTrue(Math.abs(ss[i] - ((PyramidFloatGaussianScale)pyramid).getSigmaLayers()[i]) > 0.1); } } "
    },
    {
        "test_src": "@Test public void testUploadPackage()throws Exception { ScpUploader uploader = Mockito.spy(new ScpUploader()); ScpController controller = Mockito.mock(ScpController.class); Mockito.doReturn(controller).when(uploader).getScpController(); uploader.initialize(config); Mockito.doReturn(false).when(uploader).isLocalFileExists(Mockito.anyString()); Assert.assertNull(uploader.uploadPackage()); Mockito.verify(controller, Mockito.never()).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); Mockito.doReturn(true).when(uploader).isLocalFileExists(Mockito.anyString()); Mockito.doReturn(false).when(controller).mkdirsIfNotExists(Mockito.anyString()); Assert.assertNull(uploader.uploadPackage()); Mockito.verify(controller, Mockito.never()).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); Mockito.doReturn(true).when(controller).mkdirsIfNotExists(Mockito.anyString()); Mockito.doReturn(false).when(controller).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); Assert.assertNull(uploader.uploadPackage()); Mockito.verify(controller).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); Mockito.doReturn(true).when(controller).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); Assert.assertNotNull(uploader.uploadPackage()); Mockito.verify(controller, Mockito.atLeastOnce()).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); } ",
        "focal_tgt": "@Override public URI uploadPackage()throws UploaderException { boolean fileExists = new File(topologyPackageLocation).isFile(); if( ! fileExists) { throw new UploaderException(String.format(\"Topology package does not exist at '%s'\", topologyPackageLocation)); } Path filePath = Paths.get(destTopologyFile); File parentDirectory = filePath.getParent().toFile(); assert parentDirectory != null; if( ! parentDirectory.exists()) { LOG.fine(String.format(\"Working directory does not exist. Creating it now at %s\", parentDirectory.getPath())); if( ! parentDirectory.mkdirs()) { throw new UploaderException(String.format(\"Failed to create directory for topology package at %s\", parentDirectory.getPath())); } } fileExists = new File(filePath.toString()).isFile(); if(fileExists) { LOG.fine(String.format(\"Target topology package already exists at '%s'. Overwriting it now\", filePath.toString())); } LOG.fine(String.format(\"Copying topology package at '%s' to target working directory '%s'\", topologyPackageLocation, filePath.toString())); Path source = Paths.get(topologyPackageLocation); try { CopyOption[]options = new CopyOption[] { StandardCopyOption.REPLACE_EXISTING }; Files.copy(source, filePath, options); } catch(IOException e) { throw new UploaderException(String.format(\"Unable to copy topology file from '%s' to '%s'\", source, filePath), e); } return getUri(destTopologyFile); } ",
        "focal_src": "@Override public URI uploadPackage() { boolean fileExists = new File(topologyPackageLocation).isFile(); if( ! fileExists) { LOG.info(\"Topology file \" + topologyPackageLocation + \" does not exist.\"); return null; } Path filePath = Paths.get(destTopologyFile); File parentDirectory = filePath.getParent().toFile(); assert parentDirectory != null; if( ! parentDirectory.exists()) { LOG.fine(\"The working directory does not exist; creating it.\"); if( ! parentDirectory.mkdirs()) { LOG.severe(\"Failed to create directory: \" + parentDirectory.getPath()); return null; } } fileExists = new File(filePath.toString()).isFile(); if(fileExists) { LOG.fine(\"Target topology file \" + filePath.toString() + \" exists, overwriting...\"); } LOG.fine(\"Copying topology \" + topologyPackageLocation + \" package to target working directory \" + filePath.toString()); Path source = Paths.get(topologyPackageLocation); try { CopyOption[]options = new CopyOption[] { StandardCopyOption.REPLACE_EXISTING }; Files.copy(source, filePath, options); } catch(IOException ex) { LOG.info(\"Unable to copy: \" + source.toString() + \" \" + ex); return null; } return getUri(destTopologyFile); } ",
        "test_tgt": "@Test public void testUploadPackage() { ScpUploader uploader = Mockito.spy(new ScpUploader()); Mockito.doReturn(true).when(uploader).isLocalFileExists(Mockito.anyString()); ScpController controller = Mockito.mock(ScpController.class); Mockito.doReturn(controller).when(uploader).getScpController(); Mockito.doReturn(true).when(controller).mkdirsIfNotExists(Mockito.anyString()); uploader.initialize(config); Mockito.doReturn(true).when(controller).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); uploader.uploadPackage(); Mockito.verify(controller, Mockito.atLeastOnce()).copyFromLocalFile(Mockito.anyString(), Mockito.anyString()); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should set retired to false if retireReason is null or empty\", method = \"validate(Object,Errors)\")public void validate_shouldSetRetiredToFalseIfRetireReasonIsNullOrEmpty()throws Exception { Location location = new Location(); location.setName(\"County General\"); location.setRetired(true); Errors errors = new BindException(location, \"location\"); new LocationValidator().validate(location, errors); Assert.assertFalse(location.isRetired()); } ",
        "focal_tgt": "@Override public void validate(Object obj, Errors errors) { Alert alert = (Alert)obj; if(alert == null) { errors.rejectValue(\"alert\", \"error.general\"); } else { ValidationUtils.rejectIfEmptyOrWhitespace(errors, \"text\", \"Alert.text.required\"); ValidateUtil.validateFieldLengths(errors, obj.getClass(), \"text\"); } } ",
        "focal_src": "public void validate(Object obj, Errors errors) { Alert alert = (Alert)obj; if(alert == null) { errors.rejectValue(\"alert\", \"error.general\"); } else { ValidationUtils.rejectIfEmptyOrWhitespace(errors, \"text\", \"Alert.text.required\"); ValidateUtil.validateFieldLengths(errors, obj.getClass(), \"text\"); } } ",
        "test_tgt": "@Test@Verifies(value = \"should set retired to false if retireReason is null or empty\", method = \"validate(Object,Errors)\")public void validate_shouldSetRetiredToFalseIfRetireReasonIsNullOrEmpty()throws Exception { Location location = new Location(); location.setName(\"County General\"); location.setRetired(true); Errors errors = new BindException(location, \"location\"); new LocationValidator().validate(location, errors); Assert.assertFalse(location.getRetired()); } "
    },
    {
        "test_src": "@Test public void testInitializeClientHelloExtension() { MaxFragmentLengthExtensionMessage initializedMessage; MaxFragmentLengthExtensionHandler maxFragmentHandlerInitialised = MaxFragmentLengthExtensionHandler.getInstance(); initializedMessage = new MaxFragmentLengthExtensionMessage(); initializedMessage.setMaxFragmentLengthConfig(MaxFragmentLength.TWO_12); maxFragmentHandlerInitialised.initializeClientHelloExtension(initializedMessage); Assert.assertArrayEquals(\"Tests if the extension bytes are set correctly by the initializeClientHelloExtension method\", extensionMessage, initializedMessage.getExtensionBytes().getValue()); Assert.assertEquals(\"Tests if the extension length is set correctly by the initializeClientHelloExtension method\", new Integer(1), initializedMessage.getExtensionLength().getValue()); Assert.assertArrayEquals(\"Tests if the extension type method is set correctly by the initializeClientHelloExtension method\", ExtensionType.MAX_FRAGMENT_LENGTH.getValue(), initializedMessage.getExtensionType().getValue()); Assert.assertArrayEquals(\"Tests if the max fragment length is set correctly by the initializeClientHelloExtension method\", MaxFragmentLength.TWO_12.getArrayValue(), initializedMessage.getMaxFragmentLength().getValue()); } ",
        "focal_tgt": "@Override public void prepareExtension(TlsContext context) { byte[]curves = new byte[0]; for(NamedCurve curve : context.getConfig().getNamedCurves()) { curves = ArrayConverter.concatenate(curves, curve.getValue()); } EllipticCurvesExtensionMessage extension = (EllipticCurvesExtensionMessage)extensionMessage; extension.setExtensionType(ExtensionType.ELLIPTIC_CURVES.getValue()); extension.setSupportedCurves(curves); extension.setSupportedCurvesLength(curves != null ? curves.length : 0); extension.setExtensionLength(extension.getSupportedCurvesLength().getValue() + ExtensionByteLength.EXTENSIONS); byte[]ecExtensionBytes = ArrayConverter.concatenate(extension.getExtensionType().getValue(), ArrayConverter.intToBytes(extension.getExtensionLength().getValue(), ExtensionByteLength.EXTENSIONS), ArrayConverter.intToBytes(extension.getSupportedCurvesLength().getValue(), SUPPORTED_ELLIPTIC_CURVES_LENGTH), extension.getSupportedCurves().getValue()); extension.setExtensionBytes(ecExtensionBytes); } ",
        "focal_src": "@Override public void initializeClientHelloExtension(EllipticCurvesExtensionMessage extension) { byte[]curves = new byte[0]; for(NamedCurve curve : extension.getSupportedCurvesConfig()) { curves = ArrayConverter.concatenate(curves, curve.getValue()); } extension.setExtensionType(ExtensionType.ELLIPTIC_CURVES.getValue()); extension.setSupportedCurves(curves); extension.setSupportedCurvesLength(curves != null ? curves.length : 0); extension.setExtensionLength(extension.getSupportedCurvesLength().getValue() + ExtensionByteLength.EXTENSIONS); byte[]ecExtensionBytes = ArrayConverter.concatenate(extension.getExtensionType().getValue(), ArrayConverter.intToBytes(extension.getExtensionLength().getValue(), ExtensionByteLength.EXTENSIONS), ArrayConverter.intToBytes(extension.getSupportedCurvesLength().getValue(), SUPPORTED_ELLIPTIC_CURVES_LENGTH), extension.getSupportedCurves().getValue()); extension.setExtensionBytes(ecExtensionBytes); } ",
        "test_tgt": "@Test public void testInitializeClientHelloExtension() { MaxFragmentLengthExtensionMessage initializedMessage; MaxFragmentLengthExtensionHandler maxFragmentHandlerInitialised = new MaxFragmentLengthExtensionHandler(); initializedMessage = new MaxFragmentLengthExtensionMessage(); initializedMessage.setMaxFragmentLengthConfig(MaxFragmentLength.TWO_12); maxFragmentHandlerInitialised.prepareExtension(new TlsContext(new TlsConfig())); Assert.assertArrayEquals(\"Tests if the extension bytes are set correctly by the initializeClientHelloExtension method\", extensionMessage, initializedMessage.getExtensionBytes().getValue()); Assert.assertEquals(\"Tests if the extension length is set correctly by the initializeClientHelloExtension method\", new Integer(1), initializedMessage.getExtensionLength().getValue()); Assert.assertArrayEquals(\"Tests if the extension type method is set correctly by the initializeClientHelloExtension method\", ExtensionType.MAX_FRAGMENT_LENGTH.getValue(), initializedMessage.getExtensionType().getValue()); Assert.assertArrayEquals(\"Tests if the max fragment length is set correctly by the initializeClientHelloExtension method\", MaxFragmentLength.TWO_12.getArrayValue(), initializedMessage.getMaxFragmentLength().getValue()); } "
    },
    {
        "test_src": "@Test public void testGetStreamSegmentInfo() { @Cleanup val context = new TestContext(); context.container.startAsync().awaitRunning(); AssertExtensions.assertSuppliedFutureThrows(\"Unexpected exception when the segment does not exist.\", () -> context.container.getStreamSegmentInfo(SEGMENT_NAME, false, TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); val storageInfo = context.storage.create(SEGMENT_NAME, TIMEOUT).thenCompose(handle -> context.storage.write(handle, 0, new ByteArrayInputStream(new byte[10]), 10, TIMEOUT)).thenCompose(v -> context.storage.getStreamSegmentInfo(SEGMENT_NAME, TIMEOUT)).join(); val expectedInfo = StreamSegmentInformation.from(storageInfo).startOffset(storageInfo.getLength() / 2).attributes(ImmutableMap.of(UUID.randomUUID(), 100L, Attributes.EVENT_COUNT, 1L)).build(); val actual = context.container.getStreamSegmentInfo(SEGMENT_NAME, false, TIMEOUT).join(); Assert.assertEquals(\"Unexpected Name.\", expectedInfo.getName(), actual.getName()); Assert.assertEquals(\"Unexpected Length.\", expectedInfo.getLength(), actual.getLength()); Assert.assertEquals(\"Unexpected Sealed status.\", expectedInfo.isSealed(), actual.isSealed()); } ",
        "focal_tgt": "CompletableFuture < SegmentProperties > getStreamSegmentInfo(String streamSegmentName, Duration timeout); ",
        "focal_src": "CompletableFuture < SegmentProperties > getStreamSegmentInfo(String streamSegmentName, boolean waitForPendingOps, Duration timeout); ",
        "test_tgt": "@Test public void testGetStreamSegmentInfo() { @Cleanup val context = new TestContext(); context.container.startAsync().awaitRunning(); AssertExtensions.assertSuppliedFutureThrows(\"Unexpected exception when the segment does not exist.\", () -> context.container.getStreamSegmentInfo(SEGMENT_NAME, TIMEOUT), ex -> ex instanceof StreamSegmentNotExistsException); val storageInfo = context.storage.create(SEGMENT_NAME, TIMEOUT).thenCompose(handle -> context.storage.write(handle, 0, new ByteArrayInputStream(new byte[10]), 10, TIMEOUT)).thenCompose(v -> context.storage.getStreamSegmentInfo(SEGMENT_NAME, TIMEOUT)).join(); val expectedInfo = StreamSegmentInformation.from(storageInfo).startOffset(storageInfo.getLength() / 2).attributes(ImmutableMap.of(UUID.randomUUID(), 100L, Attributes.EVENT_COUNT, 1L)).build(); val actual = context.container.getStreamSegmentInfo(SEGMENT_NAME, TIMEOUT).join(); Assert.assertEquals(\"Unexpected Name.\", expectedInfo.getName(), actual.getName()); Assert.assertEquals(\"Unexpected Length.\", expectedInfo.getLength(), actual.getLength()); Assert.assertEquals(\"Unexpected Sealed status.\", expectedInfo.isSealed(), actual.isSealed()); } "
    },
    {
        "test_src": "@Test public void testIsNull() { assertEquals(new IsNullCriterion(\"name\"), instance.isNull(\"name\").getQueryCriterion()); } ",
        "focal_tgt": "public CriteriaQuery isNull(String propName) { criterion = criterion.and(Criteria.isNull(propName)); return this; } ",
        "focal_src": "public CriteriaQuery isNull(String propName) { criterion = criterion.and(criterionBuilder.isNull(propName)); return this; } ",
        "test_tgt": "@Test public void testIsNull() { assertEquals(Criteria.isNull(\"name\"), instance.isNull(\"name\").getQueryCriterion()); } "
    },
    {
        "test_src": "@Test public void integerFromBase() { query(_CONVERT_INTEGER_FROM_BASE.args(\"100\", 2), \"4\"); query(_CONVERT_INTEGER_FROM_BASE.args(\"1111111111111111\", 2), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"10000000000000000\", 2), 65536); query(_CONVERT_INTEGER_FROM_BASE.args(\"4\", 16), 4); query(_CONVERT_INTEGER_FROM_BASE.args(\"ffff\", 16), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"FFFF\", 16), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"10000\", 16), 65536); query(_CONVERT_INTEGER_FROM_BASE.args(\"4\", 10), 4); query(_CONVERT_INTEGER_FROM_BASE.args(\"65535\", 10), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"65536\", 10), 65536); error(_CONVERT_INTEGER_FROM_BASE.args(\"1\", 1), Err.INVBASE); error(_CONVERT_INTEGER_FROM_BASE.args(\"1\", 100), Err.INVBASE); error(_CONVERT_INTEGER_FROM_BASE.args(\"abc\", 10), Err.INVDIG); error(_CONVERT_INTEGER_FROM_BASE.args(\"012\", 2), Err.INVDIG); } ",
        "focal_tgt": "private Int integerFromBase(final QueryContext qc, final InputInfo ii)throws QueryException { final byte[]str = toToken(exprs[0], qc); final long base = toLong(exprs[1], qc); if(base < 2 || base > 36)throw INVBASE_X.get(ii, base); long res = 0; for(final byte b : str) { final int num = b <= '9' ? b - 0x30 : (b & 0xDF) - 0x37; if( ! (b >= '0' && b <= '9' || b >= 'a' && b <= 'z' || b >= 'A' && b <= 'Z') || num >= base)throw INVBASEDIG_X_X.get(ii, base, (char)(b & 0xff)); res = res * base + num; } return Int.get(res); } ",
        "focal_src": "private Int integerFromBase(final QueryContext qc, final InputInfo ii)throws QueryException { final byte[]str = checkStr(exprs[0], qc); final long base = checkItr(exprs[1], qc); if(base < 2 || base > 36)throw INVBASE.get(ii, base); long res = 0; for(final byte b : str) { final int num = b <= '9' ? b - 0x30 : (b & 0xDF) - 0x37; if( ! (b >= '0' && b <= '9' || b >= 'a' && b <= 'z' || b >= 'A' && b <= 'Z') || num >= base)throw INVDIG.get(ii, base, (char)(b & 0xff)); res = res * base + num; } return Int.get(res); } ",
        "test_tgt": "@Test public void integerFromBase() { query(_CONVERT_INTEGER_FROM_BASE.args(\"100\", 2), \"4\"); query(_CONVERT_INTEGER_FROM_BASE.args(\"1111111111111111\", 2), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"10000000000000000\", 2), 65536); query(_CONVERT_INTEGER_FROM_BASE.args(\"4\", 16), 4); query(_CONVERT_INTEGER_FROM_BASE.args(\"ffff\", 16), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"FFFF\", 16), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"10000\", 16), 65536); query(_CONVERT_INTEGER_FROM_BASE.args(\"4\", 10), 4); query(_CONVERT_INTEGER_FROM_BASE.args(\"65535\", 10), 65535); query(_CONVERT_INTEGER_FROM_BASE.args(\"65536\", 10), 65536); error(_CONVERT_INTEGER_FROM_BASE.args(\"1\", 1), Err.INVBASE_X); error(_CONVERT_INTEGER_FROM_BASE.args(\"1\", 100), Err.INVBASE_X); error(_CONVERT_INTEGER_FROM_BASE.args(\"abc\", 10), Err.INVBASEDIG_X_X); error(_CONVERT_INTEGER_FROM_BASE.args(\"012\", 2), Err.INVBASEDIG_X_X); } "
    },
    {
        "test_src": "@Test public void addQty_HavingNegativeQtyFree() { final BigDecimal qtyTotal = new BigDecimal(\"10\"); final BigDecimal qty = new BigDecimal(\"13\"); final boolean allowNegativeCapacity = false; final Capacity capacityTotal = Capacity.createCapacity(qtyTotal, pTomato, uomEach, allowNegativeCapacity); final Bucket capacity = Bucket.createBucketWithCapacityAndQty(capacityTotal, qty); assertCapacityLevels(capacity, \"10\", \"13\", \"-3\"); addQtyAndTest(capacity, uomEach, \"1\", \"0\"); assertCapacityLevels(capacity, \"10\", \"13\", \"-3\"); } ",
        "focal_tgt": "void addQty(ProductId productId, BigDecimal qty, I_C_UOM uom); ",
        "focal_src": "void addQty(I_M_Product product, BigDecimal qty, I_C_UOM uom); ",
        "test_tgt": "@Test public void addQty_HavingNegativeQtyFree() { final BigDecimal qtyTotal = new BigDecimal(\"10\"); final BigDecimal qty = new BigDecimal(\"13\"); final boolean allowNegativeCapacity = false; final Capacity capacityTotal = Capacity.createCapacity(qtyTotal, pTomatoId, uomEach, allowNegativeCapacity); final Bucket capacity = Bucket.createBucketWithCapacityAndQty(capacityTotal, qty); assertCapacityLevels(capacity, \"10\", \"13\", \"-3\"); addQtyAndTest(capacity, uomEach, \"1\", \"0\"); assertCapacityLevels(capacity, \"10\", \"13\", \"-3\"); } "
    },
    {
        "test_src": "@Test public void allInside() { fail(\"implement\"); } ",
        "focal_tgt": "public static PointTransform_F32 allInside(IntrinsicParameters param, boolean applyLeftToRight, IntrinsicParameters paramAdj) { RemoveRadialPtoP_F32 removeDistort = new RemoveRadialPtoP_F32(); AddRadialPtoP_F32 addDistort = new AddRadialPtoP_F32(); removeDistort.set(param.fx, param.fy, param.skew, param.cx, param.cy, param.radial); addDistort.set(param.fx, param.fy, param.skew, param.cx, param.cy, param.radial); Rectangle2D_F32 bound = LensDistortionOps.boundBoxInside(param.width, param.height, new PointToPixelTransform_F32(removeDistort)); double scaleX = bound.width / param.width; double scaleY = bound.height / param.height; double scale = Math.min(scaleX, scaleY); double deltaX = bound.tl_x + (scaleX - scale) * param.width / 2.0; double deltaY = bound.tl_y + (scaleY - scale) * param.height / 2.0; DenseMatrix64F A = new DenseMatrix64F(3, 3, true, scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1); PointTransform_F32 tranAdj = UtilIntrinsic.adjustIntrinsic_F32(addDistort, false, param, A, paramAdj); if(applyLeftToRight) { PointTransform_F32 l2r = new LeftToRightHanded_F32(param.height); return new SequencePointTransform_F32(l2r, tranAdj, l2r); } else return tranAdj; } ",
        "focal_src": "public static PointTransform_F32 allInside(IntrinsicParameters param, boolean applyLeftToRight, IntrinsicParameters paramAdj) { RemoveRadialPtoP_F32 removeDistort = new RemoveRadialPtoP_F32(); AddRadialPtoP_F32 addDistort = new AddRadialPtoP_F32(); removeDistort.set(param.fx, param.fy, param.skew, param.cx, param.cy, param.radial); addDistort.set(param.fx, param.fy, param.skew, param.cx, param.cy, param.radial); Rectangle2D_F32 bound = LensDistortionOps.boundBoxInside(param.width, param.height, new PointToPixelTransform_F32(removeDistort)); double scaleX = param.width / bound.width; double scaleY = param.height / bound.height; double scale = Math.min(scaleX, scaleY); double deltaX = bound.tl_x; double deltaY = bound.tl_y; DenseMatrix64F A = new DenseMatrix64F(3, 3, true, scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1); PointTransform_F32 tranAdj = UtilIntrinsic.adjustDistortion_F32(addDistort, param, A, paramAdj); if(applyLeftToRight) { PointTransform_F32 l2r = new LeftToRightHanded_F32(param.height); return new SequencePointTransform_F32(l2r, tranAdj, l2r); } else return tranAdj; } ",
        "test_tgt": "@Test public void allInside() { IntrinsicParameters param = new IntrinsicParameters(300, 320, 0, 150, 130, width, height, new double[] { 0.1, 1e-4 }); PointTransform_F32 adjusted = LensDistortionOps.allInside(param, false, null); checkInside(adjusted); } "
    },
    {
        "test_src": "@Test public void pointN() { runQuery(\"geo:pointN(<gml:LinearRing><gml:coordinates>2,3 20,1 20,20 2,3\" + \"</gml:coordinates></gml:LinearRing>, 1)\", \"<gml:Point srsName=\\\"0\\\"><gml:coordinates>2.0,3.0</gml:coordinates>\" + \"</gml:Point>\"); runQuery(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 4)\", \"<gml:Point srsName=\\\"0\\\"><gml:coordinates>12.0,13.0</gml:coordinates>\" + \"</gml:Point>\"); runError(\"geo:pointN(<gml:MultiLineString><gml:LineString><gml:coordinates>\" + \"1,1 0,0 2,1</gml:coordinates></gml:LineString><gml:LineString>\" + \"<gml:coordinates>2,1 3,3 4,4</gml:coordinates></gml:LineString>\" + \"</gml:MultiLineString>, 4)\", GeoErrors.qname(4)); runError(\"geo:pointN(\" + \"<gml:unknown><gml:coordinates>1,1</gml:coordinates></gml:unknown>,1)\", GeoErrors.qname(1)); runError(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 5)\", GeoErrors.qname(6)); runError(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 0)\", GeoErrors.qname(6)); runError(\"geo:pointN(text {'a'},3)\", FUNCMP.qname()); } ",
        "focal_tgt": "public Value pointN(final ANode node, final Int number)throws QueryException { final Geometry geo = geo(node, Q_GML_LINEARRING, Q_GML_LINESTRING); if(geo == null && checkGeo(node) != null)throw GeoErrors.geoType(node.qname().local(), \"Line\"); final int max = geo.getNumPoints(); final long n = number.itr(); if(n < 1 || n > max)throw GeoErrors.outOfRangeIdx(number); return gmlWriter(geo instanceof LineString ? ((LineString)geo).getPointN((int)n - 1) : ((LinearRing)geo).getPointN((int)n - 1)); } ",
        "focal_src": "public Value pointN(final ANode node, final Int number)throws QueryException { final Geometry geo = geo(node, Q_GML_LINEARRING, Q_GML_LINESTRING); if(geo == null && checkGeo(node) != null)throw GeoErrors.lineNeeded(node.qname().local()); final int max = geo.getNumPoints(); final long n = number.itr(); if(n < 1 || n > max)throw GeoErrors.outOfRangeIdx(number); return gmlWriter(geo instanceof LineString ? ((LineString)geo).getPointN((int)n - 1) : ((LinearRing)geo).getPointN((int)n - 1)); } ",
        "test_tgt": "@Test public void pointN() { runQuery(\"geo:pointN(<gml:LinearRing><gml:coordinates>2,3 20,1 20,20 2,3\" + \"</gml:coordinates></gml:LinearRing>, 1)\", \"<gml:Point srsName=\\\"0\\\"><gml:coordinates>2.0,3.0</gml:coordinates>\" + \"</gml:Point>\"); runQuery(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 4)\", \"<gml:Point srsName=\\\"0\\\"><gml:coordinates>12.0,13.0</gml:coordinates>\" + \"</gml:Point>\"); runError(\"geo:pointN(<gml:MultiLineString><gml:LineString><gml:coordinates>\" + \"1,1 0,0 2,1</gml:coordinates></gml:LineString><gml:LineString>\" + \"<gml:coordinates>2,1 3,3 4,4</gml:coordinates></gml:LineString>\" + \"</gml:MultiLineString>, 4)\", GeoErrors.qname(3)); runError(\"geo:pointN(\" + \"<gml:unknown><gml:coordinates>1,1</gml:coordinates></gml:unknown>,1)\", GeoErrors.qname(1)); runError(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 5)\", GeoErrors.qname(4)); runError(\"geo:pointN(<gml:LineString><gml:coordinates>11,10 20,1 20,20 12,13\" + \"</gml:coordinates></gml:LineString>, 0)\", GeoErrors.qname(4)); runError(\"geo:pointN(text {'a'},3)\", FUNCMP.qname()); } "
    },
    {
        "test_src": "@Test public void getWorker()throws Exception { List < BlockWorkerInfo > workerInfoList = new ArrayList < > (); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker1\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker2\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 2 * (long)Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker3\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 3 * (long)Constants.GB, 0)); RoundRobinPolicy policy = new RoundRobinPolicy(); Assert.assertNotEquals(policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost(), policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost()); } ",
        "focal_tgt": "WorkerNetAddress getWorker(GetWorkerOptions options); ",
        "focal_src": "WorkerNetAddress getWorker(GetWorkerOptions options)throws UnavailableException; ",
        "test_tgt": "@Test public void getWorker() { List < BlockWorkerInfo > workerInfoList = new ArrayList < > (); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker1\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker2\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 2 * (long)Constants.GB, 0)); workerInfoList.add(new BlockWorkerInfo(new WorkerNetAddress().setHost(\"worker3\").setRpcPort(PORT).setDataPort(PORT).setWebPort(PORT), 3 * (long)Constants.GB, 0)); RoundRobinPolicy policy = new RoundRobinPolicy(); Assert.assertNotEquals(policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost(), policy.getWorkerForNextBlock(workerInfoList, 2 * (long)Constants.GB).getHost()); } "
    },
    {
        "test_src": "@Test public void testBuild() { Map < Integer, Integer > data = new HashMap < > (); for(int i = 0; i < 100; i ++ )data.put(i, i); LocalDatasetBuilder < Integer, Integer > builder = new LocalDatasetBuilder < > (data, 10); LocalDataset < Serializable, TestPartitionData > dataset = buildDataset(builder); assertEquals(10, dataset.getCtx().size()); assertEquals(10, dataset.getData().size()); AtomicLong cnt = new AtomicLong(); dataset.compute((partData, partIdx) -> { cnt.incrementAndGet(); int[]arr = partData.data; assertEquals(10, arr.length); for(int i = 0; i < 10; i ++ )assertEquals(partIdx * 10 + i, arr[i]); }); assertEquals(10, cnt.intValue()); } ",
        "focal_tgt": "public C build(LearningEnvironment env, Iterator < UpstreamEntry < K, V > > upstreamData, long upstreamDataSize); ",
        "focal_src": "public C build(Iterator < UpstreamEntry < K, V > > upstreamData, long upstreamDataSize); ",
        "test_tgt": "@Test public void testBuild() { Map < Integer, Integer > data = new HashMap < > (); for(int i = 0; i < 100; i ++ )data.put(i, i); LocalDatasetBuilder < Integer, Integer > builder = new LocalDatasetBuilder < > (data, 10); LocalDataset < Serializable, TestPartitionData > dataset = buildDataset(builder); assertEquals(10, dataset.getCtx().size()); assertEquals(10, dataset.getData().size()); AtomicLong cnt = new AtomicLong(); dataset.compute((partData, env) -> { cnt.incrementAndGet(); int[]arr = partData.data; assertEquals(10, arr.length); for(int i = 0; i < 10; i ++ )assertEquals(env.partition() * 10 + i, arr[i]); }); assertEquals(10, cnt.intValue()); } "
    },
    {
        "test_src": "@Test public final void testStart() { Map < String, Double > context = new HashMap < String, Double > (); average.start(context, null); TupleListCollector resultEntryCollector = new TupleListCollector(new Fields(\"field\")); average.complete(context, resultEntryCollector); Tuple tuple = resultEntryCollector.iterator().next(); assertEquals(\"Got expected initial value on start\", 0.0, tuple.getDouble(0), 0.0d); } ",
        "focal_tgt": "@SuppressWarnings(\"unchecked\")public void start(Map context, TupleEntry groupEntry) { context.put(FIELD_NAME, 0.0d); context.put(KEY_COUNT, 0L); } ",
        "focal_src": "@SuppressWarnings(\"unchecked\")public void start(Map context, TupleEntry groupEntry) { context.put(FIELD_NAME, new Double(0.0)); context.put(KEY_COUNT, 0l); } ",
        "test_tgt": "@Test public final void testStart() { Map < String, Double > context = new HashMap < String, Double > (); average.start(context, null); TupleListCollector resultEntryCollector = new TupleListCollector(new Fields(\"field\")); average.complete(context, resultEntryCollector); Tuple tuple = resultEntryCollector.iterator().next(); assertEquals(\"Got expected initial value on start\", Double.NaN, tuple.getDouble(0), 0.0d); } "
    },
    {
        "test_src": "@Test public void deletePerformance() { if(VERBOSE)Util.err(\"Tested mapping: \"); deletePerformance(testedmap, basemap); } ",
        "focal_tgt": "private static void deletePerformance(final IdPreMap m, final DummyIdPreMap b) { final int[][]d = new int[BASEID + 1][2]; for(int i = 0, id = BASEID + 1; i < d.length; -- id, ++ i) { d[i][0] = RANDOM.nextInt(id); d[i][1] = b.id(d[i][0]); b.delete(d[i][0], d[i][1], - 1); } for(final int[]dd : d)m.delete(dd[0], dd[1], - 1); } ",
        "focal_src": "private static void deletePerformance(final IdPreMap m, final DummyIdPreMap b) { final int[][]d = new int[BASEID + 1][2]; for(int i = 0, id = BASEID + 1; i < d.length; -- id, ++ i) { d[i][0] = RANDOM.nextInt(id); d[i][1] = b.id(d[i][0]); b.delete(d[i][0], d[i][1], - 1); } final Performance p = new Performance(); for(final int[]dd : d)m.delete(dd[0], dd[1], - 1); if(VERBOSE)Util.errln(d.length + \" records deleted in: \" + p); } ",
        "test_tgt": "@Test public void deletePerformance() { deletePerformance(testedmap, basemap); } "
    },
    {
        "test_src": "@Test public void testGetHourOfYear() { LOGGER.debug(DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-01-05 12:00:05\", DatePattern.COMMON_DATE_AND_TIME)) + \"\"); LOGGER.debug(DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-01-01 00:00:05\", DatePattern.COMMON_DATE_AND_TIME)) + \"\"); LOGGER.debug(DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-09-16 11:42:22\", DatePattern.COMMON_DATE_AND_TIME)) + \"\"); LOGGER.debug(DateUtil.getHourOfYear(NOW) + \"\"); } ",
        "focal_tgt": "public static int getHourOfYear(Date date) { Validate.notNull(date, \"date can't be null!\"); return(getDayOfYear(date) - 1) * 24 + CalendarUtil.getFieldValue(date, Calendar.HOUR_OF_DAY); } ",
        "focal_src": "public static int getHourOfYear(Date date) { Date firstDateOfThisYear = getFirstDateOfThisYear(date); return getIntervalHour(firstDateOfThisYear, date); } ",
        "test_tgt": "@Test public void testGetHourOfYear() { assertEquals(0, DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-01-01 00:00:05\", DatePattern.COMMON_DATE_AND_TIME))); assertEquals(31 * 24, DateUtil.getHourOfYear(DateUtil.string2Date(\"2016-02-01 00:00:05\", DatePattern.COMMON_DATE_AND_TIME))); assertEquals(24, DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-01-02 00:00:05\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-01-05 12:00:05\", DatePattern.COMMON_DATE_AND_TIME)) + \"\"); LOGGER.debug(DateUtil.getHourOfYear(DateUtil.string2Date(\"2013-09-16 11:42:22\", DatePattern.COMMON_DATE_AND_TIME)) + \"\"); LOGGER.debug(DateUtil.getHourOfYear(NOW) + \"\"); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should return default location for the implementation\", method = \"getDefaultLocation()\")public void getDefaultLocation_shouldReturnDefaultLocationForTheImplementation()throws Exception { Assert.assertNotNull(Context.getLocationService().getDefaultLocation()); } ",
        "focal_tgt": "public Location getDefaultLocation()throws APIException { Location location = null; String locationGP = Context.getAdministrationService().getGlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_DEFAULT_LOCATION_NAME); if(StringUtils.hasText(locationGP))location = getLocation(locationGP); if(location == null && ( ! StringUtils.hasText(locationGP) || ! locationGP.equalsIgnoreCase(\"Unknown Location\")))location = getLocation(\"Unknown Location\"); if(location == null && ( ! StringUtils.hasText(locationGP) || ! locationGP.equalsIgnoreCase(\"Unknown\"))) { location = getLocation(\"Unknown\"); } if(location == null) { location = getLocation(Integer.valueOf(1)); } return location; } ",
        "focal_src": "public Location getDefaultLocation()throws APIException { Location location = getLocation(\"Unknown Location\"); if(location == null) { location = getLocation(\"Unknown\"); } if(location == null) { location = getLocation(Integer.valueOf(1)); } return location; } ",
        "test_tgt": "@Test@Verifies(value = \"should return default location for the implementation\", method = \"getDefaultLocation()\")public void getDefaultLocation_shouldReturnDefaultLocationForTheImplementation()throws Exception { GlobalProperty gp = new GlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_DEFAULT_LOCATION_NAME, \"Test Parent Location\", \"Testing default Location\"); Context.getAdministrationService().saveGlobalProperty(gp); Assert.assertEquals(\"Test Parent Location\", Context.getLocationService().getDefaultLocation().getName()); } "
    },
    {
        "test_src": "@Test public void cacheSendedMessage() { messageCacheService.cacheSendedMessage(blockMessage); assertNotNull(messageCacheService.getSendMessage(blockMessage.getHash().getDigestHex())); } ",
        "focal_tgt": "public void cacheSendedMessage(BaseMessage messgae) { this.cacheMapSended.put(messgae.getHash(), messgae); } ",
        "focal_src": "public void cacheSendedMessage(BaseMessage messgae) { this.cacheMapSended.put(messgae.getHash().getDigestHex(), messgae); } ",
        "test_tgt": "@Test public void cacheSendedMessage() { messageCacheService.cacheSendedMessage(blockMessage); assertNotNull(messageCacheService.getSendMessage(blockMessage.getHash())); } "
    },
    {
        "test_src": "@Test public void testCompare() { int result = 0; ItemComparator ic = null; ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); result = ic.compare(one, two); assertTrue(\"testCompare 0\", result == 0); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 1\", result >= 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 2\", result <= - 1); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"0\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"3\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"0\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"-1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"-1\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"3\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"5\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"2\"); one.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"3\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"1\"); two.addMetadata(\"dc\", \"test\", \"one\", Item.ANY, \"4\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); one.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); two.clearMetadata(\"dc\", \"test\", \"one\", Item.ANY); } ",
        "focal_tgt": "protected void compare(Item item, String[]fromCSV, boolean change, String md, BulkEditChange changes, DSpaceCSVLine line)throws SQLException, AuthorizeException { String all = \"\"; for(String part : fromCSV) { all += part + \",\"; } all = all.substring(0, all.length()); log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all)); if((\"collection\".equals(md)) || (\"action\".equals(md))) { return; } String language = null; if(md.contains(\"[\")) { String[]bits = md.split(\"\\\\[\"); language = bits[1].substring(0, bits[1].length() - 1); } AuthorityValue fromAuthority = authorityValueService.getAuthorityValueType(md); if(md.indexOf(':') > 0) { md = md.substring(md.indexOf(':') + 1); } String[]bits = md.split(\"\\\\.\"); String schema = bits[0]; String element = bits[1]; if(element.contains(\"[\")) { element = element.substring(0, element.indexOf('[')); } String qualifier = null; if(bits.length > 2) { qualifier = bits[2]; if(qualifier.contains(\"[\")) { qualifier = qualifier.substring(0, qualifier.indexOf('[')); } } log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",looking_for_schema=\" + schema + \",looking_for_element=\" + element + \",looking_for_qualifier=\" + qualifier + \",looking_for_language=\" + language)); String[]dcvalues = new String[0]; if(fromAuthority == null) { List < MetadataValue > current = itemService.getMetadata(item, schema, element, qualifier, language); dcvalues = new String[current.size()]; int i = 0; for(MetadataValue dcv : current) { if(dcv.getAuthority() == null || ! isAuthorityControlledField(md)) { dcvalues[i] = dcv.getValue(); } else { dcvalues[i] = dcv.getValue() + csv.getAuthoritySeparator() + dcv.getAuthority(); dcvalues[i] += csv.getAuthoritySeparator() + (dcv.getConfidence() != - 1 ? dcv.getConfidence() : Choices.CF_ACCEPTED); } i ++ ; log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",found=\" + dcv.getValue())); } } else { dcvalues = line.get(md).toArray(new String[line.get(md).size()]); } for(int v = 0; v < fromCSV.length; v ++ ) { String value = fromCSV[v]; BulkEditMetadataValue dcv = getBulkEditValueFromCSV(language, schema, element, qualifier, value, fromAuthority); if(fromAuthority != null) { value = dcv.getValue() + csv.getAuthoritySeparator() + dcv.getAuthority() + csv.getAuthoritySeparator() + dcv.getConfidence(); fromCSV[v] = value; } if((value != null) && ( ! \"\".equals(value)) && ( ! contains(value, dcvalues))) { changes.registerAdd(dcv); } else { changes.registerConstant(dcv); } } for(String value : dcvalues) { BulkEditMetadataValue dcv = new BulkEditMetadataValue(); dcv.setSchema(schema); dcv.setElement(element); dcv.setQualifier(qualifier); dcv.setLanguage(language); if(value == null || ! value.contains(csv.getAuthoritySeparator()))simplyCopyValue(value, dcv); else { String[]parts = value.split(csv.getAuthoritySeparator()); dcv.setValue(parts[0]); dcv.setAuthority(parts[1]); dcv.setConfidence((parts.length > 2 ? Integer.valueOf(parts[2]) : Choices.CF_ACCEPTED)); } if((value != null) && ( ! \"\".equals(value)) && ( ! contains(value, fromCSV)) && fromAuthority == null) { log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",removing_schema=\" + schema + \",removing_element=\" + element + \",removing_qualifier=\" + qualifier + \",removing_language=\" + language)); changes.registerRemove(dcv); } } if((change) && ((changes.getAdds().size() > 0) || (changes.getRemoves().size() > 0))) { List < BulkEditMetadataValue > list = changes.getComplete(); List < String > values = new ArrayList < String > (); List < String > authorities = new ArrayList < String > (); List < Integer > confidences = new ArrayList < Integer > (); for(BulkEditMetadataValue value : list) { if((qualifier == null) && (language == null)) { if((schema.equals(value.getSchema())) && (element.equals(value.getElement())) && (value.getQualifier() == null) && (value.getLanguage() == null)) { values.add(value.getValue()); authorities.add(value.getAuthority()); confidences.add(value.getConfidence()); } } else if(qualifier == null) { if((schema.equals(value.getSchema())) && (element.equals(value.getElement())) && (language.equals(value.getLanguage())) && (value.getQualifier() == null)) { values.add(value.getValue()); authorities.add(value.getAuthority()); confidences.add(value.getConfidence()); } } else if(language == null) { if((schema.equals(value.getSchema())) && (element.equals(value.getElement())) && (qualifier.equals(value.getQualifier())) && (value.getLanguage() == null)) { values.add(value.getValue()); authorities.add(value.getAuthority()); confidences.add(value.getConfidence()); } } else { if((schema.equals(value.getSchema())) && (element.equals(value.getElement())) && (qualifier.equals(value.getQualifier())) && (language.equals(value.getLanguage()))) { values.add(value.getValue()); authorities.add(value.getAuthority()); confidences.add(value.getConfidence()); } } } itemService.clearMetadata(c, item, schema, element, qualifier, language); itemService.addMetadata(c, item, schema, element, qualifier, language, values, authorities, confidences); itemService.update(c, item); } } ",
        "focal_src": "private void compare(Item item, String[]fromCSV, boolean change, String md, BulkEditChange changes, DSpaceCSVLine line)throws SQLException, AuthorizeException { String all = \"\"; for(String part : fromCSV) { all += part + \",\"; } all = all.substring(0, all.length()); log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all)); if((\"collection\".equals(md)) || (\"action\".equals(md))) { return; } String language = null; if(md.contains(\"[\")) { String[]bits = md.split(\"\\\\[\"); language = bits[1].substring(0, bits[1].length() - 1); } AuthorityValue fromAuthority = getAuthorityValueType(md); if(md.indexOf(':') > 0) { md = md.substring(md.indexOf(':') + 1); } String[]bits = md.split(\"\\\\.\"); String schema = bits[0]; String element = bits[1]; if(element.contains(\"[\")) { element = element.substring(0, element.indexOf('[')); } String qualifier = null; if(bits.length > 2) { qualifier = bits[2]; if(qualifier.contains(\"[\")) { qualifier = qualifier.substring(0, qualifier.indexOf('[')); } } log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",looking_for_schema=\" + schema + \",looking_for_element=\" + element + \",looking_for_qualifier=\" + qualifier + \",looking_for_language=\" + language)); String[]dcvalues = new String[0]; if(fromAuthority == null) { Metadatum[]current = item.getMetadata(schema, element, qualifier, language); dcvalues = new String[current.length]; int i = 0; for(Metadatum dcv : current) { if(dcv.authority == null || ! isAuthorityControlledField(md)) { dcvalues[i] = dcv.value; } else { dcvalues[i] = dcv.value + DSpaceCSV.authoritySeparator + dcv.authority; dcvalues[i] += DSpaceCSV.authoritySeparator + (dcv.confidence != - 1 ? dcv.confidence : Choices.CF_ACCEPTED); } i ++ ; log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",found=\" + dcv.value)); } } else { dcvalues = line.get(md).toArray(new String[line.get(md).size()]); } for(int v = 0; v < fromCSV.length; v ++ ) { String value = fromCSV[v]; Metadatum dcv = getDcValueFromCSV(language, schema, element, qualifier, value, fromAuthority); if(fromAuthority != null) { value = dcv.value + DSpaceCSV.authoritySeparator + dcv.authority + DSpaceCSV.authoritySeparator + dcv.confidence; fromCSV[v] = value; } if((value != null) && ( ! \"\".equals(value)) && ( ! contains(value, dcvalues))) { changes.registerAdd(dcv); } else { changes.registerConstant(dcv); } } for(String value : dcvalues) { Metadatum dcv = new Metadatum(); dcv.schema = schema; dcv.element = element; dcv.qualifier = qualifier; dcv.language = language; if(value == null || value.indexOf(DSpaceCSV.authoritySeparator) < 0)simplyCopyValue(value, dcv); else { String[]parts = value.split(DSpaceCSV.escapedAuthoritySeparator); dcv.value = parts[0]; dcv.authority = parts[1]; dcv.confidence = (parts.length > 2 ? Integer.valueOf(parts[2]) : Choices.CF_ACCEPTED); } if((value != null) && ( ! \"\".equals(value)) && ( ! contains(value, fromCSV)) && fromAuthority == null) { log.debug(LogManager.getHeader(c, \"metadata_import\", \"item_id=\" + item.getID() + \",fromCSV=\" + all + \",removing_schema=\" + schema + \",removing_element=\" + element + \",removing_qualifier=\" + qualifier + \",removing_language=\" + language)); changes.registerRemove(dcv); } } if((change) && ((changes.getAdds().size() > 0) || (changes.getRemoves().size() > 0))) { List < Metadatum > list = changes.getComplete(); List < String > values = new ArrayList < String > (); List < String > authorities = new ArrayList < String > (); List < Integer > confidences = new ArrayList < Integer > (); for(Metadatum value : list) { if((qualifier == null) && (language == null)) { if((schema.equals(value.schema)) && (element.equals(value.element)) && (value.qualifier == null) && (value.language == null)) { values.add(value.value); authorities.add(value.authority); confidences.add(value.confidence); } } else if(qualifier == null) { if((schema.equals(value.schema)) && (element.equals(value.element)) && (language.equals(value.language)) && (value.qualifier == null)) { values.add(value.value); authorities.add(value.authority); confidences.add(value.confidence); } } else if(language == null) { if((schema.equals(value.schema)) && (element.equals(value.element)) && (qualifier.equals(value.qualifier)) && (value.language == null)) { values.add(value.value); authorities.add(value.authority); confidences.add(value.confidence); } } else { if((schema.equals(value.schema)) && (element.equals(value.element)) && (qualifier.equals(value.qualifier)) && (language.equals(value.language))) { values.add(value.value); authorities.add(value.authority); confidences.add(value.confidence); } } } item.clearMetadata(schema, element, qualifier, language); String[]theValues = values.toArray(new String[values.size()]); String[]theAuthorities = authorities.toArray(new String[authorities.size()]); int[]theConfidences = new int[confidences.size()]; for(int k = 0; k < confidences.size(); k ++ ) { theConfidences[k] = confidences.get(k).intValue(); } item.addMetadata(schema, element, qualifier, language, theValues, theAuthorities, theConfidences); item.update(); } } ",
        "test_tgt": "@Test public void testCompare()throws SQLException { int result = 0; ItemComparator ic = null; ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); result = ic.compare(one, two); assertTrue(\"testCompare 0\", result == 0); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 1\", result >= 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 2\", result <= - 1); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"0\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"3\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"0\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"-1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, true); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"-1\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"3\"); result = ic.compare(one, two); assertTrue(\"testCompare 3\", result <= - 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"5\"); result = ic.compare(one, two); assertTrue(\"testCompare 4\", result == 0); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); ic = new ItemComparator(\"test\", \"one\", Item.ANY, false); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"2\"); itemService.addMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY, \"3\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"1\"); itemService.addMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY, \"4\"); result = ic.compare(one, two); assertTrue(\"testCompare 5\", result >= 1); itemService.clearMetadata(context, one, \"dc\", \"test\", \"one\", Item.ANY); itemService.clearMetadata(context, two, \"dc\", \"test\", \"one\", Item.ANY); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_getAvailableGroupIds() { Set < String > groups = ZoneRulesProvider.getAvailableGroupIds(); assertEquals(groups.contains(\"TZDB\"), true); groups.clear(); assertEquals(groups.size(), 0); Set < String > groups2 = ZoneRulesProvider.getAvailableGroupIds(); assertEquals(groups2.contains(\"TZDB\"), true); } ",
        "focal_tgt": "public static Set < String > getAvailableZoneIds() { return new HashSet < > (ZONES.keySet()); } ",
        "focal_src": "public static Set < String > getAvailableGroupIds() { return new HashSet < > (GROUPS.keySet()); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_getAvailableGroupIds() { Set < String > zoneIds = ZoneRulesProvider.getAvailableZoneIds(); assertEquals(zoneIds.contains(\"Europe/London\"), true); zoneIds.clear(); assertEquals(zoneIds.size(), 0); Set < String > zoneIds2 = ZoneRulesProvider.getAvailableZoneIds(); assertEquals(zoneIds2.contains(\"Europe/London\"), true); } "
    },
    {
        "test_src": "@Test public void saveOrder_shouldFailIfAnActiveOrderForTheSameConceptAndCareSettingExists()throws Exception { final Patient patient = patientService.getPatient(2); final Concept cd4Count = conceptService.getConcept(5497); TestOrder duplicateOrder = (TestOrder)orderService.getOrder(7); assertTrue(duplicateOrder.isActive()); assertEquals(cd4Count, duplicateOrder.getConcept()); Order order = new TestOrder(); order.setPatient(patient); order.setCareSetting(orderService.getCareSetting(2)); order.setConcept(cd4Count); order.setEncounter(encounterService.getEncounter(6)); order.setOrderer(providerService.getProvider(1)); order.setCareSetting(duplicateOrder.getCareSetting()); expectedException.expect(APIException.class); expectedException.expectMessage(\"Order.cannot.have.more.than.one\"); orderService.saveOrder(order, null); } ",
        "focal_tgt": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Order.cannot.edit.existing\", (Object[])null); } if(order.getDateActivated() == null) { order.setDateActivated(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { DrugOrder drugOrder = (DrugOrder)order; if(drugOrder.getDrug() != null) { concept = drugOrder.getDrug().getConcept(); drugOrder.setConcept(concept); } } if(isDrugOrder) { ((DrugOrder)order).setAutoExpireDateBasedOnDuration(); } if(concept == null) { throw new APIException(\"Order.concept.required\", (Object[])null); } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Order.type.cannot.determine\", (Object[])null); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Order.care.cannot.determine\", (Object[])null); } order.setCareSetting(careSetting); } if( ! order.getOrderType().getJavaClass().isAssignableFrom(order.getClass())) { throw new APIException(\"Order.type.class.does.not.match\", new Object[] { order.getOrderType().getJavaClass(), order.getClass().getName() }); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Order.previous.required\", (Object[])null); } stopOrder(previousOrder, aMomentBefore(order.getDateActivated())); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if(previousOrder != null) { boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); List < Object[] > rows = dao.getOrderFromDatabase(previousOrder, isPreviousDrugOrder); Object[]rowData = rows.get(0); if( ! rowData[0].equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Order.cannot.change.patient\", (Object[])null); } else if( ! rowData[1].equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Order.cannot.change.careSetting\", (Object[])null); } else if( ! rowData[2].equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Order.cannot.change.concept\", (Object[])null); } else if(isPreviousDrugOrder) { Drug previousDrug = ((DrugOrder)previousOrder).getDrug(); if(previousDrug == null && rowData[3] != null) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } else if(previousDrug != null && ! OpenmrsUtil.nullSafeEquals(rowData[3], previousDrug.getDrugId())) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"Order.previous.concept\", (Object[])null); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"Order.previous.drug\", (Object[])null); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"Order.type.does.not.match\", (Object[])null); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"Order.care.setting.does.not.match\", (Object[])null); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"Order.class.does.not.match\", (Object[])null); } } if(DISCONTINUE != order.getAction()) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order activeOrder : activeOrders) { if(areDrugOrdersOfSameOrderableAndOverlappingSchedule(order, activeOrder)) { throw new APIException(\"Order.cannot.have.more.than.one\", (Object[])null); } } } return saveOrderInternal(order, orderContext); } ",
        "focal_src": "public synchronized Order saveOrder(Order order, OrderContext orderContext)throws APIException { if(order.getOrderId() != null) { throw new APIException(\"Order.cannot.edit.existing\", (Object[])null); } if(order.getDateActivated() == null) { order.setDateActivated(new Date()); } boolean isDrugOrder = DrugOrder.class.isAssignableFrom(getActualType(order)); Concept concept = order.getConcept(); if(concept == null && isDrugOrder) { DrugOrder drugOrder = (DrugOrder)order; if(drugOrder.getDrug() != null) { concept = drugOrder.getDrug().getConcept(); drugOrder.setConcept(concept); } } if(isDrugOrder) { ((DrugOrder)order).setAutoExpireDateBasedOnDuration(); } if(concept == null) { throw new APIException(\"Order.concept.required\", (Object[])null); } Order previousOrder = order.getPreviousOrder(); if(order.getOrderType() == null) { OrderType orderType = null; if(orderContext != null) { orderType = orderContext.getOrderType(); } if(orderType == null) { orderType = getOrderTypeByConcept(concept); } if(orderType == null && order instanceof DrugOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.DRUG_ORDER_TYPE_UUID); } if(orderType == null && order instanceof TestOrder) { orderType = Context.getOrderService().getOrderTypeByUuid(OrderType.TEST_ORDER_TYPE_UUID); } if(orderType == null || (previousOrder != null && ! orderType.equals(previousOrder.getOrderType()))) { throw new APIException(\"Order.type.cannot.determine\", (Object[])null); } order.setOrderType(orderType); } if(order.getCareSetting() == null) { CareSetting careSetting = null; if(orderContext != null) { careSetting = orderContext.getCareSetting(); } if(careSetting == null || (previousOrder != null && ! careSetting.equals(previousOrder.getCareSetting()))) { throw new APIException(\"Order.care.cannot.determine\", (Object[])null); } order.setCareSetting(careSetting); } if( ! order.getOrderType().getJavaClass().isAssignableFrom(order.getClass())) { throw new APIException(\"Order.type.class.does.not.match\", new Object[] { order.getOrderType().getJavaClass(), order.getClass().getName() }); } if(REVISE == order.getAction()) { if(previousOrder == null) { throw new APIException(\"Order.previous.required\", (Object[])null); } stopOrder(previousOrder, aMomentBefore(order.getDateActivated())); } else if(DISCONTINUE == order.getAction()) { discontinueExistingOrdersIfNecessary(order); } if(previousOrder != null) { boolean isPreviousDrugOrder = DrugOrder.class.isAssignableFrom(previousOrder.getClass()); List < Object[] > rows = dao.getOrderFromDatabase(previousOrder, isPreviousDrugOrder); Object[]rowData = rows.get(0); if( ! rowData[0].equals(previousOrder.getPatient().getPatientId())) { throw new APIException(\"Order.cannot.change.patient\", (Object[])null); } else if( ! rowData[1].equals(previousOrder.getCareSetting().getCareSettingId())) { throw new APIException(\"Order.cannot.change.careSetting\", (Object[])null); } else if( ! rowData[2].equals(previousOrder.getConcept().getConceptId())) { throw new APIException(\"Order.cannot.change.concept\", (Object[])null); } else if(isPreviousDrugOrder) { Drug previousDrug = ((DrugOrder)previousOrder).getDrug(); if(previousDrug == null && rowData[3] != null) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } else if(previousDrug != null && ! OpenmrsUtil.nullSafeEquals(rowData[3], previousDrug.getDrugId())) { throw new APIException(\"Order.cannot.change.drug\", (Object[])null); } } boolean isDrugOrderAndHasADrug = isDrugOrder && ((DrugOrder)order).getDrug() != null; if( ! OpenmrsUtil.nullSafeEquals(order.getConcept(), previousOrder.getConcept())) { throw new APIException(\"Order.previous.concept\", (Object[])null); } else if(isDrugOrderAndHasADrug) { DrugOrder drugOrder1 = (DrugOrder)order; DrugOrder drugOrder2 = (DrugOrder)previousOrder; if( ! OpenmrsUtil.nullSafeEquals(drugOrder1.getDrug(), drugOrder2.getDrug())) { throw new APIException(\"Order.previous.drug\", (Object[])null); } } else if( ! order.getOrderType().equals(previousOrder.getOrderType())) { throw new APIException(\"Order.type.does.not.match\", (Object[])null); } else if( ! order.getCareSetting().equals(previousOrder.getCareSetting())) { throw new APIException(\"Order.care.setting.does.not.match\", (Object[])null); } else if( ! getActualType(order).equals(getActualType(previousOrder))) { throw new APIException(\"Order.class.does.not.match\", (Object[])null); } } if(DISCONTINUE != order.getAction()) { List < Order > activeOrders = getActiveOrders(order.getPatient(), null, order.getCareSetting(), null); for(Order activeOrder : activeOrders) { if(order.hasSameOrderableAs(activeOrder) && ! OpenmrsUtil.nullSafeEquals(order.getPreviousOrder(), activeOrder) && OrderUtil.checkScheduleOverlap(order, activeOrder)) { throw new APIException(\"Order.cannot.have.more.than.one\", (Object[])null); } } } return saveOrderInternal(order, orderContext); } ",
        "test_tgt": "@Test public void saveOrder_shouldPassIfAnActiveTestOrderForTheSameConceptAndCareSettingExists()throws Exception { final Patient patient = patientService.getPatient(2); final Concept cd4Count = conceptService.getConcept(5497); TestOrder duplicateOrder = (TestOrder)orderService.getOrder(7); assertTrue(duplicateOrder.isActive()); assertEquals(cd4Count, duplicateOrder.getConcept()); Order order = new TestOrder(); order.setPatient(patient); order.setCareSetting(orderService.getCareSetting(2)); order.setConcept(cd4Count); order.setEncounter(encounterService.getEncounter(6)); order.setOrderer(providerService.getProvider(1)); order.setCareSetting(duplicateOrder.getCareSetting()); Order savedOrder = orderService.saveOrder(order, null); assertNotNull(orderService.getOrder(savedOrder.getOrderId())); } "
    },
    {
        "test_src": "@Test public void deleteTest()throws Exception { CreateDirectoryOptions recMkdir = CreateDirectoryOptions.defaults().setRecursive(true); DeleteOptions recDelete = new DeleteOptions.Builder().setRecursive(true).build(); for(int i = 0; i < 10; i ++ ) { String dirPath = \"/i\" + i; mTfs.createDirectory(new TachyonURI(dirPath), recMkdir); for(int j = 0; j < 10; j ++ ) { CreateFileOptions option = CreateFileOptions.defaults().setBlockSizeBytes((i + j + 1) * 64); String filePath = dirPath + \"/j\" + j; mTfs.createFile(new TachyonURI(filePath), option).close(); if(j >= 5) { mTfs.delete(new TachyonURI(filePath), recDelete); } } if(i >= 5) { mTfs.delete(new TachyonURI(dirPath), recDelete); } } mLocalTachyonCluster.stopTFS(); deleteTestUtil(); deleteFsMasterJournalLogs(); deleteTestUtil(); } ",
        "focal_tgt": "@Override public boolean delete(Path cPath, boolean recursive)throws IOException { LOG.info(\"delete({}, {})\", cPath, recursive); if(mStatistics != null) { mStatistics.incrementWriteOps(1); } TachyonURI path = new TachyonURI(Utils.getPathWithoutScheme(cPath)); DeleteOptions options = DeleteOptions.defaults().setRecursive(recursive); try { mTFS.delete(path, options); return true; } catch(InvalidPathException e) { LOG.info(\"delete failed: {}\", e.getMessage()); return false; } catch(FileDoesNotExistException e) { LOG.info(\"delete failed: {}\", e.getMessage()); return false; } catch(TachyonException e) { throw new IOException(e); } } ",
        "focal_src": "@Override public boolean delete(Path cPath, boolean recursive)throws IOException { LOG.info(\"delete({}, {})\", cPath, recursive); if(mStatistics != null) { mStatistics.incrementWriteOps(1); } TachyonURI path = new TachyonURI(Utils.getPathWithoutScheme(cPath)); DeleteOptions options = new DeleteOptions.Builder().setRecursive(recursive).build(); try { mTFS.delete(path, options); return true; } catch(InvalidPathException e) { LOG.info(\"delete failed: {}\", e.getMessage()); return false; } catch(FileDoesNotExistException e) { LOG.info(\"delete failed: {}\", e.getMessage()); return false; } catch(TachyonException e) { throw new IOException(e); } } ",
        "test_tgt": "@Test public void deleteTest()throws Exception { CreateDirectoryOptions recMkdir = CreateDirectoryOptions.defaults().setRecursive(true); DeleteOptions recDelete = DeleteOptions.defaults().setRecursive(true); for(int i = 0; i < 10; i ++ ) { String dirPath = \"/i\" + i; mTfs.createDirectory(new TachyonURI(dirPath), recMkdir); for(int j = 0; j < 10; j ++ ) { CreateFileOptions option = CreateFileOptions.defaults().setBlockSizeBytes((i + j + 1) * 64); String filePath = dirPath + \"/j\" + j; mTfs.createFile(new TachyonURI(filePath), option).close(); if(j >= 5) { mTfs.delete(new TachyonURI(filePath), recDelete); } } if(i >= 5) { mTfs.delete(new TachyonURI(dirPath), recDelete); } } mLocalTachyonCluster.stopTFS(); deleteTestUtil(); deleteFsMasterJournalLogs(); deleteTestUtil(); } "
    },
    {
        "test_src": "@Test public void testToString22() { int[]int1 = { 2, 1 }; assertEquals(\"2,1\", ConvertUtil.toString(new ToStringConfig(\",\"), int1)); } ",
        "focal_tgt": "public static < T > String toString(ToStringConfig toStringConfig, T ... arrays) { if(Validator.isNullOrEmpty(arrays)) { return StringUtils.EMPTY; } ToStringConfig useToStringConfig = null == toStringConfig ? new ToStringConfig() : toStringConfig; Object[]operateArray = toObjects(arrays); String connector = useToStringConfig.getConnector(); StringBuilder sb = new StringBuilder(); for(int i = 0, j = operateArray.length; i < j; ++ i) { @SuppressWarnings(\"unchecked\")T t = (T)operateArray[i]; if(Validator.isNullOrEmpty(t) && ! useToStringConfig.getIsJoinNullOrEmpty()) { continue; } sb.append(t); if(null != connector) { sb.append(connector); } } String returnValue = sb.toString(); if(null != connector && returnValue.endsWith(connector)) { return StringUtil.substringWithoutLast(returnValue, connector.length()); } return returnValue; } ",
        "focal_src": "@Deprecated public static < T > String toString(ToStringConfig toStringConfig, T ... arrays) { if(Validator.isNullOrEmpty(arrays)) { return StringUtils.EMPTY; } ToStringConfig useToStringConfig = null == toStringConfig ? new ToStringConfig() : toStringConfig; String connector = useToStringConfig.getConnector(); StringBuilder sb = new StringBuilder(); for(int i = 0, j = arrays.length; i < j; ++ i) { T t = arrays[i]; if(Validator.isNullOrEmpty(t) && ! useToStringConfig.getIsJoinNullOrEmpty()) { continue; } sb.append(t); if(null != connector) { sb.append(connector); } } String returnValue = sb.toString(); if(Validator.isNotNullOrEmpty(connector) && returnValue.endsWith(connector)) { return StringUtil.substringWithoutLast(returnValue, connector.length()); } return returnValue; } ",
        "test_tgt": "@Test public void testToString22() { int[]int1 = { 2, 1 }; assertEquals(\"2,1\", ConvertUtil.toString(new ToStringConfig(\",\"), int1)); assertEquals(\"2\", ConvertUtil.toString(new ToStringConfig(\",\"), 2)); assertEquals(\"2\", ConvertUtil.toString(new ToStringConfig(\",\"), new Integer(2))); } "
    },
    {
        "test_src": "@Test public void testToPrettyDateString() { LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 13:55:00\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 14:14:22\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 14:15:22\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-17 14:15:02\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-16 14:15:02\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-15 14:15:02\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-09-15 14:15:02\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2015-08-02 14:15:02\", DatePattern.COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2015-7-30 13:00:00\", DatePattern.COMMON_DATE_AND_TIME))); } ",
        "focal_tgt": "public static String toPrettyDateString(Date inDate) { Validate.notNull(inDate, \"inDate can't be null!\"); Date nowDate = new Date(); int inYear = DateUtil.getYear(inDate); int currentYear = DateUtil.getYear(nowDate); boolean isSameYear = currentYear == inYear; long spaceTime = DateExtensionUtil.getIntervalTime(inDate, nowDate); int spaceDay = DateExtensionUtil.getIntervalDay(spaceTime); switch(spaceDay) { case 0 : return doWithZeroDayInterval(inDate, nowDate, spaceTime); case 1 : return doWithOneDayInterval(inDate, nowDate); case 2 : return doWithTwoDaysInterval(inDate, nowDate, isSameYear); default : return isSameYear ? DateUtil.toString(inDate, COMMON_DATE_AND_TIME_WITHOUT_YEAR_AND_SECOND) : DateUtil.toString(inDate, COMMON_DATE_AND_TIME_WITHOUT_SECOND); } } ",
        "focal_src": "public static String toPrettyDateString(Date inDate) { Validate.notNull(inDate, \"inDate can't be null!\"); Date nowDate = new Date(); int inYear = DateUtil.getYear(inDate); int currentYear = DateUtil.getYear(nowDate); boolean isSameYear = currentYear == inYear; long spaceTime = DateExtensionUtil.getIntervalTime(inDate, nowDate); int spaceDay = DateExtensionUtil.getIntervalDay(spaceTime); switch(spaceDay) { case 0 : return doWithZeroDayInterval(inDate, nowDate, spaceTime); case 1 : return doWithOneDayInterval(inDate, nowDate); case 2 : return doWithTwoDaysInterval(inDate, nowDate, isSameYear); default : return isSameYear ? DateUtil.toString(inDate, DatePattern.COMMON_DATE_AND_TIME_WITHOUT_YEAR_AND_SECOND) : DateUtil.toString(inDate, DatePattern.COMMON_DATE_AND_TIME_WITHOUT_SECOND); } } ",
        "test_tgt": "@Test public void testToPrettyDateString() { LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 13:55:00\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 14:14:22\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-18 14:15:22\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-17 14:15:02\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-16 14:15:02\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-10-15 14:15:02\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2012-09-15 14:15:02\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2015-08-02 14:15:02\", COMMON_DATE_AND_TIME))); LOGGER.debug(toPrettyDateString(DateUtil.toDate(\"2015-7-30 13:00:00\", COMMON_DATE_AND_TIME))); } "
    }
]