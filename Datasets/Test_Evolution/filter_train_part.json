[
    {
        "test_src": "@Test public void testRebalanceNode() { HashMap < ByteArray, byte[] > entrySet = ServerTestUtils.createRandomKeyValuePairs(TEST_STREAM_KEYS_SIZE); List < Integer > fetchAndUpdatePartitionsList = Arrays.asList(0, 2); int fetchPartitionKeyCount = 0; Store < ByteArray, byte[] > store = getStore(0, testStoreName); for(Entry < ByteArray, byte[] > entry : entrySet.entrySet()) { store.put(entry.getKey(), new Versioned < byte[] > (entry.getValue())); if(isKeyPartition(entry.getKey(), 0, testStoreName, fetchAndUpdatePartitionsList)) { fetchPartitionKeyCount ++ ; } } List < Integer > rebalancePartitionList = Arrays.asList(1, 3); RebalancePartitionsInfo stealInfo = new RebalancePartitionsInfo(1, 0, rebalancePartitionList, rebalancePartitionList, rebalancePartitionList, Arrays.asList(testStoreName), new HashMap < String, String > (), 0); int asyncId = adminClient.rebalanceNode(stealInfo); assertNotSame(\"Got a valid rebalanceAsyncId\", - 1, asyncId); getAdminClient().waitForCompletion(1, asyncId, 120, TimeUnit.SECONDS); store = getStore(1, testStoreName); for(Entry < ByteArray, byte[] > entry : entrySet.entrySet()) { if(isKeyPartition(entry.getKey(), 1, testStoreName, rebalancePartitionList)) { assertSame(\"entry should be present at store\", 1, store.get(entry.getKey()).size()); assertEquals(\"entry value should match\", new String(entry.getValue()), new String(store.get(entry.getKey()).get(0).getValue())); } } } ",
        "test_tgt": "@Test public void testRebalanceNode() { HashMap < ByteArray, byte[] > entrySet = ServerTestUtils.createRandomKeyValuePairs(TEST_STREAM_KEYS_SIZE); List < Integer > fetchAndUpdatePartitionsList = Arrays.asList(0, 2); int fetchPartitionKeyCount = 0; Store < ByteArray, byte[] > store = getStore(0, testStoreName); for(Entry < ByteArray, byte[] > entry : entrySet.entrySet()) { store.put(entry.getKey(), new Versioned < byte[] > (entry.getValue())); if(isKeyPartition(entry.getKey(), 0, testStoreName, fetchAndUpdatePartitionsList)) { fetchPartitionKeyCount ++ ; } } List < Integer > rebalancePartitionList = Arrays.asList(1, 3); RebalancePartitionsInfo stealInfo = new RebalancePartitionsInfo(1, 0, rebalancePartitionList, rebalancePartitionList, rebalancePartitionList, Arrays.asList(testStoreName), new HashMap < String, String > (), new HashMap < String, String > (), 0); int asyncId = adminClient.rebalanceNode(stealInfo); assertNotSame(\"Got a valid rebalanceAsyncId\", - 1, asyncId); getAdminClient().waitForCompletion(1, asyncId, 120, TimeUnit.SECONDS); store = getStore(1, testStoreName); for(Entry < ByteArray, byte[] > entry : entrySet.entrySet()) { if(isKeyPartition(entry.getKey(), 1, testStoreName, rebalancePartitionList)) { assertSame(\"entry should be present at store\", 1, store.get(entry.getKey()).size()); assertEquals(\"entry value should match\", new String(entry.getValue()), new String(store.get(entry.getKey()).get(0).getValue())); } } } ",
        "focal_src": "public int rebalanceNode(RebalancePartitionsInfo stealInfo) { VAdminProto.InitiateRebalanceNodeRequest rebalanceNodeRequest = VAdminProto.InitiateRebalanceNodeRequest.newBuilder().setAttempt(stealInfo.getAttempt()).setDonorId(stealInfo.getDonorId()).setStealerId(stealInfo.getStealerId()).addAllPartitions(stealInfo.getPartitionList()).addAllUnbalancedStore(stealInfo.getUnbalancedStoreList()).addAllDeletePartitions(stealInfo.getDeletePartitionsList()).addAllStealMasterPartitions(stealInfo.getStealMasterPartitions()).addAllStoreToRODir(decodeROStoreVersionDirMap(stealInfo.getStoreToRODir())).build(); VAdminProto.VoldemortAdminRequest adminRequest = VAdminProto.VoldemortAdminRequest.newBuilder().setType(VAdminProto.AdminRequestType.INITIATE_REBALANCE_NODE).setInitiateRebalanceNode(rebalanceNodeRequest).build(); VAdminProto.AsyncOperationStatusResponse.Builder response = sendAndReceive(stealInfo.getStealerId(), adminRequest, VAdminProto.AsyncOperationStatusResponse.newBuilder()); if(response.hasError())throwException(response.getError()); return response.getRequestId(); } ",
        "focal_tgt": "public int rebalanceNode(RebalancePartitionsInfo stealInfo) { VAdminProto.InitiateRebalanceNodeRequest rebalanceNodeRequest = VAdminProto.InitiateRebalanceNodeRequest.newBuilder().setAttempt(stealInfo.getAttempt()).setDonorId(stealInfo.getDonorId()).setStealerId(stealInfo.getStealerId()).addAllPartitions(stealInfo.getPartitionList()).addAllUnbalancedStore(stealInfo.getUnbalancedStoreList()).addAllDeletePartitions(stealInfo.getDeletePartitionsList()).addAllStealMasterPartitions(stealInfo.getStealMasterPartitions()).addAllStealerRoStoreToDir(decodeROStoreVersionDirMap(stealInfo.getStealerNodeROStoreToDir())).addAllDonorRoStoreToDir(decodeROStoreVersionDirMap(stealInfo.getDonorNodeROStoreToDir())).build(); VAdminProto.VoldemortAdminRequest adminRequest = VAdminProto.VoldemortAdminRequest.newBuilder().setType(VAdminProto.AdminRequestType.INITIATE_REBALANCE_NODE).setInitiateRebalanceNode(rebalanceNodeRequest).build(); VAdminProto.AsyncOperationStatusResponse.Builder response = sendAndReceive(stealInfo.getStealerId(), adminRequest, VAdminProto.AsyncOperationStatusResponse.newBuilder()); if(response.hasError())throwException(response.getError()); return response.getRequestId(); } "
    },
    {
        "test_src": "@Test public void testTestConnection() { try { boolean result = false; try { DataSource dataSource = initSystemDataSourceAndDataSourceIdNotExist(); result = dataSource.testConnection(); assertFalse(true); } catch(Exception e) { assertTrue( ! result); } DataSource dataSource2 = initSystemDataSourceAndDataSourceIdExist(); boolean result2 = dataSource2.testConnection(); assertTrue(result2); DataSource dataSource3 = initCustomDataSourceCannotConnect(); boolean result3 = dataSource3.testConnection(); assertTrue( ! result3); DataSource dataSource4 = initCustomDataSourceCanConnect(); boolean result4 = dataSource4.testConnection(); assertTrue(result4); } catch(Exception e) { assertFalse(true); } } ",
        "test_tgt": "@Test public void testTestConnection() { DataSource dataSource = initSystemDataSourceAndDataSourceIdExist(); boolean result = dataSource.testConnection(); assertTrue(result); DataSource dataSource2 = initCustomDataSourceCanConnect(); boolean result2 = dataSource2.testConnection(); assertTrue(result2); } ",
        "focal_src": "public boolean testConnection(Long id) { DataSourceVO dataSourceVO = this.getDataSource(id); try { DataSource dataSource = new DataSource(); BeanUtils.copyProperties(dataSource, dataSourceVO); return dataSource.testConnection(); } catch(Exception e) { return false; } } ",
        "focal_tgt": "public boolean testConnection(Long id) { DataSourceVO dataSourceVO = this.getDataSourceVoById(id); try { DataSource dataSource = new DataSource(); BeanUtils.copyProperties(dataSource, dataSourceVO); return dataSource.testConnection(); } catch(Exception e) { return false; } } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"getLastAccessedTime\", args = { })@KnownFailure(\"Time returned is corrupted\")@AndroidOnly(\"Uses bks key store. Change useBKS to false to run on the RI\")public void test_getLastAccessedTime() { try { long diff = new Date().getTime() - clientSession.getLastAccessedTime(); assertTrue(diff < 10000); } catch(Exception ex) { fail(\"Unexpected exception \" + ex); } } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"getLastAccessedTime\", args = { })@AndroidOnly(\"Uses bks key store. Change useBKS to false to run on the RI\")public void test_getLastAccessedTime() { try { long diff = new Date().getTime() - clientSession.getLastAccessedTime(); assertTrue(diff < 10000); } catch(Exception ex) { fail(\"Unexpected exception \" + ex); } } ",
        "focal_src": "public long getLastAccessedTime() { if(lastAccessedTime == 0)return nativegetcreationtime(); else return lastAccessedTime; } ",
        "focal_tgt": "public long getLastAccessedTime() { return(lastAccessedTime == 0) ? getCreationTime() : lastAccessedTime; } "
    },
    {
        "test_src": "@Test public void testSizeGe() { assertEquals(new SizeGeCriterion(\"id\", 3), instance.sizeGe(\"id\", 3).getQueryCriterion()); } ",
        "test_tgt": "@Test public void testSizeGe() { assertEquals(Criteria.sizeGe(\"id\", 3), instance.sizeGe(\"id\", 3).getQueryCriterion()); } ",
        "focal_src": "public CriteriaQuery sizeGe(String propName, int size) { criterion = criterion.and(criterionBuilder.sizeGe(propName, size)); return this; } ",
        "focal_tgt": "public CriteriaQuery sizeGe(String propName, int size) { criterion = criterion.and(Criteria.sizeGe(propName, size)); return this; } "
    },
    {
        "test_src": "@Test public void testAddProperty__localCategory_asPropertyName()throws Exception { ResourceInstance resource = createNiceMock(ResourceInstance.class); ResourceDefinition resourceDefinition = createNiceMock(ResourceDefinition.class); Schema schema = createNiceMock(Schema.class); Map < String, Set < String > > mapSchemaProps = new HashMap < String, Set < String > > (); Set < String > setProps = new HashSet < String > (); setProps.add(\"property\"); setProps.add(\"property2\"); mapSchemaProps.put(\"category\", setProps); Set < String > setInnerProps = new HashSet < String > (); setInnerProps.add(\"property3\"); setInnerProps.add(\"property4\"); mapSchemaProps.put(\"category/nestedCategory\", setInnerProps); mapSchemaProps.put(null, Collections.singleton(\"property5\")); expect(resource.getResourceDefinition()).andReturn(resourceDefinition).anyTimes(); expect(resourceDefinition.getType()).andReturn(Resource.Type.Service).anyTimes(); expect(m_controller.getSchema(Resource.Type.Service)).andReturn(schema).anyTimes(); expect(schema.getCategoryProperties()).andReturn(mapSchemaProps).anyTimes(); replay(m_controller, resource, resourceDefinition, schema); Query query = new TestQuery(resource, null); query.addProperty(null, \"category\", null); Map < String, Set < String > > mapProperties = query.getProperties(); assertEquals(2, mapProperties.size()); Set < String > setResultProps = mapProperties.get(\"category\"); assertEquals(2, setResultProps.size()); assertTrue(setResultProps.contains(\"property\")); assertTrue(setResultProps.contains(\"property2\")); setResultProps = mapProperties.get(\"category/nestedCategory\"); assertEquals(2, setResultProps.size()); assertTrue(setResultProps.contains(\"property3\")); assertTrue(setResultProps.contains(\"property4\")); verify(m_controller, resource, resourceDefinition, schema); } ",
        "test_tgt": "@Test public void testAddProperty__localCategory_asPropertyName()throws Exception { ResourceInstance resource = createNiceMock(ResourceInstance.class); ResourceDefinition resourceDefinition = createNiceMock(ResourceDefinition.class); Schema schema = createNiceMock(Schema.class); expect(resource.getResourceDefinition()).andReturn(resourceDefinition).anyTimes(); expect(resourceDefinition.getType()).andReturn(Resource.Type.Service).anyTimes(); expect(m_controller.getSchema(Resource.Type.Service)).andReturn(schema).anyTimes(); expect(resource.getSubResources()).andReturn(Collections. < String, ResourceInstance > emptyMap()).anyTimes(); replay(m_controller, resource, resourceDefinition, schema); Query query = new TestQuery(resource, null); query.addProperty(null, \"category\", null); Set < String > setProperties = query.getProperties(); assertEquals(1, setProperties.size()); assertTrue(setProperties.contains(\"category\")); verify(m_controller, resource, resourceDefinition, schema); } ",
        "focal_src": "public void addProperty(String property); ",
        "focal_tgt": "public void addLocalProperty(String property); "
    },
    {
        "test_src": "@Test public void testCollectResults() { TestVector t = new TestVector(new WorkflowTrace(), null, null, ExecutorType.TLS, null); Result r = agent.collectResults(new File(\"../resources/EvolutionaryFuzzer/AFLTest/graph.trace\"), t); assertTrue(\"Failure: Test result should have exactly 4 Vertices\", r.getBranchTrace().getVerticesSet().size() == 4); assertTrue(\"Failure: Test result should have exactly 6 Edges\", r.getBranchTrace().getEdgeMap().size() == 6); } ",
        "test_tgt": "@Test public void testCollectResults() { TestVector t = new TestVector(new WorkflowTrace(), null, null, ExecutorType.TLS, null); AgentResult r = agent.collectResults(new File(\"../resources/EvolutionaryFuzzer/AFLTest/graph.trace\"), t); assertTrue(\"Failure: Test result should have exactly 4 Vertices\", r.getBranchTrace().getVerticesSet().size() == 4); assertTrue(\"Failure: Test result should have exactly 6 Edges\", r.getBranchTrace().getEdgeMap().size() == 6); } ",
        "focal_src": "public abstract Result collectResults(File branchTrace, TestVector vector); ",
        "focal_tgt": "public abstract AgentResult collectResults(File branchTrace, TestVector vector); "
    },
    {
        "test_src": "@Test public void parse() { query(EXISTS.args(_HTML_PARSE.args(\"&lt;html/&gt;\") + \"/*:html\"), \"true\"); query(_HTML_PARSE.args(\"&lt;html/&gt;\", \" map{'nons':=true()}\"), \"<html/>\"); } ",
        "test_tgt": "@Test public void parse() { query(EXISTS.args(_HTML_PARSE.args(\"&lt;html/&gt;\") + \"/*:html\"), \"true\"); query(_HTML_PARSE.args(\"&lt;html/&gt;\", \" {'nons':true()}\"), \"<html/>\"); } ",
        "focal_src": "private FElem parse(final QueryContext ctx)throws QueryException { final Item opt = expr.length > 1 ? expr[1].item(ctx, info) : null; final TokenMap map = new FuncParams(Q_OPTIONS, info).parse(opt); final boolean header = map.contains(HEADER) && eq(map.get(HEADER), TRUE); byte sep = CsvParser.SEPMAPPINGS[0]; final byte[]s = map.get(SEPARATOR); if(s != null) { if(s.length != 1)BXCS_SEP.thrw(info); sep = s[0]; } final CsvParser parser = new CsvParser(sep, header); try { return parser.convert(checkStr(expr[0], ctx)); } catch(final IOException ex) { throw BXCS_ERROR.thrw(info, ex); } } ",
        "focal_tgt": "private FElem parse(final QueryContext ctx)throws QueryException { final byte[]input = checkStr(expr[0], ctx); final Item opt = expr.length > 1 ? expr[1].item(ctx, info) : null; final TokenMap map = new FuncParams(Q_OPTIONS, info).parse(opt); final boolean header = map.contains(HEADER) && eq(map.get(HEADER), TRUE); byte sep = CsvParser.SEPMAPPINGS[0]; final byte[]s = map.get(SEPARATOR); if(s != null) { if(s.length != 1)BXCS_SEP.thrw(info); sep = s[0]; } try { return new CsvParser(sep, header).convert(input); } catch(final IOException ex) { throw BXCS_ERROR.thrw(info, ex); } } "
    },
    {
        "test_src": "@Test public void testInitialize() { Weld weld = new Weld().initialize(); MainTestBean mainTestBean = weld.instance().select(MainTestBean.class).get(); Assert.assertNotNull(mainTestBean); ParametersTestBean paramsBean = mainTestBean.getParametersTestBean(); Assert.assertNotNull(paramsBean); Assert.assertNotNull(paramsBean.getParameters()); shutdownManager(weld.getBeanManager()); } ",
        "test_tgt": "@Test public void testInitialize() { WeldContainer weld = new Weld().initialize(); MainTestBean mainTestBean = weld.instance().select(MainTestBean.class).get(); Assert.assertNotNull(mainTestBean); ParametersTestBean paramsBean = mainTestBean.getParametersTestBean(); Assert.assertNotNull(paramsBean); Assert.assertNotNull(paramsBean.getParameters()); shutdownManager(weld.getBeanManager()); } ",
        "focal_src": "public Weld initialize() { SEWeldDeployment deployment = new SEWeldDeployment() { }; bootstrap.startContainer(Environments.SE, deployment, this.applicationBeanStore); final BeanDeploymentArchive mainBeanDepArch = deployment.getBeanDeploymentArchives().get(0); this.manager = bootstrap.getManager(mainBeanDepArch); bootstrap.startInitialization(); bootstrap.deployBeans(); WeldManagerUtils.getInstanceByType(manager, ShutdownManager.class).setBootstrap(bootstrap); bootstrap.validateBeans(); bootstrap.endInitialization(); instanceManager = WeldManagerUtils.getInstanceByType(manager, InstanceManager.class); return this; } ",
        "focal_tgt": "public WeldContainer initialize() { SEWeldDeployment deployment = new SEWeldDeployment() { }; bootstrap.startContainer(Environments.SE, deployment, this.applicationBeanStore); final BeanDeploymentArchive mainBeanDepArch = deployment.getBeanDeploymentArchives().get(0); this.manager = bootstrap.getManager(mainBeanDepArch); bootstrap.startInitialization(); bootstrap.deployBeans(); WeldManagerUtils.getInstanceByType(manager, ShutdownManager.class).setBootstrap(bootstrap); bootstrap.validateBeans(); bootstrap.endInitialization(); InstanceManager instanceManager = WeldManagerUtils.getInstanceByType(manager, InstanceManager.class); return new WeldContainer(instanceManager, manager); } "
    },
    {
        "test_src": "@Test public void prepareConfigurationTest()throws Exception { Configuration tConf = new Configuration(); org.apache.hadoop.conf.Configuration hConf = new org.apache.hadoop.conf.Configuration(); mMockHdfsUnderFileSystem.prepareConfiguration(\"\", tConf, hConf); Assert.assertEquals(\"org.apache.hadoop.hdfs.DistributedFileSystem\", hConf.get(\"fs.hdfs.impl\")); Assert.assertFalse(hConf.getBoolean(\"fs.hdfs.impl.disable.cache\", false)); Assert.assertNotNull(hConf.get(Constants.UNDERFS_HDFS_CONFIGURATION)); } ",
        "test_tgt": "@Test public void prepareConfigurationTest()throws Exception { Configuration.defaultInit(); org.apache.hadoop.conf.Configuration conf = new org.apache.hadoop.conf.Configuration(); mMockHdfsUnderFileSystem.prepareConfiguration(\"\", conf); Assert.assertEquals(\"org.apache.hadoop.hdfs.DistributedFileSystem\", conf.get(\"fs.hdfs.impl\")); Assert.assertFalse(conf.getBoolean(\"fs.hdfs.impl.disable.cache\", false)); Assert.assertNotNull(conf.get(Constants.UNDERFS_HDFS_CONFIGURATION)); } ",
        "focal_src": "protected void prepareConfiguration(String path, Configuration conf, org.apache.hadoop.conf.Configuration hadoopConf) { String ufsHdfsImpl = mConfiguration.get(Constants.UNDERFS_HDFS_IMPL); if( ! StringUtils.isEmpty(ufsHdfsImpl)) { hadoopConf.set(\"fs.hdfs.impl\", ufsHdfsImpl); } hadoopConf.set(\"fs.hdfs.impl.disable.cache\", System.getProperty(\"fs.hdfs.impl.disable.cache\", \"false\")); HdfsUnderFileSystemUtils.addKey(hadoopConf, conf, Constants.UNDERFS_HDFS_CONFIGURATION); } ",
        "focal_tgt": "protected void prepareConfiguration(String path, org.apache.hadoop.conf.Configuration hadoopConf) { String ufsHdfsImpl = Configuration.get(Constants.UNDERFS_HDFS_IMPL); if( ! StringUtils.isEmpty(ufsHdfsImpl)) { hadoopConf.set(\"fs.hdfs.impl\", ufsHdfsImpl); } hadoopConf.set(\"fs.hdfs.impl.disable.cache\", System.getProperty(\"fs.hdfs.impl.disable.cache\", \"false\")); HdfsUnderFileSystemUtils.addKey(hadoopConf, Constants.UNDERFS_HDFS_CONFIGURATION); } "
    },
    {
        "test_src": "@Test public void toScript()throws Exception { final TransformRequest request = new TransformRequest(); request.setScript(\"sqlContext.range(1,10)\"); final TransformService service = new TransformService(TransformScript.class, Mockito.mock(SparkScriptEngine.class), Mockito.mock(SparkContextService.class), Mockito.mock(TransformJobTracker.class)); final String expected = IOUtils.toString(getClass().getResourceAsStream(\"transform-service-script1.scala\"), \"UTF-8\"); Assert.assertEquals(expected, service.toScript(request)); } ",
        "test_tgt": "@Test public void toScript()throws Exception { final TransformRequest request = new TransformRequest(); request.setScript(\"sqlContext.range(1,10)\"); final TransformService service = new TransformService(TransformScript.class, Mockito.mock(SparkScriptEngine.class), Mockito.mock(SparkContextService.class), Mockito.mock(JobTrackerService.class)); final String expected = IOUtils.toString(getClass().getResourceAsStream(\"transform-service-script1.scala\"), \"UTF-8\"); Assert.assertEquals(expected, service.toScript(request)); } ",
        "focal_src": "@Nonnull String toScript(@Nonnull final TransformRequest request) { final StringBuilder script = new StringBuilder(); script.append(\"class Transform (sqlContext: org.apache.spark.sql.SQLContext, sparkContextService: com.thinkbiganalytics.spark.SparkContextService) extends \"); script.append(transformScriptClass.getName()); script.append(\"(sqlContext, sparkContextService) {\\n\"); script.append(\"override def dataFrame: org.apache.spark.sql.DataFrame = {\"); script.append(request.getScript()); script.append(\"}\\n\"); if(request.getParent() != null) { script.append(\"override def parentDataFrame: org.apache.spark.sql.DataFrame = {\"); script.append(request.getParent().getScript()); script.append(\"}\\n\"); script.append(\"override def parentTable: String = {\\\"\"); script.append(StringEscapeUtils.escapeJava(request.getParent().getTable())); script.append(\"\\\"}\\n\"); } script.append(\"}\\n\"); script.append(\"new Transform(sqlContext, sparkContextService).run()\\n\"); return script.toString(); } ",
        "focal_tgt": "@Nonnull@VisibleForTesting String toScript(@Nonnull final TransformRequest request) { final StringBuilder script = new StringBuilder(); script.append(\"class Transform (sqlContext: org.apache.spark.sql.SQLContext, sparkContextService: com.thinkbiganalytics.spark.SparkContextService) extends \"); script.append(transformScriptClass.getName()); script.append(\"(sqlContext, sparkContextService) {\\n\"); script.append(\"override def dataFrame: org.apache.spark.sql.DataFrame = {\"); script.append(request.getScript()); script.append(\"}\\n\"); if(request.getParent() != null) { script.append(\"override def parentDataFrame: org.apache.spark.sql.DataFrame = {\"); script.append(request.getParent().getScript()); script.append(\"}\\n\"); script.append(\"override def parentTable: String = {\\\"\"); script.append(StringEscapeUtils.escapeJava(request.getParent().getTable())); script.append(\"\\\"}\\n\"); } script.append(\"}\\n\"); script.append(\"new Transform(sqlContext, sparkContextService).run()\\n\"); return script.toString(); } "
    },
    {
        "test_src": "@Test public void testDelete() { final Request request = RequestBuilder.delete(urlWithQuery).build(); assertEquals(\"DELETE\", request.method()); assertEquals(urlWithQuery, request.url().toString()); } ",
        "test_tgt": "@Test public void testDelete() { final Request request = RequestBuilder.delete(HttpUrl.parse(urlWithQuery)).build(); assertEquals(\"DELETE\", request.method()); assertEquals(urlWithQuery, request.url().toString()); } ",
        "focal_src": "public static RequestBuilder delete(String url) { return new RequestBuilder(HTTPMethod.DELETE, url); } ",
        "focal_tgt": "public static RequestBuilder delete(HttpUrl url) { return new RequestBuilder(HTTPMethod.DELETE, url); } "
    },
    {
        "test_src": "@Test public void testGetIntervalDay() { String fromString = \"2008-12-1\"; String toString = \"2008-9-29\"; int intervalDay = DateUtil.getIntervalDay(fromString, toString, DatePattern.COMMON_DATE); log.debug(intervalDay + \"\"); } ",
        "test_tgt": "@Test public void testGetIntervalDay() { String fromString = \"2008-12-1\"; String toString = \"2008-9-29\"; int intervalDay = DateUtil.getIntervalDay(fromString, toString, DatePattern.COMMON_DATE); log.debug(intervalDay + \"\"); } ",
        "focal_src": "public static final int getIntervalDay(long spaceTime) { return(int)(spaceTime / (TimeInterval.SECONDS_PER_DAY * 1000)); } ",
        "focal_tgt": "public static final int getIntervalDay(long spaceTime) { return(int)(spaceTime / (TimeInterval.MILLISECOND_PER_DAY)); } "
    },
    {
        "test_src": "@Test@Ignore(\"To be run locally until we fix the Rate limitation issue\")public void testListEntities() { String entity = \"Hello\" + UUID.randomUUID().toString(); try { ListEntitiesOptions listOptions = new ListEntitiesOptions.Builder(workspaceId).build(); EntityCollection response = service.listEntities(listOptions).execute(); assertNotNull(response); assertNotNull(response.getEntities()); assertNotNull(response.getPagination()); assertNotNull(response.getPagination().getRefreshUrl()); String entityDescription = \"Description of \" + entity; String entityValue = \"Value of \" + entity; CreateEntityOptions options = new CreateEntityOptions.Builder(workspaceId, entity).description(entityDescription).addValue(new CreateValue.Builder(entityValue).build()).build(); service.createEntity(options).execute(); ListEntitiesOptions listOptions2 = listOptions.newBuilder().sort(\"-modified\").pageLimit(5L).export(true).build(); EntityCollection response2 = service.listEntities(listOptions2).execute(); assertNotNull(response2); assertNotNull(response2.getEntities()); List < EntityExport > entities = response2.getEntities(); EntityExport ieResponse = null; for(EntityExport resp : entities) { if(resp.getEntityName().equals(entity)) { ieResponse = resp; break; } } assertNotNull(ieResponse); assertNotNull(ieResponse.getDescription()); assertEquals(ieResponse.getDescription(), entityDescription); assertNotNull(ieResponse.getValues()); assertTrue(ieResponse.getValues().size() == 1); assertTrue(ieResponse.getValues().get(0).getValueText().equals(entityValue)); } catch(Exception ex) { fail(ex.getMessage()); } finally { DeleteEntityOptions deleteOptions = new DeleteEntityOptions.Builder(workspaceId, entity).build(); service.deleteEntity(deleteOptions).execute(); } } ",
        "test_tgt": "@Test@Ignore(\"To be run locally until we fix the Rate limitation issue\")public void testListEntities() { String entity = \"Hello\" + UUID.randomUUID().toString(); try { ListEntitiesOptions listOptions = new ListEntitiesOptions.Builder(workspaceId).build(); EntityCollection response = service.listEntities(listOptions).execute(); assertNotNull(response); assertNotNull(response.getEntities()); assertNotNull(response.getPagination()); assertNotNull(response.getPagination().getRefreshUrl()); String entityDescription = \"Description of \" + entity; String entityValue = \"Value of \" + entity; CreateEntityOptions options = new CreateEntityOptions.Builder(workspaceId, entity).description(entityDescription).addValue(new CreateValue.Builder(entityValue).build()).build(); service.createEntity(options).execute(); ListEntitiesOptions listOptions2 = listOptions.newBuilder().sort(\"-updated\").pageLimit(5L).export(true).build(); EntityCollection response2 = service.listEntities(listOptions2).execute(); assertNotNull(response2); assertNotNull(response2.getEntities()); List < EntityExport > entities = response2.getEntities(); EntityExport ieResponse = null; for(EntityExport resp : entities) { if(resp.getEntityName().equals(entity)) { ieResponse = resp; break; } } assertNotNull(ieResponse); assertNotNull(ieResponse.getDescription()); assertEquals(ieResponse.getDescription(), entityDescription); assertNotNull(ieResponse.getValues()); assertTrue(ieResponse.getValues().size() == 1); assertTrue(ieResponse.getValues().get(0).getValueText().equals(entityValue)); } catch(Exception ex) { fail(ex.getMessage()); } finally { DeleteEntityOptions deleteOptions = new DeleteEntityOptions.Builder(workspaceId, entity).build(); service.deleteEntity(deleteOptions).execute(); } } ",
        "focal_src": "public ServiceCall < EntityCollection > listEntities(ListEntitiesOptions listEntitiesOptions) { Validator.notNull(listEntitiesOptions, \"listEntitiesOptions cannot be null\"); RequestBuilder builder = RequestBuilder.get(String.format(\"/v1/workspaces/%s/entities\", listEntitiesOptions.workspaceId())); builder.query(VERSION, versionDate); if(listEntitiesOptions.export() != null) { builder.query(\"export\", String.valueOf(listEntitiesOptions.export())); } if(listEntitiesOptions.pageLimit() != null) { builder.query(\"page_limit\", String.valueOf(listEntitiesOptions.pageLimit())); } if(listEntitiesOptions.includeCount() != null) { builder.query(\"include_count\", String.valueOf(listEntitiesOptions.includeCount())); } if(listEntitiesOptions.sort() != null) { builder.query(\"sort\", listEntitiesOptions.sort()); } if(listEntitiesOptions.cursor() != null) { builder.query(\"cursor\", listEntitiesOptions.cursor()); } return createServiceCall(builder.build(), ResponseConverterUtils.getObject(EntityCollection.class)); } ",
        "focal_tgt": "public ServiceCall < EntityCollection > listEntities(ListEntitiesOptions listEntitiesOptions) { Validator.notNull(listEntitiesOptions, \"listEntitiesOptions cannot be null\"); RequestBuilder builder = RequestBuilder.get(String.format(\"/v1/workspaces/%s/entities\", listEntitiesOptions.workspaceId())); builder.query(VERSION, versionDate); if(listEntitiesOptions.export() != null) { builder.query(\"export\", String.valueOf(listEntitiesOptions.export())); } if(listEntitiesOptions.pageLimit() != null) { builder.query(\"page_limit\", String.valueOf(listEntitiesOptions.pageLimit())); } if(listEntitiesOptions.includeCount() != null) { builder.query(\"include_count\", String.valueOf(listEntitiesOptions.includeCount())); } if(listEntitiesOptions.sort() != null) { builder.query(\"sort\", listEntitiesOptions.sort()); } if(listEntitiesOptions.cursor() != null) { builder.query(\"cursor\", listEntitiesOptions.cursor()); } if(listEntitiesOptions.includeAudit() != null) { builder.query(\"include_audit\", String.valueOf(listEntitiesOptions.includeAudit())); } return createServiceCall(builder.build(), ResponseConverterUtils.getObject(EntityCollection.class)); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void now() { Instant expected = Instant.now(TimeSource.system()); Instant test = Instant.now(); BigInteger diff = test.toEpochNano().subtract(expected.toEpochNano()).abs(); if(diff.compareTo(BigInteger.valueOf(100000000)) >= 0) { expected = Instant.now(TimeSource.system()); test = Instant.now(); diff = test.toEpochNano().subtract(expected.toEpochNano()).abs(); } assertTrue(diff.compareTo(BigInteger.valueOf(100000000)) < 0); } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void now() { Instant expected = Instant.now(Clock.systemUTC()); Instant test = Instant.now(); BigInteger diff = test.toEpochNano().subtract(expected.toEpochNano()).abs(); if(diff.compareTo(BigInteger.valueOf(100000000)) >= 0) { expected = Instant.now(Clock.systemUTC()); test = Instant.now(); diff = test.toEpochNano().subtract(expected.toEpochNano()).abs(); } assertTrue(diff.compareTo(BigInteger.valueOf(100000000)) < 0); } ",
        "focal_src": "public static Instant now(TimeSource timeSource) { MathUtils.checkNotNull(timeSource, \"TimeSource must not be null\"); return of(timeSource.instant()); } ",
        "focal_tgt": "public static Instant now(Clock clock) { MathUtils.checkNotNull(clock, \"Clock must not be null\"); return clock.instant(); } "
    },
    {
        "test_src": "@Test public void testSetupConnectivity() { Bandwidth bandwidth = Bandwidth.bps(100); Duration latency = Duration.ofMillis(10); OpticalConnectivityId cid = target.setupConnectivity(CP12, CP71, bandwidth, latency); assertNotNull(cid); assertEquals(1, pathService.edges.size()); assertEquals(CP12.deviceId(), pathService.edges.get(0).getKey()); assertEquals(CP71.deviceId(), pathService.edges.get(0).getValue()); assertEquals(1, intentService.submitted.size()); assertEquals(OpticalConnectivityIntent.class, intentService.submitted.get(0).getClass()); OpticalConnectivityIntent connIntent = (OpticalConnectivityIntent)intentService.submitted.get(0); assertEquals(CP31, connIntent.getSrc()); assertEquals(CP52, connIntent.getDst()); } ",
        "test_tgt": "@Test public void testSetupConnectivity() { Bandwidth bandwidth = Bandwidth.bps(100); Duration latency = Duration.ofMillis(10); OpticalConnectivityId cid = target.setupConnectivity(CP12, CP71, bandwidth, latency); assertNotNull(cid); assertEquals(1, topologyService.edges.size()); assertEquals(CP12.deviceId(), topologyService.edges.get(0).getKey()); assertEquals(CP71.deviceId(), topologyService.edges.get(0).getValue()); assertEquals(1, intentService.submitted.size()); assertEquals(OpticalConnectivityIntent.class, intentService.submitted.get(0).getClass()); OpticalConnectivityIntent connIntent = (OpticalConnectivityIntent)intentService.submitted.get(0); assertEquals(CP31, connIntent.getSrc()); assertEquals(CP52, connIntent.getDst()); } ",
        "focal_src": "@Override public OpticalConnectivityId setupConnectivity(ConnectPoint ingress, ConnectPoint egress, Bandwidth bandwidth, Duration latency) { checkNotNull(ingress); checkNotNull(egress); log.info(\"setupConnectivity({}, {}, {}, {})\", ingress, egress, bandwidth, latency); bandwidth = (bandwidth == null) ? NO_BW_REQUIREMENT : bandwidth; Set < Path > paths = pathService.getPaths(ingress.deviceId(), egress.deviceId(), new BandwidthLinkWeight(bandwidth)); if(paths.isEmpty()) { log.warn(\"Unable to find multi-layer path.\"); return null; } for(Path path : paths) { if( ! path.src().equals(ingress) || ! path.dst().equals(egress)) { continue; } OpticalConnectivityId id = setupPath(path, bandwidth, latency); if(id != null) { log.info(\"Assigned OpticalConnectivityId: {}\", id); return id; } } log.error(\"setupConnectivity({}, {}, {}, {}) failed.\", ingress, egress, bandwidth, latency); return null; } ",
        "focal_tgt": "@Override public OpticalConnectivityId setupConnectivity(ConnectPoint ingress, ConnectPoint egress, Bandwidth bandwidth, Duration latency) { checkNotNull(ingress); checkNotNull(egress); log.info(\"setupConnectivity({}, {}, {}, {})\", ingress, egress, bandwidth, latency); Bandwidth bw = (bandwidth == null) ? NO_BW_REQUIREMENT : bandwidth; Stream < Path > paths = topologyService.getKShortestPaths(topologyService.currentTopology(), ingress.deviceId(), egress.deviceId(), new BandwidthLinkWeight(bandwidth)); Optional < OpticalConnectivityId > id = paths.filter(p -> p.src().equals(ingress) && p.dst().equals(egress)).limit(maxPaths).map(p -> setupPath(p, bw, latency)).filter(Objects :: nonNull).findFirst(); if(id.isPresent()) { log.info(\"Assigned OpticalConnectivityId: {}\", id); } else { log.error(\"setupConnectivity({}, {}, {}, {}) failed.\", ingress, egress, bandwidth, latency); } return id.orElse(null); } "
    },
    {
        "test_src": "@Test(groups = { \"tck\" })public void test_minusSeconds_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.toLocalDate().minusDays(1); int hour = 0; int min = 0; int sec = 0; for(int i = 0; i < 3700; i ++ ) { t = t.minusSeconds(1); sec -- ; if(sec == - 1) { min -- ; sec = 59; if(min == - 1) { hour -- ; min = 59; if(hour == - 1) { hour = 23; } } } assertEquals(t.toLocalDate(), d); assertEquals(t.getHour(), hour); assertEquals(t.getMinute(), min); assertEquals(t.getSecond(), sec); } } ",
        "test_tgt": "@Test(groups = { \"tck\" })public void test_minusSeconds_one() { LocalDateTime t = TEST_2007_07_15_12_30_40_987654321.with(LocalTime.MIDNIGHT); LocalDate d = t.getDate().minusDays(1); int hour = 0; int min = 0; int sec = 0; for(int i = 0; i < 3700; i ++ ) { t = t.minusSeconds(1); sec -- ; if(sec == - 1) { min -- ; sec = 59; if(min == - 1) { hour -- ; min = 59; if(hour == - 1) { hour = 23; } } } assertEquals(t.getDate(), d); assertEquals(t.getHour(), hour); assertEquals(t.getMinute(), min); assertEquals(t.getSecond(), sec); } } ",
        "focal_src": "ChronoZonedDateTime < C > minusSeconds(long seconds) { ChronoDateTime newDT = dateTime.toDateTime().minusSeconds(seconds); return(newDT == dateTime.toDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } ",
        "focal_tgt": "ChronoZonedDateTime < C > minusSeconds(long seconds) { ChronoDateTime newDT = dateTime.getDateTime().minusSeconds(seconds); return(newDT == dateTime.getDateTime() ? this : resolve(newDT, zone, dateTime, ZoneResolvers.retainOffset())); } "
    },
    {
        "test_src": "@Test public void toHTML()throws Exception { String source = \"wiki syntax\"; String syntaxId = \"syntax/x.y\"; Parser parser = this.mocker.registerMockComponent(Parser.class, syntaxId); XDOM xdom = new XDOM(Collections. < Block > emptyList()); when(parser.parse(any(StringReader.class))).thenReturn(xdom); Assert.assertEquals(\"\", mocker.getComponentUnderTest().toHTML(source, syntaxId)); Transformation macroTransformation = mocker.getInstance(Transformation.class, \"macro\"); RenderingContext renderingContext = mocker.getInstance(RenderingContext.class); ArgumentCaptor < TransformationContext > txContextArgument = ArgumentCaptor.forClass(TransformationContext.class); verify((MutableRenderingContext)renderingContext).transformInContext(same(macroTransformation), txContextArgument.capture(), same(xdom)); assertEquals(\"wysiwygtxid\", txContextArgument.getValue().getId()); BlockRenderer xhtmlRenderer = mocker.getInstance(BlockRenderer.class, \"annotatedxhtml/1.0\"); verify(xhtmlRenderer).render(same(xdom), any(WikiPrinter.class)); } ",
        "test_tgt": "@Test public void toHTML()throws Exception { String source = \"wiki syntax\"; Syntax syntax = new Syntax(new SyntaxType(\"syntax\", \"Syntax\"), \"x.y\"); ContentParser contentParser = this.mocker.getInstance(ContentParser.class); XDOM xdom = new XDOM(Collections. < Block > emptyList()); when(contentParser.parse(source, syntax, null)).thenReturn(xdom); Assert.assertEquals(\"\", mocker.getComponentUnderTest().toHTML(source, syntax.toIdString())); Transformation macroTransformation = mocker.getInstance(Transformation.class, \"macro\"); RenderingContext renderingContext = mocker.getInstance(RenderingContext.class); ArgumentCaptor < TransformationContext > txContextArgument = ArgumentCaptor.forClass(TransformationContext.class); verify((MutableRenderingContext)renderingContext).transformInContext(same(macroTransformation), txContextArgument.capture(), same(xdom)); assertEquals(\"wysiwygtxid\", txContextArgument.getValue().getId()); BlockRenderer xhtmlRenderer = mocker.getInstance(BlockRenderer.class, \"annotatedxhtml/1.0\"); verify(xhtmlRenderer).render(same(xdom), any(WikiPrinter.class)); } ",
        "focal_src": "String toHTML(String source, String syntaxId); ",
        "focal_tgt": "@Deprecated String toHTML(String source, String syntaxId); "
    },
    {
        "test_src": "@Test@Verifies(value = \"should fail if required fields are empty\", method = \"validate(Object,Errors)\")public void validate_shouldFailIfRequiredFieldsAreEmpty()throws Exception { executeDataSet(PERSON_ADDRESS_VALIDATOR_DATASET_PACKAGE_PATH); PersonAddress personAddress = new PersonAddress(); Errors errors = new BindException(personAddress, \"personAddress\"); validator.validate(personAddress, errors); Assert.assertEquals(true, errors.hasErrors()); } ",
        "test_tgt": "@Test@Verifies(value = \"should fail if required fields are empty\", method = \"validate(Object,Errors)\")public void validate_shouldFailIfRequiredFieldsAreEmpty()throws Exception { executeDataSet(PERSON_ADDRESS_VALIDATOR_DATASET_PACKAGE_PATH); Address personAddress = new PersonAddress(); Errors errors = new BindException(personAddress, \"personAddress\"); validator.validate(personAddress, errors); Assert.assertEquals(true, errors.hasErrors()); } ",
        "focal_src": "public void validate(Object obj, Errors errors) { Location location = (Location)obj; if(location == null) { errors.rejectValue(\"location\", \"error.general\"); } else { ValidationUtils.rejectIfEmptyOrWhitespace(errors, \"name\", \"error.name\"); if(location.isRetired() && ! StringUtils.hasLength(location.getRetireReason())) { location.setRetired(false); errors.rejectValue(\"retireReason\", \"error.null\"); } Location exist = Context.getLocationService().getLocation(location.getName()); if(exist != null && ! exist.isRetired() && ! OpenmrsUtil.nullSafeEquals(location.getUuid(), exist.getUuid())) { errors.rejectValue(\"name\", \"location.duplicate.name\"); } Location root = location; while(root.getParentLocation() != null) { root = root.getParentLocation(); if(root.equals(location)) { errors.rejectValue(\"parentLocation\", \"Location.parentLocation.error\"); break; } } ValidateUtil.validateFieldLengths(errors, obj.getClass(), \"name\", \"description\", \"address1\", \"address2\", \"cityVillage\", \"stateProvince\", \"country\", \"postalCode\", \"latitude\", \"longitude\", \"countyDistrict\", \"address3\", \"address4\", \"address5\", \"address6\", \"retireReason\"); super.validateAttributes(location, errors, Context.getLocationService().getAllLocationAttributeTypes()); } } ",
        "focal_tgt": "public void validate(Object obj, Errors errors) { Location location = (Location)obj; if(location == null) { errors.rejectValue(\"location\", \"error.general\"); } else { ValidationUtils.rejectIfEmptyOrWhitespace(errors, \"name\", \"error.name\"); if(location.isRetired() && ! StringUtils.hasLength(location.getRetireReason())) { location.setRetired(false); errors.rejectValue(\"retireReason\", \"error.null\"); } Location exist = Context.getLocationService().getLocation(location.getName()); if(exist != null && ! exist.isRetired() && ! OpenmrsUtil.nullSafeEquals(location.getUuid(), exist.getUuid())) { errors.rejectValue(\"name\", \"location.duplicate.name\"); } Location root = location; while(root.getParentLocation() != null) { root = root.getParentLocation(); if(root.equals(location)) { errors.rejectValue(\"parentLocation\", \"Location.parentLocation.error\"); break; } } ValidateUtil.validateFieldLengths(errors, obj.getClass(), \"name\", \"description\", \"address1\", \"address2\", \"cityVillage\", \"stateProvince\", \"country\", \"postalCode\", \"latitude\", \"longitude\", \"countyDistrict\", \"address3\", \"address4\", \"address5\", \"address6\", \"address7\", \"address8\", \"address9\", \"address10\", \"address11\", \"address12\", \"address13\", \"address14\", \"address15\", \"retireReason\"); super.validateAttributes(location, errors, Context.getLocationService().getAllLocationAttributeTypes()); } } "
    },
    {
        "test_src": "@Test public void testGetEdges() { String script = \"results.add(g.E)\"; Transaction tx = null; Representation curRepresentationObj = null; try { tx = curGraphDBServiceObj.beginTx(); curRepresentationObj = (Representation)curGremlinPluginObj.getEdges(script, curGraphDBServiceObj); assertNotNull(curRepresentationObj); tx.success(); System.err.println(\"GremlinPluginTest::testGetEdges the contents of the representation object=\" + curRepresentationObj.toString()); } catch(Throwable t) { t.printStackTrace(); } finally { tx.finish(); } } ",
        "test_tgt": "@Test public void testGetEdges() { String script = \"results.add(g.E)\"; Transaction tx = null; Representation curRepresentationObj = null; try { tx = curGraphDBServiceObj.beginTx(); curRepresentationObj = (Representation)curGremlinPluginObj.getEdges(script, curGraphDBServiceObj); assertNotNull(curRepresentationObj); tx.success(); } catch(Throwable t) { t.printStackTrace(); } finally { tx.finish(); } System.out.println(\"Results of testGetEdges\" + json.format(curRepresentationObj)); } ",
        "focal_src": "@Name(\"get_all_edges\")@Description(\"execute a Gremlin script with variables 'start' set to the start node 'g' set to the Neo4jGraph and 'results' containing a resulting vertex\")@PluginTarget(GraphDatabaseService.class)public Representation getEdges(@Description(\"The Gremlin script\")@Parameter(name = \"script\", optional = true)String script, @Source GraphDatabaseService graphDb) { ScriptEngineManager manager = new ScriptEngineManager(); ScriptEngine engine = manager.getEngineByName(\"gremlin\"); ArrayList < EdgeRepresentation > results = new ArrayList < EdgeRepresentation > (); Neo4jGraph graph = new Neo4jGraph(graphDb); engine.getBindings(ScriptContext.ENGINE_SCOPE).put(\"g\", graph); engine.getBindings(ScriptContext.GLOBAL_SCOPE).put(\"results\", results); try { engine.eval(script); } catch(ScriptException e) { e.printStackTrace(); } return new ListRepresentation(RepresentationType.RELATIONSHIP, results); } ",
        "focal_tgt": "@Name(\"get_all_edges\")@Description(\"execute a Gremlin script with variables 'start' set to the start node 'g' set to the Neo4jGraph and 'results' containing a resulting vertex\")@PluginTarget(GraphDatabaseService.class)public Representation getEdges(@Description(\"The Gremlin script\")@Parameter(name = \"script\", optional = true)String script, @Source GraphDatabaseService graphDb) { ScriptEngineManager manager = new ScriptEngineManager(); ScriptEngine engine = manager.getEngineByName(\"gremlin\"); ArrayList < Edge > results = new ArrayList < Edge > (); Neo4jGraph graph = new Neo4jGraph(graphDb); engine.getBindings(ScriptContext.ENGINE_SCOPE).put(\"g\", graph); engine.getBindings(ScriptContext.GLOBAL_SCOPE).put(\"results\", results); try { engine.eval(script); } catch(ScriptException e) { e.printStackTrace(); } return new PipeEdgeRepresentation(results); } "
    },
    {
        "test_src": "@Test public void testScale() { BoundingBox a = new BoundingBox( - 0.3f, - 0.5f, - 0.7f, 0.12f, 0.43f, 0.1f); BoundingBox b = new BoundingBox( - 4.5f, - 7.5f, - 10.5f, 1.8f, 6.45f, 1.5f); a.scale(1.5f); b.scale(0.1f); testValue(a, b); a.scale(new Vector3(0.6f, 0.6f, 0.6f)); b.scale( - 0.3f, - 0.3f, - 0.3f).scale( - 2.0f); testValue(a, b); } ",
        "test_tgt": "@Test public void testScale() { BoundingBox a = new BoundingBox( - 0.3f, - 0.5f, - 0.7f, 0.12f, 0.43f, 0.1f); BoundingBox b = new BoundingBox( - 4.5f, - 7.5f, - 10.5f, 1.8f, 6.45f, 1.5f); a = a.scale(1.5f); b = b.scale(0.1f); testValue(a, b); a = a.scale(new Vector3(0.6f, 0.6f, 0.6f)); b = b.scale( - 0.3f, - 0.3f, - 0.3f).scale( - 2.0f); testValue(a, b); } ",
        "focal_src": "public BoundingBox scale(Vector3 scale) { min = min.multiply(scale); max = max.multiply(scale); return this; } ",
        "focal_tgt": "public BoundingBox scale(Vector3 scale) { return new BoundingBox(min.multiply(scale), max.multiply(scale)); } "
    },
    {
        "test_src": "@Test public void testGetApplication()throws GenieException { final Application app = this.appService.getApplication(APP_1_ID); Assert.assertEquals(APP_1_ID, app.getId()); Assert.assertEquals(APP_1_NAME, app.getName()); Assert.assertEquals(APP_1_USER, app.getUser()); Assert.assertEquals(APP_1_VERSION, app.getVersion()); Assert.assertEquals(APP_1_STATUS, app.getStatus()); Assert.assertEquals(3, app.getTags().size()); Assert.assertEquals(2, app.getConfigs().size()); Assert.assertEquals(2, app.getDependencies().size()); final Application app2 = this.appService.getApplication(APP_2_ID); Assert.assertEquals(APP_2_ID, app2.getId()); Assert.assertEquals(APP_2_NAME, app2.getName()); Assert.assertEquals(APP_2_USER, app2.getUser()); Assert.assertEquals(APP_2_VERSION, app2.getVersion()); Assert.assertEquals(APP_2_STATUS, app2.getStatus()); Assert.assertEquals(4, app2.getTags().size()); Assert.assertEquals(2, app2.getConfigs().size()); Assert.assertEquals(1, app2.getDependencies().size()); final Application app3 = this.appService.getApplication(APP_3_ID); Assert.assertEquals(APP_3_ID, app3.getId()); Assert.assertEquals(APP_3_NAME, app3.getName()); Assert.assertEquals(APP_3_USER, app3.getUser()); Assert.assertEquals(APP_3_VERSION, app3.getVersion()); Assert.assertEquals(APP_3_STATUS, app3.getStatus()); Assert.assertEquals(3, app3.getTags().size()); Assert.assertEquals(1, app3.getConfigs().size()); Assert.assertEquals(2, app3.getDependencies().size()); } ",
        "test_tgt": "@Test@Ignore public void testGetApplication()throws GenieException { } ",
        "focal_src": "public Application getApplication() { return this.application; } ",
        "focal_tgt": "public Set < Application > getApplications() { return this.applications; } "
    },
    {
        "test_src": "@Test public void testInvalidateTx()throws Exception { TransactionSystemClient txClient = AppFabricTestsSuite.getTxClient(); Transaction tx1 = txClient.startShort(); HttpResponse response = AppFabricTestsSuite.doPut(\"/v2/transactions/\" + tx1.getWritePointer() + \"/invalidate\"); Assert.assertEquals(200, response.getStatusLine().getStatusCode()); Transaction tx2 = txClient.startShort(); txClient.commit(tx2); response = AppFabricTestsSuite.doPut(\"/v2/transactions/\" + tx2.getWritePointer() + \"/invalidate\"); Assert.assertEquals(409, response.getStatusLine().getStatusCode()); Assert.assertEquals(400, AppFabricTestsSuite.doPut(\"/v2/transactions/foobar/invalidate\").getStatusLine().getStatusCode()); } ",
        "test_tgt": "@Test public void testInvalidateTx()throws Exception { TransactionSystemClient txClient = AppFabricTestsSuite.getTxClient(); Transaction tx1 = txClient.startShort(); HttpResponse response = AppFabricTestsSuite.doPost(\"/v2/transactions/\" + tx1.getWritePointer() + \"/invalidate\"); Assert.assertEquals(200, response.getStatusLine().getStatusCode()); Transaction tx2 = txClient.startShort(); txClient.commit(tx2); response = AppFabricTestsSuite.doPost(\"/v2/transactions/\" + tx2.getWritePointer() + \"/invalidate\"); Assert.assertEquals(409, response.getStatusLine().getStatusCode()); Assert.assertEquals(400, AppFabricTestsSuite.doPost(\"/v2/transactions/foobar/invalidate\").getStatusLine().getStatusCode()); } ",
        "focal_src": "@Path(\"/transactions/{tx-id}/invalidate\")@PUT public void invalidateTx(HttpRequest request, HttpResponder responder, @PathParam(\"tx-id\")final String txId) { try { Long txIdLong = Long.valueOf(txId); boolean success = txClient.invalidate(txIdLong); if(success) { LOG.info(\"Transaction {} successfully invalidated\", txId); responder.sendStatus(HttpResponseStatus.OK); } else { LOG.info(\"Transaction {} could not be invalidated: not in progress.\", txId); responder.sendStatus(HttpResponseStatus.CONFLICT); } } catch(NumberFormatException e) { LOG.info(\"Could not invalidate transaction: {} is not a valid tx id\", txId); responder.sendStatus(HttpResponseStatus.BAD_REQUEST); } } ",
        "focal_tgt": "@Path(\"/transactions/{tx-id}/invalidate\")@POST public void invalidateTx(HttpRequest request, HttpResponder responder, @PathParam(\"tx-id\")final String txId) { try { long txIdLong = Long.parseLong(txId); boolean success = txClient.invalidate(txIdLong); if(success) { LOG.info(\"Transaction {} successfully invalidated\", txId); responder.sendStatus(HttpResponseStatus.OK); } else { LOG.info(\"Transaction {} could not be invalidated: not in progress.\", txId); responder.sendStatus(HttpResponseStatus.CONFLICT); } } catch(NumberFormatException e) { LOG.info(\"Could not invalidate transaction: {} is not a valid tx id\", txId); responder.sendStatus(HttpResponseStatus.BAD_REQUEST); } } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.PARTIAL_COMPLETE, notes = \"\", method = \"socket\", args = { })public void testSocket_BasicStatusBeforeConnect()throws SocketException { assertFalse(this.channel1.isConnected()); DatagramSocket s1 = this.channel1.socket(); assertSocketBeforeConnect(s1); DatagramSocket s2 = this.channel1.socket(); assertSame(s1, s2); } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.PARTIAL_COMPLETE, notes = \"\", method = \"socket\", args = { })@KnownFailure(value = \"bug 2155708\")public void testSocket_BasicStatusBeforeConnect()throws SocketException { assertFalse(this.channel1.isConnected()); DatagramSocket s1 = this.channel1.socket(); assertSocketBeforeConnect(s1); DatagramSocket s2 = this.channel1.socket(); assertSame(s1, s2); } ",
        "focal_src": "@Override synchronized public DatagramSocket socket() { if(null == socket) { socket = new DatagramSocketAdapter(SocketImplProvider.getDatagramSocketImpl(fd, localPort), this); } return socket; } ",
        "focal_tgt": "@Override synchronized public DatagramSocket socket() { if(null == socket) { socket = new DatagramSocketAdapter(new PlainDatagramSocketImpl(fd, localPort), this); } return socket; } "
    },
    {
        "test_src": "@Test public void testPutReferAntiLeech() { BucketReferAntiLeech leech = new BucketReferAntiLeech(); Response response; try { System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(TestConfig.testBucket_z0, leech); Assert.assertEquals(200, response.statusCode); leech.setAllowEmptyReferer(false); System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(TestConfig.testBucket_z0, leech); Assert.assertEquals(200, response.statusCode); leech.setAllowEmptyReferer(false); leech.setMode(1); leech.setPattern(\"www.qiniu.com\"); System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(TestConfig.testBucket_z0, leech); Assert.assertEquals(200, response.statusCode); System.out.println(response.url()); System.out.println(response.reqId); } catch(Exception e) { if(e instanceof QiniuException) { QiniuException ex = (QiniuException)e; Assert.fail(ex.response.toString()); } } } ",
        "test_tgt": "@Test public void testPutReferAntiLeech() { String[]buckets = new String[] { TestConfig.testBucket_z0, TestConfig.testBucket_na0 }; for(String bucket : buckets) { BucketReferAntiLeech leech = new BucketReferAntiLeech(); Response response; BucketInfo bucketInfo; try { leech.setMode(1); leech.setPattern(\"www.qiniu.com\"); leech.setAllowEmptyReferer(false); System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(bucket, leech); Assert.assertEquals(200, response.statusCode); bucketInfo = bucketManager.getBucketInfo(bucket); Assert.assertEquals(1, bucketInfo.getAntiLeechMode()); Assert.assertArrayEquals((new String[] { \"www.qiniu.com\" }), bucketInfo.getReferWhite()); Assert.assertEquals(false, bucketInfo.isNoRefer()); leech.setMode(2); leech.setPattern(\"www.baidu.com\"); leech.setAllowEmptyReferer(true); System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(bucket, leech); Assert.assertEquals(200, response.statusCode); bucketInfo = bucketManager.getBucketInfo(bucket); Assert.assertEquals(2, bucketInfo.getAntiLeechMode()); Assert.assertArrayEquals((new String[] { \"www.baidu.com\" }), bucketInfo.getReferBlack()); Assert.assertEquals(true, bucketInfo.isNoRefer()); leech = new BucketReferAntiLeech(); System.out.println(leech.asQueryString()); response = bucketManager.putReferAntiLeech(bucket, leech); Assert.assertEquals(200, response.statusCode); bucketInfo = bucketManager.getBucketInfo(bucket); Assert.assertEquals(0, bucketInfo.getAntiLeechMode()); Assert.assertNull(\"ReferBlack should be Null\", bucketInfo.getReferBlack()); Assert.assertNull(\"ReferWhtie should be Null\", bucketInfo.getReferWhite()); Assert.assertEquals(false, bucketInfo.isNoRefer()); } catch(Exception e) { if(e instanceof QiniuException) { QiniuException ex = (QiniuException)e; Assert.fail(ex.response.toString()); } } } } ",
        "focal_src": "public Response putReferAntiLeech(String bucket, BucketReferAntiLeech antiLeech)throws QiniuException { String url = String.format(\"%s/referAntiLeech?bucket=%s&%s\", configuration.ucHost(), bucket, antiLeech.asQueryString()); Response res = post(url, null); if( ! res.isOK()) { throw new QiniuException(res); } res.close(); return res; } ",
        "focal_tgt": "public Response putReferAntiLeech(String bucket, BucketReferAntiLeech antiLeech)throws QiniuException { String url = String.format(\"%s/referAntiLeech?bucket=%s&%s\", configuration.ucHost(), bucket, antiLeech.asQueryString()); Response res = post(url, null); if( ! res.isOK()) { throw new QiniuException(res); } return res; } "
    },
    {
        "test_src": "@Test public void testGetGraphRelatedConcepts() { final Map < String, Object > params = new HashMap < String, Object > (); final List < Concept > concepts = new ArrayList < Concept > (); concepts.add(EXAMPLE_CONCEPT); params.put(ConceptInsights.LIMIT, 10); params.put(ConceptInsights.LEVEL, 1); final RequestedFields fs = new RequestedFields(); fs.include(\"abstract\"); params.put(\"concept_fields\", fs); final Concepts conceptResults = service.getGraphRelatedConcepts(Graph.WIKIPEDIA, concepts, params); Assert.assertNotNull(conceptResults); } ",
        "test_tgt": "@Test public void testGetGraphRelatedConcepts() { final Map < String, Object > params = new HashMap < String, Object > (); final List < Concept > concepts = new ArrayList < Concept > (); concepts.add(EXAMPLE_CONCEPT); params.put(ConceptInsights.LIMIT, 10); params.put(ConceptInsights.LEVEL, 1); final RequestedFields fs = new RequestedFields(); fs.include(\"abstract\"); fs.include(\"link\"); fs.include(\"name\"); params.put(ConceptInsights.CONCEPT_FIELDS, fs); Concepts conceptResults = service.getGraphRelatedConcepts(Graph.WIKIPEDIA, concepts, params); Assert.assertNotNull(conceptResults); Assert.assertTrue( ! conceptResults.getConcepts().isEmpty()); Assert.assertNotNull(conceptResults.getConcepts().get(0).getConcept().getAbstract()); } ",
        "focal_src": "public Concepts getGraphRelatedConcepts(final Graph graph, final List < Concept > concepts, final Map < String, Object > parameters) { final String graphId = IDHelper.getGraphId(graph, getAccountId()); Validate.notEmpty(concepts, \"concepts cannot be empty\"); final Map < String, Object > queryParameters = new HashMap < String, Object > (); final String[]queryParms = new String[] { LEVEL, LIMIT }; for(final String param : queryParms) { if(parameters.containsKey(param))queryParameters.put(param, parameters.get(param)); } if(parameters.get(CONCEPT_FIELDS) != null) { final RequestedFields fields = (RequestedFields)parameters.get(CONCEPT_FIELDS); if(fields != null && ! fields.isEmpty())queryParameters.put(CONCEPT_FIELDS, fields.toString()); } final JsonObject contentJson = new JsonObject(); final JsonArray conceptsJson = new JsonArray(); for(final Concept concept : concepts) { conceptsJson.add(new JsonPrimitive(concept.getId())); } contentJson.add(CONCEPTS, conceptsJson); queryParameters.put(CONCEPTS, conceptsJson.toString()); return executeRequest(API_VERSION + graphId + RELATED_CONCEPTS_PATH, queryParameters, Concepts.class); } ",
        "focal_tgt": "public Concepts getGraphRelatedConcepts(final Graph graph, final List < Concept > concepts, final Map < String, Object > parameters) { final String graphId = IDHelper.getGraphId(graph, getAccountId()); Validate.notEmpty(concepts, \"concepts cannot be empty\"); final Map < String, Object > queryParameters = new HashMap < String, Object > (); final String[]queryParms = new String[] { LEVEL, LIMIT }; for(final String param : queryParms) { if(parameters.containsKey(param))queryParameters.put(param, parameters.get(param)); } if(parameters.get(CONCEPT_FIELDS) != null) { final RequestedFields fields = (RequestedFields)parameters.get(CONCEPT_FIELDS); if(fields != null && ! fields.isEmpty())queryParameters.put(CONCEPT_FIELDS, toJson(fields.getFields())); } final JsonObject contentJson = new JsonObject(); final JsonArray conceptsJson = new JsonArray(); for(final Concept concept : concepts) { conceptsJson.add(new JsonPrimitive(concept.getId())); } contentJson.add(CONCEPTS, conceptsJson); queryParameters.put(CONCEPTS, conceptsJson.toString()); return executeRequest(API_VERSION + graphId + RELATED_CONCEPTS_PATH, queryParameters, Concepts.class); } "
    },
    {
        "test_src": "@Test public void testRenewSessionId()throws Exception { Server server = new Server(); ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS); context.setContextPath(\"/test\"); context.setServer(server); DefaultSessionCacheFactory cacheFactory = new DefaultSessionCacheFactory(); cacheFactory.setEvictionPolicy(SessionCache.NEVER_EVICT); DefaultSessionCache cache = (DefaultSessionCache)cacheFactory.getSessionCache(context.getSessionHandler()); TestSessionDataStore store = new TestSessionDataStore(true); cache.setSessionDataStore(store); context.getSessionHandler().setSessionCache(cache); context.start(); long now = System.currentTimeMillis(); SessionData data = store.newSessionData(\"1234\", now - 20, now - 10, now - 20, TimeUnit.MINUTES.toMillis(10)); Session session = cache.newSession(data); cache.put(\"1234\", session); assertTrue(cache.contains(\"1234\")); cache.renewSessionId(\"1234\", \"5678\"); assertTrue(cache.contains(\"5678\")); assertFalse(cache.contains(\"1234\")); assertTrue(store.exists(\"5678\")); assertFalse(store.exists(\"1234\")); } ",
        "test_tgt": "@Test public void testRenewSessionId()throws Exception { Server server = new Server(); ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS); context.setContextPath(\"/test\"); context.setServer(server); DefaultSessionCacheFactory cacheFactory = new DefaultSessionCacheFactory(); cacheFactory.setEvictionPolicy(SessionCache.NEVER_EVICT); DefaultSessionCache cache = (DefaultSessionCache)cacheFactory.getSessionCache(context.getSessionHandler()); TestSessionDataStore store = new TestSessionDataStore(true); cache.setSessionDataStore(store); context.getSessionHandler().setSessionCache(cache); context.start(); long now = System.currentTimeMillis(); SessionData data = store.newSessionData(\"1234\", now - 20, now - 10, now - 20, TimeUnit.MINUTES.toMillis(10)); Session session = cache.newSession(data); cache.put(\"1234\", session); assertTrue(cache.contains(\"1234\")); cache.renewSessionId(\"1234\", \"5678\", \"1234.foo\", \"5678.foo\"); assertTrue(cache.contains(\"5678\")); assertFalse(cache.contains(\"1234\")); assertTrue(store.exists(\"5678\")); assertFalse(store.exists(\"1234\")); } ",
        "focal_src": "@Override public Session renewSessionId(String oldId, String newId)throws Exception { if(StringUtil.isBlank(oldId))throw new IllegalArgumentException(\"Old session id is null\"); if(StringUtil.isBlank(newId))throw new IllegalArgumentException(\"New session id is null\"); Session session = get(oldId); if(session == null)return null; try(Lock lock = session.lock()) { session.checkValidForWrite(); session.getSessionData().setId(newId); session.getSessionData().setLastSaved(0); session.getSessionData().setDirty(true); doPutIfAbsent(newId, session); doDelete(oldId); if(_sessionDataStore != null) { _sessionDataStore.delete(oldId); _sessionDataStore.store(newId, session.getSessionData()); } if(LOG.isDebugEnabled())LOG.debug(\"Session id {} swapped for new id {}\", oldId, newId); return session; } } ",
        "focal_tgt": "protected void renewSessionId(Session session, String newId, String newExtendedId)throws Exception { if(session == null)return; try(Lock lock = session.lock()) { String oldId = session.getId(); session.checkValidForWrite(); session.getSessionData().setId(newId); session.getSessionData().setLastSaved(0); session.getSessionData().setDirty(true); session.setExtendedId(newExtendedId); session.setIdChanged(true); doPutIfAbsent(newId, session); doDelete(oldId); if(_sessionDataStore != null) { _sessionDataStore.delete(oldId); _sessionDataStore.store(newId, session.getSessionData()); } if(LOG.isDebugEnabled())LOG.debug(\"Session id {} swapped for new id {}\", oldId, newId); } } "
    },
    {
        "test_src": "@Test public void testAddMissingPartition()throws MetadataServiceException, URISyntaxException { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/mydb/clicks/?datastamp=12&region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServerEndPoint() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); assertEquals(missingPartitions.getPartitionsMap().keySet().iterator().next(), new PartitionWrapper(hcatUri)); WaitingActions actions = missingPartitions.getPartitionsMap().get(new PartitionWrapper(hcatUri)); assertNotNull(actions); assertTrue(actions.getActions().contains(actionId)); } ",
        "test_tgt": "@Test public void testAddMissingPartition()throws MetadataServiceException, URISyntaxException { Services services = Services.get(); PartitionDependencyManagerService pdms = services.get(PartitionDependencyManagerService.class); String newHCatDependency = \"hcat://hcat.yahoo.com:5080/database/mydb/table/clicks/partition/datastamp=12,region=us\"; String actionId = \"myAction\"; pdms.addMissingPartition(newHCatDependency, actionId); HCatURI hcatUri = new HCatURI(newHCatDependency); Map < String, PartitionsGroup > tablePartitionsMap = pdms.getHCatMap().get(hcatUri.getServerEndPoint() + \"#\" + hcatUri.getDb()); assertNotNull(tablePartitionsMap); assertTrue(tablePartitionsMap.containsKey(\"clicks\")); PartitionsGroup missingPartitions = tablePartitionsMap.get(hcatUri.getTable()); assertNotNull(missingPartitions); assertEquals(missingPartitions.getPartitionsMap().keySet().iterator().next(), new PartitionWrapper(hcatUri)); WaitingActions actions = missingPartitions.getPartitionsMap().get(new PartitionWrapper(hcatUri)); assertNotNull(actions); assertTrue(actions.getActions().contains(actionId)); } ",
        "focal_src": "public void addMissingPartition(PartitionWrapper partition, String actionId)throws MetadataServiceException { String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); Map < String, PartitionsGroup > tablePartitionsMap; String tableName = partition.getTableName(); try { if(hcatInstanceMap.containsKey(prefix)) { tablePartitionsMap = hcatInstanceMap.get(prefix); if(tablePartitionsMap.containsKey(tableName)) { addPartitionEntry(tablePartitionsMap, tableName, partition, actionId); } else { tablePartitionsMap = new ConcurrentHashMap < String, PartitionsGroup > (); _createPartitionMapForTable(tablePartitionsMap, tableName, partition, actionId); } } else { _addNewEntry(hcatInstanceMap, prefix, tableName, partition, actionId); } _registerMessageReceiver(_getTopic(partition)); } catch(ClassCastException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(NullPointerException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(IllegalArgumentException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(Exception e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } } ",
        "focal_tgt": "public void addMissingPartition(PartitionWrapper partition, String actionId)throws MetadataServiceException { String prefix = PartitionWrapper.makePrefix(partition.getServerName(), partition.getDbName()); Map < String, PartitionsGroup > tablePartitionsMap; String tableName = partition.getTableName(); try { if(hcatInstanceMap.containsKey(prefix)) { tablePartitionsMap = hcatInstanceMap.get(prefix); if(tablePartitionsMap.containsKey(tableName)) { addPartitionEntry(tablePartitionsMap, tableName, partition, actionId); } else { tablePartitionsMap = new ConcurrentHashMap < String, PartitionsGroup > (); _createPartitionMapForTable(tablePartitionsMap, tableName, partition, actionId); } } else { _addNewEntry(hcatInstanceMap, prefix, tableName, partition, actionId); } _registerMessageReceiver(partition); } catch(ClassCastException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(NullPointerException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(IllegalArgumentException e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } catch(Exception e) { throw new MetadataServiceException(ErrorCode.E1501, e.getCause()); } } "
    },
    {
        "test_src": "@Test public void testUpdateStream()throws ExecutionException, InterruptedException { String resourceURI = getURI() + \"v1/scopes/\" + scope1 + \"/streams/\" + stream1; when(mockControllerService.updateStream(any())).thenReturn(updateStreamStatus); Response response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 200, response.getStatus()); StreamProperty streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 200, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); when(mockControllerService.updateStream(any())).thenReturn(updateStreamStatus2); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest2)).invoke(); assertEquals(\"Update Stream Status\", 404, response.getStatus()); response.close(); when(mockControllerService.updateStream(any())).thenReturn(updateStreamStatus3); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest3)).invoke(); assertEquals(\"Update Stream Status\", 500, response.getStatus()); response.close(); when(mockControllerService.updateStream(any())).thenReturn(updateStreamStatus4); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 404, response.getStatus()); response.close(); } ",
        "test_tgt": "@Test public void testUpdateStream()throws ExecutionException, InterruptedException { String resourceURI = getURI() + \"v1/scopes/\" + scope1 + \"/streams/\" + stream1; when(mockControllerService.updateStream(any(), any(), any())).thenReturn(updateStreamStatus); Response response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 200, response.getStatus()); StreamProperty streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(createStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 200, response.getStatus()); streamResponseActual = response.readEntity(StreamProperty.class); testExpectedVsActualObject(streamResponseExpected, streamResponseActual); response.close(); when(mockControllerService.updateStream(any(), any(), any())).thenReturn(updateStreamStatus2); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest2)).invoke(); assertEquals(\"Update Stream Status\", 404, response.getStatus()); response.close(); when(mockControllerService.updateStream(any(), any(), any())).thenReturn(updateStreamStatus3); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest3)).invoke(); assertEquals(\"Update Stream Status\", 500, response.getStatus()); response.close(); when(mockControllerService.updateStream(any(), any(), any())).thenReturn(updateStreamStatus4); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(updateStreamRequest)).invoke(); assertEquals(\"Update Stream Status\", 404, response.getStatus()); response.close(); } ",
        "focal_src": "@Override public void updateStream(final String scopeName, final String streamName, final UpdateStreamRequest updateStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"updateStream\"); try { authenticateAuthorize(scopeName + \"/\" + streamName, READ_UPDATE); } catch(AuthException e) { log.warn(\"Update stream for {} failed due to authentication failure.\", scopeName + \"/\" + streamName); asyncResponse.resume(Response.status(Status.fromStatusCode(e.getResponseCode())).build()); LoggerHelpers.traceLeave(log, \"Update stream\", traceId); return; } StreamConfiguration streamConfiguration = ModelHelper.getUpdateStreamConfig(updateStreamRequest, scopeName, streamName); controllerService.updateStream(streamConfiguration).thenApply(streamStatus -> { if(streamStatus.getStatus() == UpdateStreamStatus.Status.SUCCESS) { log.info(\"Successfully updated stream config for: {}/{}\", scopeName, streamName); return Response.status(Status.OK).entity(ModelHelper.encodeStreamResponse(streamConfiguration)).build(); } else if(streamStatus.getStatus() == UpdateStreamStatus.Status.STREAM_NOT_FOUND || streamStatus.getStatus() == UpdateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Stream: {}/{} not found\", scopeName, streamName); return Response.status(Status.NOT_FOUND).build(); } else { log.warn(\"updateStream failed for {}/{}\", scopeName, streamName); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); } }).exceptionally(exception -> { log.warn(\"updateStream for {}/{} failed with exception: {}\", scopeName, streamName, exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"updateStream\", traceId)); } ",
        "focal_tgt": "@Override public void updateStream(final String scopeName, final String streamName, final UpdateStreamRequest updateStreamRequest, final SecurityContext securityContext, final AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"updateStream\"); try { authenticateAuthorize(scopeName + \"/\" + streamName, READ_UPDATE); } catch(AuthException e) { log.warn(\"Update stream for {} failed due to authentication failure.\", scopeName + \"/\" + streamName); asyncResponse.resume(Response.status(Status.fromStatusCode(e.getResponseCode())).build()); LoggerHelpers.traceLeave(log, \"Update stream\", traceId); return; } StreamConfiguration streamConfiguration = ModelHelper.getUpdateStreamConfig(updateStreamRequest); controllerService.updateStream(scopeName, streamName, streamConfiguration).thenApply(streamStatus -> { if(streamStatus.getStatus() == UpdateStreamStatus.Status.SUCCESS) { log.info(\"Successfully updated stream config for: {}/{}\", scopeName, streamName); return Response.status(Status.OK).entity(ModelHelper.encodeStreamResponse(scopeName, streamName, streamConfiguration)).build(); } else if(streamStatus.getStatus() == UpdateStreamStatus.Status.STREAM_NOT_FOUND || streamStatus.getStatus() == UpdateStreamStatus.Status.SCOPE_NOT_FOUND) { log.warn(\"Stream: {}/{} not found\", scopeName, streamName); return Response.status(Status.NOT_FOUND).build(); } else { log.warn(\"updateStream failed for {}/{}\", scopeName, streamName); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); } }).exceptionally(exception -> { log.warn(\"updateStream for {}/{} failed with exception: {}\", scopeName, streamName, exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"updateStream\", traceId)); } "
    },
    {
        "test_src": "@Test public void testReplace()throws QueryException, BaseXException { final String fun = check(Function.REPLACEDOC); new Add(\"etc/test/input.xml\", null, \"test\").execute(CONTEXT); query(fun + \"('db/test/input.xml', document { <root/> })\"); query(\"count(collection('db/test/input.xml')/html) eq 0\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 1\", \"true\"); query(fun + \"('db/test/input.xml', 'etc/test/input.xml')\"); query(\"count(collection('db/test/input.xml')/html) eq 1\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 0\", \"true\"); } ",
        "test_tgt": "@Test public void testReplace()throws QueryException, BaseXException { final String fun = check(Function.DBREPLACE); new Add(\"etc/test/input.xml\", null, \"test\").execute(CONTEXT); query(fun + \"('db', 'test/input.xml', document { <root/> })\"); query(\"count(collection('db/test/input.xml')/html) eq 0\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 1\", \"true\"); query(fun + \"('db', 'test/input.xml', 'etc/test/input.xml')\"); query(\"count(collection('db/test/input.xml')/html) eq 1\", \"true\"); query(\"count(collection('db/test/input.xml')/root) eq 0\", \"true\"); } ",
        "focal_src": "private Item replace(final QueryContext ctx)throws QueryException { checkWrite(ctx); final String path = path(string(checkStr(expr[0], ctx))); final int pos = path.indexOf('/'); if(pos <= 0)NODB.thrw(input, path); final byte[]db = token(path.substring(0, pos)); final Data data = ctx.resource.data(db, input); final String src = path.substring(pos + 1); final byte[]trg = token(src); final Item doc = checkItem(expr[1], ctx); final int[]old = data.doc(src); if(old.length > 0) { final int pre = old[0]; if(old.length > 1 || ! eq(data.text(pre, true), trg))DOCTRGMULT.thrw(input); ctx.updates.add(new DeleteNode(pre, data, input), ctx); } final byte[]trgname; final byte[]trgpath; final int p = lastIndexOf(trg, '/'); if(p < 0) { trgname = trg; trgpath = null; } else { trgname = subtoken(trg, p + 1); trgpath = subtoken(trg, 0, p); } final ArrayList < Item > docs = new ArrayList < Item > (); docs.add(doc); final Add add = new Add(data, input, docs, trgname, trgpath, ctx.context); ctx.updates.add(add, ctx); return null; } ",
        "focal_tgt": "private Item replace(final QueryContext ctx)throws QueryException { checkWrite(ctx); final Data data = data(0, ctx); final byte[]trg = path(checkStr(expr[1], ctx)); final Item doc = checkItem(expr[2], ctx); final int[]old = data.doc(string(trg)); if(old.length > 0) { final int pre = old[0]; if(old.length > 1 || ! eq(data.text(pre, true), trg))DOCTRGMULT.thrw(input); ctx.updates.add(new DeleteNode(pre, data, input), ctx); } final byte[]trgname; final byte[]trgpath; final int p = lastIndexOf(trg, '/'); if(p < 0) { trgname = trg; trgpath = null; } else { trgname = subtoken(trg, p + 1); trgpath = subtoken(trg, 0, p); } final ArrayList < Item > docs = new ArrayList < Item > (1); docs.add(doc); final Add add = new Add(data, input, docs, trgname, trgpath, ctx.context); ctx.updates.add(add, ctx); return null; } "
    },
    {
        "test_src": "@Test public void testFreeSlot()throws Exception { final ResourceManagerId resourceManagerId = ResourceManagerId.generate(); final ResourceID resourceID = ResourceID.generate(); final JobID jobId = new JobID(); final SlotID slotId = new SlotID(resourceID, 0); final AllocationID allocationId = new AllocationID(); final ResourceProfile resourceProfile = new ResourceProfile(42.0, 1337); ResourceManagerActions resourceManagerActions = mock(ResourceManagerActions.class); final TaskExecutorGateway taskExecutorGateway = mock(TaskExecutorGateway.class); final TaskExecutorConnection taskExecutorConnection = new TaskExecutorConnection(taskExecutorGateway); final SlotStatus slotStatus = new SlotStatus(slotId, resourceProfile, jobId, allocationId); final SlotReport slotReport = new SlotReport(slotStatus); try(SlotManager slotManager = createSlotManager(resourceManagerId, resourceManagerActions)) { slotManager.registerTaskManager(taskExecutorConnection, slotReport); TaskManagerSlot slot = slotManager.getSlot(slotId); assertEquals(\"The slot has not been allocated to the expected allocation id.\", allocationId, slot.getAllocationId()); slotManager.freeSlot(slotId, new AllocationID()); assertTrue(slot.isAllocated()); assertEquals(\"The slot has not been allocated to the expected allocation id.\", allocationId, slot.getAllocationId()); slotManager.freeSlot(slotId, allocationId); assertTrue(slot.isFree()); assertNull(slot.getAllocationId()); } } ",
        "test_tgt": "@Test public void testFreeSlot()throws Exception { final ResourceManagerId resourceManagerId = ResourceManagerId.generate(); final ResourceID resourceID = ResourceID.generate(); final JobID jobId = new JobID(); final SlotID slotId = new SlotID(resourceID, 0); final AllocationID allocationId = new AllocationID(); final ResourceProfile resourceProfile = new ResourceProfile(42.0, 1337); ResourceManagerActions resourceManagerActions = mock(ResourceManagerActions.class); final TaskExecutorGateway taskExecutorGateway = mock(TaskExecutorGateway.class); final TaskExecutorConnection taskExecutorConnection = new TaskExecutorConnection(taskExecutorGateway); final SlotStatus slotStatus = new SlotStatus(slotId, resourceProfile, jobId, allocationId); final SlotReport slotReport = new SlotReport(slotStatus); try(SlotManager slotManager = createSlotManager(resourceManagerId, resourceManagerActions)) { slotManager.registerTaskManager(taskExecutorConnection, slotReport); TaskManagerSlot slot = slotManager.getSlot(slotId); assertEquals(\"The slot has not been allocated to the expected allocation id.\", allocationId, slot.getAllocationId()); slotManager.freeSlot(slotId, new AllocationID()); assertTrue(slot.getState() == TaskManagerSlot.State.ALLOCATED); assertEquals(\"The slot has not been allocated to the expected allocation id.\", allocationId, slot.getAllocationId()); slotManager.freeSlot(slotId, allocationId); assertTrue(slot.getState() == TaskManagerSlot.State.FREE); assertNull(slot.getAllocationId()); } } ",
        "focal_src": "public void freeSlot(SlotID slotId, AllocationID allocationId) { checkInit(); TaskManagerSlot slot = slots.get(slotId); if(null != slot) { if(slot.isAllocated()) { if(Objects.equals(allocationId, slot.getAllocationId())) { slot.setAllocationId(null); fulfilledSlotRequests.remove(allocationId); if(slot.isFree()) { handleFreeSlot(slot); } TaskManagerRegistration taskManagerRegistration = taskManagerRegistrations.get(slot.getInstanceId()); if(null != taskManagerRegistration) { if(anySlotUsed(taskManagerRegistration.getSlots())) { taskManagerRegistration.markUsed(); } else { taskManagerRegistration.markIdle(); } } } else { LOG.debug(\"Received request to free slot {} with expected allocation id {}, \" + \"but actual allocation id {} differs. Ignoring the request.\", slotId, allocationId, slot.getAllocationId()); } } else { LOG.debug(\"Slot {} has not been allocated.\", allocationId); } } else { LOG.debug(\"Trying to free a slot {} which has not been registered. Ignoring this message.\", slotId); } } ",
        "focal_tgt": "public void freeSlot(SlotID slotId, AllocationID allocationId) { checkInit(); TaskManagerSlot slot = slots.get(slotId); if(null != slot) { if(slot.getState() == TaskManagerSlot.State.ALLOCATED) { if(Objects.equals(allocationId, slot.getAllocationId())) { TaskManagerRegistration taskManagerRegistration = taskManagerRegistrations.get(slot.getInstanceId()); if(taskManagerRegistration == null) { throw new IllegalStateException(\"Trying to free a slot from a TaskManager \" + slot.getInstanceId() + \" which has not been registered.\"); } updateSlotState(slot, taskManagerRegistration, null); } else { LOG.debug(\"Received request to free slot {} with expected allocation id {}, \" + \"but actual allocation id {} differs. Ignoring the request.\", slotId, allocationId, slot.getAllocationId()); } } else { LOG.debug(\"Slot {} has not been allocated.\", allocationId); } } else { LOG.debug(\"Trying to free a slot {} which has not been registered. Ignoring this message.\", slotId); } } "
    },
    {
        "test_src": "@Test public void testClearStorage()throws Exception { GraphOfTheGodsFactory.load(graph); tearDown(); config.set(ConfigElement.getPath(GraphDatabaseConfiguration.DROP_ON_CLEAR), true); final Backend backend = getBackend(config, false); assertStorageExists(backend, true); clearGraph(config); try { backend.close(); } catch(Exception e) { } try(final Backend newBackend = getBackend(config, false)) { assertStorageExists(newBackend, false); } } ",
        "test_tgt": "@Test public void testClearStorage()throws Exception { GraphOfTheGodsFactory.load(graph); tearDown(); config.set(ConfigElement.getPath(GraphDatabaseConfiguration.DROP_ON_CLEAR), true); final Backend backend = getBackend(config, false); assertStorageExists(backend, true); clearGraph(config); try { backend.close(); } catch(Exception e) { } try(final Backend newBackend = getBackend(config, false)) { assertStorageExists(newBackend, false); } } ",
        "focal_src": "public void clearStorage()throws BackendException { openStores.clear(); final String lp = \"ClearStorage: \"; CTConnection conn = null; try { conn = pool.borrowObject(SYSTEM_KS); Cassandra.Client client = conn.getClient(); KsDef ksDef; try { client.set_keyspace(keySpaceName); ksDef = client.describe_keyspace(keySpaceName); } catch(NotFoundException e) { log.debug(lp + \"Keyspace {} does not exist, not attempting to truncate.\", keySpaceName); return; } catch(InvalidRequestException e) { log.debug(lp + \"InvalidRequestException when attempting to describe keyspace {}, not attempting to truncate.\", keySpaceName); return; } if(null == ksDef) { log.debug(lp + \"Received null KsDef for keyspace {}; not truncating its CFs\", keySpaceName); return; } if(this.storageConfig.get(GraphDatabaseConfiguration.DROP_ON_CLEAR)) { client.system_drop_keyspace(keySpaceName); pool.clear(); } else { final List < CfDef > cfDefs = ksDef.getCf_defs(); if(null == cfDefs) { log.debug(lp + \"Received empty CfDef list for keyspace {}; not truncating CFs\", keySpaceName); return; } for(final CfDef cfDef : ksDef.getCf_defs()) { client.truncate(cfDef.name); log.info(lp + \"Truncated CF {} in keyspace {}\", cfDef.name, keySpaceName); } } } catch(Exception e) { throw new TemporaryBackendException(e); } finally { if(conn != null && conn.getClient() != null) { try { conn.getClient().set_keyspace(SYSTEM_KS); } catch(InvalidRequestException e) { log.warn(\"Failed to reset keyspace\", e); } catch(TException e) { log.warn(\"Failed to reset keyspace\", e); } } pool.returnObjectUnsafe(SYSTEM_KS, conn); } } ",
        "focal_tgt": "public void clearStorage()throws BackendException { openStores.clear(); final String lp = \"ClearStorage: \"; CTConnection conn = null; try { conn = pool.borrowObject(SYSTEM_KS); Cassandra.Client client = conn.getClient(); KsDef ksDef; try { client.set_keyspace(keySpaceName); ksDef = client.describe_keyspace(keySpaceName); } catch(NotFoundException e) { log.debug(lp + \"Keyspace {} does not exist, not attempting to truncate.\", keySpaceName); return; } catch(InvalidRequestException e) { log.debug(lp + \"InvalidRequestException when attempting to describe keyspace {}, not attempting to truncate.\", keySpaceName); return; } if(null == ksDef) { log.debug(lp + \"Received null KsDef for keyspace {}; not truncating its CFs\", keySpaceName); return; } if(this.storageConfig.get(GraphDatabaseConfiguration.DROP_ON_CLEAR)) { client.system_drop_keyspace(keySpaceName); pool.clear(); } else { final List < CfDef > columnFamilyDefinitions = ksDef.getCf_defs(); if(null == columnFamilyDefinitions) { log.debug(lp + \"Received empty CfDef list for keyspace {}; not truncating CFs\", keySpaceName); return; } for(final CfDef cfDef : ksDef.getCf_defs()) { client.truncate(cfDef.name); log.info(lp + \"Truncated CF {} in keyspace {}\", cfDef.name, keySpaceName); } } } catch(Exception e) { throw new TemporaryBackendException(e); } finally { if(conn != null && conn.getClient() != null) { try { conn.getClient().set_keyspace(SYSTEM_KS); } catch(InvalidRequestException e) { log.warn(\"Failed to reset keyspace\", e); } catch(TException e) { log.warn(\"Failed to reset keyspace\", e); } } pool.returnObjectUnsafe(SYSTEM_KS, conn); } } "
    },
    {
        "test_src": "@Test public void testCacheConfiguration()throws Exception { try(Ignite ignored = Ignition.start(Config.getServerConfiguration()); IgniteClient client = Ignition.startClient(getClientConfiguration())) { final String CACHE_NAME = \"testCacheConfiguration\"; ClientCacheConfiguration cacheCfg = new ClientCacheConfiguration().setName(CACHE_NAME).setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL).setBackups(3).setCacheMode(CacheMode.PARTITIONED).setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC).setEagerTtl(false).setGroupName(\"FunctionalTest\").setDefaultLockTimeout(12345).setPartitionLossPolicy(PartitionLossPolicy.READ_WRITE_ALL).setReadFromBackup(true).setRebalanceBatchSize(67890).setRebalanceBatchesPrefetchCount(102938).setRebalanceDelay(54321).setRebalanceMode(CacheRebalanceMode.SYNC).setRebalanceOrder(2).setRebalanceThrottle(564738).setRebalanceTimeout(142536).setKeyConfiguration(new CacheKeyConfiguration(\"Employee\", \"orgId\")).setQueryEntities(new QueryEntity(int.class.getName(), \"Employee\").setTableName(\"EMPLOYEE\").setFields(Stream.of(new SimpleEntry < > (\"id\", Integer.class.getName()), new SimpleEntry < > (\"orgId\", Integer.class.getName())).collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue, (a, b) -> a, LinkedHashMap :: new))).setKeyFields(Collections.emptySet()).setKeyFieldName(\"id\").setNotNullFields(Collections.singleton(\"id\")).setDefaultFieldValues(Collections.singletonMap(\"id\", 0)).setIndexes(Collections.singletonList(new QueryIndex(\"id\", true, \"IDX_EMPLOYEE_ID\"))).setAliases(Stream.of(\"id\", \"orgId\").collect(Collectors.toMap(f -> f, String :: toUpperCase)))); ClientCache cache = client.createCache(cacheCfg); assertEquals(CACHE_NAME, cache.getName()); assertTrue(Comparers.equal(cacheCfg, cache.getConfiguration())); } } ",
        "test_tgt": "@Test public void testCacheConfiguration()throws Exception { try(Ignite ignored = Ignition.start(Config.getServerConfiguration()); IgniteClient client = Ignition.startClient(getClientConfiguration())) { final String CACHE_NAME = \"testCacheConfiguration\"; ClientCacheConfiguration cacheCfg = new ClientCacheConfiguration().setName(CACHE_NAME).setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL).setBackups(3).setCacheMode(CacheMode.PARTITIONED).setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC).setEagerTtl(false).setGroupName(\"FunctionalTest\").setDefaultLockTimeout(12345).setPartitionLossPolicy(PartitionLossPolicy.READ_WRITE_ALL).setReadFromBackup(true).setRebalanceBatchSize(67890).setRebalanceBatchesPrefetchCount(102938).setRebalanceDelay(54321).setRebalanceMode(CacheRebalanceMode.SYNC).setRebalanceOrder(2).setRebalanceThrottle(564738).setRebalanceTimeout(142536).setKeyConfiguration(new CacheKeyConfiguration(\"Employee\", \"orgId\")).setQueryEntities(new QueryEntity(int.class.getName(), \"Employee\").setTableName(\"EMPLOYEE\").setFields(Stream.of(new SimpleEntry < > (\"id\", Integer.class.getName()), new SimpleEntry < > (\"orgId\", Integer.class.getName())).collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue, (a, b) -> a, LinkedHashMap :: new))).setKeyFields(Collections.emptySet()).setKeyFieldName(\"id\").setNotNullFields(Collections.singleton(\"id\")).setDefaultFieldValues(Collections.singletonMap(\"id\", 0)).setIndexes(Collections.singletonList(new QueryIndex(\"id\", true, \"IDX_EMPLOYEE_ID\"))).setAliases(Stream.of(\"id\", \"orgId\").collect(Collectors.toMap(f -> f, String :: toUpperCase)))).setExpiryPolicy(new PlatformExpiryPolicy(10, 20, 30)); ClientCache cache = client.createCache(cacheCfg); assertEquals(CACHE_NAME, cache.getName()); assertTrue(Comparers.equal(cacheCfg, cache.getConfiguration())); } } ",
        "focal_src": "ClientCacheConfiguration cacheConfiguration(BinaryInputStream in, ProtocolVersion ver)throws IOException { try(BinaryReaderExImpl reader = new BinaryReaderExImpl(marsh.context(), in, null, true)) { reader.readInt(); return new ClientCacheConfiguration().setName(\"TBD\").setAtomicityMode(CacheAtomicityMode.fromOrdinal(reader.readInt())).setBackups(reader.readInt()).setCacheMode(CacheMode.fromOrdinal(reader.readInt())).setCopyOnRead(reader.readBoolean()).setDataRegionName(reader.readString()).setEagerTtl(reader.readBoolean()).setStatisticsEnabled(reader.readBoolean()).setGroupName(reader.readString()).setDefaultLockTimeout(reader.readLong()).setMaxConcurrentAsyncOperations(reader.readInt()).setMaxQueryIteratorsCount(reader.readInt()).setName(reader.readString()).setOnheapCacheEnabled(reader.readBoolean()).setPartitionLossPolicy(PartitionLossPolicy.fromOrdinal((byte)reader.readInt())).setQueryDetailMetricsSize(reader.readInt()).setQueryParallelism(reader.readInt()).setReadFromBackup(reader.readBoolean()).setRebalanceBatchSize(reader.readInt()).setRebalanceBatchesPrefetchCount(reader.readLong()).setRebalanceDelay(reader.readLong()).setRebalanceMode(CacheRebalanceMode.fromOrdinal(reader.readInt())).setRebalanceOrder(reader.readInt()).setRebalanceThrottle(reader.readLong()).setRebalanceTimeout(reader.readLong()).setSqlEscapeAll(reader.readBoolean()).setSqlIndexMaxInlineSize(reader.readInt()).setSqlSchema(reader.readString()).setWriteSynchronizationMode(CacheWriteSynchronizationMode.fromOrdinal(reader.readInt())).setKeyConfiguration(ClientUtils.collection(in, unused -> new CacheKeyConfiguration(reader.readString(), reader.readString())).toArray(new CacheKeyConfiguration[0])).setQueryEntities(ClientUtils.collection(in, unused -> { QueryEntity qryEntity = new QueryEntity(reader.readString(), reader.readString()).setTableName(reader.readString()).setKeyFieldName(reader.readString()).setValueFieldName(reader.readString()); boolean isCliVer1_2 = ver.compareTo(V1_2_0) >= 0; Collection < QueryField > qryFields = ClientUtils.collection(in, unused2 -> { String name = reader.readString(); String typeName = reader.readString(); boolean isKey = reader.readBoolean(); boolean isNotNull = reader.readBoolean(); Object dfltVal = reader.readObject(); int precision = isCliVer1_2 ? reader.readInt() : - 1; int scale = isCliVer1_2 ? reader.readInt() : - 1; return new QueryField(name, typeName, isKey, isNotNull, dfltVal, precision, scale); }); return qryEntity.setFields(qryFields.stream().collect(Collectors.toMap(QueryField :: getName, QueryField :: getTypeName, (a, b) -> a, LinkedHashMap :: new))).setKeyFields(qryFields.stream().filter(QueryField :: isKey).map(QueryField :: getName).collect(Collectors.toCollection(LinkedHashSet :: new))).setNotNullFields(qryFields.stream().filter(QueryField :: isNotNull).map(QueryField :: getName).collect(Collectors.toSet())).setDefaultFieldValues(qryFields.stream().filter(f -> f.getDefaultValue() != null).collect(Collectors.toMap(QueryField :: getName, QueryField :: getDefaultValue))).setFieldsPrecision(qryFields.stream().filter(f -> f.getPrecision() != - 1).collect(Collectors.toMap(QueryField :: getName, QueryField :: getPrecision))).setFieldsScale(qryFields.stream().filter(f -> f.getScale() != - 1).collect(Collectors.toMap(QueryField :: getName, QueryField :: getScale))).setAliases(ClientUtils.collection(in, unused3 -> new SimpleEntry < > (reader.readString(), reader.readString())).stream().collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue))).setIndexes(ClientUtils.collection(in, unused4 -> { String name = reader.readString(); QueryIndexType type = QueryIndexType.fromOrdinal(reader.readByte()); int inlineSize = reader.readInt(); LinkedHashMap < String, Boolean > fields = ClientUtils.collection(in, unused5 -> new SimpleEntry < > (reader.readString(), reader.readBoolean())).stream().collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue, (a, b) -> a, LinkedHashMap :: new)); return new QueryIndex(fields, type).setName(name).setInlineSize(inlineSize); })); }).toArray(new QueryEntity[0])); } } ",
        "focal_tgt": "ClientCacheConfiguration cacheConfiguration(BinaryInputStream in, ProtocolVersion ver)throws IOException { try(BinaryReaderExImpl reader = new BinaryReaderExImpl(marsh.context(), in, null, true)) { reader.readInt(); return new ClientCacheConfiguration().setName(\"TBD\").setAtomicityMode(CacheAtomicityMode.fromOrdinal(reader.readInt())).setBackups(reader.readInt()).setCacheMode(CacheMode.fromOrdinal(reader.readInt())).setCopyOnRead(reader.readBoolean()).setDataRegionName(reader.readString()).setEagerTtl(reader.readBoolean()).setStatisticsEnabled(reader.readBoolean()).setGroupName(reader.readString()).setDefaultLockTimeout(reader.readLong()).setMaxConcurrentAsyncOperations(reader.readInt()).setMaxQueryIteratorsCount(reader.readInt()).setName(reader.readString()).setOnheapCacheEnabled(reader.readBoolean()).setPartitionLossPolicy(PartitionLossPolicy.fromOrdinal((byte)reader.readInt())).setQueryDetailMetricsSize(reader.readInt()).setQueryParallelism(reader.readInt()).setReadFromBackup(reader.readBoolean()).setRebalanceBatchSize(reader.readInt()).setRebalanceBatchesPrefetchCount(reader.readLong()).setRebalanceDelay(reader.readLong()).setRebalanceMode(CacheRebalanceMode.fromOrdinal(reader.readInt())).setRebalanceOrder(reader.readInt()).setRebalanceThrottle(reader.readLong()).setRebalanceTimeout(reader.readLong()).setSqlEscapeAll(reader.readBoolean()).setSqlIndexMaxInlineSize(reader.readInt()).setSqlSchema(reader.readString()).setWriteSynchronizationMode(CacheWriteSynchronizationMode.fromOrdinal(reader.readInt())).setKeyConfiguration(ClientUtils.collection(in, unused -> new CacheKeyConfiguration(reader.readString(), reader.readString())).toArray(new CacheKeyConfiguration[0])).setQueryEntities(ClientUtils.collection(in, unused -> { QueryEntity qryEntity = new QueryEntity(reader.readString(), reader.readString()).setTableName(reader.readString()).setKeyFieldName(reader.readString()).setValueFieldName(reader.readString()); boolean isCliVer1_2 = ver.compareTo(V1_2_0) >= 0; Collection < QueryField > qryFields = ClientUtils.collection(in, unused2 -> { String name = reader.readString(); String typeName = reader.readString(); boolean isKey = reader.readBoolean(); boolean isNotNull = reader.readBoolean(); Object dfltVal = reader.readObject(); int precision = isCliVer1_2 ? reader.readInt() : - 1; int scale = isCliVer1_2 ? reader.readInt() : - 1; return new QueryField(name, typeName, isKey, isNotNull, dfltVal, precision, scale); }); return qryEntity.setFields(qryFields.stream().collect(Collectors.toMap(QueryField :: getName, QueryField :: getTypeName, (a, b) -> a, LinkedHashMap :: new))).setKeyFields(qryFields.stream().filter(QueryField :: isKey).map(QueryField :: getName).collect(Collectors.toCollection(LinkedHashSet :: new))).setNotNullFields(qryFields.stream().filter(QueryField :: isNotNull).map(QueryField :: getName).collect(Collectors.toSet())).setDefaultFieldValues(qryFields.stream().filter(f -> f.getDefaultValue() != null).collect(Collectors.toMap(QueryField :: getName, QueryField :: getDefaultValue))).setFieldsPrecision(qryFields.stream().filter(f -> f.getPrecision() != - 1).collect(Collectors.toMap(QueryField :: getName, QueryField :: getPrecision))).setFieldsScale(qryFields.stream().filter(f -> f.getScale() != - 1).collect(Collectors.toMap(QueryField :: getName, QueryField :: getScale))).setAliases(ClientUtils.collection(in, unused3 -> new SimpleEntry < > (reader.readString(), reader.readString())).stream().collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue))).setIndexes(ClientUtils.collection(in, unused4 -> { String name = reader.readString(); QueryIndexType type = QueryIndexType.fromOrdinal(reader.readByte()); int inlineSize = reader.readInt(); LinkedHashMap < String, Boolean > fields = ClientUtils.collection(in, unused5 -> new SimpleEntry < > (reader.readString(), reader.readBoolean())).stream().collect(Collectors.toMap(SimpleEntry :: getKey, SimpleEntry :: getValue, (a, b) -> a, LinkedHashMap :: new)); return new QueryIndex(fields, type).setName(name).setInlineSize(inlineSize); })); }).toArray(new QueryEntity[0])).setExpiryPolicy(ver.compareTo(V1_6_0) < 0 ? null : reader.readBoolean() ? new PlatformExpiryPolicy(reader.readLong(), reader.readLong(), reader.readLong()) : null); } } "
    },
    {
        "test_src": "@Test public void testGetS3SiteXmlsAsCsv() { cc.setS3CoreSiteXml(\"core\"); cc.setS3MapredSiteXml(\"mapred\"); cc.setS3HdfsSiteXml(\"hdfs\"); Assert.assertEquals(cc.getS3SiteXmlsAsCsv(), \"core,mapred,hdfs\"); } ",
        "test_tgt": "@Test public void testGetS3SiteXmlsAsCsv() { cc.setS3CoreSiteXml(\"core\"); cc.setS3MapredSiteXml(\"mapred\"); cc.setS3HdfsSiteXml(\"hdfs\"); cc.setS3YarnSiteXml(\"yarn\"); Assert.assertEquals(cc.getS3SiteXmlsAsCsv(), \"core,mapred,hdfs,yarn\"); } ",
        "focal_src": "public String getS3SiteXmlsAsCsv() { logger.debug(\"called\"); StringBuilder csv = new StringBuilder(); if(s3CoreSiteXml != null) { csv.append(s3CoreSiteXml); } csv.append(\",\"); if(s3MapredSiteXml != null) { csv.append(s3MapredSiteXml); } csv.append(\",\"); if(s3HdfsSiteXml != null) { csv.append(s3HdfsSiteXml); } return csv.toString(); } ",
        "focal_tgt": "public String getS3SiteXmlsAsCsv() { logger.debug(\"called\"); StringBuilder csv = new StringBuilder(); if(s3CoreSiteXml != null) { csv.append(s3CoreSiteXml); } if(s3MapredSiteXml != null) { csv.append(\",\"); csv.append(s3MapredSiteXml); } if(s3HdfsSiteXml != null) { csv.append(\",\"); csv.append(s3HdfsSiteXml); } if(s3YarnSiteXml != null) { csv.append(\",\"); csv.append(s3YarnSiteXml); } return csv.toString(); } "
    },
    {
        "test_src": "@Test@Verifies(value = \"should remove membership from cohort\", method = \"removeMemberShipFromCohort(Cohort, CohortMembership)\")public void removeMembershipFromCohort_shouldRemoveMembershipFromCohort()throws Exception { executeDataSet(COHORT_XML); CohortMembership memberToAddThenRemove = new CohortMembership(new Patient(4)); service.addMembershipToCohort(service.getCohort(1), memberToAddThenRemove); assertTrue(service.getCohort(1).contains(memberToAddThenRemove.getPatient())); assertNull(memberToAddThenRemove.getEndDate()); service.removeMemberShipFromCohort(service.getCohort(1), memberToAddThenRemove); assertNotNull(memberToAddThenRemove.getEndDate()); } ",
        "test_tgt": "@Test public void removeMembershipFromCohort_shouldRemoveMembershipFromCohort()throws Exception { executeDataSet(COHORT_XML); CohortMembership memberToAddThenRemove = new CohortMembership(4); service.addMembershipToCohort(service.getCohort(1), memberToAddThenRemove); assertTrue(service.getCohort(1).contains(memberToAddThenRemove.getPatientId())); assertNull(memberToAddThenRemove.getEndDate()); service.removeMembershipFromCohort(service.getCohort(1), memberToAddThenRemove); assertNotNull(memberToAddThenRemove.getEndDate()); assertFalse(service.getCohort(1).contains(memberToAddThenRemove.getPatientId())); } ",
        "focal_src": "@Authorized( { PrivilegeConstants.EDIT_COHORTS })Cohort removeMemberShipFromCohort(Cohort cohort, CohortMembership cohortMembership); ",
        "focal_tgt": "@Authorized( { PrivilegeConstants.EDIT_COHORTS })Cohort removeMembershipFromCohort(Cohort cohort, CohortMembership cohortMembership); "
    },
    {
        "test_src": "@Test public void matchOpticalSignalTypeTest() { Criterion criterion = Criteria.matchOpticalSignalType((short)40000); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result.get(\"type\").textValue(), is(criterion.type().toString())); assertThat(result.get(\"signalType\").asInt(), is(40000)); } ",
        "test_tgt": "@Test public void matchOpticalSignalTypeTest() { Criterion criterion = Criteria.matchOpticalSignalType((byte)250); ObjectNode result = criterionCodec.encode(criterion, context); assertThat(result.get(\"type\").textValue(), is(criterion.type().toString())); assertThat(result.get(\"signalType\").asInt(), is(250)); } ",
        "focal_src": "public static Criterion matchOpticalSignalType(int sigType) { return new OpticalSignalTypeCriterion(sigType, Type.OCH_SIGTYPE); } ",
        "focal_tgt": "public static Criterion matchOpticalSignalType(short sigType) { return new OpticalSignalTypeCriterion(sigType, Type.OCH_SIGTYPE); } "
    },
    {
        "test_src": "@Test public void testSetJobStatus()throws GenieException { final String msg = UUID.randomUUID().toString(); this.service.setJobStatus(JOB_1_ID, JobStatus.RUNNING, msg); final Job job = this.service.getJob(JOB_1_ID); Assert.assertEquals(JobStatus.RUNNING, job.getStatus()); Assert.assertEquals(msg, job.getStatusMsg()); } ",
        "test_tgt": "@Test@Ignore public void testSetJobStatus()throws GenieException { } ",
        "focal_src": "@Override@Transactional(rollbackFor = { GenieException.class, ConstraintViolationException.class })public void setJobStatus(@NotBlank(message = \"No id entered for the job. Unable to update the status.\")final String id, @NotNull(message = \"No status entered unable to update.\")final JobStatus status, final String msg)throws GenieException { LOG.debug(\"Setting job with id \" + id + \" to status \" + status + \" for reason \" + msg); final Job job = this.jobRepo.findOne(id); if(job != null) { job.setJobStatus(status, msg); } else { throw new GenieNotFoundException(\"No job with id \" + id + \" exists\"); } } ",
        "focal_tgt": "@Override@Transactional(rollbackFor = { GenieException.class, ConstraintViolationException.class })public void setJobStatus(@NotBlank(message = \"No id entered for the job. Unable to update the status.\")final String id, @NotNull(message = \"No status entered unable to update.\")final JobStatus status, final String msg)throws GenieException { if(LOG.isDebugEnabled()) { LOG.debug(\"Setting job with id \" + id + \" to status \" + status + \" for reason \" + msg); } final Job job = this.jobRepo.findOne(id); if(job != null) { job.setJobStatus(status, msg); } else { throw new GenieNotFoundException(\"No job with id \" + id + \" exists\"); } } "
    },
    {
        "test_src": "@Test public void users()throws BaseXException { query(_ADMIN_USERS.args() + \"= 'admin'\", \"true\"); new CreateUser(NAME, md5(NAME)).execute(context); query(_ADMIN_USERS.args() + \"= '\" + NAME + '\\'', \"true\"); new Grant(Perm.READ, NAME, NAME).execute(context); query(_ADMIN_USERS.args(NAME) + \"= '\" + NAME + '\\'', \"true\"); new DropUser(NAME).execute(context); query(_ADMIN_USERS.args(NAME) + \"= '\" + NAME + '\\'', \"false\"); query(_ADMIN_USERS.args() + \"= '\" + NAME + '\\'', \"false\"); } ",
        "test_tgt": "@Test public void users()throws BaseXException { query(_ADMIN_USERS.args() + \"= 'admin'\", \"true\"); new CreateUser(NAME, NAME).execute(context); query(_ADMIN_USERS.args() + \"= '\" + NAME + '\\'', \"true\"); new Grant(Perm.READ, NAME, NAME).execute(context); query(_ADMIN_USERS.args(NAME) + \"= '\" + NAME + '\\'', \"true\"); new DropUser(NAME).execute(context); query(_ADMIN_USERS.args(NAME) + \"= '\" + NAME + '\\'', \"false\"); query(_ADMIN_USERS.args() + \"= '\" + NAME + '\\'', \"false\"); } ",
        "focal_src": "public synchronized User[]users(final Users users) { final ArrayList < User > al = new ArrayList < > (); for(final User user : list) { if(users == null || users.get(user.name) != null)al.add(user); } return al.toArray(new User[al.size()]); } ",
        "focal_tgt": "public synchronized User[]users(final Users users) { final ArrayList < User > al = new ArrayList < > (); for(final User user : list) { if(users == null || users.get(user.name()) != null)al.add(user); } return al.toArray(new User[al.size()]); } "
    },
    {
        "test_src": "@Test public void testSpatialRangeQuery()throws Exception { RectangleRDD rectangleRDD = new RectangleRDD(sc, InputLocation, offset, splitter); for(int i = 0; i < loopTimes; i ++ ) { long resultSize = RangeQuery.SpatialRangeQuery(rectangleRDD, queryEnvelope, 0).getRawRectangleRDD().count(); assert resultSize > - 1; } assert RangeQuery.SpatialRangeQuery(rectangleRDD, queryEnvelope, 0).getRawRectangleRDD().take(10).get(1).getUserData().toString() != null; } ",
        "test_tgt": "@Test public void testSpatialRangeQuery()throws Exception { RectangleRDD spatialRDD = new RectangleRDD(sc, InputLocation, offset, splitter); for(int i = 0; i < loopTimes; i ++ ) { long resultSize = RangeQuery.SpatialRangeQuery(spatialRDD, queryEnvelope, 0, false).count(); assert resultSize > - 1; } assert RangeQuery.SpatialRangeQuery(spatialRDD, queryEnvelope, 0, false).take(10).get(1).getUserData().toString() != null; } ",
        "focal_src": "public static PointRDD SpatialRangeQuery(PointRDD pointRDD, Envelope envelope, Integer condition) { JavaRDD < Point > result = pointRDD.getRawPointRDD().filter(new PointRangeFilter(envelope, condition)); return new PointRDD(result); } ",
        "focal_tgt": "public static JavaRDD < Point > SpatialRangeQuery(PointRDD spatialRDD, Envelope queryWindow, Integer condition, boolean useIndex)throws Exception { if(useIndex == true) { if(spatialRDD.indexedRawRDD == null) { throw new Exception(\"[RangeQuery][SpatialRangeQuery] Index doesn't exist. Please build index.\"); } JavaRDD < Object > result = spatialRDD.indexedRawRDD.mapPartitions(new RangeFilterUsingIndex(queryWindow)); return result.map(new Function < Object, Point > () { @Override public Point call(Object spatialObject)throws Exception { return(Point)spatialObject; } }); } else { JavaRDD < Object > result = spatialRDD.getRawSpatialRDD().filter(new GeometryRangeFilter(queryWindow, condition)); return result.map(new Function < Object, Point > () { @Override public Point call(Object spatialObject)throws Exception { return(Point)spatialObject; } }); } } "
    },
    {
        "test_src": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"equals\", args = { java.lang.Object.class })@KnownFailure(\"equals(Onject o) method throws java.lang.ClassCastException \" + \"for TreeMap objects with different key objects.\")public void test_equals()throws Exception { Map m1 = new TreeMap(); Map m2 = new TreeMap(); m1.put(\"key1\", \"val1\"); m1.put(\"key2\", \"val2\"); m2.put(new Integer(1), \"val1\"); m2.put(new Integer(2), \"val2\"); assertFalse(\"Maps should not be equal 1\", m1.equals(m2)); assertFalse(\"Maps should not be equal 2\", m2.equals(m1)); m1 = new TreeMap(); m2 = new HashMap(); m1.put(\"key\", \"val\"); m2.put(new Object(), \"val\"); assertFalse(\"Maps should not be equal 3\", m1.equals(m2)); assertFalse(\"Maps should not be equal 4\", m2.equals(m1)); m1 = new TreeMap(); m2 = new TreeMap(); m1.put(new Object(), \"val1\"); m2.put(new Object(), \"val1\"); assertFalse(\"Maps should not be equal 5\", m1.equals(m2)); assertFalse(\"Maps should not be equal 6\", m2.equals(m1)); } ",
        "test_tgt": "@TestTargetNew(level = TestLevel.COMPLETE, notes = \"\", method = \"equals\", args = { java.lang.Object.class })public void test_equals()throws Exception { Map m1 = new TreeMap(); Map m2 = new TreeMap(); m1.put(\"key1\", \"val1\"); m1.put(\"key2\", \"val2\"); m2.put(new Integer(1), \"val1\"); m2.put(new Integer(2), \"val2\"); assertFalse(\"Maps should not be equal 1\", m1.equals(m2)); assertFalse(\"Maps should not be equal 2\", m2.equals(m1)); m1 = new TreeMap(); m2 = new HashMap(); m1.put(\"key\", \"val\"); m2.put(new Object(), \"val\"); assertFalse(\"Maps should not be equal 3\", m1.equals(m2)); assertFalse(\"Maps should not be equal 4\", m2.equals(m1)); m1 = new TreeMap(); m2 = new TreeMap(); m1.put(new Object(), \"val1\"); m2.put(new Object(), \"val1\"); assertFalse(\"Maps should not be equal 5\", m1.equals(m2)); assertFalse(\"Maps should not be equal 6\", m2.equals(m1)); } ",
        "focal_src": "@Override public boolean equals(Object object) { if(this == object) { return true; } if(object instanceof Map) { Map < ? , ? > map = (Map < ? , ? > )object; if(size() != map.size()) { return false; } Iterator < Map.Entry < K, V > > it = entrySet().iterator(); while(it.hasNext()) { Entry < K, V > entry = it.next(); K key = entry.getKey(); V value = entry.getValue(); Object obj = map.get(key); if(null != obj && ( ! obj.equals(value)) || null == obj && obj != value) { return false; } } return true; } return false; } ",
        "focal_tgt": "@Override public boolean equals(Object object) { if(this == object) { return true; } if(object instanceof Map) { Map < ? , ? > map = (Map < ? , ? > )object; if(size() != map.size()) { return false; } Iterator < Map.Entry < K, V > > it = entrySet().iterator(); try { while(it.hasNext()) { Entry < K, V > entry = it.next(); K key = entry.getKey(); V value = entry.getValue(); Object obj = map.get(key); if(null != obj && ( ! obj.equals(value)) || null == obj && obj != value) { return false; } } } catch(ClassCastException cce) { return false; } return true; } return false; } "
    },
    {
        "test_src": "@Test public void testParseQuery()throws Exception { String searchString = \"product:(resteasy) AND vendor:(red hat)\"; String expResult = \"+product:resteasy +(vendor:red vendor:redhat vendor:hat)\"; Query result = instance.parseQuery(searchString); assertEquals(expResult, result.toString()); instance.close(); } ",
        "test_tgt": "@Test public void testParseQuery()throws Exception { String searchString = \"product:(resteasy) AND vendor:(red hat)\"; String expResult = \"+product:resteasy +(vendor:red vendor:redhat vendor:hat)\"; Query result = instance.parseQuery(searchString); assertEquals(expResult, result.toString()); instance.resetAnalyzers(); searchString = \"product:(struts2\\\\-core^2 struts^3 core) AND vendor:(apache.struts apache^3 foundation)\"; expResult = \"+((product:struts product:strutsstruts2 product:struts2 product:struts2core product:core)^2.0 (product:corestruts product:struts)^3.0 (product:strutscore product:core)) +((vendor:apache vendor:apachestruts vendor:struts) (vendor:strutsapache vendor:apache)^3.0)\"; result = instance.parseQuery(searchString); assertEquals(expResult, result.toString()); instance.close(); } ",
        "focal_src": "protected Query parseQuery(String searchString)throws ParseException { if(searchString == null || searchString.trim().isEmpty()) { throw new ParseException(\"Query is null or empty\"); } LOGGER.debug(searchString); final Query query = queryParser.parse(searchString); return query; } ",
        "focal_tgt": "public synchronized Query parseQuery(String searchString)throws ParseException, IndexException { if(searchString == null || searchString.trim().isEmpty()) { throw new ParseException(\"Query is null or empty\"); } LOGGER.debug(searchString); final Query query = queryParser.parse(searchString); try { resetAnalyzers(); } catch(IOException ex) { throw new IndexException(\"Unable to reset the analyzer after parsing\", ex); } return query; } "
    },
    {
        "test_src": "@Test public void findSegment() { System.out.println(\"findSegment\"); System.out.println(\"before: \" + instance.getSequenceString()); Point point = new Point(11, 3); instance.setStickyDistance(2); assertEquals(p1, instance.findSegment(point)); instance.setStickyDistance(0); assertEquals(null, instance.findSegment(point)); instance = new BrokenLine(); instance.setStickyDistance(2); assertEquals(null, instance.findSegment(point)); instance.addPoint(p1); assertEquals(null, instance.findSegment(point)); instance.addPoint(p2); assertEquals(p1, instance.findSegment(point)); } ",
        "test_tgt": "@Test public void findSegment() { System.out.println(\"findSegment\"); System.out.println(\"before: \" + instance.getSequenceString()); Point point = new Point(11, 3); assertEquals(p1, instance.findSegment(point)); instance = new BrokenLine(); assertEquals(null, instance.findSegment(point)); instance.addPoint(p1); assertEquals(null, instance.findSegment(point)); instance.addPoint(p2); assertEquals(p1, instance.findSegment(point)); } ",
        "focal_src": "public Point findSegment(Point point) { Point bestPoint = null; double bestDistSq = java.lang.Double.MAX_VALUE; if(points.size() < 2) { return null; } Point prevPt = points.get(0); for(Point pt : points) { if(pt == prevPt) { continue; } Line2D.Double line = new Line2D.Double(prevPt, pt); double distSq = line.ptSegDistSq(point); if(distSq < bestDistSq) { bestPoint = prevPt; bestDistSq = distSq; } prevPt = pt; } if(bestDistSq <= (stickyDistance * stickyDistance)) { return bestPoint; } else { return null; } } ",
        "focal_tgt": "public Point findSegment(Point point) { final int sqrStickyDistance = getStickyDistance() * getStickyDistance(); Point bestPoint = null; double bestDistSq = java.lang.Double.MAX_VALUE; if(points.size() < 2) { return null; } Point prevPt = points.get(0); for(Point pt : points) { if(pt == prevPt) { continue; } Line2D.Double line = new Line2D.Double(prevPt, pt); double distSq = line.ptSegDistSq(point); if(distSq < bestDistSq) { bestPoint = prevPt; bestDistSq = distSq; } prevPt = pt; } if(bestDistSq <= sqrStickyDistance) { return bestPoint; } else { return null; } } "
    },
    {
        "test_src": "@Test public void testFit() { Map < Integer, double[] > data = new HashMap < > (); data.put(1, new double[] { 2, 4, 1 }); data.put(2, new double[] { 1, 8, 22 }); data.put(3, new double[] { 4, 10, 100 }); data.put(4, new double[] { 0, 22, 300 }); DatasetBuilder < Integer, double[] > datasetBuilder = new LocalDatasetBuilder < > (data, parts); NormalizationTrainer < Integer, double[] > standardizationTrainer = new NormalizationTrainer < > (); NormalizationPreprocessor < Integer, double[] > preprocessor = standardizationTrainer.fit(datasetBuilder, (k, v) -> v); assertArrayEquals(new double[] { 0, 4, 1 }, preprocessor.getMin(), 1e-8); assertArrayEquals(new double[] { 4, 22, 300 }, preprocessor.getMax(), 1e-8); } ",
        "test_tgt": "@Test public void testFit() { Map < Integer, double[] > data = new HashMap < > (); data.put(1, new double[] { 2, 4, 1 }); data.put(2, new double[] { 1, 8, 22 }); data.put(3, new double[] { 4, 10, 100 }); data.put(4, new double[] { 0, 22, 300 }); DatasetBuilder < Integer, double[] > datasetBuilder = new LocalDatasetBuilder < > (data, parts); NormalizationTrainer < Integer, double[] > normalizationTrainer = new NormalizationTrainer < Integer, double[] > ().withP(3); NormalizationPreprocessor < Integer, double[] > preprocessor = normalizationTrainer.fit(datasetBuilder, (k, v) -> v); assertArrayEquals(new double[] { 0.125, 0.99, 0.125 }, preprocessor.apply(5, new double[] { 1, 8, 1 }), 1e-2); } ",
        "focal_src": "@Override public NormalizationPreprocessor < K, V > fit(DatasetBuilder < K, V > datasetBuilder, IgniteBiFunction < K, V, double[] > basePreprocessor) { try(Dataset < EmptyContext, NormalizationPartitionData > dataset = datasetBuilder.build((upstream, upstreamSize) -> new EmptyContext(), (upstream, upstreamSize, ctx) -> { double[]min = null; double[]max = null; while(upstream.hasNext()) { UpstreamEntry < K, V > entity = upstream.next(); double[]row = basePreprocessor.apply(entity.getKey(), entity.getValue()); if(min == null) { min = new double[row.length]; for(int i = 0; i < min.length; i ++ )min[i] = Double.MAX_VALUE; } else assert min.length == row.length : \"Base preprocessor must return exactly \" + min.length + \" features\"; if(max == null) { max = new double[row.length]; for(int i = 0; i < max.length; i ++ )max[i] = - Double.MAX_VALUE; } else assert max.length == row.length : \"Base preprocessor must return exactly \" + min.length + \" features\"; for(int i = 0; i < row.length; i ++ ) { if(row[i] < min[i])min[i] = row[i]; if(row[i] > max[i])max[i] = row[i]; } } return new NormalizationPartitionData(min, max); })) { double[][]minMax = dataset.compute(data -> data.getMin() != null ? new double[][] { data.getMin(), data.getMax() } : null, (a, b) -> { if(a == null)return b; if(b == null)return a; double[][]res = new double[2][]; res[0] = new double[a[0].length]; for(int i = 0; i < res[0].length; i ++ )res[0][i] = Math.min(a[0][i], b[0][i]); res[1] = new double[a[1].length]; for(int i = 0; i < res[1].length; i ++ )res[1][i] = Math.max(a[1][i], b[1][i]); return res; }); return new NormalizationPreprocessor < > (minMax[0], minMax[1], basePreprocessor); } catch(Exception e) { throw new RuntimeException(e); } } ",
        "focal_tgt": "@Override public NormalizationPreprocessor < K, V > fit(DatasetBuilder < K, V > datasetBuilder, IgniteBiFunction < K, V, double[] > basePreprocessor) { return new NormalizationPreprocessor < > (p, basePreprocessor); } "
    },
    {
        "test_src": "@Test public void noProxySelected() { when(proxySelector.select(argThat(u -> u.getHost().equals(HOSTNAME)))).thenReturn(Collections.singletonList(PROXY)); final WebSocketsProxyConnectionHandler handler = new WebSocketsProxyConnectionHandler(CONNECTION_ID, HOSTNAME, PROXY_CONFIGURATION); Assert.assertEquals(PROXY_ADDRESS.getHostName(), handler.getHostname()); Assert.assertEquals(PROXY_ADDRESS.getPort(), handler.getProtocolPort()); } ",
        "test_tgt": "@Test public void noProxySelected() { when(proxySelector.select(argThat(u -> u.getHost().equals(HOSTNAME)))).thenReturn(Collections.singletonList(PROXY)); final WebSocketsProxyConnectionHandler handler = new WebSocketsProxyConnectionHandler(CONNECTION_ID, HOSTNAME, PROXY_CONFIGURATION); Assertions.assertEquals(PROXY_ADDRESS.getHostName(), handler.getHostname()); Assertions.assertEquals(PROXY_ADDRESS.getPort(), handler.getProtocolPort()); } ",
        "focal_src": "@Theory public void noProxySelected(@FromDataPoints(\"configurations\")ProxyConfiguration configuration) { final String hostname = \"foo.eventhubs.azure.com\"; when(proxySelector.select(argThat(u -> u.getHost().equals(hostname)))).thenReturn(Collections.singletonList(PROXY)); final ConnectionHandler handler = provider.createConnectionHandler(CONNECTION_ID, hostname, TransportType.AMQP_WEB_SOCKETS, configuration); Assert.assertEquals(PROXY_ADDRESS.getHostName(), handler.getHostname()); Assert.assertEquals(PROXY_ADDRESS.getPort(), handler.getProtocolPort()); } ",
        "focal_tgt": "@ParameterizedTest@MethodSource(\"getProxyConfigurations\")public void noProxySelected(ProxyConfiguration configuration) { final String hostname = \"foo.eventhubs.azure.com\"; when(proxySelector.select(argThat(u -> u.getHost().equals(hostname)))).thenReturn(Collections.singletonList(PROXY)); final ConnectionHandler handler = provider.createConnectionHandler(CONNECTION_ID, hostname, TransportType.AMQP_WEB_SOCKETS, configuration); Assertions.assertEquals(PROXY_ADDRESS.getHostName(), handler.getHostname()); Assertions.assertEquals(PROXY_ADDRESS.getPort(), handler.getProtocolPort()); } "
    },
    {
        "test_src": "@Test public void testAdd() { BytesRef ref = new BytesRef(); BytesRef scratch = new BytesRef(); int num = atLeast(2); for(int j = 0; j < num; j ++ ) { Set < String > strings = new HashSet < String > (); int uniqueCount = 0; for(int i = 0; i < 797; i ++ ) { String str; do { str = _TestUtil.randomRealisticUnicodeString(random, 1000); } while(str.length() == 0); ref.copy(str); int count = hash.size(); int key = hash.add(ref); if(key >= 0) { assertTrue(strings.add(str)); assertEquals(uniqueCount, key); assertEquals(hash.size(), count + 1); uniqueCount ++ ; } else { assertFalse(strings.add(str)); assertTrue(( - key) - 1 < count); assertEquals(str, hash.get(( - key) - 1, scratch).utf8ToString()); assertEquals(count, hash.size()); } } assertAllIn(strings, hash); hash.clear(); assertEquals(0, hash.size()); hash.reinit(); } } ",
        "test_tgt": "@Test public void testAdd() { BytesRef ref = new BytesRef(); BytesRef scratch = new BytesRef(); int num = atLeast(2); for(int j = 0; j < num; j ++ ) { Set < String > strings = new HashSet < String > (); int uniqueCount = 0; for(int i = 0; i < 797; i ++ ) { String str; do { str = _TestUtil.randomRealisticUnicodeString(random, 1000); } while(str.length() == 0); ref.copyChars(str); int count = hash.size(); int key = hash.add(ref); if(key >= 0) { assertTrue(strings.add(str)); assertEquals(uniqueCount, key); assertEquals(hash.size(), count + 1); uniqueCount ++ ; } else { assertFalse(strings.add(str)); assertTrue(( - key) - 1 < count); assertEquals(str, hash.get(( - key) - 1, scratch).utf8ToString()); assertEquals(count, hash.size()); } } assertAllIn(strings, hash); hash.clear(); assertEquals(0, hash.size()); hash.reinit(); } } ",
        "focal_src": "private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) { if(numInputWords <= 0) { throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\"); } if(input.length <= 0) { throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\"); } if(numOutputWords <= 0) { throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\"); } if(output.length <= 0) { throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\"); } assert ! hasHoles(input) : \"input has holes: \" + input; assert ! hasHoles(output) : \"output has holes: \" + output; final int hashCode = UnicodeUtil.UTF16toUTF8WithHash(output.chars, output.offset, output.length, utf8Scratch); int ord = words.add(utf8Scratch, hashCode); if(ord < 0) { ord = ( - ord) - 1; } else { } MapEntry e = workingSet.get(input); if(e == null) { e = new MapEntry(); workingSet.put(new CharsRef(input), e); } e.ords.add(ord); e.includeOrig |= includeOrig; maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords); maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords); } ",
        "focal_tgt": "private void add(CharsRef input, int numInputWords, CharsRef output, int numOutputWords, boolean includeOrig) { if(numInputWords <= 0) { throw new IllegalArgumentException(\"numInputWords must be > 0 (got \" + numInputWords + \")\"); } if(input.length <= 0) { throw new IllegalArgumentException(\"input.length must be > 0 (got \" + input.length + \")\"); } if(numOutputWords <= 0) { throw new IllegalArgumentException(\"numOutputWords must be > 0 (got \" + numOutputWords + \")\"); } if(output.length <= 0) { throw new IllegalArgumentException(\"output.length must be > 0 (got \" + output.length + \")\"); } assert ! hasHoles(input) : \"input has holes: \" + input; assert ! hasHoles(output) : \"output has holes: \" + output; final int hashCode = UnicodeUtil.UTF16toUTF8WithHash(output.chars, output.offset, output.length, utf8Scratch); int ord = words.add(utf8Scratch, hashCode); if(ord < 0) { ord = ( - ord) - 1; } else { } MapEntry e = workingSet.get(input); if(e == null) { e = new MapEntry(); workingSet.put(CharsRef.deepCopyOf(input), e); } e.ords.add(ord); e.includeOrig |= includeOrig; maxHorizontalContext = Math.max(maxHorizontalContext, numInputWords); maxHorizontalContext = Math.max(maxHorizontalContext, numOutputWords); } "
    },
    {
        "test_src": "@Test public void testInitialize() { @Cleanup TestContext context = new TestContext(DEFAULT_CONFIG); context.transactionAggregators[0].initialize(TIMEOUT).join(); Assert.assertTrue(\"isDeleted() flag not set on metadata for deleted segment.\", context.transactionAggregators[0].getMetadata().isDeleted()); context.storage.create(context.transactionAggregators[1].getMetadata().getName(), TIMEOUT).join(); context.storage.seal(context.transactionAggregators[1].getMetadata().getName(), TIMEOUT).join(); AssertExtensions.assertThrows(\"initialize() succeeded on a Segment is sealed in Storage but not in the metadata.\", () -> context.transactionAggregators[1].initialize(TIMEOUT), ex -> ex instanceof DataCorruptionException); context.storage.create(context.transactionAggregators[2].getMetadata().getName(), TIMEOUT).join(); context.storage.seal(context.transactionAggregators[2].getMetadata().getName(), TIMEOUT).join(); ((UpdateableSegmentMetadata)context.transactionAggregators[2].getMetadata()).markSealed(); context.transactionAggregators[2].initialize(TIMEOUT).join(); Assert.assertTrue(\"isSealedInStorage() flag not set on metadata for storage-sealed segment.\", context.transactionAggregators[2].getMetadata().isSealedInStorage()); final int writeLength = 10; context.storage.create(context.segmentAggregator.getMetadata().getName(), TIMEOUT).join(); context.storage.write(context.segmentAggregator.getMetadata().getName(), 0, new ByteArrayInputStream(new byte[writeLength]), writeLength, TIMEOUT).join(); context.segmentAggregator.initialize(TIMEOUT).join(); Assert.assertEquals(\"SegmentMetadata.StorageLength was not updated after call to initialize().\", writeLength, context.segmentAggregator.getMetadata().getStorageLength()); } ",
        "test_tgt": "@Test public void testInitialize() { @Cleanup TestContext context = new TestContext(DEFAULT_CONFIG); context.transactionAggregators[0].initialize(TIMEOUT, executorService()).join(); Assert.assertTrue(\"isDeleted() flag not set on metadata for deleted segment.\", context.transactionAggregators[0].getMetadata().isDeleted()); context.storage.create(context.transactionAggregators[1].getMetadata().getName(), TIMEOUT).join(); context.storage.seal(writeHandle(context.transactionAggregators[1].getMetadata().getName()), TIMEOUT).join(); AssertExtensions.assertThrows(\"initialize() succeeded on a Segment is sealed in Storage but not in the metadata.\", () -> context.transactionAggregators[1].initialize(TIMEOUT, executorService()), ex -> ex instanceof DataCorruptionException); context.storage.create(context.transactionAggregators[2].getMetadata().getName(), TIMEOUT).join(); context.storage.seal(writeHandle(context.transactionAggregators[2].getMetadata().getName()), TIMEOUT).join(); ((UpdateableSegmentMetadata)context.transactionAggregators[2].getMetadata()).markSealed(); context.transactionAggregators[2].initialize(TIMEOUT, executorService()).join(); Assert.assertTrue(\"isSealedInStorage() flag not set on metadata for storage-sealed segment.\", context.transactionAggregators[2].getMetadata().isSealedInStorage()); final int writeLength = 10; context.storage.create(context.segmentAggregator.getMetadata().getName(), TIMEOUT).join(); context.storage.write(writeHandle(context.segmentAggregator.getMetadata().getName()), 0, new ByteArrayInputStream(new byte[writeLength]), writeLength, TIMEOUT).join(); context.segmentAggregator.initialize(TIMEOUT, executorService()).join(); Assert.assertEquals(\"SegmentMetadata.StorageLength was not updated after call to initialize().\", writeLength, context.segmentAggregator.getMetadata().getStorageLength()); } ",
        "focal_src": "public void initialize()throws IOException { Preconditions.checkState(this.fileSystem == null, \"HDFSStorage has already been initialized.\"); Exceptions.checkNotClosed(this.closed.get(), this); Configuration conf = new Configuration(); conf.set(\"fs.default.name\", config.getHdfsHostURL()); conf.set(\"fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\"); this.fileSystem = FileSystem.get(conf); log.info(\"{}: Initialized.\", LOG_ID); } ",
        "focal_tgt": "@Override@SneakyThrows(IOException.class)public void initialize(long epoch) { Preconditions.checkState(this.fileSystem == null, \"HDFSStorage has already been initialized.\"); Exceptions.checkNotClosed(this.closed.get(), this); Configuration conf = new Configuration(); conf.set(\"fs.default.name\", config.getHdfsHostURL()); conf.set(\"fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\"); this.fileSystem = FileSystem.get(conf); log.info(\"{}: Initialized.\", LOG_ID); } "
    },
    {
        "test_src": "@Test public void removeFromRealm_removedFromResults() { realm.beginTransaction(); realm.clear(Dog.class); Dog dogToAdd = realm.createObject(Dog.class); dogToAdd.setName(\"Rex\"); realm.commitTransaction(); assertEquals(1, realm.allObjects(Dog.class).size()); Dog dogToRemove = realm.where(Dog.class).findFirst(); assertNotNull(dogToRemove); realm.beginTransaction(); dogToRemove.removeFromRealm(); realm.commitTransaction(); assertEquals(0, realm.allObjects(Dog.class).size()); try { dogToAdd.getName(); realm.close(); fail(); } catch(IllegalStateException ignored) { } try { dogToRemove.getName(); realm.close(); fail(); } catch(IllegalStateException ignored) { } realm.close(); } ",
        "test_tgt": "@Test public void deleteFromRealm_removedFromResults() { realm.beginTransaction(); realm.delete(Dog.class); Dog dogToAdd = realm.createObject(Dog.class); dogToAdd.setName(\"Rex\"); realm.commitTransaction(); assertEquals(1, realm.allObjects(Dog.class).size()); Dog dogToRemove = realm.where(Dog.class).findFirst(); assertNotNull(dogToRemove); realm.beginTransaction(); dogToRemove.deleteFromRealm(); realm.commitTransaction(); assertEquals(0, realm.allObjects(Dog.class).size()); try { dogToAdd.getName(); realm.close(); fail(); } catch(IllegalStateException ignored) { } try { dogToRemove.getName(); realm.close(); fail(); } catch(IllegalStateException ignored) { } realm.close(); } ",
        "focal_src": "public void removeFromRealm() { if(row == null) { throw new IllegalStateException(\"Object malformed: missing object in Realm. Make sure to instantiate RealmObjects with Realm.createObject()\"); } if(realm == null) { throw new IllegalStateException(\"Object malformed: missing Realm. Make sure to instantiate RealmObjects with Realm.createObject()\"); } realm.checkIfValid(); row.getTable().moveLastOver(row.getIndex()); row = InvalidRow.INSTANCE; } ",
        "focal_tgt": "@Deprecated public void removeFromRealm() { deleteFromRealm(); } "
    },
    {
        "test_src": "@Test void testEnsureCapacity() { GroupByResultHolder resultHolder = new DoubleGroupByResultHolder(INITIAL_CAPACITY, MAX_CAPACITY, MAX_CAPACITY, DEFAULT_VALUE); for(int i = 0; i < INITIAL_CAPACITY; i ++ ) { resultHolder.setValueForKey(i, _expected[i]); } resultHolder.ensureCapacity(MAX_CAPACITY); for(int i = INITIAL_CAPACITY; i < MAX_CAPACITY; i ++ ) { double actual = resultHolder.getDoubleResult(i); Assert.assertEquals(actual, DEFAULT_VALUE, \"Default Value mis-match: Actual: \" + actual + \" Expected: \" + DEFAULT_VALUE + \" Random seed: \" + RANDOM_SEED); resultHolder.setValueForKey(i, _expected[i]); } testValues(resultHolder, _expected, 0, MAX_CAPACITY); } ",
        "test_tgt": "@Test void testEnsureCapacity() { GroupByResultHolder resultHolder = new DoubleGroupByResultHolder(INITIAL_CAPACITY, MAX_CAPACITY, DEFAULT_VALUE); for(int i = 0; i < INITIAL_CAPACITY; i ++ ) { resultHolder.setValueForKey(i, _expected[i]); } resultHolder.ensureCapacity(MAX_CAPACITY); for(int i = INITIAL_CAPACITY; i < MAX_CAPACITY; i ++ ) { double actual = resultHolder.getDoubleResult(i); Assert.assertEquals(actual, DEFAULT_VALUE, \"Default Value mis-match: Actual: \" + actual + \" Expected: \" + DEFAULT_VALUE + \" Random seed: \" + RANDOM_SEED); resultHolder.setValueForKey(i, _expected[i]); } testValues(resultHolder, _expected, 0, MAX_CAPACITY); } ",
        "focal_src": "@Override public void ensureCapacity(int capacity) { Preconditions.checkArgument(capacity <= _maxCapacity); if(_storageMode == StorageMode.MAP_STORAGE) { return; } if(capacity > _trimSize) { switchToMapMode(capacity); return; } if(capacity > _resultHolderCapacity) { int copyLength = _resultHolderCapacity; _resultHolderCapacity = Math.max(_resultHolderCapacity * 2, capacity); _resultHolderCapacity = Math.min(_resultHolderCapacity, _maxCapacity); double[]current = _resultArray; _resultArray = new double[_resultHolderCapacity]; System.arraycopy(current, 0, _resultArray, 0, copyLength); if(_defaultValue != 0.0) { Arrays.fill(_resultArray, copyLength, _resultHolderCapacity, _defaultValue); } } } ",
        "focal_tgt": "@Override public void ensureCapacity(int capacity) { Preconditions.checkArgument(capacity <= _maxCapacity); if(capacity > _resultHolderCapacity) { int copyLength = _resultHolderCapacity; _resultHolderCapacity = Math.max(_resultHolderCapacity * 2, capacity); _resultHolderCapacity = Math.min(_resultHolderCapacity, _maxCapacity); double[]current = _resultArray; _resultArray = new double[_resultHolderCapacity]; System.arraycopy(current, 0, _resultArray, 0, copyLength); if(_defaultValue != 0.0) { Arrays.fill(_resultArray, copyLength, _resultHolderCapacity, _defaultValue); } } } "
    },
    {
        "test_src": "@Test public void testEnableGroup() { assertFf4j.assertThatFeatureIsDisabled(F2); testedStore.enableGroup(G0); assertFf4j.assertThatFeatureIsEnabled(F2); testedStore.disable(F2); } ",
        "test_tgt": "@Test public void testEnableGroup() { assertFf4j.assertThatFeatureIsDisabled(F2); assertFf4j.assertThatFeatureIsInGroup(F2, G0); testedStore.enableGroup(G0); assertFf4j.assertThatFeatureIsEnabled(F2); testedStore.disable(F2); } ",
        "focal_src": "@Override public void enableGroup(String groupName) { if( ! existGroup(groupName)) { throw new GroupNotFoundException(groupName); } for(String feat : featureGroups.get(groupName)) { this.enable(feat); } } ",
        "focal_tgt": "@Override public void enableGroup(String groupName) { if(groupName == null || groupName.isEmpty()) { throw new IllegalArgumentException(\"Groupname cannot be null nor empty\"); } if( ! existGroup(groupName)) { throw new GroupNotFoundException(groupName); } for(String feat : featureGroups.get(groupName)) { this.enable(feat); } } "
    },
    {
        "test_src": "@Test public void process() { Se2_F32 initial = new Se2_F32(1, 2, 3); Se2_F32 computed = new Se2_F32(4, 5, 6); Se2_F32 model = new Se2_F32(); DummyTracker tracker = new DummyTracker(); DummyModelMatcher < Se2_F32 > matcher = new DummyModelMatcher < Se2_F32 > (computed, 5); ImageUInt8 input = new ImageUInt8(20, 30); ImageMotionPointKey < ImageUInt8, Se2_F32 > alg = new ImageMotionPointKey < ImageUInt8, Se2_F32 > (tracker, matcher, model); alg.setInitialTransform(initial); assertTrue(alg.process(input)); Se2_F32 found = alg.getWorldToCurr(); assertEquals(initial.getX(), found.getX(), 1e-8); assertEquals(1, tracker.numSpawn); assertTrue(alg.process(input)); assertEquals(1, tracker.numSpawn); Se2_F32 keyToCurr = alg.getKeyToCurr(); assertEquals(computed.getX(), keyToCurr.getX(), 1e-8); Se2_F32 worldToCurr = initial.concat(keyToCurr, null); found = alg.getWorldToCurr(); assertEquals(worldToCurr.getX(), found.getX(), 1e-8); } ",
        "test_tgt": "@Test public void process() { Se2_F32 initial = new Se2_F32(1, 2, 3); Se2_F32 computed = new Se2_F32(4, 5, 6); Se2_F32 model = new Se2_F32(); DummyTracker tracker = new DummyTracker(); DummyModelMatcher < Se2_F32 > matcher = new DummyModelMatcher < Se2_F32 > (computed, 5); ImageUInt8 input = new ImageUInt8(20, 30); ImageMotionPointKey < ImageUInt8, Se2_F32 > alg = new ImageMotionPointKey < ImageUInt8, Se2_F32 > (tracker, matcher, null, model); alg.setInitialTransform(initial); assertTrue(alg.process(input)); Se2_F32 found = alg.getWorldToCurr(); assertEquals(initial.getX(), found.getX(), 1e-8); assertEquals(1, tracker.numSpawn); assertTrue(alg.process(input)); assertEquals(1, tracker.numSpawn); Se2_F32 keyToCurr = alg.getKeyToCurr(); assertEquals(computed.getX(), keyToCurr.getX(), 1e-8); Se2_F32 worldToCurr = initial.concat(keyToCurr, null); found = alg.getWorldToCurr(); assertEquals(worldToCurr.getX(), found.getX(), 1e-8); } ",
        "focal_src": "public boolean process(I frame) { tracker.process(frame); totalProcessed ++ ; if(totalProcessed == 1) { tracker.spawnTracks(); worldToKey.set(worldToInit); worldToCurr.set(worldToInit); return true; } List < AssociatedPair > pairs = tracker.getActiveTracks(); if( ! modelMatcher.process(pairs, null)) { return false; } keyToCurr.set(modelMatcher.getModel()); worldToKey.concat(keyToCurr, worldToCurr); return true; } ",
        "focal_tgt": "public boolean process(I frame) { tracker.process(frame); totalProcessed ++ ; if(totalProcessed == 1) { tracker.spawnTracks(); worldToKey.set(worldToInit); worldToCurr.set(worldToInit); return true; } List < AssociatedPair > pairs = tracker.getActiveTracks(); if( ! modelMatcher.process(pairs, null)) { return false; } if(modelRefiner == null || ! modelRefiner.fitModel(modelMatcher.getMatchSet(), modelMatcher.getModel(), keyToCurr)) { keyToCurr.set(modelMatcher.getModel()); } worldToKey.concat(keyToCurr, worldToCurr); return true; } "
    },
    {
        "test_src": "@Test public void testUpdateStreamState()throws Exception { final String resourceURI = getURI() + \"v1/scopes/scope1/streams/stream1/state\"; when(mockControllerService.sealStream(\"scope1\", \"stream1\")).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.SUCCESS).build())); StreamState streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); Response response = client.target(resourceURI).request().buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 200, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.SCOPE_NOT_FOUND).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = client.target(resourceURI).request().buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 404, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.STREAM_NOT_FOUND).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = client.target(resourceURI).request().buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 404, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.FAILURE).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = client.target(resourceURI).request().buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 500, response.getStatus()); response.close(); } ",
        "test_tgt": "@Test public void testUpdateStreamState()throws Exception { final String resourceURI = getURI() + \"v1/scopes/scope1/streams/stream1/state\"; when(mockControllerService.sealStream(\"scope1\", \"stream1\")).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.SUCCESS).build())); StreamState streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); Response response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 200, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.SCOPE_NOT_FOUND).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 404, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.STREAM_NOT_FOUND).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 404, response.getStatus()); response.close(); when(mockControllerService.sealStream(scope1, stream1)).thenReturn(CompletableFuture.completedFuture(UpdateStreamStatus.newBuilder().setStatus(UpdateStreamStatus.Status.FAILURE).build())); streamState = new StreamState().streamState(StreamState.StreamStateEnum.SEALED); response = addAuthHeaders(client.target(resourceURI).request()).buildPut(Entity.json(streamState)).invoke(); assertEquals(\"Update Stream State response code\", 500, response.getStatus()); response.close(); } ",
        "focal_src": "@Override public void updateStreamState(final String scopeName, final String streamName, final StreamState updateStreamStateRequest, SecurityContext securityContext, AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"updateStreamState\"); if(updateStreamStateRequest.getStreamState() != StreamState.StreamStateEnum.SEALED) { log.warn(\"Received invalid stream state: {} from client for stream {}/{}\", updateStreamStateRequest.getStreamState(), scopeName, streamName); asyncResponse.resume(Response.status(Status.BAD_REQUEST).build()); return; } controllerService.sealStream(scopeName, streamName).thenApply(updateStreamStatus -> { if(updateStreamStatus.getStatus() == UpdateStreamStatus.Status.SUCCESS) { log.info(\"Successfully sealed stream: {}\", streamName); return Response.status(Status.OK).entity(updateStreamStateRequest).build(); } else if(updateStreamStatus.getStatus() == UpdateStreamStatus.Status.SCOPE_NOT_FOUND || updateStreamStatus.getStatus() == UpdateStreamStatus.Status.STREAM_NOT_FOUND) { log.warn(\"Scope: {} or Stream {} not found\", scopeName, streamName); return Response.status(Status.NOT_FOUND).build(); } else { log.warn(\"updateStreamState for {} failed\", streamName); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); } }).exceptionally(exception -> { log.warn(\"updateStreamState for {} failed with exception: {}\", streamName, exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"updateStreamState\", traceId)); } ",
        "focal_tgt": "@Override public void updateStreamState(final String scopeName, final String streamName, final StreamState updateStreamStateRequest, SecurityContext securityContext, AsyncResponse asyncResponse) { long traceId = LoggerHelpers.traceEnter(log, \"updateStreamState\"); try { authenticate(scopeName + \"/\" + streamName, READ_UPDATE); } catch(AuthenticationException e) { log.warn(\"Update stream for {} failed due to authentication failure.\", scopeName + \"/\" + streamName); asyncResponse.resume(Response.status(Status.UNAUTHORIZED).build()); LoggerHelpers.traceLeave(log, \"Update stream\", traceId); return; } if(updateStreamStateRequest.getStreamState() != StreamState.StreamStateEnum.SEALED) { log.warn(\"Received invalid stream state: {} from client for stream {}/{}\", updateStreamStateRequest.getStreamState(), scopeName, streamName); asyncResponse.resume(Response.status(Status.BAD_REQUEST).build()); return; } controllerService.sealStream(scopeName, streamName).thenApply(updateStreamStatus -> { if(updateStreamStatus.getStatus() == UpdateStreamStatus.Status.SUCCESS) { log.info(\"Successfully sealed stream: {}\", streamName); return Response.status(Status.OK).entity(updateStreamStateRequest).build(); } else if(updateStreamStatus.getStatus() == UpdateStreamStatus.Status.SCOPE_NOT_FOUND || updateStreamStatus.getStatus() == UpdateStreamStatus.Status.STREAM_NOT_FOUND) { log.warn(\"Scope: {} or Stream {} not found\", scopeName, streamName); return Response.status(Status.NOT_FOUND).build(); } else { log.warn(\"updateStreamState for {} failed\", streamName); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); } }).exceptionally(exception -> { log.warn(\"updateStreamState for {} failed with exception: {}\", streamName, exception); return Response.status(Status.INTERNAL_SERVER_ERROR).build(); }).thenApply(asyncResponse :: resume).thenAccept(x -> LoggerHelpers.traceLeave(log, \"updateStreamState\", traceId)); } "
    }
]